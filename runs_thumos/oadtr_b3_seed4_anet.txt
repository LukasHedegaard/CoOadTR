Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet
dim_feature:3072
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:4
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  74.578 M, 99.825% Params, 2.446 GMac, 100.000% MACs, 
  (linear_encoding): Linear(3.147 M, 4.212% Params, 0.201 GMac, 8.231% MACs, in_features=3072, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 25.276% Params, 1.227 GMac, 50.169% MACs, 
    (net): Sequential(
      18.884 M, 25.276% Params, 1.227 GMac, 50.169% MACs, 
      (0): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.060% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 70.246% Params, 1.017 GMac, 41.591% MACs, 
    (layers): ModuleList(
      52.48 M, 70.246% Params, 1.017 GMac, 41.591% MACs, 
      (0): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.030% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2445837356.0
Model params: 74709036
Loaded data/thumos_anet_val.pickle
Loaded data/thumos_anet_test.pickle
Start training
Epoch: [1]  [   0/1404]  eta: 0:48:03  lr: 0.000100  loss: 4.7189 (4.7189)  labels_encoder: 3.0721 (3.0721)  labels_decoder: 1.6469 (1.6469)  labels_encoder_unscaled: 3.0721 (3.0721)  labels_decoder_unscaled: 3.2938 (3.2938)  time: 2.0537  data: 1.5053  max mem: 2528
Epoch: [1]  [  50/1404]  eta: 0:03:59  lr: 0.000100  loss: 1.1364 (1.6233)  labels_encoder: 0.7315 (1.0523)  labels_decoder: 0.3961 (0.5710)  labels_encoder_unscaled: 0.7315 (1.0523)  labels_decoder_unscaled: 0.7922 (1.1421)  time: 0.1280  data: 0.0002  max mem: 3384
Epoch: [1]  [ 100/1404]  eta: 0:03:23  lr: 0.000100  loss: 0.8140 (1.2508)  labels_encoder: 0.5134 (0.8023)  labels_decoder: 0.3006 (0.4485)  labels_encoder_unscaled: 0.5134 (0.8023)  labels_decoder_unscaled: 0.6012 (0.8970)  time: 0.1336  data: 0.0002  max mem: 3384
Epoch: [1]  [ 150/1404]  eta: 0:03:06  lr: 0.000100  loss: 0.7261 (1.0900)  labels_encoder: 0.4538 (0.6954)  labels_decoder: 0.2709 (0.3947)  labels_encoder_unscaled: 0.4538 (0.6954)  labels_decoder_unscaled: 0.5418 (0.7893)  time: 0.1316  data: 0.0003  max mem: 3384
Epoch: [1]  [ 200/1404]  eta: 0:02:57  lr: 0.000100  loss: 0.6682 (0.9931)  labels_encoder: 0.4127 (0.6288)  labels_decoder: 0.2646 (0.3644)  labels_encoder_unscaled: 0.4127 (0.6288)  labels_decoder_unscaled: 0.5293 (0.7287)  time: 0.1428  data: 0.0003  max mem: 3384
Epoch: [1]  [ 250/1404]  eta: 0:02:46  lr: 0.000100  loss: 0.6935 (0.9309)  labels_encoder: 0.4304 (0.5876)  labels_decoder: 0.2779 (0.3433)  labels_encoder_unscaled: 0.4304 (0.5876)  labels_decoder_unscaled: 0.5558 (0.6866)  time: 0.1338  data: 0.0003  max mem: 3384
Epoch: [1]  [ 300/1404]  eta: 0:02:37  lr: 0.000100  loss: 0.6050 (0.8807)  labels_encoder: 0.3754 (0.5535)  labels_decoder: 0.2561 (0.3272)  labels_encoder_unscaled: 0.3754 (0.5535)  labels_decoder_unscaled: 0.5121 (0.6543)  time: 0.1306  data: 0.0003  max mem: 3384
Epoch: [1]  [ 350/1404]  eta: 0:02:28  lr: 0.000100  loss: 0.5371 (0.8392)  labels_encoder: 0.3389 (0.5254)  labels_decoder: 0.2098 (0.3138)  labels_encoder_unscaled: 0.3389 (0.5254)  labels_decoder_unscaled: 0.4197 (0.6276)  time: 0.1273  data: 0.0003  max mem: 3384
Epoch: [1]  [ 400/1404]  eta: 0:02:20  lr: 0.000100  loss: 0.5505 (0.8027)  labels_encoder: 0.3227 (0.5002)  labels_decoder: 0.2179 (0.3025)  labels_encoder_unscaled: 0.3227 (0.5002)  labels_decoder_unscaled: 0.4357 (0.6050)  time: 0.1353  data: 0.0003  max mem: 3384
Epoch: [1]  [ 450/1404]  eta: 0:02:13  lr: 0.000100  loss: 0.5423 (0.7734)  labels_encoder: 0.3082 (0.4805)  labels_decoder: 0.2054 (0.2928)  labels_encoder_unscaled: 0.3082 (0.4805)  labels_decoder_unscaled: 0.4109 (0.5857)  time: 0.1352  data: 0.0003  max mem: 3384
Epoch: [1]  [ 500/1404]  eta: 0:02:05  lr: 0.000100  loss: 0.4981 (0.7493)  labels_encoder: 0.2815 (0.4643)  labels_decoder: 0.1975 (0.2850)  labels_encoder_unscaled: 0.2815 (0.4643)  labels_decoder_unscaled: 0.3949 (0.5699)  time: 0.1312  data: 0.0003  max mem: 3384
Epoch: [1]  [ 550/1404]  eta: 0:01:57  lr: 0.000100  loss: 0.4888 (0.7281)  labels_encoder: 0.3004 (0.4503)  labels_decoder: 0.2016 (0.2778)  labels_encoder_unscaled: 0.3004 (0.4503)  labels_decoder_unscaled: 0.4031 (0.5555)  time: 0.1314  data: 0.0003  max mem: 3384
Epoch: [1]  [ 600/1404]  eta: 0:01:50  lr: 0.000100  loss: 0.5089 (0.7095)  labels_encoder: 0.3049 (0.4378)  labels_decoder: 0.2035 (0.2717)  labels_encoder_unscaled: 0.3049 (0.4378)  labels_decoder_unscaled: 0.4069 (0.5433)  time: 0.1354  data: 0.0003  max mem: 3384
Epoch: [1]  [ 650/1404]  eta: 0:01:43  lr: 0.000100  loss: 0.5050 (0.6931)  labels_encoder: 0.3039 (0.4270)  labels_decoder: 0.2011 (0.2661)  labels_encoder_unscaled: 0.3039 (0.4270)  labels_decoder_unscaled: 0.4022 (0.5323)  time: 0.1318  data: 0.0003  max mem: 3384
Epoch: [1]  [ 700/1404]  eta: 0:01:36  lr: 0.000100  loss: 0.4706 (0.6795)  labels_encoder: 0.2883 (0.4181)  labels_decoder: 0.1980 (0.2615)  labels_encoder_unscaled: 0.2883 (0.4181)  labels_decoder_unscaled: 0.3959 (0.5229)  time: 0.1317  data: 0.0003  max mem: 3384
Epoch: [1]  [ 750/1404]  eta: 0:01:29  lr: 0.000100  loss: 0.4576 (0.6665)  labels_encoder: 0.2630 (0.4092)  labels_decoder: 0.1879 (0.2573)  labels_encoder_unscaled: 0.2630 (0.4092)  labels_decoder_unscaled: 0.3758 (0.5146)  time: 0.1341  data: 0.0002  max mem: 3384
Epoch: [1]  [ 800/1404]  eta: 0:01:22  lr: 0.000100  loss: 0.4862 (0.6557)  labels_encoder: 0.2814 (0.4019)  labels_decoder: 0.1980 (0.2539)  labels_encoder_unscaled: 0.2814 (0.4019)  labels_decoder_unscaled: 0.3960 (0.5077)  time: 0.1297  data: 0.0002  max mem: 3384
Epoch: [1]  [ 850/1404]  eta: 0:01:15  lr: 0.000100  loss: 0.4168 (0.6441)  labels_encoder: 0.2384 (0.3939)  labels_decoder: 0.1783 (0.2502)  labels_encoder_unscaled: 0.2384 (0.3939)  labels_decoder_unscaled: 0.3566 (0.5003)  time: 0.1360  data: 0.0003  max mem: 3384
Epoch: [1]  [ 900/1404]  eta: 0:01:08  lr: 0.000100  loss: 0.4502 (0.6341)  labels_encoder: 0.2626 (0.3874)  labels_decoder: 0.1722 (0.2467)  labels_encoder_unscaled: 0.2626 (0.3874)  labels_decoder_unscaled: 0.3444 (0.4935)  time: 0.1348  data: 0.0003  max mem: 3384
Epoch: [1]  [ 950/1404]  eta: 0:01:01  lr: 0.000100  loss: 0.4419 (0.6237)  labels_encoder: 0.2761 (0.3803)  labels_decoder: 0.1855 (0.2434)  labels_encoder_unscaled: 0.2761 (0.3803)  labels_decoder_unscaled: 0.3710 (0.4868)  time: 0.1328  data: 0.0003  max mem: 3384
Epoch: [1]  [1000/1404]  eta: 0:00:54  lr: 0.000100  loss: 0.4223 (0.6138)  labels_encoder: 0.2564 (0.3736)  labels_decoder: 0.1862 (0.2402)  labels_encoder_unscaled: 0.2564 (0.3736)  labels_decoder_unscaled: 0.3724 (0.4803)  time: 0.1323  data: 0.0003  max mem: 3384
Epoch: [1]  [1050/1404]  eta: 0:00:48  lr: 0.000100  loss: 0.4247 (0.6050)  labels_encoder: 0.2298 (0.3676)  labels_decoder: 0.1917 (0.2374)  labels_encoder_unscaled: 0.2298 (0.3676)  labels_decoder_unscaled: 0.3834 (0.4747)  time: 0.1336  data: 0.0003  max mem: 3384
Epoch: [1]  [1100/1404]  eta: 0:00:41  lr: 0.000100  loss: 0.3983 (0.5966)  labels_encoder: 0.2219 (0.3618)  labels_decoder: 0.1753 (0.2348)  labels_encoder_unscaled: 0.2219 (0.3618)  labels_decoder_unscaled: 0.3507 (0.4697)  time: 0.1267  data: 0.0003  max mem: 3384
Epoch: [1]  [1150/1404]  eta: 0:00:34  lr: 0.000100  loss: 0.4076 (0.5885)  labels_encoder: 0.2368 (0.3562)  labels_decoder: 0.1772 (0.2323)  labels_encoder_unscaled: 0.2368 (0.3562)  labels_decoder_unscaled: 0.3545 (0.4646)  time: 0.1370  data: 0.0003  max mem: 3384
Epoch: [1]  [1200/1404]  eta: 0:00:27  lr: 0.000100  loss: 0.4194 (0.5810)  labels_encoder: 0.2415 (0.3513)  labels_decoder: 0.1706 (0.2298)  labels_encoder_unscaled: 0.2415 (0.3513)  labels_decoder_unscaled: 0.3411 (0.4595)  time: 0.1372  data: 0.0003  max mem: 3384
Epoch: [1]  [1250/1404]  eta: 0:00:20  lr: 0.000100  loss: 0.4043 (0.5736)  labels_encoder: 0.2327 (0.3462)  labels_decoder: 0.1669 (0.2274)  labels_encoder_unscaled: 0.2327 (0.3462)  labels_decoder_unscaled: 0.3337 (0.4548)  time: 0.1344  data: 0.0003  max mem: 3384
Epoch: [1]  [1300/1404]  eta: 0:00:14  lr: 0.000100  loss: 0.3936 (0.5663)  labels_encoder: 0.2153 (0.3413)  labels_decoder: 0.1665 (0.2250)  labels_encoder_unscaled: 0.2153 (0.3413)  labels_decoder_unscaled: 0.3330 (0.4500)  time: 0.1273  data: 0.0003  max mem: 3384
Epoch: [1]  [1350/1404]  eta: 0:00:07  lr: 0.000100  loss: 0.3817 (0.5598)  labels_encoder: 0.2180 (0.3370)  labels_decoder: 0.1627 (0.2229)  labels_encoder_unscaled: 0.2180 (0.3370)  labels_decoder_unscaled: 0.3254 (0.4457)  time: 0.1335  data: 0.0003  max mem: 3384
Epoch: [1]  [1400/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3665 (0.5535)  labels_encoder: 0.2069 (0.3328)  labels_decoder: 0.1596 (0.2207)  labels_encoder_unscaled: 0.2069 (0.3328)  labels_decoder_unscaled: 0.3192 (0.4414)  time: 0.1291  data: 0.0005  max mem: 3384
Epoch: [1]  [1403/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3665 (0.5532)  labels_encoder: 0.2069 (0.3326)  labels_decoder: 0.1586 (0.2205)  labels_encoder_unscaled: 0.2069 (0.3326)  labels_decoder_unscaled: 0.3172 (0.4411)  time: 0.1282  data: 0.0005  max mem: 3384
Epoch: [1] Total time: 0:03:09 (0.1350 s / it)
Averaged stats: lr: 0.000100  loss: 0.3665 (0.5532)  labels_encoder: 0.2069 (0.3326)  labels_decoder: 0.1586 (0.2205)  labels_encoder_unscaled: 0.2069 (0.3326)  labels_decoder_unscaled: 0.3172 (0.4411)
Test:  [   0/1613]  eta: 0:32:21  loss: 0.4857 (0.4857)  labels_encoder: 0.1983 (0.1983)  labels_decoder: 0.2873 (0.2873)  labels_encoder_unscaled: 0.1983 (0.1983)  labels_decoder_unscaled: 0.5747 (0.5747)  time: 1.2037  data: 1.1159  max mem: 3384
Test:  [  50/1613]  eta: 0:02:20  loss: 0.6463 (1.0149)  labels_encoder: 0.4225 (0.6649)  labels_decoder: 0.2248 (0.3500)  labels_encoder_unscaled: 0.4225 (0.6649)  labels_decoder_unscaled: 0.4497 (0.7000)  time: 0.0647  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:55  loss: 0.1988 (0.8466)  labels_encoder: 0.1298 (0.5515)  labels_decoder: 0.0670 (0.2951)  labels_encoder_unscaled: 0.1298 (0.5515)  labels_decoder_unscaled: 0.1341 (0.5903)  time: 0.0638  data: 0.0012  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:45  loss: 1.0131 (0.8554)  labels_encoder: 0.6587 (0.5626)  labels_decoder: 0.2741 (0.2928)  labels_encoder_unscaled: 0.6587 (0.5626)  labels_decoder_unscaled: 0.5483 (0.5856)  time: 0.0622  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:39  loss: 0.9175 (0.9899)  labels_encoder: 0.5458 (0.6497)  labels_decoder: 0.3599 (0.3402)  labels_encoder_unscaled: 0.5458 (0.6497)  labels_decoder_unscaled: 0.7198 (0.6803)  time: 0.0677  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:33  loss: 0.6524 (0.9975)  labels_encoder: 0.4134 (0.6498)  labels_decoder: 0.2487 (0.3477)  labels_encoder_unscaled: 0.4134 (0.6498)  labels_decoder_unscaled: 0.4974 (0.6953)  time: 0.0647  data: 0.0003  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:28  loss: 0.8201 (1.0489)  labels_encoder: 0.4897 (0.6895)  labels_decoder: 0.2951 (0.3594)  labels_encoder_unscaled: 0.4897 (0.6895)  labels_decoder_unscaled: 0.5901 (0.7187)  time: 0.0591  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:24  loss: 1.1526 (1.0669)  labels_encoder: 0.6381 (0.6980)  labels_decoder: 0.4341 (0.3689)  labels_encoder_unscaled: 0.6381 (0.6980)  labels_decoder_unscaled: 0.8682 (0.7378)  time: 0.0633  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:20  loss: 1.0822 (1.1637)  labels_encoder: 0.6209 (0.7627)  labels_decoder: 0.4418 (0.4010)  labels_encoder_unscaled: 0.6209 (0.7627)  labels_decoder_unscaled: 0.8836 (0.8020)  time: 0.0606  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:16  loss: 1.1996 (1.2648)  labels_encoder: 0.7318 (0.8303)  labels_decoder: 0.4433 (0.4344)  labels_encoder_unscaled: 0.7318 (0.8303)  labels_decoder_unscaled: 0.8867 (0.8689)  time: 0.0657  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:12  loss: 0.3695 (1.2038)  labels_encoder: 0.1913 (0.7863)  labels_decoder: 0.1782 (0.4175)  labels_encoder_unscaled: 0.1913 (0.7863)  labels_decoder_unscaled: 0.3564 (0.8350)  time: 0.0637  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:09  loss: 1.5082 (1.2216)  labels_encoder: 1.2270 (0.7988)  labels_decoder: 0.3978 (0.4228)  labels_encoder_unscaled: 1.2270 (0.7988)  labels_decoder_unscaled: 0.7956 (0.8455)  time: 0.0631  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:05  loss: 1.0572 (1.3702)  labels_encoder: 0.6118 (0.9236)  labels_decoder: 0.3528 (0.4466)  labels_encoder_unscaled: 0.6118 (0.9236)  labels_decoder_unscaled: 0.7056 (0.8932)  time: 0.0610  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:02  loss: 0.7628 (1.3410)  labels_encoder: 0.3591 (0.8983)  labels_decoder: 0.4037 (0.4428)  labels_encoder_unscaled: 0.3591 (0.8983)  labels_decoder_unscaled: 0.8075 (0.8855)  time: 0.0646  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:00:58  loss: 0.5000 (1.3021)  labels_encoder: 0.3252 (0.8705)  labels_decoder: 0.2001 (0.4316)  labels_encoder_unscaled: 0.3252 (0.8705)  labels_decoder_unscaled: 0.4001 (0.8632)  time: 0.0598  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:55  loss: 0.5985 (1.2579)  labels_encoder: 0.2759 (0.8375)  labels_decoder: 0.2431 (0.4204)  labels_encoder_unscaled: 0.2759 (0.8375)  labels_decoder_unscaled: 0.4863 (0.8408)  time: 0.0556  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:52  loss: 0.7006 (1.2386)  labels_encoder: 0.4337 (0.8225)  labels_decoder: 0.2785 (0.4161)  labels_encoder_unscaled: 0.4337 (0.8225)  labels_decoder_unscaled: 0.5569 (0.8322)  time: 0.0610  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:48  loss: 2.0919 (1.2468)  labels_encoder: 1.2023 (0.8244)  labels_decoder: 0.7475 (0.4224)  labels_encoder_unscaled: 1.2023 (0.8244)  labels_decoder_unscaled: 1.4951 (0.8448)  time: 0.0583  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:45  loss: 0.8174 (1.2676)  labels_encoder: 0.5592 (0.8381)  labels_decoder: 0.2946 (0.4295)  labels_encoder_unscaled: 0.5592 (0.8381)  labels_decoder_unscaled: 0.5893 (0.8589)  time: 0.0602  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:42  loss: 0.7587 (1.2456)  labels_encoder: 0.5174 (0.8227)  labels_decoder: 0.2603 (0.4229)  labels_encoder_unscaled: 0.5174 (0.8227)  labels_decoder_unscaled: 0.5206 (0.8459)  time: 0.0588  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:38  loss: 0.8831 (1.2316)  labels_encoder: 0.5265 (0.8110)  labels_decoder: 0.3275 (0.4206)  labels_encoder_unscaled: 0.5265 (0.8110)  labels_decoder_unscaled: 0.6550 (0.8411)  time: 0.0628  data: 0.0012  max mem: 3384
Test:  [1050/1613]  eta: 0:00:35  loss: 0.9113 (1.2138)  labels_encoder: 0.5299 (0.7980)  labels_decoder: 0.3498 (0.4159)  labels_encoder_unscaled: 0.5299 (0.7980)  labels_decoder_unscaled: 0.6997 (0.8317)  time: 0.0632  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:32  loss: 0.8485 (1.2124)  labels_encoder: 0.4782 (0.7958)  labels_decoder: 0.3787 (0.4166)  labels_encoder_unscaled: 0.4782 (0.7958)  labels_decoder_unscaled: 0.7574 (0.8332)  time: 0.0573  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:29  loss: 0.6220 (1.1893)  labels_encoder: 0.3614 (0.7797)  labels_decoder: 0.2110 (0.4096)  labels_encoder_unscaled: 0.3614 (0.7797)  labels_decoder_unscaled: 0.4221 (0.8192)  time: 0.0597  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:25  loss: 0.6660 (1.1914)  labels_encoder: 0.4169 (0.7801)  labels_decoder: 0.2743 (0.4113)  labels_encoder_unscaled: 0.4169 (0.7801)  labels_decoder_unscaled: 0.5485 (0.8226)  time: 0.0588  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:22  loss: 0.4428 (1.1944)  labels_encoder: 0.2514 (0.7814)  labels_decoder: 0.2040 (0.4130)  labels_encoder_unscaled: 0.2514 (0.7814)  labels_decoder_unscaled: 0.4079 (0.8260)  time: 0.0593  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5673 (1.1867)  labels_encoder: 0.3663 (0.7762)  labels_decoder: 0.2587 (0.4105)  labels_encoder_unscaled: 0.3663 (0.7762)  labels_decoder_unscaled: 0.5174 (0.8210)  time: 0.0604  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:16  loss: 0.7926 (1.1929)  labels_encoder: 0.5732 (0.7798)  labels_decoder: 0.3251 (0.4131)  labels_encoder_unscaled: 0.5732 (0.7798)  labels_decoder_unscaled: 0.6501 (0.8263)  time: 0.0575  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:13  loss: 0.7856 (1.1836)  labels_encoder: 0.5102 (0.7733)  labels_decoder: 0.3023 (0.4103)  labels_encoder_unscaled: 0.5102 (0.7733)  labels_decoder_unscaled: 0.6046 (0.8205)  time: 0.0638  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.8743 (1.1897)  labels_encoder: 0.4553 (0.7775)  labels_decoder: 0.3444 (0.4123)  labels_encoder_unscaled: 0.4553 (0.7775)  labels_decoder_unscaled: 0.6889 (0.8245)  time: 0.0600  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.6814 (1.1924)  labels_encoder: 0.4227 (0.7794)  labels_decoder: 0.2841 (0.4130)  labels_encoder_unscaled: 0.4227 (0.7794)  labels_decoder_unscaled: 0.5681 (0.8261)  time: 0.0516  data: 0.0001  max mem: 3384
Test:  [1550/1613]  eta: 0:00:03  loss: 0.6214 (1.1812)  labels_encoder: 0.3634 (0.7717)  labels_decoder: 0.2526 (0.4095)  labels_encoder_unscaled: 0.3634 (0.7717)  labels_decoder_unscaled: 0.5052 (0.8189)  time: 0.0494  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8785 (1.1742)  labels_encoder: 0.5165 (0.7667)  labels_decoder: 0.3510 (0.4075)  labels_encoder_unscaled: 0.5165 (0.7667)  labels_decoder_unscaled: 0.7020 (0.8150)  time: 0.0462  data: 0.0001  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.4498 (1.1728)  labels_encoder: 0.2775 (0.7664)  labels_decoder: 0.1770 (0.4064)  labels_encoder_unscaled: 0.2775 (0.7664)  labels_decoder_unscaled: 0.3540 (0.8128)  time: 0.0401  data: 0.0001  max mem: 3384
Test: Total time: 0:01:39 (0.0615 s / it)
Averaged stats: loss: 0.4498 (1.1728)  labels_encoder: 0.2775 (0.7664)  labels_decoder: 0.1770 (0.4064)  labels_encoder_unscaled: 0.2775 (0.7664)  labels_decoder_unscaled: 0.3540 (0.8128)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet] mAP: 0.5591

dec_mAP all together: | 0.4409963855869273 |.
dec_mAP_pred | 0 : 0.49119915349909915 |.
dec_mAP_pred | 1 : 0.4804106050159344 |.
dec_mAP_pred | 2 : 0.46599246800267197 |.
dec_mAP_pred | 3 : 0.4504570319360968 |.
dec_mAP_pred | 4 : 0.43476564487707947 |.
dec_mAP_pred | 5 : 0.41958035816630285 |.
dec_mAP_pred | 6 : 0.405108271328264 |.
dec_mAP_pred | 7 : 0.39175927737673005 |.
all decoder map: | 0.4424 |.
BaseballPitch: 0.2322
BasketballDunk: 0.7456
Billiards: 0.3923
CleanAndJerk: 0.7512
CliffDiving: 0.8247
CricketBowling: 0.3926
CricketShot: 0.2238
Diving: 0.6472
FrisbeeCatch: 0.1894
GolfSwing: 0.5468
HammerThrow: 0.8573
HighJump: 0.6362
JavelinThrow: 0.6905
LongJump: 0.7850
PoleVault: 0.8471
Shotput: 0.6538
SoccerPenalty: 0.3226
TennisSwing: 0.5826
ThrowDiscus: 0.6122
VolleyballSpiking: 0.2497
Epoch: [2]  [   0/1404]  eta: 0:35:27  lr: 0.000010  loss: 0.3247 (0.3247)  labels_encoder: 0.1691 (0.1691)  labels_decoder: 0.1556 (0.1556)  labels_encoder_unscaled: 0.1691 (0.1691)  labels_decoder_unscaled: 0.3113 (0.3113)  time: 1.5155  data: 1.3332  max mem: 3384
Epoch: [2]  [  50/1404]  eta: 0:03:49  lr: 0.000010  loss: 0.3117 (0.3227)  labels_encoder: 0.1625 (0.1818)  labels_decoder: 0.1418 (0.1409)  labels_encoder_unscaled: 0.1625 (0.1818)  labels_decoder_unscaled: 0.2835 (0.2819)  time: 0.1389  data: 0.0003  max mem: 3384
Epoch: [2]  [ 100/1404]  eta: 0:03:20  lr: 0.000010  loss: 0.2808 (0.3131)  labels_encoder: 0.1458 (0.1722)  labels_decoder: 0.1380 (0.1409)  labels_encoder_unscaled: 0.1458 (0.1722)  labels_decoder_unscaled: 0.2760 (0.2817)  time: 0.1359  data: 0.0003  max mem: 3384
Epoch: [2]  [ 150/1404]  eta: 0:03:06  lr: 0.000010  loss: 0.2889 (0.3066)  labels_encoder: 0.1493 (0.1672)  labels_decoder: 0.1377 (0.1394)  labels_encoder_unscaled: 0.1493 (0.1672)  labels_decoder_unscaled: 0.2754 (0.2789)  time: 0.1366  data: 0.0003  max mem: 3384
Epoch: [2]  [ 200/1404]  eta: 0:02:54  lr: 0.000010  loss: 0.3041 (0.3037)  labels_encoder: 0.1592 (0.1660)  labels_decoder: 0.1270 (0.1377)  labels_encoder_unscaled: 0.1592 (0.1660)  labels_decoder_unscaled: 0.2540 (0.2755)  time: 0.1367  data: 0.0003  max mem: 3384
Epoch: [2]  [ 250/1404]  eta: 0:02:45  lr: 0.000010  loss: 0.2858 (0.3035)  labels_encoder: 0.1478 (0.1659)  labels_decoder: 0.1349 (0.1376)  labels_encoder_unscaled: 0.1478 (0.1659)  labels_decoder_unscaled: 0.2698 (0.2751)  time: 0.1382  data: 0.0003  max mem: 3384
Epoch: [2]  [ 300/1404]  eta: 0:02:37  lr: 0.000010  loss: 0.2676 (0.2999)  labels_encoder: 0.1376 (0.1637)  labels_decoder: 0.1283 (0.1362)  labels_encoder_unscaled: 0.1376 (0.1637)  labels_decoder_unscaled: 0.2566 (0.2725)  time: 0.1373  data: 0.0003  max mem: 3384
Epoch: [2]  [ 350/1404]  eta: 0:02:29  lr: 0.000010  loss: 0.2868 (0.2987)  labels_encoder: 0.1463 (0.1630)  labels_decoder: 0.1269 (0.1357)  labels_encoder_unscaled: 0.1463 (0.1630)  labels_decoder_unscaled: 0.2538 (0.2713)  time: 0.1374  data: 0.0003  max mem: 3384
Epoch: [2]  [ 400/1404]  eta: 0:02:21  lr: 0.000010  loss: 0.2850 (0.2986)  labels_encoder: 0.1512 (0.1626)  labels_decoder: 0.1292 (0.1360)  labels_encoder_unscaled: 0.1512 (0.1626)  labels_decoder_unscaled: 0.2584 (0.2720)  time: 0.1335  data: 0.0003  max mem: 3384
Epoch: [2]  [ 450/1404]  eta: 0:02:13  lr: 0.000010  loss: 0.2482 (0.2955)  labels_encoder: 0.1335 (0.1606)  labels_decoder: 0.1183 (0.1349)  labels_encoder_unscaled: 0.1335 (0.1606)  labels_decoder_unscaled: 0.2365 (0.2697)  time: 0.1333  data: 0.0002  max mem: 3384
Epoch: [2]  [ 500/1404]  eta: 0:02:05  lr: 0.000010  loss: 0.2715 (0.2932)  labels_encoder: 0.1333 (0.1589)  labels_decoder: 0.1243 (0.1343)  labels_encoder_unscaled: 0.1333 (0.1589)  labels_decoder_unscaled: 0.2486 (0.2686)  time: 0.1316  data: 0.0003  max mem: 3384
Epoch: [2]  [ 550/1404]  eta: 0:01:58  lr: 0.000010  loss: 0.2535 (0.2922)  labels_encoder: 0.1291 (0.1584)  labels_decoder: 0.1257 (0.1338)  labels_encoder_unscaled: 0.1291 (0.1584)  labels_decoder_unscaled: 0.2513 (0.2677)  time: 0.1319  data: 0.0003  max mem: 3384
Epoch: [2]  [ 600/1404]  eta: 0:01:51  lr: 0.000010  loss: 0.2383 (0.2902)  labels_encoder: 0.1294 (0.1569)  labels_decoder: 0.1235 (0.1333)  labels_encoder_unscaled: 0.1294 (0.1569)  labels_decoder_unscaled: 0.2469 (0.2666)  time: 0.1357  data: 0.0003  max mem: 3384
Epoch: [2]  [ 650/1404]  eta: 0:01:43  lr: 0.000010  loss: 0.2651 (0.2889)  labels_encoder: 0.1464 (0.1561)  labels_decoder: 0.1223 (0.1328)  labels_encoder_unscaled: 0.1464 (0.1561)  labels_decoder_unscaled: 0.2446 (0.2655)  time: 0.1319  data: 0.0003  max mem: 3384
Epoch: [2]  [ 700/1404]  eta: 0:01:36  lr: 0.000010  loss: 0.2700 (0.2875)  labels_encoder: 0.1431 (0.1553)  labels_decoder: 0.1251 (0.1322)  labels_encoder_unscaled: 0.1431 (0.1553)  labels_decoder_unscaled: 0.2501 (0.2644)  time: 0.1320  data: 0.0003  max mem: 3384
Epoch: [2]  [ 750/1404]  eta: 0:01:29  lr: 0.000010  loss: 0.2481 (0.2859)  labels_encoder: 0.1314 (0.1545)  labels_decoder: 0.1139 (0.1313)  labels_encoder_unscaled: 0.1314 (0.1545)  labels_decoder_unscaled: 0.2278 (0.2627)  time: 0.1327  data: 0.0002  max mem: 3384
Epoch: [2]  [ 800/1404]  eta: 0:01:22  lr: 0.000010  loss: 0.2472 (0.2850)  labels_encoder: 0.1233 (0.1540)  labels_decoder: 0.1259 (0.1310)  labels_encoder_unscaled: 0.1233 (0.1540)  labels_decoder_unscaled: 0.2519 (0.2620)  time: 0.1272  data: 0.0003  max mem: 3384
Epoch: [2]  [ 850/1404]  eta: 0:01:15  lr: 0.000010  loss: 0.2437 (0.2835)  labels_encoder: 0.1248 (0.1531)  labels_decoder: 0.1161 (0.1305)  labels_encoder_unscaled: 0.1248 (0.1531)  labels_decoder_unscaled: 0.2322 (0.2609)  time: 0.1298  data: 0.0003  max mem: 3384
Epoch: [2]  [ 900/1404]  eta: 0:01:08  lr: 0.000010  loss: 0.2497 (0.2824)  labels_encoder: 0.1313 (0.1524)  labels_decoder: 0.1228 (0.1301)  labels_encoder_unscaled: 0.1313 (0.1524)  labels_decoder_unscaled: 0.2456 (0.2601)  time: 0.1344  data: 0.0003  max mem: 3384
Epoch: [2]  [ 950/1404]  eta: 0:01:01  lr: 0.000010  loss: 0.2540 (0.2813)  labels_encoder: 0.1388 (0.1515)  labels_decoder: 0.1166 (0.1298)  labels_encoder_unscaled: 0.1388 (0.1515)  labels_decoder_unscaled: 0.2332 (0.2596)  time: 0.1368  data: 0.0003  max mem: 3384
Epoch: [2]  [1000/1404]  eta: 0:00:54  lr: 0.000010  loss: 0.2457 (0.2803)  labels_encoder: 0.1186 (0.1508)  labels_decoder: 0.1246 (0.1295)  labels_encoder_unscaled: 0.1186 (0.1508)  labels_decoder_unscaled: 0.2493 (0.2590)  time: 0.1317  data: 0.0003  max mem: 3384
Epoch: [2]  [1050/1404]  eta: 0:00:48  lr: 0.000010  loss: 0.2492 (0.2800)  labels_encoder: 0.1377 (0.1506)  labels_decoder: 0.1190 (0.1295)  labels_encoder_unscaled: 0.1377 (0.1506)  labels_decoder_unscaled: 0.2380 (0.2589)  time: 0.1349  data: 0.0003  max mem: 3384
Epoch: [2]  [1100/1404]  eta: 0:00:41  lr: 0.000010  loss: 0.2637 (0.2792)  labels_encoder: 0.1230 (0.1498)  labels_decoder: 0.1266 (0.1294)  labels_encoder_unscaled: 0.1230 (0.1498)  labels_decoder_unscaled: 0.2533 (0.2587)  time: 0.1323  data: 0.0003  max mem: 3384
Epoch: [2]  [1150/1404]  eta: 0:00:34  lr: 0.000010  loss: 0.2703 (0.2782)  labels_encoder: 0.1279 (0.1491)  labels_decoder: 0.1249 (0.1290)  labels_encoder_unscaled: 0.1279 (0.1491)  labels_decoder_unscaled: 0.2498 (0.2581)  time: 0.1338  data: 0.0003  max mem: 3384
Epoch: [2]  [1200/1404]  eta: 0:00:27  lr: 0.000010  loss: 0.2586 (0.2773)  labels_encoder: 0.1383 (0.1485)  labels_decoder: 0.1171 (0.1288)  labels_encoder_unscaled: 0.1383 (0.1485)  labels_decoder_unscaled: 0.2342 (0.2576)  time: 0.1322  data: 0.0003  max mem: 3384
Epoch: [2]  [1250/1404]  eta: 0:00:20  lr: 0.000010  loss: 0.2675 (0.2771)  labels_encoder: 0.1416 (0.1485)  labels_decoder: 0.1207 (0.1286)  labels_encoder_unscaled: 0.1416 (0.1485)  labels_decoder_unscaled: 0.2414 (0.2573)  time: 0.1338  data: 0.0003  max mem: 3384
Epoch: [2]  [1300/1404]  eta: 0:00:14  lr: 0.000010  loss: 0.2502 (0.2768)  labels_encoder: 0.1281 (0.1483)  labels_decoder: 0.1235 (0.1285)  labels_encoder_unscaled: 0.1281 (0.1483)  labels_decoder_unscaled: 0.2471 (0.2570)  time: 0.1382  data: 0.0003  max mem: 3384
Epoch: [2]  [1350/1404]  eta: 0:00:07  lr: 0.000010  loss: 0.2688 (0.2762)  labels_encoder: 0.1410 (0.1478)  labels_decoder: 0.1239 (0.1284)  labels_encoder_unscaled: 0.1410 (0.1478)  labels_decoder_unscaled: 0.2478 (0.2569)  time: 0.1334  data: 0.0003  max mem: 3384
Epoch: [2]  [1400/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2659 (0.2757)  labels_encoder: 0.1384 (0.1474)  labels_decoder: 0.1287 (0.1283)  labels_encoder_unscaled: 0.1384 (0.1474)  labels_decoder_unscaled: 0.2574 (0.2566)  time: 0.1209  data: 0.0003  max mem: 3384
Epoch: [2]  [1403/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2526 (0.2756)  labels_encoder: 0.1378 (0.1473)  labels_decoder: 0.1287 (0.1283)  labels_encoder_unscaled: 0.1378 (0.1473)  labels_decoder_unscaled: 0.2574 (0.2566)  time: 0.1191  data: 0.0003  max mem: 3384
Epoch: [2] Total time: 0:03:10 (0.1353 s / it)
Averaged stats: lr: 0.000010  loss: 0.2526 (0.2756)  labels_encoder: 0.1378 (0.1473)  labels_decoder: 0.1287 (0.1283)  labels_encoder_unscaled: 0.1378 (0.1473)  labels_decoder_unscaled: 0.2574 (0.2566)
Test:  [   0/1613]  eta: 0:44:14  loss: 0.5870 (0.5870)  labels_encoder: 0.3061 (0.3061)  labels_decoder: 0.2809 (0.2809)  labels_encoder_unscaled: 0.3061 (0.3061)  labels_decoder_unscaled: 0.5617 (0.5617)  time: 1.6455  data: 1.5952  max mem: 3384
Test:  [  50/1613]  eta: 0:02:50  loss: 0.5320 (1.0278)  labels_encoder: 0.2803 (0.6561)  labels_decoder: 0.2233 (0.3717)  labels_encoder_unscaled: 0.2803 (0.6561)  labels_decoder_unscaled: 0.4465 (0.7433)  time: 0.0671  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:02:12  loss: 0.1114 (0.8204)  labels_encoder: 0.0755 (0.5261)  labels_decoder: 0.0385 (0.2942)  labels_encoder_unscaled: 0.0755 (0.5261)  labels_decoder_unscaled: 0.0769 (0.5885)  time: 0.0637  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:58  loss: 0.7524 (0.7652)  labels_encoder: 0.4637 (0.4867)  labels_decoder: 0.2835 (0.2786)  labels_encoder_unscaled: 0.4637 (0.4867)  labels_decoder_unscaled: 0.5669 (0.5571)  time: 0.0660  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:49  loss: 0.9632 (0.8907)  labels_encoder: 0.5566 (0.5691)  labels_decoder: 0.3575 (0.3216)  labels_encoder_unscaled: 0.5566 (0.5691)  labels_decoder_unscaled: 0.7150 (0.6433)  time: 0.0674  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:43  loss: 0.7066 (0.9485)  labels_encoder: 0.4271 (0.6055)  labels_decoder: 0.2658 (0.3430)  labels_encoder_unscaled: 0.4271 (0.6055)  labels_decoder_unscaled: 0.5316 (0.6860)  time: 0.0706  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:37  loss: 0.5941 (0.9580)  labels_encoder: 0.3398 (0.6174)  labels_decoder: 0.2094 (0.3407)  labels_encoder_unscaled: 0.3398 (0.6174)  labels_decoder_unscaled: 0.4188 (0.6813)  time: 0.0716  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:33  loss: 1.1301 (0.9698)  labels_encoder: 0.6771 (0.6209)  labels_decoder: 0.4531 (0.3489)  labels_encoder_unscaled: 0.6771 (0.6209)  labels_decoder_unscaled: 0.9061 (0.6978)  time: 0.0677  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:29  loss: 0.8127 (1.1092)  labels_encoder: 0.4359 (0.7181)  labels_decoder: 0.3811 (0.3911)  labels_encoder_unscaled: 0.4359 (0.7181)  labels_decoder_unscaled: 0.7622 (0.7822)  time: 0.0670  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:24  loss: 1.1566 (1.2073)  labels_encoder: 0.7146 (0.7848)  labels_decoder: 0.4273 (0.4225)  labels_encoder_unscaled: 0.7146 (0.7848)  labels_decoder_unscaled: 0.8547 (0.8450)  time: 0.0690  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:20  loss: 0.4152 (1.1544)  labels_encoder: 0.2133 (0.7479)  labels_decoder: 0.1832 (0.4065)  labels_encoder_unscaled: 0.2133 (0.7479)  labels_decoder_unscaled: 0.3664 (0.8130)  time: 0.0694  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:16  loss: 1.0682 (1.1583)  labels_encoder: 0.6550 (0.7487)  labels_decoder: 0.3820 (0.4096)  labels_encoder_unscaled: 0.6550 (0.7487)  labels_decoder_unscaled: 0.7639 (0.8193)  time: 0.0682  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:12  loss: 1.6786 (1.1861)  labels_encoder: 0.8841 (0.7728)  labels_decoder: 0.5665 (0.4133)  labels_encoder_unscaled: 0.8841 (0.7728)  labels_decoder_unscaled: 1.1330 (0.8266)  time: 0.0690  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:08  loss: 0.8089 (1.1632)  labels_encoder: 0.4127 (0.7541)  labels_decoder: 0.3963 (0.4091)  labels_encoder_unscaled: 0.4127 (0.7541)  labels_decoder_unscaled: 0.7926 (0.8182)  time: 0.0682  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:01:05  loss: 0.5341 (1.1365)  labels_encoder: 0.3339 (0.7360)  labels_decoder: 0.2001 (0.4004)  labels_encoder_unscaled: 0.3339 (0.7360)  labels_decoder_unscaled: 0.4003 (0.8009)  time: 0.0667  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:01:01  loss: 0.7857 (1.1110)  labels_encoder: 0.4661 (0.7190)  labels_decoder: 0.2589 (0.3921)  labels_encoder_unscaled: 0.4661 (0.7190)  labels_decoder_unscaled: 0.5177 (0.7841)  time: 0.0684  data: 0.0003  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:57  loss: 0.7742 (1.1075)  labels_encoder: 0.4970 (0.7169)  labels_decoder: 0.2772 (0.3905)  labels_encoder_unscaled: 0.4970 (0.7169)  labels_decoder_unscaled: 0.5543 (0.7810)  time: 0.0626  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:53  loss: 1.4472 (1.1141)  labels_encoder: 0.9778 (0.7196)  labels_decoder: 0.5332 (0.3945)  labels_encoder_unscaled: 0.9778 (0.7196)  labels_decoder_unscaled: 1.0665 (0.7890)  time: 0.0657  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:50  loss: 0.7455 (1.1411)  labels_encoder: 0.4434 (0.7392)  labels_decoder: 0.2985 (0.4018)  labels_encoder_unscaled: 0.4434 (0.7392)  labels_decoder_unscaled: 0.5970 (0.8036)  time: 0.0677  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:46  loss: 1.0441 (1.1304)  labels_encoder: 0.7539 (0.7330)  labels_decoder: 0.3080 (0.3973)  labels_encoder_unscaled: 0.7539 (0.7330)  labels_decoder_unscaled: 0.6160 (0.7947)  time: 0.0629  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:42  loss: 0.6409 (1.1155)  labels_encoder: 0.3752 (0.7228)  labels_decoder: 0.2908 (0.3927)  labels_encoder_unscaled: 0.3752 (0.7228)  labels_decoder_unscaled: 0.5816 (0.7854)  time: 0.0632  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:39  loss: 0.8461 (1.1078)  labels_encoder: 0.4976 (0.7179)  labels_decoder: 0.3274 (0.3899)  labels_encoder_unscaled: 0.4976 (0.7179)  labels_decoder_unscaled: 0.6547 (0.7798)  time: 0.0669  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:35  loss: 0.8185 (1.1152)  labels_encoder: 0.4809 (0.7235)  labels_decoder: 0.3841 (0.3917)  labels_encoder_unscaled: 0.4809 (0.7235)  labels_decoder_unscaled: 0.7681 (0.7835)  time: 0.0688  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:32  loss: 0.5793 (1.1029)  labels_encoder: 0.3131 (0.7148)  labels_decoder: 0.2576 (0.3881)  labels_encoder_unscaled: 0.3131 (0.7148)  labels_decoder_unscaled: 0.5152 (0.7763)  time: 0.0668  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:28  loss: 0.6508 (1.1103)  labels_encoder: 0.3700 (0.7188)  labels_decoder: 0.2680 (0.3915)  labels_encoder_unscaled: 0.3700 (0.7188)  labels_decoder_unscaled: 0.5361 (0.7830)  time: 0.0657  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:25  loss: 0.4920 (1.1115)  labels_encoder: 0.2695 (0.7194)  labels_decoder: 0.2252 (0.3921)  labels_encoder_unscaled: 0.2695 (0.7194)  labels_decoder_unscaled: 0.4505 (0.7843)  time: 0.0643  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:21  loss: 0.6050 (1.0998)  labels_encoder: 0.3567 (0.7114)  labels_decoder: 0.2021 (0.3884)  labels_encoder_unscaled: 0.3567 (0.7114)  labels_decoder_unscaled: 0.4041 (0.7768)  time: 0.0652  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:18  loss: 0.7383 (1.1192)  labels_encoder: 0.4924 (0.7250)  labels_decoder: 0.3075 (0.3942)  labels_encoder_unscaled: 0.4924 (0.7250)  labels_decoder_unscaled: 0.6150 (0.7884)  time: 0.0660  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:14  loss: 0.9841 (1.1166)  labels_encoder: 0.6326 (0.7233)  labels_decoder: 0.3784 (0.3932)  labels_encoder_unscaled: 0.6326 (0.7233)  labels_decoder_unscaled: 0.7567 (0.7864)  time: 0.0644  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:11  loss: 0.6311 (1.1270)  labels_encoder: 0.2930 (0.7303)  labels_decoder: 0.2973 (0.3968)  labels_encoder_unscaled: 0.2930 (0.7303)  labels_decoder_unscaled: 0.5947 (0.7935)  time: 0.0662  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.6995 (1.1387)  labels_encoder: 0.4017 (0.7383)  labels_decoder: 0.2978 (0.4003)  labels_encoder_unscaled: 0.4017 (0.7383)  labels_decoder_unscaled: 0.5955 (0.8006)  time: 0.0662  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:04  loss: 0.7902 (1.1333)  labels_encoder: 0.4949 (0.7349)  labels_decoder: 0.2751 (0.3984)  labels_encoder_unscaled: 0.4949 (0.7349)  labels_decoder_unscaled: 0.5502 (0.7967)  time: 0.0625  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8103 (1.1280)  labels_encoder: 0.4992 (0.7312)  labels_decoder: 0.3017 (0.3969)  labels_encoder_unscaled: 0.4992 (0.7312)  labels_decoder_unscaled: 0.6034 (0.7938)  time: 0.0564  data: 0.0002  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6530 (1.1249)  labels_encoder: 0.3880 (0.7293)  labels_decoder: 0.2940 (0.3957)  labels_encoder_unscaled: 0.3880 (0.7293)  labels_decoder_unscaled: 0.5881 (0.7914)  time: 0.0448  data: 0.0001  max mem: 3384
Test: Total time: 0:01:50 (0.0684 s / it)
Averaged stats: loss: 0.6530 (1.1249)  labels_encoder: 0.3880 (0.7293)  labels_decoder: 0.2940 (0.3957)  labels_encoder_unscaled: 0.3880 (0.7293)  labels_decoder_unscaled: 0.5881 (0.7914)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet] mAP: 0.5762

dec_mAP all together: | 0.45168927030172973 |.
dec_mAP_pred | 0 : 0.49490720056939425 |.
dec_mAP_pred | 1 : 0.4867636311391087 |.
dec_mAP_pred | 2 : 0.4747532173712686 |.
dec_mAP_pred | 3 : 0.4614513256661355 |.
dec_mAP_pred | 4 : 0.4470236206083949 |.
dec_mAP_pred | 5 : 0.432917361922222 |.
dec_mAP_pred | 6 : 0.41929464688834306 |.
dec_mAP_pred | 7 : 0.40626119399604804 |.
all decoder map: | 0.4529 |.
BaseballPitch: 0.2026
BasketballDunk: 0.7727
Billiards: 0.4295
CleanAndJerk: 0.7515
CliffDiving: 0.8160
CricketBowling: 0.4026
CricketShot: 0.1889
Diving: 0.6605
FrisbeeCatch: 0.3943
GolfSwing: 0.5963
HammerThrow: 0.8549
HighJump: 0.6214
JavelinThrow: 0.7131
LongJump: 0.7868
PoleVault: 0.8603
Shotput: 0.6865
SoccerPenalty: 0.3430
TennisSwing: 0.5760
ThrowDiscus: 0.5901
VolleyballSpiking: 0.2767
Epoch: [3]  [   0/1404]  eta: 0:37:23  lr: 0.000001  loss: 0.3297 (0.3297)  labels_encoder: 0.1952 (0.1952)  labels_decoder: 0.1345 (0.1345)  labels_encoder_unscaled: 0.1952 (0.1952)  labels_decoder_unscaled: 0.2691 (0.2691)  time: 1.5982  data: 1.4251  max mem: 3384
Epoch: [3]  [  50/1404]  eta: 0:03:47  lr: 0.000001  loss: 0.2379 (0.2472)  labels_encoder: 0.1218 (0.1265)  labels_decoder: 0.1171 (0.1207)  labels_encoder_unscaled: 0.1218 (0.1265)  labels_decoder_unscaled: 0.2342 (0.2414)  time: 0.1338  data: 0.0003  max mem: 3384
Epoch: [3]  [ 100/1404]  eta: 0:03:20  lr: 0.000001  loss: 0.2378 (0.2415)  labels_encoder: 0.1303 (0.1247)  labels_decoder: 0.1082 (0.1168)  labels_encoder_unscaled: 0.1303 (0.1247)  labels_decoder_unscaled: 0.2164 (0.2336)  time: 0.1404  data: 0.0004  max mem: 3384
Epoch: [3]  [ 150/1404]  eta: 0:03:06  lr: 0.000001  loss: 0.2177 (0.2392)  labels_encoder: 0.1065 (0.1235)  labels_decoder: 0.1079 (0.1157)  labels_encoder_unscaled: 0.1065 (0.1235)  labels_decoder_unscaled: 0.2157 (0.2314)  time: 0.1336  data: 0.0004  max mem: 3384
Epoch: [3]  [ 200/1404]  eta: 0:02:55  lr: 0.000001  loss: 0.2146 (0.2388)  labels_encoder: 0.1008 (0.1235)  labels_decoder: 0.1086 (0.1153)  labels_encoder_unscaled: 0.1008 (0.1235)  labels_decoder_unscaled: 0.2173 (0.2307)  time: 0.1372  data: 0.0003  max mem: 3384
Epoch: [3]  [ 250/1404]  eta: 0:02:47  lr: 0.000001  loss: 0.2411 (0.2390)  labels_encoder: 0.1246 (0.1233)  labels_decoder: 0.1201 (0.1157)  labels_encoder_unscaled: 0.1246 (0.1233)  labels_decoder_unscaled: 0.2402 (0.2314)  time: 0.1374  data: 0.0003  max mem: 3384
Epoch: [3]  [ 300/1404]  eta: 0:02:38  lr: 0.000001  loss: 0.2369 (0.2389)  labels_encoder: 0.1211 (0.1229)  labels_decoder: 0.1143 (0.1161)  labels_encoder_unscaled: 0.1211 (0.1229)  labels_decoder_unscaled: 0.2285 (0.2321)  time: 0.1383  data: 0.0003  max mem: 3384
Epoch: [3]  [ 350/1404]  eta: 0:02:30  lr: 0.000001  loss: 0.2262 (0.2405)  labels_encoder: 0.1205 (0.1237)  labels_decoder: 0.1167 (0.1168)  labels_encoder_unscaled: 0.1205 (0.1237)  labels_decoder_unscaled: 0.2335 (0.2336)  time: 0.1386  data: 0.0003  max mem: 3384
Epoch: [3]  [ 400/1404]  eta: 0:02:22  lr: 0.000001  loss: 0.2357 (0.2404)  labels_encoder: 0.1166 (0.1232)  labels_decoder: 0.1229 (0.1171)  labels_encoder_unscaled: 0.1166 (0.1232)  labels_decoder_unscaled: 0.2458 (0.2343)  time: 0.1404  data: 0.0003  max mem: 3384
Epoch: [3]  [ 450/1404]  eta: 0:02:15  lr: 0.000001  loss: 0.2685 (0.2417)  labels_encoder: 0.1341 (0.1239)  labels_decoder: 0.1204 (0.1179)  labels_encoder_unscaled: 0.1341 (0.1239)  labels_decoder_unscaled: 0.2408 (0.2357)  time: 0.1363  data: 0.0003  max mem: 3384
Epoch: [3]  [ 500/1404]  eta: 0:02:07  lr: 0.000001  loss: 0.2128 (0.2412)  labels_encoder: 0.1103 (0.1232)  labels_decoder: 0.1176 (0.1180)  labels_encoder_unscaled: 0.1103 (0.1232)  labels_decoder_unscaled: 0.2351 (0.2360)  time: 0.1378  data: 0.0003  max mem: 3384
Epoch: [3]  [ 550/1404]  eta: 0:01:59  lr: 0.000001  loss: 0.2532 (0.2413)  labels_encoder: 0.1309 (0.1234)  labels_decoder: 0.1194 (0.1178)  labels_encoder_unscaled: 0.1309 (0.1234)  labels_decoder_unscaled: 0.2389 (0.2357)  time: 0.1346  data: 0.0003  max mem: 3384
Epoch: [3]  [ 600/1404]  eta: 0:01:52  lr: 0.000001  loss: 0.2413 (0.2412)  labels_encoder: 0.1148 (0.1238)  labels_decoder: 0.1206 (0.1175)  labels_encoder_unscaled: 0.1148 (0.1238)  labels_decoder_unscaled: 0.2411 (0.2349)  time: 0.1359  data: 0.0003  max mem: 3384
Epoch: [3]  [ 650/1404]  eta: 0:01:45  lr: 0.000001  loss: 0.2287 (0.2408)  labels_encoder: 0.1102 (0.1237)  labels_decoder: 0.1053 (0.1171)  labels_encoder_unscaled: 0.1102 (0.1237)  labels_decoder_unscaled: 0.2107 (0.2341)  time: 0.1435  data: 0.0011  max mem: 3384
Epoch: [3]  [ 700/1404]  eta: 0:01:38  lr: 0.000001  loss: 0.2485 (0.2414)  labels_encoder: 0.1347 (0.1244)  labels_decoder: 0.1161 (0.1170)  labels_encoder_unscaled: 0.1347 (0.1244)  labels_decoder_unscaled: 0.2321 (0.2339)  time: 0.1350  data: 0.0003  max mem: 3384
Epoch: [3]  [ 750/1404]  eta: 0:01:31  lr: 0.000001  loss: 0.2526 (0.2418)  labels_encoder: 0.1336 (0.1246)  labels_decoder: 0.1198 (0.1172)  labels_encoder_unscaled: 0.1336 (0.1246)  labels_decoder_unscaled: 0.2396 (0.2344)  time: 0.1424  data: 0.0003  max mem: 3384
Epoch: [3]  [ 800/1404]  eta: 0:01:24  lr: 0.000001  loss: 0.2423 (0.2415)  labels_encoder: 0.1242 (0.1244)  labels_decoder: 0.1129 (0.1171)  labels_encoder_unscaled: 0.1242 (0.1244)  labels_decoder_unscaled: 0.2258 (0.2342)  time: 0.1369  data: 0.0003  max mem: 3384
Epoch: [3]  [ 850/1404]  eta: 0:01:17  lr: 0.000001  loss: 0.2315 (0.2412)  labels_encoder: 0.1167 (0.1244)  labels_decoder: 0.1112 (0.1169)  labels_encoder_unscaled: 0.1167 (0.1244)  labels_decoder_unscaled: 0.2223 (0.2337)  time: 0.1363  data: 0.0003  max mem: 3384
Epoch: [3]  [ 900/1404]  eta: 0:01:10  lr: 0.000001  loss: 0.2446 (0.2412)  labels_encoder: 0.1327 (0.1244)  labels_decoder: 0.1188 (0.1168)  labels_encoder_unscaled: 0.1327 (0.1244)  labels_decoder_unscaled: 0.2375 (0.2336)  time: 0.1378  data: 0.0003  max mem: 3384
Epoch: [3]  [ 950/1404]  eta: 0:01:03  lr: 0.000001  loss: 0.2236 (0.2408)  labels_encoder: 0.1083 (0.1241)  labels_decoder: 0.1111 (0.1167)  labels_encoder_unscaled: 0.1083 (0.1241)  labels_decoder_unscaled: 0.2222 (0.2335)  time: 0.1376  data: 0.0003  max mem: 3384
Epoch: [3]  [1000/1404]  eta: 0:00:56  lr: 0.000001  loss: 0.2412 (0.2402)  labels_encoder: 0.1318 (0.1238)  labels_decoder: 0.1110 (0.1164)  labels_encoder_unscaled: 0.1318 (0.1238)  labels_decoder_unscaled: 0.2221 (0.2328)  time: 0.1347  data: 0.0003  max mem: 3384
Epoch: [3]  [1050/1404]  eta: 0:00:49  lr: 0.000001  loss: 0.2364 (0.2401)  labels_encoder: 0.1238 (0.1238)  labels_decoder: 0.1092 (0.1164)  labels_encoder_unscaled: 0.1238 (0.1238)  labels_decoder_unscaled: 0.2183 (0.2328)  time: 0.1344  data: 0.0003  max mem: 3384
Epoch: [3]  [1100/1404]  eta: 0:00:42  lr: 0.000001  loss: 0.2526 (0.2409)  labels_encoder: 0.1261 (0.1242)  labels_decoder: 0.1223 (0.1167)  labels_encoder_unscaled: 0.1261 (0.1242)  labels_decoder_unscaled: 0.2446 (0.2333)  time: 0.1400  data: 0.0003  max mem: 3384
Epoch: [3]  [1150/1404]  eta: 0:00:35  lr: 0.000001  loss: 0.2509 (0.2412)  labels_encoder: 0.1419 (0.1245)  labels_decoder: 0.1142 (0.1167)  labels_encoder_unscaled: 0.1419 (0.1245)  labels_decoder_unscaled: 0.2284 (0.2335)  time: 0.1350  data: 0.0003  max mem: 3384
Epoch: [3]  [1200/1404]  eta: 0:00:28  lr: 0.000001  loss: 0.2279 (0.2412)  labels_encoder: 0.1140 (0.1244)  labels_decoder: 0.1139 (0.1168)  labels_encoder_unscaled: 0.1140 (0.1244)  labels_decoder_unscaled: 0.2279 (0.2336)  time: 0.1324  data: 0.0003  max mem: 3384
Epoch: [3]  [1250/1404]  eta: 0:00:21  lr: 0.000001  loss: 0.2302 (0.2405)  labels_encoder: 0.1169 (0.1240)  labels_decoder: 0.1046 (0.1165)  labels_encoder_unscaled: 0.1169 (0.1240)  labels_decoder_unscaled: 0.2092 (0.2329)  time: 0.1369  data: 0.0003  max mem: 3384
Epoch: [3]  [1300/1404]  eta: 0:00:14  lr: 0.000001  loss: 0.2071 (0.2401)  labels_encoder: 0.1042 (0.1238)  labels_decoder: 0.1017 (0.1163)  labels_encoder_unscaled: 0.1042 (0.1238)  labels_decoder_unscaled: 0.2034 (0.2326)  time: 0.1369  data: 0.0003  max mem: 3384
Epoch: [3]  [1350/1404]  eta: 0:00:07  lr: 0.000001  loss: 0.2302 (0.2402)  labels_encoder: 0.1229 (0.1238)  labels_decoder: 0.1088 (0.1163)  labels_encoder_unscaled: 0.1229 (0.1238)  labels_decoder_unscaled: 0.2176 (0.2326)  time: 0.1364  data: 0.0003  max mem: 3384
Epoch: [3]  [1400/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2305 (0.2403)  labels_encoder: 0.1314 (0.1238)  labels_decoder: 0.1141 (0.1165)  labels_encoder_unscaled: 0.1314 (0.1238)  labels_decoder_unscaled: 0.2283 (0.2329)  time: 0.1215  data: 0.0003  max mem: 3384
Epoch: [3]  [1403/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2267 (0.2402)  labels_encoder: 0.1088 (0.1237)  labels_decoder: 0.1133 (0.1164)  labels_encoder_unscaled: 0.1088 (0.1237)  labels_decoder_unscaled: 0.2266 (0.2329)  time: 0.1192  data: 0.0002  max mem: 3384
Epoch: [3] Total time: 0:03:14 (0.1383 s / it)
Averaged stats: lr: 0.000001  loss: 0.2267 (0.2402)  labels_encoder: 0.1088 (0.1237)  labels_decoder: 0.1133 (0.1164)  labels_encoder_unscaled: 0.1088 (0.1237)  labels_decoder_unscaled: 0.2266 (0.2329)
Test:  [   0/1613]  eta: 0:39:57  loss: 0.5135 (0.5135)  labels_encoder: 0.2820 (0.2820)  labels_decoder: 0.2315 (0.2315)  labels_encoder_unscaled: 0.2820 (0.2820)  labels_decoder_unscaled: 0.4630 (0.4630)  time: 1.4864  data: 1.4025  max mem: 3384
Test:  [  50/1613]  eta: 0:02:31  loss: 0.5349 (1.0177)  labels_encoder: 0.2942 (0.6557)  labels_decoder: 0.2179 (0.3620)  labels_encoder_unscaled: 0.2942 (0.6557)  labels_decoder_unscaled: 0.4358 (0.7240)  time: 0.0649  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:02:01  loss: 0.0987 (0.8117)  labels_encoder: 0.0682 (0.5261)  labels_decoder: 0.0342 (0.2856)  labels_encoder_unscaled: 0.0682 (0.5261)  labels_decoder_unscaled: 0.0683 (0.5713)  time: 0.0638  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:50  loss: 0.8593 (0.7693)  labels_encoder: 0.5395 (0.4960)  labels_decoder: 0.2897 (0.2734)  labels_encoder_unscaled: 0.5395 (0.4960)  labels_decoder_unscaled: 0.5794 (0.5468)  time: 0.0663  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:43  loss: 1.0274 (0.8931)  labels_encoder: 0.6111 (0.5772)  labels_decoder: 0.3851 (0.3160)  labels_encoder_unscaled: 0.6111 (0.5772)  labels_decoder_unscaled: 0.7702 (0.6320)  time: 0.0641  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:37  loss: 0.6758 (0.9530)  labels_encoder: 0.4176 (0.6142)  labels_decoder: 0.2582 (0.3388)  labels_encoder_unscaled: 0.4176 (0.6142)  labels_decoder_unscaled: 0.5163 (0.6776)  time: 0.0668  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:33  loss: 0.5831 (0.9747)  labels_encoder: 0.4111 (0.6333)  labels_decoder: 0.2216 (0.3414)  labels_encoder_unscaled: 0.4111 (0.6333)  labels_decoder_unscaled: 0.4432 (0.6828)  time: 0.0646  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:28  loss: 1.2589 (0.9886)  labels_encoder: 0.7517 (0.6360)  labels_decoder: 0.5212 (0.3526)  labels_encoder_unscaled: 0.7517 (0.6360)  labels_decoder_unscaled: 1.0423 (0.7052)  time: 0.0677  data: 0.0012  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:24  loss: 0.9202 (1.1474)  labels_encoder: 0.6117 (0.7473)  labels_decoder: 0.3918 (0.4001)  labels_encoder_unscaled: 0.6117 (0.7473)  labels_decoder_unscaled: 0.7837 (0.8003)  time: 0.0651  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:20  loss: 1.2215 (1.2479)  labels_encoder: 0.7571 (0.8153)  labels_decoder: 0.3709 (0.4326)  labels_encoder_unscaled: 0.7571 (0.8153)  labels_decoder_unscaled: 0.7418 (0.8652)  time: 0.0665  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:17  loss: 0.4052 (1.1915)  labels_encoder: 0.1885 (0.7754)  labels_decoder: 0.1860 (0.4161)  labels_encoder_unscaled: 0.1885 (0.7754)  labels_decoder_unscaled: 0.3719 (0.8321)  time: 0.0722  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:13  loss: 0.8838 (1.1945)  labels_encoder: 0.5866 (0.7768)  labels_decoder: 0.3018 (0.4177)  labels_encoder_unscaled: 0.5866 (0.7768)  labels_decoder_unscaled: 0.6036 (0.8354)  time: 0.0668  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:10  loss: 1.4447 (1.2382)  labels_encoder: 0.8136 (0.8156)  labels_decoder: 0.5808 (0.4226)  labels_encoder_unscaled: 0.8136 (0.8156)  labels_decoder_unscaled: 1.1617 (0.8452)  time: 0.0683  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:06  loss: 0.8647 (1.2174)  labels_encoder: 0.4091 (0.7974)  labels_decoder: 0.4350 (0.4200)  labels_encoder_unscaled: 0.4091 (0.7974)  labels_decoder_unscaled: 0.8700 (0.8401)  time: 0.0680  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:01:02  loss: 0.4797 (1.1872)  labels_encoder: 0.3003 (0.7765)  labels_decoder: 0.2060 (0.4107)  labels_encoder_unscaled: 0.3003 (0.7765)  labels_decoder_unscaled: 0.4120 (0.8215)  time: 0.0649  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:59  loss: 0.7421 (1.1601)  labels_encoder: 0.4202 (0.7573)  labels_decoder: 0.2796 (0.4029)  labels_encoder_unscaled: 0.4202 (0.7573)  labels_decoder_unscaled: 0.5592 (0.8058)  time: 0.0666  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:55  loss: 0.7790 (1.1523)  labels_encoder: 0.4915 (0.7522)  labels_decoder: 0.2876 (0.4001)  labels_encoder_unscaled: 0.4915 (0.7522)  labels_decoder_unscaled: 0.5751 (0.8003)  time: 0.0677  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:52  loss: 1.5840 (1.1595)  labels_encoder: 1.0919 (0.7545)  labels_decoder: 0.6114 (0.4050)  labels_encoder_unscaled: 1.0919 (0.7545)  labels_decoder_unscaled: 1.2229 (0.8099)  time: 0.0650  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:48  loss: 0.8293 (1.1845)  labels_encoder: 0.5052 (0.7724)  labels_decoder: 0.3192 (0.4121)  labels_encoder_unscaled: 0.5052 (0.7724)  labels_decoder_unscaled: 0.6384 (0.8242)  time: 0.0634  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:45  loss: 1.0462 (1.1746)  labels_encoder: 0.7586 (0.7658)  labels_decoder: 0.2854 (0.4088)  labels_encoder_unscaled: 0.7586 (0.7658)  labels_decoder_unscaled: 0.5709 (0.8175)  time: 0.0646  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:41  loss: 0.6588 (1.1588)  labels_encoder: 0.3846 (0.7546)  labels_decoder: 0.2814 (0.4042)  labels_encoder_unscaled: 0.3846 (0.7546)  labels_decoder_unscaled: 0.5629 (0.8085)  time: 0.0656  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:38  loss: 0.8258 (1.1496)  labels_encoder: 0.4868 (0.7482)  labels_decoder: 0.3282 (0.4014)  labels_encoder_unscaled: 0.4868 (0.7482)  labels_decoder_unscaled: 0.6564 (0.8028)  time: 0.0644  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:34  loss: 0.7842 (1.1540)  labels_encoder: 0.4717 (0.7513)  labels_decoder: 0.4172 (0.4026)  labels_encoder_unscaled: 0.4717 (0.7513)  labels_decoder_unscaled: 0.8343 (0.8053)  time: 0.0641  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:31  loss: 0.6492 (1.1430)  labels_encoder: 0.3698 (0.7436)  labels_decoder: 0.2663 (0.3995)  labels_encoder_unscaled: 0.3698 (0.7436)  labels_decoder_unscaled: 0.5325 (0.7990)  time: 0.0610  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:27  loss: 0.6874 (1.1494)  labels_encoder: 0.3928 (0.7466)  labels_decoder: 0.2796 (0.4028)  labels_encoder_unscaled: 0.3928 (0.7466)  labels_decoder_unscaled: 0.5591 (0.8056)  time: 0.0637  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:24  loss: 0.5160 (1.1488)  labels_encoder: 0.2858 (0.7458)  labels_decoder: 0.2303 (0.4030)  labels_encoder_unscaled: 0.2858 (0.7458)  labels_decoder_unscaled: 0.4605 (0.8061)  time: 0.0672  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:21  loss: 0.6024 (1.1369)  labels_encoder: 0.3559 (0.7375)  labels_decoder: 0.2134 (0.3993)  labels_encoder_unscaled: 0.3559 (0.7375)  labels_decoder_unscaled: 0.4267 (0.7987)  time: 0.0661  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:17  loss: 0.7536 (1.1533)  labels_encoder: 0.4365 (0.7490)  labels_decoder: 0.3278 (0.4043)  labels_encoder_unscaled: 0.4365 (0.7490)  labels_decoder_unscaled: 0.6557 (0.8086)  time: 0.0635  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:14  loss: 1.0724 (1.1483)  labels_encoder: 0.7092 (0.7454)  labels_decoder: 0.3919 (0.4028)  labels_encoder_unscaled: 0.7092 (0.7454)  labels_decoder_unscaled: 0.7838 (0.8056)  time: 0.0660  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.6118 (1.1585)  labels_encoder: 0.2859 (0.7521)  labels_decoder: 0.2744 (0.4064)  labels_encoder_unscaled: 0.2859 (0.7521)  labels_decoder_unscaled: 0.5488 (0.8129)  time: 0.0627  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.7778 (1.1753)  labels_encoder: 0.4962 (0.7641)  labels_decoder: 0.3163 (0.4112)  labels_encoder_unscaled: 0.4962 (0.7641)  labels_decoder_unscaled: 0.6326 (0.8224)  time: 0.0616  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:04  loss: 0.7696 (1.1690)  labels_encoder: 0.4744 (0.7599)  labels_decoder: 0.2911 (0.4091)  labels_encoder_unscaled: 0.4744 (0.7599)  labels_decoder_unscaled: 0.5821 (0.8182)  time: 0.0648  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8689 (1.1625)  labels_encoder: 0.5598 (0.7552)  labels_decoder: 0.3091 (0.4073)  labels_encoder_unscaled: 0.5598 (0.7552)  labels_decoder_unscaled: 0.6181 (0.8146)  time: 0.0619  data: 0.0002  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6660 (1.1597)  labels_encoder: 0.4044 (0.7535)  labels_decoder: 0.2814 (0.4061)  labels_encoder_unscaled: 0.4044 (0.7535)  labels_decoder_unscaled: 0.5627 (0.8122)  time: 0.0485  data: 0.0001  max mem: 3384
Test: Total time: 0:01:47 (0.0667 s / it)
Averaged stats: loss: 0.6660 (1.1597)  labels_encoder: 0.4044 (0.7535)  labels_decoder: 0.2814 (0.4061)  labels_encoder_unscaled: 0.4044 (0.7535)  labels_decoder_unscaled: 0.5627 (0.8122)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet] mAP: 0.5747

dec_mAP all together: | 0.4487394645065842 |.
dec_mAP_pred | 0 : 0.49127607638095727 |.
dec_mAP_pred | 1 : 0.4833129012475676 |.
dec_mAP_pred | 2 : 0.4714548838760787 |.
dec_mAP_pred | 3 : 0.458352487425049 |.
dec_mAP_pred | 4 : 0.4441810084286633 |.
dec_mAP_pred | 5 : 0.4302210509982315 |.
dec_mAP_pred | 6 : 0.4167053865800292 |.
dec_mAP_pred | 7 : 0.40375065205171917 |.
all decoder map: | 0.4499 |.
BaseballPitch: 0.2134
BasketballDunk: 0.7733
Billiards: 0.4332
CleanAndJerk: 0.7533
CliffDiving: 0.8118
CricketBowling: 0.4005
CricketShot: 0.1883
Diving: 0.6642
FrisbeeCatch: 0.3912
GolfSwing: 0.6013
HammerThrow: 0.8542
HighJump: 0.6209
JavelinThrow: 0.7059
LongJump: 0.7846
PoleVault: 0.8515
Shotput: 0.6879
SoccerPenalty: 0.3287
TennisSwing: 0.5768
ThrowDiscus: 0.5743
VolleyballSpiking: 0.2779
Epoch: [4]  [   0/1404]  eta: 0:34:29  lr: 0.000000  loss: 0.2243 (0.2243)  labels_encoder: 0.1242 (0.1242)  labels_decoder: 0.1001 (0.1001)  labels_encoder_unscaled: 0.1242 (0.1242)  labels_decoder_unscaled: 0.2001 (0.2001)  time: 1.4740  data: 1.3054  max mem: 3384
Epoch: [4]  [  50/1404]  eta: 0:03:41  lr: 0.000000  loss: 0.2227 (0.2337)  labels_encoder: 0.1130 (0.1188)  labels_decoder: 0.1099 (0.1149)  labels_encoder_unscaled: 0.1130 (0.1188)  labels_decoder_unscaled: 0.2198 (0.2299)  time: 0.1370  data: 0.0003  max mem: 3384
Epoch: [4]  [ 100/1404]  eta: 0:03:15  lr: 0.000000  loss: 0.2336 (0.2392)  labels_encoder: 0.1229 (0.1221)  labels_decoder: 0.1208 (0.1172)  labels_encoder_unscaled: 0.1229 (0.1221)  labels_decoder_unscaled: 0.2415 (0.2343)  time: 0.1385  data: 0.0003  max mem: 3384
Epoch: [4]  [ 150/1404]  eta: 0:03:02  lr: 0.000000  loss: 0.2276 (0.2377)  labels_encoder: 0.1072 (0.1211)  labels_decoder: 0.1105 (0.1166)  labels_encoder_unscaled: 0.1072 (0.1211)  labels_decoder_unscaled: 0.2209 (0.2333)  time: 0.1356  data: 0.0002  max mem: 3384
Epoch: [4]  [ 200/1404]  eta: 0:02:53  lr: 0.000000  loss: 0.2224 (0.2378)  labels_encoder: 0.1107 (0.1222)  labels_decoder: 0.1096 (0.1156)  labels_encoder_unscaled: 0.1107 (0.1222)  labels_decoder_unscaled: 0.2192 (0.2312)  time: 0.1431  data: 0.0003  max mem: 3384
Epoch: [4]  [ 250/1404]  eta: 0:02:44  lr: 0.000000  loss: 0.2108 (0.2382)  labels_encoder: 0.1109 (0.1229)  labels_decoder: 0.1027 (0.1153)  labels_encoder_unscaled: 0.1109 (0.1229)  labels_decoder_unscaled: 0.2053 (0.2307)  time: 0.1384  data: 0.0003  max mem: 3384
Epoch: [4]  [ 300/1404]  eta: 0:02:36  lr: 0.000000  loss: 0.2356 (0.2387)  labels_encoder: 0.1228 (0.1231)  labels_decoder: 0.1133 (0.1156)  labels_encoder_unscaled: 0.1228 (0.1231)  labels_decoder_unscaled: 0.2267 (0.2312)  time: 0.1328  data: 0.0003  max mem: 3384
Epoch: [4]  [ 350/1404]  eta: 0:02:28  lr: 0.000000  loss: 0.2228 (0.2361)  labels_encoder: 0.1109 (0.1209)  labels_decoder: 0.1142 (0.1152)  labels_encoder_unscaled: 0.1109 (0.1209)  labels_decoder_unscaled: 0.2284 (0.2304)  time: 0.1331  data: 0.0003  max mem: 3384
Epoch: [4]  [ 400/1404]  eta: 0:02:20  lr: 0.000000  loss: 0.2386 (0.2368)  labels_encoder: 0.1336 (0.1218)  labels_decoder: 0.1156 (0.1150)  labels_encoder_unscaled: 0.1336 (0.1218)  labels_decoder_unscaled: 0.2313 (0.2300)  time: 0.1342  data: 0.0003  max mem: 3384
Epoch: [4]  [ 450/1404]  eta: 0:02:12  lr: 0.000000  loss: 0.2345 (0.2366)  labels_encoder: 0.1217 (0.1216)  labels_decoder: 0.1147 (0.1151)  labels_encoder_unscaled: 0.1217 (0.1216)  labels_decoder_unscaled: 0.2294 (0.2301)  time: 0.1336  data: 0.0002  max mem: 3384
Epoch: [4]  [ 500/1404]  eta: 0:02:05  lr: 0.000000  loss: 0.2292 (0.2368)  labels_encoder: 0.1231 (0.1215)  labels_decoder: 0.1138 (0.1154)  labels_encoder_unscaled: 0.1231 (0.1215)  labels_decoder_unscaled: 0.2276 (0.2307)  time: 0.1319  data: 0.0003  max mem: 3384
Epoch: [4]  [ 550/1404]  eta: 0:01:57  lr: 0.000000  loss: 0.2465 (0.2375)  labels_encoder: 0.1261 (0.1220)  labels_decoder: 0.1123 (0.1155)  labels_encoder_unscaled: 0.1261 (0.1220)  labels_decoder_unscaled: 0.2246 (0.2310)  time: 0.1355  data: 0.0003  max mem: 3384
Epoch: [4]  [ 600/1404]  eta: 0:01:50  lr: 0.000000  loss: 0.2220 (0.2372)  labels_encoder: 0.1141 (0.1220)  labels_decoder: 0.1133 (0.1152)  labels_encoder_unscaled: 0.1141 (0.1220)  labels_decoder_unscaled: 0.2266 (0.2304)  time: 0.1342  data: 0.0003  max mem: 3384
Epoch: [4]  [ 650/1404]  eta: 0:01:43  lr: 0.000000  loss: 0.2364 (0.2373)  labels_encoder: 0.1251 (0.1222)  labels_decoder: 0.1168 (0.1151)  labels_encoder_unscaled: 0.1251 (0.1222)  labels_decoder_unscaled: 0.2337 (0.2303)  time: 0.1360  data: 0.0003  max mem: 3384
Epoch: [4]  [ 700/1404]  eta: 0:01:36  lr: 0.000000  loss: 0.2294 (0.2372)  labels_encoder: 0.1100 (0.1220)  labels_decoder: 0.1112 (0.1151)  labels_encoder_unscaled: 0.1100 (0.1220)  labels_decoder_unscaled: 0.2224 (0.2303)  time: 0.1328  data: 0.0003  max mem: 3384
Epoch: [4]  [ 750/1404]  eta: 0:01:29  lr: 0.000000  loss: 0.2343 (0.2368)  labels_encoder: 0.1185 (0.1216)  labels_decoder: 0.1167 (0.1153)  labels_encoder_unscaled: 0.1185 (0.1216)  labels_decoder_unscaled: 0.2334 (0.2306)  time: 0.1332  data: 0.0012  max mem: 3384
Epoch: [4]  [ 800/1404]  eta: 0:01:22  lr: 0.000000  loss: 0.2158 (0.2360)  labels_encoder: 0.0967 (0.1209)  labels_decoder: 0.1128 (0.1151)  labels_encoder_unscaled: 0.0967 (0.1209)  labels_decoder_unscaled: 0.2255 (0.2303)  time: 0.1323  data: 0.0003  max mem: 3384
Epoch: [4]  [ 850/1404]  eta: 0:01:15  lr: 0.000000  loss: 0.2276 (0.2357)  labels_encoder: 0.1095 (0.1207)  labels_decoder: 0.1117 (0.1149)  labels_encoder_unscaled: 0.1095 (0.1207)  labels_decoder_unscaled: 0.2233 (0.2299)  time: 0.1412  data: 0.0003  max mem: 3384
Epoch: [4]  [ 900/1404]  eta: 0:01:08  lr: 0.000000  loss: 0.2209 (0.2356)  labels_encoder: 0.1029 (0.1208)  labels_decoder: 0.1137 (0.1148)  labels_encoder_unscaled: 0.1029 (0.1208)  labels_decoder_unscaled: 0.2274 (0.2297)  time: 0.1327  data: 0.0003  max mem: 3384
Epoch: [4]  [ 950/1404]  eta: 0:01:01  lr: 0.000000  loss: 0.2206 (0.2355)  labels_encoder: 0.1092 (0.1208)  labels_decoder: 0.1067 (0.1148)  labels_encoder_unscaled: 0.1092 (0.1208)  labels_decoder_unscaled: 0.2135 (0.2295)  time: 0.1288  data: 0.0003  max mem: 3384
Epoch: [4]  [1000/1404]  eta: 0:00:55  lr: 0.000000  loss: 0.2371 (0.2359)  labels_encoder: 0.1248 (0.1211)  labels_decoder: 0.1091 (0.1149)  labels_encoder_unscaled: 0.1248 (0.1211)  labels_decoder_unscaled: 0.2183 (0.2298)  time: 0.1344  data: 0.0003  max mem: 3384
Epoch: [4]  [1050/1404]  eta: 0:00:48  lr: 0.000000  loss: 0.2177 (0.2360)  labels_encoder: 0.1116 (0.1211)  labels_decoder: 0.1100 (0.1150)  labels_encoder_unscaled: 0.1116 (0.1211)  labels_decoder_unscaled: 0.2200 (0.2299)  time: 0.1373  data: 0.0003  max mem: 3384
Epoch: [4]  [1100/1404]  eta: 0:00:41  lr: 0.000000  loss: 0.2325 (0.2362)  labels_encoder: 0.1190 (0.1212)  labels_decoder: 0.1167 (0.1150)  labels_encoder_unscaled: 0.1190 (0.1212)  labels_decoder_unscaled: 0.2334 (0.2301)  time: 0.1346  data: 0.0003  max mem: 3384
Epoch: [4]  [1150/1404]  eta: 0:00:34  lr: 0.000000  loss: 0.2431 (0.2363)  labels_encoder: 0.1261 (0.1212)  labels_decoder: 0.1194 (0.1151)  labels_encoder_unscaled: 0.1261 (0.1212)  labels_decoder_unscaled: 0.2388 (0.2302)  time: 0.1394  data: 0.0003  max mem: 3384
Epoch: [4]  [1200/1404]  eta: 0:00:27  lr: 0.000000  loss: 0.2211 (0.2361)  labels_encoder: 0.1124 (0.1211)  labels_decoder: 0.1096 (0.1150)  labels_encoder_unscaled: 0.1124 (0.1211)  labels_decoder_unscaled: 0.2192 (0.2301)  time: 0.1343  data: 0.0003  max mem: 3384
Epoch: [4]  [1250/1404]  eta: 0:00:20  lr: 0.000000  loss: 0.2326 (0.2363)  labels_encoder: 0.1151 (0.1211)  labels_decoder: 0.1181 (0.1151)  labels_encoder_unscaled: 0.1151 (0.1211)  labels_decoder_unscaled: 0.2363 (0.2303)  time: 0.1367  data: 0.0003  max mem: 3384
Epoch: [4]  [1300/1404]  eta: 0:00:14  lr: 0.000000  loss: 0.2196 (0.2363)  labels_encoder: 0.1105 (0.1212)  labels_decoder: 0.1095 (0.1151)  labels_encoder_unscaled: 0.1105 (0.1212)  labels_decoder_unscaled: 0.2189 (0.2303)  time: 0.1355  data: 0.0003  max mem: 3384
Epoch: [4]  [1350/1404]  eta: 0:00:07  lr: 0.000000  loss: 0.2140 (0.2362)  labels_encoder: 0.1048 (0.1210)  labels_decoder: 0.1072 (0.1151)  labels_encoder_unscaled: 0.1048 (0.1210)  labels_decoder_unscaled: 0.2144 (0.2302)  time: 0.1355  data: 0.0003  max mem: 3384
Epoch: [4]  [1400/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2385 (0.2364)  labels_encoder: 0.1234 (0.1212)  labels_decoder: 0.1126 (0.1151)  labels_encoder_unscaled: 0.1234 (0.1212)  labels_decoder_unscaled: 0.2252 (0.2303)  time: 0.1257  data: 0.0003  max mem: 3384
Epoch: [4]  [1403/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2391 (0.2363)  labels_encoder: 0.1223 (0.1212)  labels_decoder: 0.1126 (0.1151)  labels_encoder_unscaled: 0.1223 (0.1212)  labels_decoder_unscaled: 0.2252 (0.2303)  time: 0.1226  data: 0.0003  max mem: 3384
Epoch: [4] Total time: 0:03:10 (0.1359 s / it)
Averaged stats: lr: 0.000000  loss: 0.2391 (0.2363)  labels_encoder: 0.1223 (0.1212)  labels_decoder: 0.1126 (0.1151)  labels_encoder_unscaled: 0.1223 (0.1212)  labels_decoder_unscaled: 0.2252 (0.2303)
Test:  [   0/1613]  eta: 0:34:47  loss: 0.5291 (0.5291)  labels_encoder: 0.2973 (0.2973)  labels_decoder: 0.2318 (0.2318)  labels_encoder_unscaled: 0.2973 (0.2973)  labels_decoder_unscaled: 0.4635 (0.4635)  time: 1.2942  data: 1.2302  max mem: 3384
Test:  [  50/1613]  eta: 0:02:06  loss: 0.5269 (1.0136)  labels_encoder: 0.2989 (0.6514)  labels_decoder: 0.2169 (0.3622)  labels_encoder_unscaled: 0.2989 (0.6514)  labels_decoder_unscaled: 0.4338 (0.7244)  time: 0.0558  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:47  loss: 0.1105 (0.8111)  labels_encoder: 0.0784 (0.5247)  labels_decoder: 0.0386 (0.2864)  labels_encoder_unscaled: 0.0784 (0.5247)  labels_decoder_unscaled: 0.0773 (0.5727)  time: 0.0601  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:40  loss: 0.8864 (0.7688)  labels_encoder: 0.5613 (0.4948)  labels_decoder: 0.2926 (0.2740)  labels_encoder_unscaled: 0.5613 (0.4948)  labels_decoder_unscaled: 0.5853 (0.5480)  time: 0.0667  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:34  loss: 1.0193 (0.8943)  labels_encoder: 0.6048 (0.5769)  labels_decoder: 0.3831 (0.3174)  labels_encoder_unscaled: 0.6048 (0.5769)  labels_decoder_unscaled: 0.7661 (0.6348)  time: 0.0606  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:30  loss: 0.6742 (0.9555)  labels_encoder: 0.4230 (0.6151)  labels_decoder: 0.2613 (0.3404)  labels_encoder_unscaled: 0.4230 (0.6151)  labels_decoder_unscaled: 0.5226 (0.6809)  time: 0.0619  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:26  loss: 0.5488 (0.9727)  labels_encoder: 0.3860 (0.6310)  labels_decoder: 0.2201 (0.3417)  labels_encoder_unscaled: 0.3860 (0.6310)  labels_decoder_unscaled: 0.4403 (0.6834)  time: 0.0636  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:21  loss: 1.2324 (0.9872)  labels_encoder: 0.7477 (0.6342)  labels_decoder: 0.5192 (0.3531)  labels_encoder_unscaled: 0.7477 (0.6342)  labels_decoder_unscaled: 1.0384 (0.7062)  time: 0.0609  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:18  loss: 0.9578 (1.1445)  labels_encoder: 0.6204 (0.7444)  labels_decoder: 0.3988 (0.4001)  labels_encoder_unscaled: 0.6204 (0.7444)  labels_decoder_unscaled: 0.7976 (0.8002)  time: 0.0633  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:15  loss: 1.2207 (1.2452)  labels_encoder: 0.7634 (0.8126)  labels_decoder: 0.4065 (0.4326)  labels_encoder_unscaled: 0.7634 (0.8126)  labels_decoder_unscaled: 0.8131 (0.8652)  time: 0.0644  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:11  loss: 0.4008 (1.1888)  labels_encoder: 0.2018 (0.7728)  labels_decoder: 0.1825 (0.4160)  labels_encoder_unscaled: 0.2018 (0.7728)  labels_decoder_unscaled: 0.3650 (0.8320)  time: 0.0642  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:08  loss: 0.9102 (1.1927)  labels_encoder: 0.5898 (0.7745)  labels_decoder: 0.3204 (0.4182)  labels_encoder_unscaled: 0.5898 (0.7745)  labels_decoder_unscaled: 0.6408 (0.8363)  time: 0.0629  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:04  loss: 1.4730 (1.2346)  labels_encoder: 0.8333 (0.8118)  labels_decoder: 0.6272 (0.4228)  labels_encoder_unscaled: 0.8333 (0.8118)  labels_decoder_unscaled: 1.2545 (0.8455)  time: 0.0616  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:01  loss: 0.8181 (1.2127)  labels_encoder: 0.3847 (0.7930)  labels_decoder: 0.4256 (0.4197)  labels_encoder_unscaled: 0.3847 (0.7930)  labels_decoder_unscaled: 0.8512 (0.8394)  time: 0.0599  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:00:58  loss: 0.4811 (1.1829)  labels_encoder: 0.2985 (0.7724)  labels_decoder: 0.2059 (0.4105)  labels_encoder_unscaled: 0.2985 (0.7724)  labels_decoder_unscaled: 0.4117 (0.8209)  time: 0.0607  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:54  loss: 0.7246 (1.1557)  labels_encoder: 0.4095 (0.7532)  labels_decoder: 0.2727 (0.4025)  labels_encoder_unscaled: 0.4095 (0.7532)  labels_decoder_unscaled: 0.5454 (0.8049)  time: 0.0628  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:51  loss: 0.7575 (1.1487)  labels_encoder: 0.4717 (0.7487)  labels_decoder: 0.2858 (0.3999)  labels_encoder_unscaled: 0.4717 (0.7487)  labels_decoder_unscaled: 0.5716 (0.7999)  time: 0.0582  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:48  loss: 1.5655 (1.1561)  labels_encoder: 1.0778 (0.7513)  labels_decoder: 0.6119 (0.4048)  labels_encoder_unscaled: 1.0778 (0.7513)  labels_decoder_unscaled: 1.2239 (0.8096)  time: 0.0634  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:45  loss: 0.8020 (1.1818)  labels_encoder: 0.4874 (0.7697)  labels_decoder: 0.3021 (0.4121)  labels_encoder_unscaled: 0.4874 (0.7697)  labels_decoder_unscaled: 0.6041 (0.8242)  time: 0.0642  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:41  loss: 1.0398 (1.1722)  labels_encoder: 0.7500 (0.7635)  labels_decoder: 0.2780 (0.4088)  labels_encoder_unscaled: 0.7500 (0.7635)  labels_decoder_unscaled: 0.5561 (0.8176)  time: 0.0594  data: 0.0011  max mem: 3384
Test:  [1000/1613]  eta: 0:00:38  loss: 0.6635 (1.1565)  labels_encoder: 0.3899 (0.7523)  labels_decoder: 0.2878 (0.4042)  labels_encoder_unscaled: 0.3899 (0.7523)  labels_decoder_unscaled: 0.5757 (0.8085)  time: 0.0641  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:35  loss: 0.8265 (1.1475)  labels_encoder: 0.4970 (0.7461)  labels_decoder: 0.3268 (0.4014)  labels_encoder_unscaled: 0.4970 (0.7461)  labels_decoder_unscaled: 0.6536 (0.8029)  time: 0.0632  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:32  loss: 0.7588 (1.1512)  labels_encoder: 0.4627 (0.7488)  labels_decoder: 0.4103 (0.4024)  labels_encoder_unscaled: 0.4627 (0.7488)  labels_decoder_unscaled: 0.8207 (0.8048)  time: 0.0586  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:29  loss: 0.5967 (1.1402)  labels_encoder: 0.3547 (0.7410)  labels_decoder: 0.2577 (0.3991)  labels_encoder_unscaled: 0.3547 (0.7410)  labels_decoder_unscaled: 0.5154 (0.7982)  time: 0.0616  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:25  loss: 0.6880 (1.1467)  labels_encoder: 0.3933 (0.7442)  labels_decoder: 0.2791 (0.4025)  labels_encoder_unscaled: 0.3933 (0.7442)  labels_decoder_unscaled: 0.5583 (0.8049)  time: 0.0606  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:22  loss: 0.4946 (1.1465)  labels_encoder: 0.2728 (0.7436)  labels_decoder: 0.2219 (0.4028)  labels_encoder_unscaled: 0.2728 (0.7436)  labels_decoder_unscaled: 0.4437 (0.8057)  time: 0.0614  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5943 (1.1341)  labels_encoder: 0.3506 (0.7351)  labels_decoder: 0.2089 (0.3990)  labels_encoder_unscaled: 0.3506 (0.7351)  labels_decoder_unscaled: 0.4178 (0.7979)  time: 0.0619  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:16  loss: 0.7366 (1.1501)  labels_encoder: 0.4439 (0.7463)  labels_decoder: 0.3319 (0.4038)  labels_encoder_unscaled: 0.4439 (0.7463)  labels_decoder_unscaled: 0.6639 (0.8076)  time: 0.0623  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:13  loss: 1.0679 (1.1456)  labels_encoder: 0.7022 (0.7431)  labels_decoder: 0.3897 (0.4026)  labels_encoder_unscaled: 0.7022 (0.7431)  labels_decoder_unscaled: 0.7794 (0.8051)  time: 0.0596  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.6579 (1.1562)  labels_encoder: 0.3023 (0.7499)  labels_decoder: 0.2959 (0.4063)  labels_encoder_unscaled: 0.3023 (0.7499)  labels_decoder_unscaled: 0.5918 (0.8126)  time: 0.0610  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.7695 (1.1732)  labels_encoder: 0.4896 (0.7621)  labels_decoder: 0.3311 (0.4112)  labels_encoder_unscaled: 0.4896 (0.7621)  labels_decoder_unscaled: 0.6621 (0.8223)  time: 0.0608  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:03  loss: 0.7602 (1.1672)  labels_encoder: 0.4624 (0.7581)  labels_decoder: 0.2925 (0.4091)  labels_encoder_unscaled: 0.4624 (0.7581)  labels_decoder_unscaled: 0.5849 (0.8182)  time: 0.0599  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8369 (1.1605)  labels_encoder: 0.5392 (0.7533)  labels_decoder: 0.2977 (0.4073)  labels_encoder_unscaled: 0.5392 (0.7533)  labels_decoder_unscaled: 0.5953 (0.8145)  time: 0.0602  data: 0.0002  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6509 (1.1577)  labels_encoder: 0.3939 (0.7516)  labels_decoder: 0.2843 (0.4061)  labels_encoder_unscaled: 0.3939 (0.7516)  labels_decoder_unscaled: 0.5687 (0.8122)  time: 0.0463  data: 0.0001  max mem: 3384
Test: Total time: 0:01:41 (0.0627 s / it)
Averaged stats: loss: 0.6509 (1.1577)  labels_encoder: 0.3939 (0.7516)  labels_decoder: 0.2843 (0.4061)  labels_encoder_unscaled: 0.3939 (0.7516)  labels_decoder_unscaled: 0.5687 (0.8122)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet] mAP: 0.5746

dec_mAP all together: | 0.4484515303369535 |.
dec_mAP_pred | 0 : 0.49110781475188503 |.
dec_mAP_pred | 1 : 0.4830976615028648 |.
dec_mAP_pred | 2 : 0.47121776771702617 |.
dec_mAP_pred | 3 : 0.45806420624247146 |.
dec_mAP_pred | 4 : 0.4438890507270458 |.
dec_mAP_pred | 5 : 0.4299237027398212 |.
dec_mAP_pred | 6 : 0.4163836476787578 |.
dec_mAP_pred | 7 : 0.40343379690004316 |.
all decoder map: | 0.4496 |.
BaseballPitch: 0.2123
BasketballDunk: 0.7735
Billiards: 0.4333
CleanAndJerk: 0.7527
CliffDiving: 0.8115
CricketBowling: 0.4011
CricketShot: 0.1884
Diving: 0.6642
FrisbeeCatch: 0.3911
GolfSwing: 0.5989
HammerThrow: 0.8544
HighJump: 0.6181
JavelinThrow: 0.7058
LongJump: 0.7854
PoleVault: 0.8506
Shotput: 0.6881
SoccerPenalty: 0.3291
TennisSwing: 0.5774
ThrowDiscus: 0.5782
VolleyballSpiking: 0.2781
Training time 0:22:15
