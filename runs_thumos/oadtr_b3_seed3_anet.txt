Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet
dim_feature:3072
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:3
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  74.578 M, 99.825% Params, 2.446 GMac, 100.000% MACs, 
  (linear_encoding): Linear(3.147 M, 4.212% Params, 0.201 GMac, 8.231% MACs, in_features=3072, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 25.276% Params, 1.227 GMac, 50.169% MACs, 
    (net): Sequential(
      18.884 M, 25.276% Params, 1.227 GMac, 50.169% MACs, 
      (0): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.060% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 70.246% Params, 1.017 GMac, 41.591% MACs, 
    (layers): ModuleList(
      52.48 M, 70.246% Params, 1.017 GMac, 41.591% MACs, 
      (0): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.030% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2445837356.0
Model params: 74709036
Loaded data/thumos_anet_val.pickle
Loaded data/thumos_anet_test.pickle
Start training
Epoch: [1]  [   0/1406]  eta: 0:51:50  lr: 0.000100  loss: 4.5497 (4.5497)  labels_encoder: 2.8814 (2.8814)  labels_decoder: 1.6683 (1.6683)  labels_encoder_unscaled: 2.8814 (2.8814)  labels_decoder_unscaled: 3.3366 (3.3366)  time: 2.2124  data: 1.4482  max mem: 2528
Epoch: [1]  [  50/1406]  eta: 0:03:58  lr: 0.000100  loss: 1.1170 (1.6291)  labels_encoder: 0.7282 (1.0461)  labels_decoder: 0.4015 (0.5830)  labels_encoder_unscaled: 0.7282 (1.0461)  labels_decoder_unscaled: 0.8030 (1.1660)  time: 0.1313  data: 0.0002  max mem: 3384
Epoch: [1]  [ 100/1406]  eta: 0:03:23  lr: 0.000100  loss: 0.8125 (1.2506)  labels_encoder: 0.5026 (0.7937)  labels_decoder: 0.3190 (0.4568)  labels_encoder_unscaled: 0.5026 (0.7937)  labels_decoder_unscaled: 0.6381 (0.9137)  time: 0.1351  data: 0.0002  max mem: 3384
Epoch: [1]  [ 150/1406]  eta: 0:03:08  lr: 0.000100  loss: 0.7131 (1.0835)  labels_encoder: 0.4244 (0.6846)  labels_decoder: 0.2736 (0.3989)  labels_encoder_unscaled: 0.4244 (0.6846)  labels_decoder_unscaled: 0.5471 (0.7978)  time: 0.1393  data: 0.0002  max mem: 3384
Epoch: [1]  [ 200/1406]  eta: 0:02:55  lr: 0.000100  loss: 0.6343 (0.9795)  labels_encoder: 0.3646 (0.6139)  labels_decoder: 0.2533 (0.3657)  labels_encoder_unscaled: 0.3646 (0.6139)  labels_decoder_unscaled: 0.5066 (0.7313)  time: 0.1343  data: 0.0002  max mem: 3384
Epoch: [1]  [ 250/1406]  eta: 0:02:46  lr: 0.000100  loss: 0.6246 (0.9117)  labels_encoder: 0.3843 (0.5697)  labels_decoder: 0.2468 (0.3420)  labels_encoder_unscaled: 0.3843 (0.5697)  labels_decoder_unscaled: 0.4936 (0.6839)  time: 0.1360  data: 0.0002  max mem: 3384
Epoch: [1]  [ 300/1406]  eta: 0:02:37  lr: 0.000100  loss: 0.5770 (0.8578)  labels_encoder: 0.3710 (0.5349)  labels_decoder: 0.2168 (0.3229)  labels_encoder_unscaled: 0.3710 (0.5349)  labels_decoder_unscaled: 0.4336 (0.6459)  time: 0.1393  data: 0.0003  max mem: 3384
Epoch: [1]  [ 350/1406]  eta: 0:02:29  lr: 0.000100  loss: 0.5423 (0.8195)  labels_encoder: 0.3272 (0.5100)  labels_decoder: 0.2300 (0.3095)  labels_encoder_unscaled: 0.3272 (0.5100)  labels_decoder_unscaled: 0.4599 (0.6190)  time: 0.1337  data: 0.0003  max mem: 3384
Epoch: [1]  [ 400/1406]  eta: 0:02:21  lr: 0.000100  loss: 0.5843 (0.7874)  labels_encoder: 0.3386 (0.4887)  labels_decoder: 0.2307 (0.2987)  labels_encoder_unscaled: 0.3386 (0.4887)  labels_decoder_unscaled: 0.4614 (0.5975)  time: 0.1331  data: 0.0003  max mem: 3384
Epoch: [1]  [ 450/1406]  eta: 0:02:13  lr: 0.000100  loss: 0.5150 (0.7618)  labels_encoder: 0.2899 (0.4711)  labels_decoder: 0.2175 (0.2906)  labels_encoder_unscaled: 0.2899 (0.4711)  labels_decoder_unscaled: 0.4350 (0.5813)  time: 0.1329  data: 0.0002  max mem: 3384
Epoch: [1]  [ 500/1406]  eta: 0:02:07  lr: 0.000100  loss: 0.4995 (0.7407)  labels_encoder: 0.2985 (0.4569)  labels_decoder: 0.2020 (0.2838)  labels_encoder_unscaled: 0.2985 (0.4569)  labels_decoder_unscaled: 0.4040 (0.5675)  time: 0.1565  data: 0.0003  max mem: 3384
Epoch: [1]  [ 550/1406]  eta: 0:01:59  lr: 0.000100  loss: 0.5033 (0.7198)  labels_encoder: 0.2990 (0.4426)  labels_decoder: 0.2112 (0.2772)  labels_encoder_unscaled: 0.2990 (0.4426)  labels_decoder_unscaled: 0.4225 (0.5545)  time: 0.1283  data: 0.0002  max mem: 3384
Epoch: [1]  [ 600/1406]  eta: 0:01:52  lr: 0.000100  loss: 0.4995 (0.7015)  labels_encoder: 0.2926 (0.4302)  labels_decoder: 0.2103 (0.2713)  labels_encoder_unscaled: 0.2926 (0.4302)  labels_decoder_unscaled: 0.4205 (0.5426)  time: 0.1382  data: 0.0003  max mem: 3384
Epoch: [1]  [ 650/1406]  eta: 0:01:44  lr: 0.000100  loss: 0.5055 (0.6839)  labels_encoder: 0.2887 (0.4184)  labels_decoder: 0.1923 (0.2655)  labels_encoder_unscaled: 0.2887 (0.4184)  labels_decoder_unscaled: 0.3846 (0.5310)  time: 0.1341  data: 0.0003  max mem: 3384
Epoch: [1]  [ 700/1406]  eta: 0:01:37  lr: 0.000100  loss: 0.4688 (0.6699)  labels_encoder: 0.2644 (0.4093)  labels_decoder: 0.1839 (0.2606)  labels_encoder_unscaled: 0.2644 (0.4093)  labels_decoder_unscaled: 0.3679 (0.5213)  time: 0.1369  data: 0.0011  max mem: 3384
Epoch: [1]  [ 750/1406]  eta: 0:01:30  lr: 0.000100  loss: 0.4517 (0.6557)  labels_encoder: 0.2461 (0.3996)  labels_decoder: 0.1953 (0.2561)  labels_encoder_unscaled: 0.2461 (0.3996)  labels_decoder_unscaled: 0.3907 (0.5122)  time: 0.1381  data: 0.0003  max mem: 3384
Epoch: [1]  [ 800/1406]  eta: 0:01:23  lr: 0.000100  loss: 0.4653 (0.6453)  labels_encoder: 0.2629 (0.3929)  labels_decoder: 0.1938 (0.2524)  labels_encoder_unscaled: 0.2629 (0.3929)  labels_decoder_unscaled: 0.3875 (0.5048)  time: 0.1389  data: 0.0003  max mem: 3384
Epoch: [1]  [ 850/1406]  eta: 0:01:17  lr: 0.000100  loss: 0.4298 (0.6346)  labels_encoder: 0.2364 (0.3856)  labels_decoder: 0.1873 (0.2491)  labels_encoder_unscaled: 0.2364 (0.3856)  labels_decoder_unscaled: 0.3746 (0.4981)  time: 0.1388  data: 0.0003  max mem: 3384
Epoch: [1]  [ 900/1406]  eta: 0:01:10  lr: 0.000100  loss: 0.4358 (0.6236)  labels_encoder: 0.2395 (0.3781)  labels_decoder: 0.1841 (0.2455)  labels_encoder_unscaled: 0.2395 (0.3781)  labels_decoder_unscaled: 0.3682 (0.4909)  time: 0.1403  data: 0.0003  max mem: 3384
Epoch: [1]  [ 950/1406]  eta: 0:01:03  lr: 0.000100  loss: 0.4304 (0.6136)  labels_encoder: 0.2488 (0.3718)  labels_decoder: 0.1673 (0.2418)  labels_encoder_unscaled: 0.2488 (0.3718)  labels_decoder_unscaled: 0.3346 (0.4836)  time: 0.1381  data: 0.0003  max mem: 3384
Epoch: [1]  [1000/1406]  eta: 0:00:56  lr: 0.000100  loss: 0.4039 (0.6046)  labels_encoder: 0.2299 (0.3659)  labels_decoder: 0.1752 (0.2387)  labels_encoder_unscaled: 0.2299 (0.3659)  labels_decoder_unscaled: 0.3503 (0.4775)  time: 0.1402  data: 0.0003  max mem: 3384
Epoch: [1]  [1050/1406]  eta: 0:00:49  lr: 0.000100  loss: 0.4260 (0.5970)  labels_encoder: 0.2377 (0.3607)  labels_decoder: 0.1793 (0.2363)  labels_encoder_unscaled: 0.2377 (0.3607)  labels_decoder_unscaled: 0.3586 (0.4726)  time: 0.1355  data: 0.0003  max mem: 3384
Epoch: [1]  [1100/1406]  eta: 0:00:42  lr: 0.000100  loss: 0.3785 (0.5887)  labels_encoder: 0.2046 (0.3550)  labels_decoder: 0.1736 (0.2338)  labels_encoder_unscaled: 0.2046 (0.3550)  labels_decoder_unscaled: 0.3472 (0.4675)  time: 0.1352  data: 0.0003  max mem: 3384
Epoch: [1]  [1150/1406]  eta: 0:00:35  lr: 0.000100  loss: 0.4134 (0.5814)  labels_encoder: 0.2502 (0.3503)  labels_decoder: 0.1743 (0.2311)  labels_encoder_unscaled: 0.2502 (0.3503)  labels_decoder_unscaled: 0.3486 (0.4622)  time: 0.1415  data: 0.0003  max mem: 3384
Epoch: [1]  [1200/1406]  eta: 0:00:28  lr: 0.000100  loss: 0.4022 (0.5750)  labels_encoder: 0.2310 (0.3462)  labels_decoder: 0.1680 (0.2288)  labels_encoder_unscaled: 0.2310 (0.3462)  labels_decoder_unscaled: 0.3360 (0.4576)  time: 0.1333  data: 0.0003  max mem: 3384
Epoch: [1]  [1250/1406]  eta: 0:00:21  lr: 0.000100  loss: 0.3956 (0.5675)  labels_encoder: 0.2419 (0.3414)  labels_decoder: 0.1648 (0.2261)  labels_encoder_unscaled: 0.2419 (0.3414)  labels_decoder_unscaled: 0.3297 (0.4522)  time: 0.1365  data: 0.0003  max mem: 3384
Epoch: [1]  [1300/1406]  eta: 0:00:14  lr: 0.000100  loss: 0.3958 (0.5615)  labels_encoder: 0.2302 (0.3373)  labels_decoder: 0.1722 (0.2242)  labels_encoder_unscaled: 0.2302 (0.3373)  labels_decoder_unscaled: 0.3444 (0.4484)  time: 0.1388  data: 0.0003  max mem: 3384
Epoch: [1]  [1350/1406]  eta: 0:00:07  lr: 0.000100  loss: 0.3693 (0.5556)  labels_encoder: 0.2036 (0.3334)  labels_decoder: 0.1672 (0.2222)  labels_encoder_unscaled: 0.2036 (0.3334)  labels_decoder_unscaled: 0.3345 (0.4444)  time: 0.1362  data: 0.0003  max mem: 3384
Epoch: [1]  [1400/1406]  eta: 0:00:00  lr: 0.000100  loss: 0.4435 (0.5501)  labels_encoder: 0.2563 (0.3297)  labels_decoder: 0.2015 (0.2205)  labels_encoder_unscaled: 0.2563 (0.3297)  labels_decoder_unscaled: 0.4030 (0.4409)  time: 0.1284  data: 0.0004  max mem: 3384
Epoch: [1]  [1405/1406]  eta: 0:00:00  lr: 0.000100  loss: 0.4051 (0.5495)  labels_encoder: 0.2013 (0.3292)  labels_decoder: 0.1961 (0.2202)  labels_encoder_unscaled: 0.2013 (0.3292)  labels_decoder_unscaled: 0.3922 (0.4405)  time: 0.1233  data: 0.0003  max mem: 3384
Epoch: [1] Total time: 0:03:13 (0.1380 s / it)
Averaged stats: lr: 0.000100  loss: 0.4051 (0.5495)  labels_encoder: 0.2013 (0.3292)  labels_decoder: 0.1961 (0.2202)  labels_encoder_unscaled: 0.2013 (0.3292)  labels_decoder_unscaled: 0.3922 (0.4405)
Test:  [   0/1613]  eta: 0:38:24  loss: 0.9493 (0.9493)  labels_encoder: 0.5446 (0.5446)  labels_decoder: 0.4047 (0.4047)  labels_encoder_unscaled: 0.5446 (0.5446)  labels_decoder_unscaled: 0.8094 (0.8094)  time: 1.4286  data: 1.3091  max mem: 3384
Test:  [  50/1613]  eta: 0:02:21  loss: 0.4256 (0.7862)  labels_encoder: 0.2135 (0.4703)  labels_decoder: 0.1763 (0.3159)  labels_encoder_unscaled: 0.2135 (0.4703)  labels_decoder_unscaled: 0.3525 (0.6318)  time: 0.0612  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:55  loss: 0.1467 (0.6923)  labels_encoder: 0.0990 (0.4278)  labels_decoder: 0.0453 (0.2645)  labels_encoder_unscaled: 0.0990 (0.4278)  labels_decoder_unscaled: 0.0907 (0.5289)  time: 0.0617  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:44  loss: 0.6972 (0.6888)  labels_encoder: 0.5659 (0.4252)  labels_decoder: 0.1363 (0.2635)  labels_encoder_unscaled: 0.5659 (0.4252)  labels_decoder_unscaled: 0.2727 (0.5271)  time: 0.0605  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:36  loss: 0.9770 (0.8261)  labels_encoder: 0.5909 (0.5141)  labels_decoder: 0.3703 (0.3120)  labels_encoder_unscaled: 0.5909 (0.5141)  labels_decoder_unscaled: 0.7405 (0.6241)  time: 0.0593  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:31  loss: 0.6439 (0.9336)  labels_encoder: 0.3792 (0.5889)  labels_decoder: 0.2634 (0.3447)  labels_encoder_unscaled: 0.3792 (0.5889)  labels_decoder_unscaled: 0.5268 (0.6894)  time: 0.0585  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:26  loss: 0.4872 (0.9522)  labels_encoder: 0.2623 (0.5975)  labels_decoder: 0.2381 (0.3547)  labels_encoder_unscaled: 0.2623 (0.5975)  labels_decoder_unscaled: 0.4761 (0.7093)  time: 0.0594  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:21  loss: 0.9954 (0.9509)  labels_encoder: 0.5534 (0.5938)  labels_decoder: 0.3734 (0.3571)  labels_encoder_unscaled: 0.5534 (0.5938)  labels_decoder_unscaled: 0.7469 (0.7141)  time: 0.0601  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:18  loss: 1.1427 (1.0469)  labels_encoder: 0.6286 (0.6646)  labels_decoder: 0.4340 (0.3823)  labels_encoder_unscaled: 0.6286 (0.6646)  labels_decoder_unscaled: 0.8679 (0.7646)  time: 0.0620  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:14  loss: 0.8701 (1.1140)  labels_encoder: 0.4790 (0.7082)  labels_decoder: 0.3331 (0.4058)  labels_encoder_unscaled: 0.4790 (0.7082)  labels_decoder_unscaled: 0.6663 (0.8116)  time: 0.0599  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:10  loss: 0.4429 (1.0827)  labels_encoder: 0.1910 (0.6875)  labels_decoder: 0.2519 (0.3951)  labels_encoder_unscaled: 0.1910 (0.6875)  labels_decoder_unscaled: 0.5038 (0.7903)  time: 0.0570  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:07  loss: 0.6950 (1.0721)  labels_encoder: 0.3621 (0.6795)  labels_decoder: 0.3304 (0.3926)  labels_encoder_unscaled: 0.3621 (0.6795)  labels_decoder_unscaled: 0.6608 (0.7853)  time: 0.0668  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:04  loss: 1.0538 (1.1064)  labels_encoder: 0.7350 (0.7133)  labels_decoder: 0.4611 (0.3931)  labels_encoder_unscaled: 0.7350 (0.7133)  labels_decoder_unscaled: 0.9222 (0.7862)  time: 0.0636  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:01  loss: 1.1263 (1.0893)  labels_encoder: 0.7939 (0.7016)  labels_decoder: 0.3902 (0.3877)  labels_encoder_unscaled: 0.7939 (0.7016)  labels_decoder_unscaled: 0.7803 (0.7754)  time: 0.0681  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:00:58  loss: 0.4983 (1.0753)  labels_encoder: 0.2713 (0.6920)  labels_decoder: 0.2402 (0.3833)  labels_encoder_unscaled: 0.2713 (0.6920)  labels_decoder_unscaled: 0.4804 (0.7666)  time: 0.0597  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:55  loss: 0.8473 (1.0648)  labels_encoder: 0.5370 (0.6856)  labels_decoder: 0.2872 (0.3793)  labels_encoder_unscaled: 0.5370 (0.6856)  labels_decoder_unscaled: 0.5744 (0.7585)  time: 0.0676  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:51  loss: 1.6805 (1.0822)  labels_encoder: 1.0563 (0.6985)  labels_decoder: 0.5950 (0.3837)  labels_encoder_unscaled: 1.0563 (0.6985)  labels_decoder_unscaled: 1.1900 (0.7674)  time: 0.0628  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:48  loss: 1.2779 (1.0928)  labels_encoder: 0.8061 (0.7050)  labels_decoder: 0.3522 (0.3878)  labels_encoder_unscaled: 0.8061 (0.7050)  labels_decoder_unscaled: 0.7044 (0.7757)  time: 0.0620  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:45  loss: 0.7201 (1.1101)  labels_encoder: 0.4406 (0.7148)  labels_decoder: 0.3551 (0.3953)  labels_encoder_unscaled: 0.4406 (0.7148)  labels_decoder_unscaled: 0.7102 (0.7906)  time: 0.0665  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:42  loss: 1.0467 (1.1057)  labels_encoder: 0.6653 (0.7103)  labels_decoder: 0.3613 (0.3954)  labels_encoder_unscaled: 0.6653 (0.7103)  labels_decoder_unscaled: 0.7226 (0.7908)  time: 0.0625  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:38  loss: 0.5114 (1.0902)  labels_encoder: 0.2670 (0.6992)  labels_decoder: 0.2043 (0.3911)  labels_encoder_unscaled: 0.2670 (0.6992)  labels_decoder_unscaled: 0.4085 (0.7821)  time: 0.0588  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:35  loss: 0.8903 (1.0938)  labels_encoder: 0.5284 (0.7019)  labels_decoder: 0.3449 (0.3919)  labels_encoder_unscaled: 0.5284 (0.7019)  labels_decoder_unscaled: 0.6898 (0.7838)  time: 0.0625  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:32  loss: 1.2556 (1.1247)  labels_encoder: 0.7857 (0.7246)  labels_decoder: 0.3024 (0.4001)  labels_encoder_unscaled: 0.7857 (0.7246)  labels_decoder_unscaled: 0.6048 (0.8002)  time: 0.0641  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:29  loss: 0.8304 (1.1080)  labels_encoder: 0.4609 (0.7135)  labels_decoder: 0.2744 (0.3945)  labels_encoder_unscaled: 0.4609 (0.7135)  labels_decoder_unscaled: 0.5487 (0.7891)  time: 0.0626  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:26  loss: 0.7378 (1.1164)  labels_encoder: 0.4011 (0.7189)  labels_decoder: 0.2919 (0.3975)  labels_encoder_unscaled: 0.4011 (0.7189)  labels_decoder_unscaled: 0.5837 (0.7951)  time: 0.0630  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:22  loss: 0.4813 (1.1231)  labels_encoder: 0.1896 (0.7226)  labels_decoder: 0.2216 (0.4005)  labels_encoder_unscaled: 0.1896 (0.7226)  labels_decoder_unscaled: 0.4431 (0.8010)  time: 0.0592  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5110 (1.1166)  labels_encoder: 0.3251 (0.7172)  labels_decoder: 0.2258 (0.3994)  labels_encoder_unscaled: 0.3251 (0.7172)  labels_decoder_unscaled: 0.4515 (0.7988)  time: 0.0632  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:16  loss: 1.1544 (1.1520)  labels_encoder: 0.8030 (0.7424)  labels_decoder: 0.3699 (0.4096)  labels_encoder_unscaled: 0.8030 (0.7424)  labels_decoder_unscaled: 0.7398 (0.8192)  time: 0.0594  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:13  loss: 0.8235 (1.1468)  labels_encoder: 0.4999 (0.7384)  labels_decoder: 0.2902 (0.4083)  labels_encoder_unscaled: 0.4999 (0.7384)  labels_decoder_unscaled: 0.5803 (0.8166)  time: 0.0583  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.9432 (1.1501)  labels_encoder: 0.6066 (0.7405)  labels_decoder: 0.3511 (0.4096)  labels_encoder_unscaled: 0.6066 (0.7405)  labels_decoder_unscaled: 0.7022 (0.8191)  time: 0.0653  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.5698 (1.1459)  labels_encoder: 0.3165 (0.7383)  labels_decoder: 0.2107 (0.4076)  labels_encoder_unscaled: 0.3165 (0.7383)  labels_decoder_unscaled: 0.4214 (0.8152)  time: 0.0864  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:03  loss: 0.6241 (1.1390)  labels_encoder: 0.3467 (0.7337)  labels_decoder: 0.2828 (0.4053)  labels_encoder_unscaled: 0.3467 (0.7337)  labels_decoder_unscaled: 0.5656 (0.8107)  time: 0.0573  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8558 (1.1351)  labels_encoder: 0.5912 (0.7311)  labels_decoder: 0.3337 (0.4040)  labels_encoder_unscaled: 0.5912 (0.7311)  labels_decoder_unscaled: 0.6673 (0.8079)  time: 0.0647  data: 0.0001  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8382 (1.1330)  labels_encoder: 0.5162 (0.7303)  labels_decoder: 0.2321 (0.4026)  labels_encoder_unscaled: 0.5162 (0.7303)  labels_decoder_unscaled: 0.4641 (0.8052)  time: 0.0530  data: 0.0001  max mem: 3384
Test: Total time: 0:01:41 (0.0631 s / it)
Averaged stats: loss: 0.8382 (1.1330)  labels_encoder: 0.5162 (0.7303)  labels_decoder: 0.2321 (0.4026)  labels_encoder_unscaled: 0.5162 (0.7303)  labels_decoder_unscaled: 0.4641 (0.8052)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet] mAP: 0.5648

dec_mAP all together: | 0.4610296441829222 |.
dec_mAP_pred | 0 : 0.5208783848514809 |.
dec_mAP_pred | 1 : 0.5076133045002499 |.
dec_mAP_pred | 2 : 0.49014097628853026 |.
dec_mAP_pred | 3 : 0.47182533583532554 |.
dec_mAP_pred | 4 : 0.4535010052137639 |.
dec_mAP_pred | 5 : 0.43613675581277456 |.
dec_mAP_pred | 6 : 0.41947060891956783 |.
dec_mAP_pred | 7 : 0.40434640040214404 |.
all decoder map: | 0.4630 |.
BaseballPitch: 0.1789
BasketballDunk: 0.7460
Billiards: 0.3708
CleanAndJerk: 0.7722
CliffDiving: 0.8263
CricketBowling: 0.4224
CricketShot: 0.1867
Diving: 0.6797
FrisbeeCatch: 0.3522
GolfSwing: 0.4708
HammerThrow: 0.8541
HighJump: 0.5527
JavelinThrow: 0.7050
LongJump: 0.8084
PoleVault: 0.8761
Shotput: 0.7151
SoccerPenalty: 0.2627
TennisSwing: 0.5186
ThrowDiscus: 0.6637
VolleyballSpiking: 0.3341
Epoch: [2]  [   0/1406]  eta: 0:40:43  lr: 0.000010  loss: 0.3066 (0.3066)  labels_encoder: 0.1945 (0.1945)  labels_decoder: 0.1121 (0.1121)  labels_encoder_unscaled: 0.1945 (0.1945)  labels_decoder_unscaled: 0.2241 (0.2241)  time: 1.7380  data: 1.5322  max mem: 3384
Epoch: [2]  [  50/1406]  eta: 0:03:58  lr: 0.000010  loss: 0.3255 (0.3291)  labels_encoder: 0.1793 (0.1785)  labels_decoder: 0.1441 (0.1506)  labels_encoder_unscaled: 0.1793 (0.1785)  labels_decoder_unscaled: 0.2881 (0.3012)  time: 0.1384  data: 0.0003  max mem: 3384
Epoch: [2]  [ 100/1406]  eta: 0:03:24  lr: 0.000010  loss: 0.3193 (0.3188)  labels_encoder: 0.1666 (0.1725)  labels_decoder: 0.1427 (0.1463)  labels_encoder_unscaled: 0.1666 (0.1725)  labels_decoder_unscaled: 0.2853 (0.2926)  time: 0.1378  data: 0.0003  max mem: 3384
Epoch: [2]  [ 150/1406]  eta: 0:03:07  lr: 0.000010  loss: 0.2947 (0.3140)  labels_encoder: 0.1628 (0.1704)  labels_decoder: 0.1331 (0.1436)  labels_encoder_unscaled: 0.1628 (0.1704)  labels_decoder_unscaled: 0.2663 (0.2872)  time: 0.1354  data: 0.0003  max mem: 3384
Epoch: [2]  [ 200/1406]  eta: 0:02:55  lr: 0.000010  loss: 0.2890 (0.3095)  labels_encoder: 0.1598 (0.1678)  labels_decoder: 0.1288 (0.1417)  labels_encoder_unscaled: 0.1598 (0.1678)  labels_decoder_unscaled: 0.2575 (0.2835)  time: 0.1355  data: 0.0003  max mem: 3384
Epoch: [2]  [ 250/1406]  eta: 0:02:45  lr: 0.000010  loss: 0.2743 (0.3049)  labels_encoder: 0.1474 (0.1647)  labels_decoder: 0.1315 (0.1402)  labels_encoder_unscaled: 0.1474 (0.1647)  labels_decoder_unscaled: 0.2631 (0.2804)  time: 0.1323  data: 0.0003  max mem: 3384
Epoch: [2]  [ 300/1406]  eta: 0:02:36  lr: 0.000010  loss: 0.2868 (0.3019)  labels_encoder: 0.1548 (0.1626)  labels_decoder: 0.1391 (0.1393)  labels_encoder_unscaled: 0.1548 (0.1626)  labels_decoder_unscaled: 0.2781 (0.2787)  time: 0.1326  data: 0.0003  max mem: 3384
Epoch: [2]  [ 350/1406]  eta: 0:02:29  lr: 0.000010  loss: 0.2752 (0.2993)  labels_encoder: 0.1339 (0.1608)  labels_decoder: 0.1329 (0.1386)  labels_encoder_unscaled: 0.1339 (0.1608)  labels_decoder_unscaled: 0.2657 (0.2772)  time: 0.1458  data: 0.0003  max mem: 3384
Epoch: [2]  [ 400/1406]  eta: 0:02:21  lr: 0.000010  loss: 0.2712 (0.2968)  labels_encoder: 0.1430 (0.1593)  labels_decoder: 0.1259 (0.1375)  labels_encoder_unscaled: 0.1430 (0.1593)  labels_decoder_unscaled: 0.2518 (0.2750)  time: 0.1400  data: 0.0003  max mem: 3384
Epoch: [2]  [ 450/1406]  eta: 0:02:14  lr: 0.000010  loss: 0.3130 (0.2964)  labels_encoder: 0.1722 (0.1594)  labels_decoder: 0.1333 (0.1371)  labels_encoder_unscaled: 0.1722 (0.1594)  labels_decoder_unscaled: 0.2665 (0.2741)  time: 0.1367  data: 0.0003  max mem: 3384
Epoch: [2]  [ 500/1406]  eta: 0:02:06  lr: 0.000010  loss: 0.2605 (0.2961)  labels_encoder: 0.1257 (0.1587)  labels_decoder: 0.1295 (0.1373)  labels_encoder_unscaled: 0.1257 (0.1587)  labels_decoder_unscaled: 0.2591 (0.2747)  time: 0.1350  data: 0.0003  max mem: 3384
Epoch: [2]  [ 550/1406]  eta: 0:01:59  lr: 0.000010  loss: 0.2570 (0.2935)  labels_encoder: 0.1283 (0.1570)  labels_decoder: 0.1234 (0.1365)  labels_encoder_unscaled: 0.1283 (0.1570)  labels_decoder_unscaled: 0.2468 (0.2731)  time: 0.1366  data: 0.0003  max mem: 3384
Epoch: [2]  [ 600/1406]  eta: 0:01:52  lr: 0.000010  loss: 0.2701 (0.2920)  labels_encoder: 0.1454 (0.1561)  labels_decoder: 0.1222 (0.1358)  labels_encoder_unscaled: 0.1454 (0.1561)  labels_decoder_unscaled: 0.2445 (0.2717)  time: 0.1368  data: 0.0003  max mem: 3384
Epoch: [2]  [ 650/1406]  eta: 0:01:45  lr: 0.000010  loss: 0.2706 (0.2908)  labels_encoder: 0.1402 (0.1553)  labels_decoder: 0.1269 (0.1355)  labels_encoder_unscaled: 0.1402 (0.1553)  labels_decoder_unscaled: 0.2538 (0.2710)  time: 0.1364  data: 0.0003  max mem: 3384
Epoch: [2]  [ 700/1406]  eta: 0:01:38  lr: 0.000010  loss: 0.2712 (0.2902)  labels_encoder: 0.1419 (0.1549)  labels_decoder: 0.1268 (0.1352)  labels_encoder_unscaled: 0.1419 (0.1549)  labels_decoder_unscaled: 0.2535 (0.2705)  time: 0.1359  data: 0.0003  max mem: 3384
Epoch: [2]  [ 750/1406]  eta: 0:01:31  lr: 0.000010  loss: 0.2856 (0.2897)  labels_encoder: 0.1553 (0.1549)  labels_decoder: 0.1161 (0.1348)  labels_encoder_unscaled: 0.1553 (0.1549)  labels_decoder_unscaled: 0.2323 (0.2697)  time: 0.1363  data: 0.0003  max mem: 3384
Epoch: [2]  [ 800/1406]  eta: 0:01:24  lr: 0.000010  loss: 0.2673 (0.2890)  labels_encoder: 0.1429 (0.1545)  labels_decoder: 0.1259 (0.1345)  labels_encoder_unscaled: 0.1429 (0.1545)  labels_decoder_unscaled: 0.2518 (0.2690)  time: 0.1340  data: 0.0002  max mem: 3384
Epoch: [2]  [ 850/1406]  eta: 0:01:17  lr: 0.000010  loss: 0.2772 (0.2885)  labels_encoder: 0.1454 (0.1544)  labels_decoder: 0.1252 (0.1342)  labels_encoder_unscaled: 0.1454 (0.1544)  labels_decoder_unscaled: 0.2503 (0.2683)  time: 0.1391  data: 0.0003  max mem: 3384
Epoch: [2]  [ 900/1406]  eta: 0:01:10  lr: 0.000010  loss: 0.2391 (0.2872)  labels_encoder: 0.1298 (0.1535)  labels_decoder: 0.1206 (0.1337)  labels_encoder_unscaled: 0.1298 (0.1535)  labels_decoder_unscaled: 0.2412 (0.2674)  time: 0.1359  data: 0.0003  max mem: 3384
Epoch: [2]  [ 950/1406]  eta: 0:01:03  lr: 0.000010  loss: 0.2385 (0.2855)  labels_encoder: 0.1208 (0.1523)  labels_decoder: 0.1295 (0.1332)  labels_encoder_unscaled: 0.1208 (0.1523)  labels_decoder_unscaled: 0.2590 (0.2663)  time: 0.1423  data: 0.0003  max mem: 3384
Epoch: [2]  [1000/1406]  eta: 0:00:56  lr: 0.000010  loss: 0.2790 (0.2845)  labels_encoder: 0.1436 (0.1517)  labels_decoder: 0.1331 (0.1328)  labels_encoder_unscaled: 0.1436 (0.1517)  labels_decoder_unscaled: 0.2662 (0.2656)  time: 0.1388  data: 0.0003  max mem: 3384
Epoch: [2]  [1050/1406]  eta: 0:00:49  lr: 0.000010  loss: 0.2525 (0.2837)  labels_encoder: 0.1311 (0.1511)  labels_decoder: 0.1181 (0.1326)  labels_encoder_unscaled: 0.1311 (0.1511)  labels_decoder_unscaled: 0.2363 (0.2652)  time: 0.1349  data: 0.0003  max mem: 3384
Epoch: [2]  [1100/1406]  eta: 0:00:42  lr: 0.000010  loss: 0.2734 (0.2827)  labels_encoder: 0.1309 (0.1503)  labels_decoder: 0.1221 (0.1324)  labels_encoder_unscaled: 0.1309 (0.1503)  labels_decoder_unscaled: 0.2442 (0.2648)  time: 0.1341  data: 0.0004  max mem: 3384
Epoch: [2]  [1150/1406]  eta: 0:00:35  lr: 0.000010  loss: 0.2696 (0.2816)  labels_encoder: 0.1316 (0.1496)  labels_decoder: 0.1292 (0.1320)  labels_encoder_unscaled: 0.1316 (0.1496)  labels_decoder_unscaled: 0.2584 (0.2639)  time: 0.1352  data: 0.0002  max mem: 3384
Epoch: [2]  [1200/1406]  eta: 0:00:28  lr: 0.000010  loss: 0.2498 (0.2803)  labels_encoder: 0.1356 (0.1488)  labels_decoder: 0.1158 (0.1315)  labels_encoder_unscaled: 0.1356 (0.1488)  labels_decoder_unscaled: 0.2317 (0.2631)  time: 0.1347  data: 0.0003  max mem: 3384
Epoch: [2]  [1250/1406]  eta: 0:00:21  lr: 0.000010  loss: 0.2663 (0.2800)  labels_encoder: 0.1298 (0.1487)  labels_decoder: 0.1241 (0.1313)  labels_encoder_unscaled: 0.1298 (0.1487)  labels_decoder_unscaled: 0.2483 (0.2626)  time: 0.1380  data: 0.0003  max mem: 3384
Epoch: [2]  [1300/1406]  eta: 0:00:14  lr: 0.000010  loss: 0.2658 (0.2795)  labels_encoder: 0.1394 (0.1484)  labels_decoder: 0.1241 (0.1311)  labels_encoder_unscaled: 0.1394 (0.1484)  labels_decoder_unscaled: 0.2482 (0.2623)  time: 0.1361  data: 0.0003  max mem: 3384
Epoch: [2]  [1350/1406]  eta: 0:00:07  lr: 0.000010  loss: 0.2603 (0.2789)  labels_encoder: 0.1412 (0.1481)  labels_decoder: 0.1186 (0.1307)  labels_encoder_unscaled: 0.1412 (0.1481)  labels_decoder_unscaled: 0.2373 (0.2615)  time: 0.1342  data: 0.0003  max mem: 3384
Epoch: [2]  [1400/1406]  eta: 0:00:00  lr: 0.000010  loss: 0.2535 (0.2788)  labels_encoder: 0.1268 (0.1482)  labels_decoder: 0.1261 (0.1307)  labels_encoder_unscaled: 0.1268 (0.1482)  labels_decoder_unscaled: 0.2523 (0.2613)  time: 0.1305  data: 0.0004  max mem: 3384
Epoch: [2]  [1405/1406]  eta: 0:00:00  lr: 0.000010  loss: 0.2531 (0.2787)  labels_encoder: 0.1242 (0.1481)  labels_decoder: 0.1261 (0.1306)  labels_encoder_unscaled: 0.1242 (0.1481)  labels_decoder_unscaled: 0.2523 (0.2613)  time: 0.1240  data: 0.0003  max mem: 3384
Epoch: [2] Total time: 0:03:14 (0.1386 s / it)
Averaged stats: lr: 0.000010  loss: 0.2531 (0.2787)  labels_encoder: 0.1242 (0.1481)  labels_decoder: 0.1261 (0.1306)  labels_encoder_unscaled: 0.1242 (0.1481)  labels_decoder_unscaled: 0.2523 (0.2613)
Test:  [   0/1613]  eta: 0:53:48  loss: 0.8645 (0.8645)  labels_encoder: 0.5177 (0.5177)  labels_decoder: 0.3469 (0.3469)  labels_encoder_unscaled: 0.5177 (0.5177)  labels_decoder_unscaled: 0.6937 (0.6937)  time: 2.0016  data: 1.9258  max mem: 3384
Test:  [  50/1613]  eta: 0:02:38  loss: 0.4879 (1.0004)  labels_encoder: 0.2522 (0.6390)  labels_decoder: 0.1998 (0.3614)  labels_encoder_unscaled: 0.2522 (0.6390)  labels_decoder_unscaled: 0.3996 (0.7228)  time: 0.0621  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:02:04  loss: 0.0832 (0.7604)  labels_encoder: 0.0533 (0.4849)  labels_decoder: 0.0299 (0.2755)  labels_encoder_unscaled: 0.0533 (0.4849)  labels_decoder_unscaled: 0.0598 (0.5510)  time: 0.0628  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:51  loss: 0.7431 (0.7478)  labels_encoder: 0.6133 (0.4784)  labels_decoder: 0.1532 (0.2694)  labels_encoder_unscaled: 0.6133 (0.4784)  labels_decoder_unscaled: 0.3064 (0.5389)  time: 0.0668  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:43  loss: 1.2181 (0.9163)  labels_encoder: 0.7691 (0.5919)  labels_decoder: 0.4465 (0.3245)  labels_encoder_unscaled: 0.7691 (0.5919)  labels_decoder_unscaled: 0.8930 (0.6489)  time: 0.0675  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:36  loss: 0.8344 (0.9822)  labels_encoder: 0.4955 (0.6341)  labels_decoder: 0.3179 (0.3481)  labels_encoder_unscaled: 0.4955 (0.6341)  labels_decoder_unscaled: 0.6358 (0.6962)  time: 0.0618  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:31  loss: 0.5144 (1.0023)  labels_encoder: 0.3216 (0.6498)  labels_decoder: 0.2040 (0.3525)  labels_encoder_unscaled: 0.3216 (0.6498)  labels_decoder_unscaled: 0.4079 (0.7051)  time: 0.0622  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:27  loss: 1.2254 (1.0124)  labels_encoder: 0.7978 (0.6516)  labels_decoder: 0.4992 (0.3609)  labels_encoder_unscaled: 0.7978 (0.6516)  labels_decoder_unscaled: 0.9985 (0.7218)  time: 0.0667  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:22  loss: 0.7723 (1.1556)  labels_encoder: 0.4767 (0.7572)  labels_decoder: 0.3721 (0.3983)  labels_encoder_unscaled: 0.4767 (0.7572)  labels_decoder_unscaled: 0.7441 (0.7967)  time: 0.0633  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:19  loss: 0.9783 (1.2520)  labels_encoder: 0.6646 (0.8208)  labels_decoder: 0.3171 (0.4312)  labels_encoder_unscaled: 0.6646 (0.8208)  labels_decoder_unscaled: 0.6342 (0.8624)  time: 0.0658  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:15  loss: 0.3587 (1.1900)  labels_encoder: 0.2027 (0.7764)  labels_decoder: 0.2129 (0.4136)  labels_encoder_unscaled: 0.2027 (0.7764)  labels_decoder_unscaled: 0.4258 (0.8271)  time: 0.0635  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:11  loss: 1.2408 (1.1952)  labels_encoder: 0.6696 (0.7765)  labels_decoder: 0.4455 (0.4186)  labels_encoder_unscaled: 0.6696 (0.7765)  labels_decoder_unscaled: 0.8909 (0.8372)  time: 0.0627  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:08  loss: 1.2188 (1.2243)  labels_encoder: 0.7599 (0.8029)  labels_decoder: 0.4139 (0.4214)  labels_encoder_unscaled: 0.7599 (0.8029)  labels_decoder_unscaled: 0.8278 (0.8427)  time: 0.0627  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:04  loss: 0.6710 (1.2075)  labels_encoder: 0.3941 (0.7883)  labels_decoder: 0.3672 (0.4192)  labels_encoder_unscaled: 0.3941 (0.7883)  labels_decoder_unscaled: 0.7344 (0.8385)  time: 0.0666  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:01:01  loss: 0.4851 (1.1757)  labels_encoder: 0.2950 (0.7666)  labels_decoder: 0.2041 (0.4091)  labels_encoder_unscaled: 0.2950 (0.7666)  labels_decoder_unscaled: 0.4081 (0.8181)  time: 0.0641  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:57  loss: 0.5992 (1.1490)  labels_encoder: 0.3723 (0.7492)  labels_decoder: 0.2268 (0.3998)  labels_encoder_unscaled: 0.3723 (0.7492)  labels_decoder_unscaled: 0.4537 (0.7997)  time: 0.0677  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:54  loss: 0.8173 (1.1473)  labels_encoder: 0.5034 (0.7493)  labels_decoder: 0.3168 (0.3980)  labels_encoder_unscaled: 0.5034 (0.7493)  labels_decoder_unscaled: 0.6336 (0.7960)  time: 0.0662  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:50  loss: 1.7212 (1.1533)  labels_encoder: 1.1167 (0.7508)  labels_decoder: 0.6869 (0.4025)  labels_encoder_unscaled: 1.1167 (0.7508)  labels_decoder_unscaled: 1.3739 (0.8049)  time: 0.0639  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:47  loss: 0.7763 (1.1699)  labels_encoder: 0.5105 (0.7615)  labels_decoder: 0.3336 (0.4084)  labels_encoder_unscaled: 0.5105 (0.7615)  labels_decoder_unscaled: 0.6671 (0.8169)  time: 0.0630  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:43  loss: 0.9823 (1.1590)  labels_encoder: 0.6816 (0.7550)  labels_decoder: 0.3012 (0.4041)  labels_encoder_unscaled: 0.6816 (0.7550)  labels_decoder_unscaled: 0.6023 (0.8081)  time: 0.0638  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:40  loss: 0.5984 (1.1397)  labels_encoder: 0.3331 (0.7412)  labels_decoder: 0.2780 (0.3985)  labels_encoder_unscaled: 0.3331 (0.7412)  labels_decoder_unscaled: 0.5559 (0.7970)  time: 0.0660  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:37  loss: 0.8106 (1.1326)  labels_encoder: 0.4585 (0.7371)  labels_decoder: 0.3174 (0.3955)  labels_encoder_unscaled: 0.4585 (0.7371)  labels_decoder_unscaled: 0.6349 (0.7909)  time: 0.0686  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:34  loss: 0.6541 (1.1301)  labels_encoder: 0.3699 (0.7364)  labels_decoder: 0.2969 (0.3937)  labels_encoder_unscaled: 0.3699 (0.7364)  labels_decoder_unscaled: 0.5937 (0.7875)  time: 0.0702  data: 0.0006  max mem: 3384
Test:  [1150/1613]  eta: 0:00:30  loss: 0.8105 (1.1188)  labels_encoder: 0.4663 (0.7282)  labels_decoder: 0.3401 (0.3907)  labels_encoder_unscaled: 0.4663 (0.7282)  labels_decoder_unscaled: 0.6801 (0.7814)  time: 0.0701  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:27  loss: 0.6089 (1.1255)  labels_encoder: 0.3876 (0.7324)  labels_decoder: 0.2521 (0.3931)  labels_encoder_unscaled: 0.3876 (0.7324)  labels_decoder_unscaled: 0.5042 (0.7862)  time: 0.0673  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:24  loss: 0.4562 (1.1240)  labels_encoder: 0.2276 (0.7308)  labels_decoder: 0.2286 (0.3932)  labels_encoder_unscaled: 0.2276 (0.7308)  labels_decoder_unscaled: 0.4571 (0.7865)  time: 0.0809  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:21  loss: 0.6437 (1.1123)  labels_encoder: 0.3861 (0.7224)  labels_decoder: 0.2576 (0.3898)  labels_encoder_unscaled: 0.3861 (0.7224)  labels_decoder_unscaled: 0.5153 (0.7796)  time: 0.0698  data: 0.0014  max mem: 3384
Test:  [1350/1613]  eta: 0:00:17  loss: 0.7197 (1.1247)  labels_encoder: 0.4652 (0.7319)  labels_decoder: 0.3042 (0.3928)  labels_encoder_unscaled: 0.4652 (0.7319)  labels_decoder_unscaled: 0.6084 (0.7856)  time: 0.0759  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:14  loss: 1.0297 (1.1190)  labels_encoder: 0.7088 (0.7280)  labels_decoder: 0.3815 (0.3911)  labels_encoder_unscaled: 0.7088 (0.7280)  labels_decoder_unscaled: 0.7630 (0.7822)  time: 0.0743  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.5696 (1.1303)  labels_encoder: 0.2928 (0.7346)  labels_decoder: 0.2899 (0.3957)  labels_encoder_unscaled: 0.2928 (0.7346)  labels_decoder_unscaled: 0.5798 (0.7914)  time: 0.0661  data: 0.0003  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.7399 (1.1409)  labels_encoder: 0.4592 (0.7423)  labels_decoder: 0.2649 (0.3986)  labels_encoder_unscaled: 0.4592 (0.7423)  labels_decoder_unscaled: 0.5299 (0.7971)  time: 0.0612  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:04  loss: 0.6967 (1.1350)  labels_encoder: 0.4266 (0.7390)  labels_decoder: 0.2692 (0.3960)  labels_encoder_unscaled: 0.4266 (0.7390)  labels_decoder_unscaled: 0.5385 (0.7921)  time: 0.0680  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.7901 (1.1255)  labels_encoder: 0.4670 (0.7323)  labels_decoder: 0.3109 (0.3932)  labels_encoder_unscaled: 0.4670 (0.7323)  labels_decoder_unscaled: 0.6218 (0.7864)  time: 0.0597  data: 0.0001  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5706 (1.1227)  labels_encoder: 0.3637 (0.7306)  labels_decoder: 0.2236 (0.3920)  labels_encoder_unscaled: 0.3637 (0.7306)  labels_decoder_unscaled: 0.4473 (0.7840)  time: 0.0516  data: 0.0001  max mem: 3384
Test: Total time: 0:01:48 (0.0673 s / it)
Averaged stats: loss: 0.5706 (1.1227)  labels_encoder: 0.3637 (0.7306)  labels_decoder: 0.2236 (0.3920)  labels_encoder_unscaled: 0.3637 (0.7306)  labels_decoder_unscaled: 0.4473 (0.7840)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet] mAP: 0.5704

dec_mAP all together: | 0.4502576443850746 |.
dec_mAP_pred | 0 : 0.4924492805315994 |.
dec_mAP_pred | 1 : 0.484509791082479 |.
dec_mAP_pred | 2 : 0.47283971731979413 |.
dec_mAP_pred | 3 : 0.4597778587419031 |.
dec_mAP_pred | 4 : 0.44570872449811433 |.
dec_mAP_pred | 5 : 0.43196833645549704 |.
dec_mAP_pred | 6 : 0.4184613488652059 |.
dec_mAP_pred | 7 : 0.40576958184191947 |.
all decoder map: | 0.4514 |.
BaseballPitch: 0.1592
BasketballDunk: 0.7695
Billiards: 0.3915
CleanAndJerk: 0.7481
CliffDiving: 0.8133
CricketBowling: 0.4435
CricketShot: 0.1917
Diving: 0.6821
FrisbeeCatch: 0.3246
GolfSwing: 0.5619
HammerThrow: 0.8530
HighJump: 0.6290
JavelinThrow: 0.7089
LongJump: 0.7925
PoleVault: 0.8530
Shotput: 0.6867
SoccerPenalty: 0.3520
TennisSwing: 0.5459
ThrowDiscus: 0.5879
VolleyballSpiking: 0.3141
Epoch: [3]  [   0/1406]  eta: 0:41:52  lr: 0.000001  loss: 0.2859 (0.2859)  labels_encoder: 0.1497 (0.1497)  labels_decoder: 0.1362 (0.1362)  labels_encoder_unscaled: 0.1497 (0.1497)  labels_decoder_unscaled: 0.2724 (0.2724)  time: 1.7867  data: 1.5872  max mem: 3384
Epoch: [3]  [  50/1406]  eta: 0:04:05  lr: 0.000001  loss: 0.2399 (0.2484)  labels_encoder: 0.1174 (0.1255)  labels_decoder: 0.1218 (0.1229)  labels_encoder_unscaled: 0.1174 (0.1255)  labels_decoder_unscaled: 0.2436 (0.2458)  time: 0.1547  data: 0.0003  max mem: 3384
Epoch: [3]  [ 100/1406]  eta: 0:03:31  lr: 0.000001  loss: 0.2280 (0.2459)  labels_encoder: 0.1287 (0.1250)  labels_decoder: 0.1126 (0.1209)  labels_encoder_unscaled: 0.1287 (0.1250)  labels_decoder_unscaled: 0.2252 (0.2419)  time: 0.1417  data: 0.0003  max mem: 3384
Epoch: [3]  [ 150/1406]  eta: 0:03:15  lr: 0.000001  loss: 0.2288 (0.2428)  labels_encoder: 0.1105 (0.1239)  labels_decoder: 0.1088 (0.1189)  labels_encoder_unscaled: 0.1105 (0.1239)  labels_decoder_unscaled: 0.2177 (0.2378)  time: 0.1387  data: 0.0003  max mem: 3384
Epoch: [3]  [ 200/1406]  eta: 0:03:03  lr: 0.000001  loss: 0.2334 (0.2458)  labels_encoder: 0.1148 (0.1256)  labels_decoder: 0.1219 (0.1202)  labels_encoder_unscaled: 0.1148 (0.1256)  labels_decoder_unscaled: 0.2438 (0.2404)  time: 0.1438  data: 0.0003  max mem: 3384
Epoch: [3]  [ 250/1406]  eta: 0:02:53  lr: 0.000001  loss: 0.2325 (0.2465)  labels_encoder: 0.1144 (0.1260)  labels_decoder: 0.1181 (0.1205)  labels_encoder_unscaled: 0.1144 (0.1260)  labels_decoder_unscaled: 0.2362 (0.2409)  time: 0.1314  data: 0.0003  max mem: 3384
Epoch: [3]  [ 300/1406]  eta: 0:02:43  lr: 0.000001  loss: 0.2400 (0.2462)  labels_encoder: 0.1269 (0.1263)  labels_decoder: 0.1152 (0.1199)  labels_encoder_unscaled: 0.1269 (0.1263)  labels_decoder_unscaled: 0.2304 (0.2398)  time: 0.1329  data: 0.0003  max mem: 3384
Epoch: [3]  [ 350/1406]  eta: 0:02:33  lr: 0.000001  loss: 0.2388 (0.2466)  labels_encoder: 0.1148 (0.1263)  labels_decoder: 0.1189 (0.1203)  labels_encoder_unscaled: 0.1148 (0.1263)  labels_decoder_unscaled: 0.2379 (0.2405)  time: 0.1325  data: 0.0002  max mem: 3384
Epoch: [3]  [ 400/1406]  eta: 0:02:24  lr: 0.000001  loss: 0.2406 (0.2462)  labels_encoder: 0.1237 (0.1262)  labels_decoder: 0.1133 (0.1200)  labels_encoder_unscaled: 0.1237 (0.1262)  labels_decoder_unscaled: 0.2266 (0.2400)  time: 0.1320  data: 0.0003  max mem: 3384
Epoch: [3]  [ 450/1406]  eta: 0:02:16  lr: 0.000001  loss: 0.2380 (0.2461)  labels_encoder: 0.1159 (0.1261)  labels_decoder: 0.1235 (0.1201)  labels_encoder_unscaled: 0.1159 (0.1261)  labels_decoder_unscaled: 0.2471 (0.2401)  time: 0.1368  data: 0.0003  max mem: 3384
Epoch: [3]  [ 500/1406]  eta: 0:02:08  lr: 0.000001  loss: 0.2383 (0.2465)  labels_encoder: 0.1201 (0.1259)  labels_decoder: 0.1203 (0.1206)  labels_encoder_unscaled: 0.1201 (0.1259)  labels_decoder_unscaled: 0.2407 (0.2411)  time: 0.1442  data: 0.0003  max mem: 3384
Epoch: [3]  [ 550/1406]  eta: 0:02:01  lr: 0.000001  loss: 0.2361 (0.2450)  labels_encoder: 0.1125 (0.1248)  labels_decoder: 0.1236 (0.1202)  labels_encoder_unscaled: 0.1125 (0.1248)  labels_decoder_unscaled: 0.2473 (0.2403)  time: 0.1405  data: 0.0003  max mem: 3384
Epoch: [3]  [ 600/1406]  eta: 0:01:53  lr: 0.000001  loss: 0.2471 (0.2452)  labels_encoder: 0.1267 (0.1252)  labels_decoder: 0.1168 (0.1200)  labels_encoder_unscaled: 0.1267 (0.1252)  labels_decoder_unscaled: 0.2337 (0.2400)  time: 0.1347  data: 0.0003  max mem: 3384
Epoch: [3]  [ 650/1406]  eta: 0:01:46  lr: 0.000001  loss: 0.2357 (0.2455)  labels_encoder: 0.1164 (0.1253)  labels_decoder: 0.1207 (0.1201)  labels_encoder_unscaled: 0.1164 (0.1253)  labels_decoder_unscaled: 0.2414 (0.2402)  time: 0.1420  data: 0.0002  max mem: 3384
Epoch: [3]  [ 700/1406]  eta: 0:01:39  lr: 0.000001  loss: 0.2173 (0.2451)  labels_encoder: 0.1040 (0.1250)  labels_decoder: 0.1073 (0.1201)  labels_encoder_unscaled: 0.1040 (0.1250)  labels_decoder_unscaled: 0.2147 (0.2401)  time: 0.1386  data: 0.0003  max mem: 3384
Epoch: [3]  [ 750/1406]  eta: 0:01:32  lr: 0.000001  loss: 0.2416 (0.2447)  labels_encoder: 0.1303 (0.1249)  labels_decoder: 0.1192 (0.1198)  labels_encoder_unscaled: 0.1303 (0.1249)  labels_decoder_unscaled: 0.2383 (0.2396)  time: 0.1381  data: 0.0002  max mem: 3384
Epoch: [3]  [ 800/1406]  eta: 0:01:25  lr: 0.000001  loss: 0.2357 (0.2441)  labels_encoder: 0.1250 (0.1245)  labels_decoder: 0.1161 (0.1196)  labels_encoder_unscaled: 0.1250 (0.1245)  labels_decoder_unscaled: 0.2323 (0.2392)  time: 0.1368  data: 0.0003  max mem: 3384
Epoch: [3]  [ 850/1406]  eta: 0:01:18  lr: 0.000001  loss: 0.2061 (0.2434)  labels_encoder: 0.1105 (0.1243)  labels_decoder: 0.0979 (0.1191)  labels_encoder_unscaled: 0.1105 (0.1243)  labels_decoder_unscaled: 0.1958 (0.2382)  time: 0.1380  data: 0.0003  max mem: 3384
Epoch: [3]  [ 900/1406]  eta: 0:01:11  lr: 0.000001  loss: 0.2261 (0.2435)  labels_encoder: 0.1162 (0.1245)  labels_decoder: 0.1120 (0.1191)  labels_encoder_unscaled: 0.1162 (0.1245)  labels_decoder_unscaled: 0.2240 (0.2381)  time: 0.1422  data: 0.0003  max mem: 3384
Epoch: [3]  [ 950/1406]  eta: 0:01:03  lr: 0.000001  loss: 0.2384 (0.2439)  labels_encoder: 0.1194 (0.1248)  labels_decoder: 0.1189 (0.1191)  labels_encoder_unscaled: 0.1194 (0.1248)  labels_decoder_unscaled: 0.2378 (0.2382)  time: 0.1456  data: 0.0003  max mem: 3384
Epoch: [3]  [1000/1406]  eta: 0:00:56  lr: 0.000001  loss: 0.2215 (0.2443)  labels_encoder: 0.1055 (0.1252)  labels_decoder: 0.1093 (0.1191)  labels_encoder_unscaled: 0.1055 (0.1252)  labels_decoder_unscaled: 0.2185 (0.2381)  time: 0.1311  data: 0.0003  max mem: 3384
Epoch: [3]  [1050/1406]  eta: 0:00:49  lr: 0.000001  loss: 0.2340 (0.2442)  labels_encoder: 0.1098 (0.1250)  labels_decoder: 0.1212 (0.1191)  labels_encoder_unscaled: 0.1098 (0.1250)  labels_decoder_unscaled: 0.2423 (0.2383)  time: 0.1391  data: 0.0003  max mem: 3384
Epoch: [3]  [1100/1406]  eta: 0:00:42  lr: 0.000001  loss: 0.2250 (0.2441)  labels_encoder: 0.1204 (0.1250)  labels_decoder: 0.1161 (0.1191)  labels_encoder_unscaled: 0.1204 (0.1250)  labels_decoder_unscaled: 0.2322 (0.2382)  time: 0.1397  data: 0.0003  max mem: 3384
Epoch: [3]  [1150/1406]  eta: 0:00:35  lr: 0.000001  loss: 0.2189 (0.2437)  labels_encoder: 0.1059 (0.1245)  labels_decoder: 0.1195 (0.1192)  labels_encoder_unscaled: 0.1059 (0.1245)  labels_decoder_unscaled: 0.2389 (0.2384)  time: 0.1383  data: 0.0003  max mem: 3384
Epoch: [3]  [1200/1406]  eta: 0:00:28  lr: 0.000001  loss: 0.2347 (0.2433)  labels_encoder: 0.1197 (0.1242)  labels_decoder: 0.1192 (0.1192)  labels_encoder_unscaled: 0.1197 (0.1242)  labels_decoder_unscaled: 0.2385 (0.2383)  time: 0.1384  data: 0.0003  max mem: 3384
Epoch: [3]  [1250/1406]  eta: 0:00:21  lr: 0.000001  loss: 0.2504 (0.2435)  labels_encoder: 0.1195 (0.1242)  labels_decoder: 0.1200 (0.1193)  labels_encoder_unscaled: 0.1195 (0.1242)  labels_decoder_unscaled: 0.2400 (0.2386)  time: 0.1357  data: 0.0003  max mem: 3384
Epoch: [3]  [1300/1406]  eta: 0:00:14  lr: 0.000001  loss: 0.2179 (0.2436)  labels_encoder: 0.1131 (0.1244)  labels_decoder: 0.1052 (0.1192)  labels_encoder_unscaled: 0.1131 (0.1244)  labels_decoder_unscaled: 0.2104 (0.2384)  time: 0.1380  data: 0.0002  max mem: 3384
Epoch: [3]  [1350/1406]  eta: 0:00:07  lr: 0.000001  loss: 0.2469 (0.2436)  labels_encoder: 0.1287 (0.1245)  labels_decoder: 0.1126 (0.1191)  labels_encoder_unscaled: 0.1287 (0.1245)  labels_decoder_unscaled: 0.2251 (0.2382)  time: 0.1387  data: 0.0003  max mem: 3384
Epoch: [3]  [1400/1406]  eta: 0:00:00  lr: 0.000001  loss: 0.2331 (0.2435)  labels_encoder: 0.1117 (0.1244)  labels_decoder: 0.1177 (0.1191)  labels_encoder_unscaled: 0.1117 (0.1244)  labels_decoder_unscaled: 0.2354 (0.2381)  time: 0.1340  data: 0.0004  max mem: 3384
Epoch: [3]  [1405/1406]  eta: 0:00:00  lr: 0.000001  loss: 0.2331 (0.2435)  labels_encoder: 0.1128 (0.1244)  labels_decoder: 0.1183 (0.1190)  labels_encoder_unscaled: 0.1128 (0.1244)  labels_decoder_unscaled: 0.2366 (0.2381)  time: 0.1260  data: 0.0004  max mem: 3384
Epoch: [3] Total time: 0:03:17 (0.1403 s / it)
Averaged stats: lr: 0.000001  loss: 0.2331 (0.2435)  labels_encoder: 0.1128 (0.1244)  labels_decoder: 0.1183 (0.1190)  labels_encoder_unscaled: 0.1128 (0.1244)  labels_decoder_unscaled: 0.2366 (0.2381)
Test:  [   0/1613]  eta: 0:43:38  loss: 0.7136 (0.7136)  labels_encoder: 0.4263 (0.4263)  labels_decoder: 0.2872 (0.2872)  labels_encoder_unscaled: 0.4263 (0.4263)  labels_decoder_unscaled: 0.5745 (0.5745)  time: 1.6231  data: 1.5481  max mem: 3384
Test:  [  50/1613]  eta: 0:02:25  loss: 0.4639 (0.9844)  labels_encoder: 0.2485 (0.6289)  labels_decoder: 0.2064 (0.3555)  labels_encoder_unscaled: 0.2485 (0.6289)  labels_decoder_unscaled: 0.4127 (0.7109)  time: 0.0639  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:56  loss: 0.1236 (0.7595)  labels_encoder: 0.0887 (0.4858)  labels_decoder: 0.0350 (0.2737)  labels_encoder_unscaled: 0.0887 (0.4858)  labels_decoder_unscaled: 0.0699 (0.5475)  time: 0.0594  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:45  loss: 0.8906 (0.7506)  labels_encoder: 0.6418 (0.4811)  labels_decoder: 0.1940 (0.2695)  labels_encoder_unscaled: 0.6418 (0.4811)  labels_decoder_unscaled: 0.3880 (0.5390)  time: 0.0606  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:39  loss: 1.0816 (0.9105)  labels_encoder: 0.6743 (0.5873)  labels_decoder: 0.4314 (0.3232)  labels_encoder_unscaled: 0.6743 (0.5873)  labels_decoder_unscaled: 0.8628 (0.6465)  time: 0.0647  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:34  loss: 0.8701 (0.9748)  labels_encoder: 0.4825 (0.6271)  labels_decoder: 0.2879 (0.3477)  labels_encoder_unscaled: 0.4825 (0.6271)  labels_decoder_unscaled: 0.5758 (0.6953)  time: 0.0645  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:29  loss: 0.4639 (0.9912)  labels_encoder: 0.2896 (0.6393)  labels_decoder: 0.1975 (0.3519)  labels_encoder_unscaled: 0.2896 (0.6393)  labels_decoder_unscaled: 0.3949 (0.7038)  time: 0.0610  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:24  loss: 1.2845 (0.9990)  labels_encoder: 0.7366 (0.6402)  labels_decoder: 0.5118 (0.3588)  labels_encoder_unscaled: 0.7366 (0.6402)  labels_decoder_unscaled: 1.0235 (0.7176)  time: 0.0605  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:20  loss: 0.7837 (1.1461)  labels_encoder: 0.4975 (0.7477)  labels_decoder: 0.3528 (0.3984)  labels_encoder_unscaled: 0.4975 (0.7477)  labels_decoder_unscaled: 0.7057 (0.7967)  time: 0.0630  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:16  loss: 0.9604 (1.2424)  labels_encoder: 0.5861 (0.8119)  labels_decoder: 0.3742 (0.4305)  labels_encoder_unscaled: 0.5861 (0.8119)  labels_decoder_unscaled: 0.7485 (0.8610)  time: 0.0621  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:13  loss: 0.3625 (1.1818)  labels_encoder: 0.2085 (0.7695)  labels_decoder: 0.2046 (0.4123)  labels_encoder_unscaled: 0.2085 (0.7695)  labels_decoder_unscaled: 0.4093 (0.8245)  time: 0.0655  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:09  loss: 1.0933 (1.1798)  labels_encoder: 0.6041 (0.7655)  labels_decoder: 0.4013 (0.4143)  labels_encoder_unscaled: 0.6041 (0.7655)  labels_decoder_unscaled: 0.8025 (0.8285)  time: 0.0669  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:06  loss: 1.2821 (1.2120)  labels_encoder: 0.7071 (0.7956)  labels_decoder: 0.4285 (0.4164)  labels_encoder_unscaled: 0.7071 (0.7956)  labels_decoder_unscaled: 0.8569 (0.8328)  time: 0.0613  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:02  loss: 0.6555 (1.1929)  labels_encoder: 0.3913 (0.7794)  labels_decoder: 0.3739 (0.4135)  labels_encoder_unscaled: 0.3913 (0.7794)  labels_decoder_unscaled: 0.7478 (0.8269)  time: 0.0598  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:00:58  loss: 0.5147 (1.1635)  labels_encoder: 0.2854 (0.7591)  labels_decoder: 0.2174 (0.4044)  labels_encoder_unscaled: 0.2854 (0.7591)  labels_decoder_unscaled: 0.4348 (0.8088)  time: 0.0573  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:55  loss: 0.5798 (1.1364)  labels_encoder: 0.3628 (0.7405)  labels_decoder: 0.2170 (0.3959)  labels_encoder_unscaled: 0.3628 (0.7405)  labels_decoder_unscaled: 0.4341 (0.7918)  time: 0.0550  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:51  loss: 0.8001 (1.1347)  labels_encoder: 0.5361 (0.7400)  labels_decoder: 0.3134 (0.3947)  labels_encoder_unscaled: 0.5361 (0.7400)  labels_decoder_unscaled: 0.6269 (0.7894)  time: 0.0580  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:48  loss: 1.7292 (1.1406)  labels_encoder: 1.1446 (0.7418)  labels_decoder: 0.6670 (0.3988)  labels_encoder_unscaled: 1.1446 (0.7418)  labels_decoder_unscaled: 1.3339 (0.7976)  time: 0.0673  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:45  loss: 0.7272 (1.1597)  labels_encoder: 0.5137 (0.7544)  labels_decoder: 0.3209 (0.4053)  labels_encoder_unscaled: 0.5137 (0.7544)  labels_decoder_unscaled: 0.6418 (0.8106)  time: 0.0613  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:42  loss: 0.9688 (1.1468)  labels_encoder: 0.6642 (0.7460)  labels_decoder: 0.3046 (0.4008)  labels_encoder_unscaled: 0.6642 (0.7460)  labels_decoder_unscaled: 0.6093 (0.8016)  time: 0.0606  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:38  loss: 0.5457 (1.1277)  labels_encoder: 0.3245 (0.7323)  labels_decoder: 0.2544 (0.3954)  labels_encoder_unscaled: 0.3245 (0.7323)  labels_decoder_unscaled: 0.5088 (0.7907)  time: 0.0593  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:35  loss: 0.8049 (1.1211)  labels_encoder: 0.4584 (0.7287)  labels_decoder: 0.3296 (0.3924)  labels_encoder_unscaled: 0.4584 (0.7287)  labels_decoder_unscaled: 0.6592 (0.7849)  time: 0.0636  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:32  loss: 0.6455 (1.1213)  labels_encoder: 0.3651 (0.7297)  labels_decoder: 0.3051 (0.3916)  labels_encoder_unscaled: 0.3651 (0.7297)  labels_decoder_unscaled: 0.6103 (0.7831)  time: 0.0610  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:29  loss: 0.6980 (1.1108)  labels_encoder: 0.4313 (0.7222)  labels_decoder: 0.2773 (0.3886)  labels_encoder_unscaled: 0.4313 (0.7222)  labels_decoder_unscaled: 0.5547 (0.7771)  time: 0.0657  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:26  loss: 0.6177 (1.1183)  labels_encoder: 0.3972 (0.7269)  labels_decoder: 0.2645 (0.3915)  labels_encoder_unscaled: 0.3972 (0.7269)  labels_decoder_unscaled: 0.5289 (0.7829)  time: 0.0634  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:23  loss: 0.4438 (1.1176)  labels_encoder: 0.2100 (0.7255)  labels_decoder: 0.2192 (0.3921)  labels_encoder_unscaled: 0.2100 (0.7255)  labels_decoder_unscaled: 0.4384 (0.7842)  time: 0.0661  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5996 (1.1066)  labels_encoder: 0.3693 (0.7176)  labels_decoder: 0.2443 (0.3890)  labels_encoder_unscaled: 0.3693 (0.7176)  labels_decoder_unscaled: 0.4886 (0.7780)  time: 0.0651  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:16  loss: 0.7787 (1.1202)  labels_encoder: 0.4950 (0.7280)  labels_decoder: 0.3160 (0.3923)  labels_encoder_unscaled: 0.4950 (0.7280)  labels_decoder_unscaled: 0.6319 (0.7845)  time: 0.0632  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:13  loss: 1.0385 (1.1157)  labels_encoder: 0.7109 (0.7246)  labels_decoder: 0.4138 (0.3911)  labels_encoder_unscaled: 0.7109 (0.7246)  labels_decoder_unscaled: 0.8275 (0.7822)  time: 0.0626  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.6532 (1.1262)  labels_encoder: 0.2926 (0.7307)  labels_decoder: 0.3080 (0.3955)  labels_encoder_unscaled: 0.2926 (0.7307)  labels_decoder_unscaled: 0.6160 (0.7910)  time: 0.0665  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.7015 (1.1368)  labels_encoder: 0.4245 (0.7383)  labels_decoder: 0.2656 (0.3985)  labels_encoder_unscaled: 0.4245 (0.7383)  labels_decoder_unscaled: 0.5311 (0.7970)  time: 0.0776  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:04  loss: 0.6733 (1.1310)  labels_encoder: 0.4370 (0.7348)  labels_decoder: 0.2853 (0.3962)  labels_encoder_unscaled: 0.4370 (0.7348)  labels_decoder_unscaled: 0.5706 (0.7924)  time: 0.0632  data: 0.0008  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.9345 (1.1229)  labels_encoder: 0.5774 (0.7289)  labels_decoder: 0.3496 (0.3939)  labels_encoder_unscaled: 0.5774 (0.7289)  labels_decoder_unscaled: 0.6993 (0.7879)  time: 0.0769  data: 0.0002  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6527 (1.1204)  labels_encoder: 0.4012 (0.7275)  labels_decoder: 0.2514 (0.3929)  labels_encoder_unscaled: 0.4012 (0.7275)  labels_decoder_unscaled: 0.5029 (0.7858)  time: 0.0519  data: 0.0001  max mem: 3384
Test: Total time: 0:01:43 (0.0644 s / it)
Averaged stats: loss: 0.6527 (1.1204)  labels_encoder: 0.4012 (0.7275)  labels_decoder: 0.2514 (0.3929)  labels_encoder_unscaled: 0.4012 (0.7275)  labels_decoder_unscaled: 0.5029 (0.7858)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet] mAP: 0.5732

dec_mAP all together: | 0.45341962769238 |.
dec_mAP_pred | 0 : 0.49778819718766804 |.
dec_mAP_pred | 1 : 0.48925332762662166 |.
dec_mAP_pred | 2 : 0.4770201357051039 |.
dec_mAP_pred | 3 : 0.46326579001230994 |.
dec_mAP_pred | 4 : 0.4485050309643371 |.
dec_mAP_pred | 5 : 0.43424714262424713 |.
dec_mAP_pred | 6 : 0.4202032113905701 |.
dec_mAP_pred | 7 : 0.40709696834770526 |.
all decoder map: | 0.4547 |.
BaseballPitch: 0.1608
BasketballDunk: 0.7681
Billiards: 0.3890
CleanAndJerk: 0.7526
CliffDiving: 0.8118
CricketBowling: 0.4441
CricketShot: 0.1871
Diving: 0.6797
FrisbeeCatch: 0.3472
GolfSwing: 0.5784
HammerThrow: 0.8549
HighJump: 0.6306
JavelinThrow: 0.7074
LongJump: 0.7904
PoleVault: 0.8558
Shotput: 0.6864
SoccerPenalty: 0.3488
TennisSwing: 0.5558
ThrowDiscus: 0.6001
VolleyballSpiking: 0.3144
Epoch: [4]  [   0/1406]  eta: 0:43:28  lr: 0.000000  loss: 0.1842 (0.1842)  labels_encoder: 0.0943 (0.0943)  labels_decoder: 0.0900 (0.0900)  labels_encoder_unscaled: 0.0943 (0.0943)  labels_decoder_unscaled: 0.1799 (0.1799)  time: 1.8550  data: 1.6410  max mem: 3384
Epoch: [4]  [  50/1406]  eta: 0:03:58  lr: 0.000000  loss: 0.2236 (0.2258)  labels_encoder: 0.1113 (0.1101)  labels_decoder: 0.1157 (0.1157)  labels_encoder_unscaled: 0.1113 (0.1101)  labels_decoder_unscaled: 0.2314 (0.2313)  time: 0.1436  data: 0.0003  max mem: 3384
Epoch: [4]  [ 100/1406]  eta: 0:03:30  lr: 0.000000  loss: 0.2214 (0.2329)  labels_encoder: 0.1227 (0.1160)  labels_decoder: 0.1134 (0.1169)  labels_encoder_unscaled: 0.1227 (0.1160)  labels_decoder_unscaled: 0.2269 (0.2337)  time: 0.1436  data: 0.0003  max mem: 3384
Epoch: [4]  [ 150/1406]  eta: 0:03:15  lr: 0.000000  loss: 0.2295 (0.2337)  labels_encoder: 0.1023 (0.1168)  labels_decoder: 0.1136 (0.1169)  labels_encoder_unscaled: 0.1023 (0.1168)  labels_decoder_unscaled: 0.2271 (0.2338)  time: 0.1454  data: 0.0003  max mem: 3384
Epoch: [4]  [ 200/1406]  eta: 0:03:04  lr: 0.000000  loss: 0.2274 (0.2344)  labels_encoder: 0.1068 (0.1178)  labels_decoder: 0.1092 (0.1166)  labels_encoder_unscaled: 0.1068 (0.1178)  labels_decoder_unscaled: 0.2185 (0.2332)  time: 0.1440  data: 0.0003  max mem: 3384
Epoch: [4]  [ 250/1406]  eta: 0:02:54  lr: 0.000000  loss: 0.2299 (0.2344)  labels_encoder: 0.1190 (0.1179)  labels_decoder: 0.1144 (0.1165)  labels_encoder_unscaled: 0.1190 (0.1179)  labels_decoder_unscaled: 0.2287 (0.2329)  time: 0.1392  data: 0.0003  max mem: 3384
Epoch: [4]  [ 300/1406]  eta: 0:02:45  lr: 0.000000  loss: 0.2406 (0.2361)  labels_encoder: 0.1203 (0.1187)  labels_decoder: 0.1243 (0.1174)  labels_encoder_unscaled: 0.1203 (0.1187)  labels_decoder_unscaled: 0.2486 (0.2349)  time: 0.1401  data: 0.0003  max mem: 3384
Epoch: [4]  [ 350/1406]  eta: 0:02:36  lr: 0.000000  loss: 0.2277 (0.2380)  labels_encoder: 0.1220 (0.1202)  labels_decoder: 0.1131 (0.1178)  labels_encoder_unscaled: 0.1220 (0.1202)  labels_decoder_unscaled: 0.2262 (0.2355)  time: 0.1433  data: 0.0003  max mem: 3384
Epoch: [4]  [ 400/1406]  eta: 0:02:27  lr: 0.000000  loss: 0.2368 (0.2376)  labels_encoder: 0.1182 (0.1200)  labels_decoder: 0.1128 (0.1175)  labels_encoder_unscaled: 0.1182 (0.1200)  labels_decoder_unscaled: 0.2256 (0.2351)  time: 0.1375  data: 0.0003  max mem: 3384
Epoch: [4]  [ 450/1406]  eta: 0:02:19  lr: 0.000000  loss: 0.2333 (0.2383)  labels_encoder: 0.1215 (0.1209)  labels_decoder: 0.1098 (0.1174)  labels_encoder_unscaled: 0.1215 (0.1209)  labels_decoder_unscaled: 0.2197 (0.2348)  time: 0.1358  data: 0.0003  max mem: 3384
Epoch: [4]  [ 500/1406]  eta: 0:02:11  lr: 0.000000  loss: 0.2150 (0.2386)  labels_encoder: 0.1005 (0.1211)  labels_decoder: 0.1089 (0.1175)  labels_encoder_unscaled: 0.1005 (0.1211)  labels_decoder_unscaled: 0.2177 (0.2350)  time: 0.1355  data: 0.0002  max mem: 3384
Epoch: [4]  [ 550/1406]  eta: 0:02:02  lr: 0.000000  loss: 0.2341 (0.2391)  labels_encoder: 0.1306 (0.1215)  labels_decoder: 0.1094 (0.1176)  labels_encoder_unscaled: 0.1306 (0.1215)  labels_decoder_unscaled: 0.2188 (0.2352)  time: 0.1319  data: 0.0002  max mem: 3384
Epoch: [4]  [ 600/1406]  eta: 0:01:55  lr: 0.000000  loss: 0.2363 (0.2392)  labels_encoder: 0.1098 (0.1215)  labels_decoder: 0.1156 (0.1177)  labels_encoder_unscaled: 0.1098 (0.1215)  labels_decoder_unscaled: 0.2311 (0.2354)  time: 0.1327  data: 0.0002  max mem: 3384
Epoch: [4]  [ 650/1406]  eta: 0:01:47  lr: 0.000000  loss: 0.2135 (0.2385)  labels_encoder: 0.1074 (0.1211)  labels_decoder: 0.1090 (0.1174)  labels_encoder_unscaled: 0.1074 (0.1211)  labels_decoder_unscaled: 0.2179 (0.2348)  time: 0.1335  data: 0.0002  max mem: 3384
Epoch: [4]  [ 700/1406]  eta: 0:01:39  lr: 0.000000  loss: 0.2406 (0.2385)  labels_encoder: 0.1195 (0.1211)  labels_decoder: 0.1166 (0.1174)  labels_encoder_unscaled: 0.1195 (0.1211)  labels_decoder_unscaled: 0.2332 (0.2348)  time: 0.1369  data: 0.0003  max mem: 3384
Epoch: [4]  [ 750/1406]  eta: 0:01:32  lr: 0.000000  loss: 0.2440 (0.2388)  labels_encoder: 0.1240 (0.1216)  labels_decoder: 0.1160 (0.1172)  labels_encoder_unscaled: 0.1240 (0.1216)  labels_decoder_unscaled: 0.2319 (0.2344)  time: 0.1367  data: 0.0003  max mem: 3384
Epoch: [4]  [ 800/1406]  eta: 0:01:25  lr: 0.000000  loss: 0.2222 (0.2387)  labels_encoder: 0.1106 (0.1215)  labels_decoder: 0.1186 (0.1172)  labels_encoder_unscaled: 0.1106 (0.1215)  labels_decoder_unscaled: 0.2372 (0.2344)  time: 0.1397  data: 0.0003  max mem: 3384
Epoch: [4]  [ 850/1406]  eta: 0:01:18  lr: 0.000000  loss: 0.2315 (0.2386)  labels_encoder: 0.1183 (0.1212)  labels_decoder: 0.1129 (0.1174)  labels_encoder_unscaled: 0.1183 (0.1212)  labels_decoder_unscaled: 0.2258 (0.2348)  time: 0.1407  data: 0.0003  max mem: 3384
Epoch: [4]  [ 900/1406]  eta: 0:01:11  lr: 0.000000  loss: 0.2450 (0.2385)  labels_encoder: 0.1316 (0.1212)  labels_decoder: 0.1138 (0.1173)  labels_encoder_unscaled: 0.1316 (0.1212)  labels_decoder_unscaled: 0.2277 (0.2347)  time: 0.1398  data: 0.0003  max mem: 3384
Epoch: [4]  [ 950/1406]  eta: 0:01:04  lr: 0.000000  loss: 0.2242 (0.2382)  labels_encoder: 0.1043 (0.1209)  labels_decoder: 0.1183 (0.1173)  labels_encoder_unscaled: 0.1043 (0.1209)  labels_decoder_unscaled: 0.2367 (0.2347)  time: 0.1399  data: 0.0002  max mem: 3384
Epoch: [4]  [1000/1406]  eta: 0:00:56  lr: 0.000000  loss: 0.2431 (0.2388)  labels_encoder: 0.1236 (0.1213)  labels_decoder: 0.1260 (0.1175)  labels_encoder_unscaled: 0.1236 (0.1213)  labels_decoder_unscaled: 0.2521 (0.2350)  time: 0.1378  data: 0.0002  max mem: 3384
Epoch: [4]  [1050/1406]  eta: 0:00:49  lr: 0.000000  loss: 0.2302 (0.2389)  labels_encoder: 0.1199 (0.1215)  labels_decoder: 0.1121 (0.1174)  labels_encoder_unscaled: 0.1199 (0.1215)  labels_decoder_unscaled: 0.2243 (0.2348)  time: 0.1350  data: 0.0002  max mem: 3384
Epoch: [4]  [1100/1406]  eta: 0:00:42  lr: 0.000000  loss: 0.2450 (0.2389)  labels_encoder: 0.1205 (0.1213)  labels_decoder: 0.1168 (0.1176)  labels_encoder_unscaled: 0.1205 (0.1213)  labels_decoder_unscaled: 0.2337 (0.2352)  time: 0.1367  data: 0.0003  max mem: 3384
Epoch: [4]  [1150/1406]  eta: 0:00:35  lr: 0.000000  loss: 0.2226 (0.2391)  labels_encoder: 0.1210 (0.1214)  labels_decoder: 0.1123 (0.1177)  labels_encoder_unscaled: 0.1210 (0.1214)  labels_decoder_unscaled: 0.2246 (0.2353)  time: 0.1356  data: 0.0003  max mem: 3384
Epoch: [4]  [1200/1406]  eta: 0:00:28  lr: 0.000000  loss: 0.2560 (0.2391)  labels_encoder: 0.1279 (0.1215)  labels_decoder: 0.1183 (0.1177)  labels_encoder_unscaled: 0.1279 (0.1215)  labels_decoder_unscaled: 0.2365 (0.2353)  time: 0.1383  data: 0.0002  max mem: 3384
Epoch: [4]  [1250/1406]  eta: 0:00:21  lr: 0.000000  loss: 0.2478 (0.2395)  labels_encoder: 0.1254 (0.1217)  labels_decoder: 0.1200 (0.1178)  labels_encoder_unscaled: 0.1254 (0.1217)  labels_decoder_unscaled: 0.2400 (0.2356)  time: 0.1398  data: 0.0003  max mem: 3384
Epoch: [4]  [1300/1406]  eta: 0:00:14  lr: 0.000000  loss: 0.2395 (0.2396)  labels_encoder: 0.1260 (0.1218)  labels_decoder: 0.1114 (0.1177)  labels_encoder_unscaled: 0.1260 (0.1218)  labels_decoder_unscaled: 0.2229 (0.2355)  time: 0.1344  data: 0.0003  max mem: 3384
Epoch: [4]  [1350/1406]  eta: 0:00:07  lr: 0.000000  loss: 0.2224 (0.2396)  labels_encoder: 0.1037 (0.1219)  labels_decoder: 0.1179 (0.1177)  labels_encoder_unscaled: 0.1037 (0.1219)  labels_decoder_unscaled: 0.2358 (0.2355)  time: 0.1307  data: 0.0002  max mem: 3384
Epoch: [4]  [1400/1406]  eta: 0:00:00  lr: 0.000000  loss: 0.2219 (0.2395)  labels_encoder: 0.1127 (0.1218)  labels_decoder: 0.1131 (0.1177)  labels_encoder_unscaled: 0.1127 (0.1218)  labels_decoder_unscaled: 0.2263 (0.2353)  time: 0.1269  data: 0.0003  max mem: 3384
Epoch: [4]  [1405/1406]  eta: 0:00:00  lr: 0.000000  loss: 0.2314 (0.2395)  labels_encoder: 0.1184 (0.1218)  labels_decoder: 0.1131 (0.1177)  labels_encoder_unscaled: 0.1184 (0.1218)  labels_decoder_unscaled: 0.2263 (0.2353)  time: 0.1222  data: 0.0003  max mem: 3384
Epoch: [4] Total time: 0:03:15 (0.1391 s / it)
Averaged stats: lr: 0.000000  loss: 0.2314 (0.2395)  labels_encoder: 0.1184 (0.1218)  labels_decoder: 0.1131 (0.1177)  labels_encoder_unscaled: 0.1184 (0.1218)  labels_decoder_unscaled: 0.2263 (0.2353)
Test:  [   0/1613]  eta: 0:44:50  loss: 0.7029 (0.7029)  labels_encoder: 0.4114 (0.4114)  labels_decoder: 0.2916 (0.2916)  labels_encoder_unscaled: 0.4114 (0.4114)  labels_decoder_unscaled: 0.5831 (0.5831)  time: 1.6682  data: 1.6082  max mem: 3384
Test:  [  50/1613]  eta: 0:02:22  loss: 0.4571 (0.9878)  labels_encoder: 0.2553 (0.6321)  labels_decoder: 0.2056 (0.3558)  labels_encoder_unscaled: 0.2553 (0.6321)  labels_decoder_unscaled: 0.4112 (0.7115)  time: 0.0616  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:55  loss: 0.1182 (0.7595)  labels_encoder: 0.0826 (0.4862)  labels_decoder: 0.0356 (0.2733)  labels_encoder_unscaled: 0.0826 (0.4862)  labels_decoder_unscaled: 0.0712 (0.5466)  time: 0.0598  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:43  loss: 0.8099 (0.7472)  labels_encoder: 0.6479 (0.4791)  labels_decoder: 0.1749 (0.2680)  labels_encoder_unscaled: 0.6479 (0.4791)  labels_decoder_unscaled: 0.3498 (0.5361)  time: 0.0617  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:37  loss: 1.0823 (0.9077)  labels_encoder: 0.6796 (0.5859)  labels_decoder: 0.4212 (0.3218)  labels_encoder_unscaled: 0.6796 (0.5859)  labels_decoder_unscaled: 0.8424 (0.6436)  time: 0.0624  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:32  loss: 0.8929 (0.9714)  labels_encoder: 0.4803 (0.6257)  labels_decoder: 0.2913 (0.3458)  labels_encoder_unscaled: 0.4803 (0.6257)  labels_decoder_unscaled: 0.5826 (0.6916)  time: 0.0587  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:28  loss: 0.4666 (0.9910)  labels_encoder: 0.2961 (0.6405)  labels_decoder: 0.1963 (0.3505)  labels_encoder_unscaled: 0.2961 (0.6405)  labels_decoder_unscaled: 0.3926 (0.7010)  time: 0.0701  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:25  loss: 1.2795 (0.9997)  labels_encoder: 0.7358 (0.6417)  labels_decoder: 0.5106 (0.3579)  labels_encoder_unscaled: 0.7358 (0.6417)  labels_decoder_unscaled: 1.0212 (0.7159)  time: 0.0647  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:21  loss: 0.7816 (1.1481)  labels_encoder: 0.4955 (0.7505)  labels_decoder: 0.3604 (0.3977)  labels_encoder_unscaled: 0.4955 (0.7505)  labels_decoder_unscaled: 0.7208 (0.7953)  time: 0.0620  data: 0.0011  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:17  loss: 0.9460 (1.2440)  labels_encoder: 0.5851 (0.8143)  labels_decoder: 0.3692 (0.4297)  labels_encoder_unscaled: 0.5851 (0.8143)  labels_decoder_unscaled: 0.7385 (0.8594)  time: 0.0624  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:14  loss: 0.3791 (1.1842)  labels_encoder: 0.2129 (0.7721)  labels_decoder: 0.2004 (0.4120)  labels_encoder_unscaled: 0.2129 (0.7721)  labels_decoder_unscaled: 0.4008 (0.8241)  time: 0.0645  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:10  loss: 1.0728 (1.1835)  labels_encoder: 0.6020 (0.7689)  labels_decoder: 0.3830 (0.4145)  labels_encoder_unscaled: 0.6020 (0.7689)  labels_decoder_unscaled: 0.7661 (0.8290)  time: 0.0622  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:06  loss: 1.2641 (1.2160)  labels_encoder: 0.6978 (0.7992)  labels_decoder: 0.4371 (0.4168)  labels_encoder_unscaled: 0.6978 (0.7992)  labels_decoder_unscaled: 0.8741 (0.8336)  time: 0.0626  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:03  loss: 0.6630 (1.1970)  labels_encoder: 0.4029 (0.7831)  labels_decoder: 0.3726 (0.4139)  labels_encoder_unscaled: 0.4029 (0.7831)  labels_decoder_unscaled: 0.7451 (0.8278)  time: 0.0676  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:01:00  loss: 0.5138 (1.1676)  labels_encoder: 0.2925 (0.7628)  labels_decoder: 0.2157 (0.4048)  labels_encoder_unscaled: 0.2925 (0.7628)  labels_decoder_unscaled: 0.4315 (0.8096)  time: 0.0634  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:56  loss: 0.5821 (1.1407)  labels_encoder: 0.3683 (0.7444)  labels_decoder: 0.2139 (0.3962)  labels_encoder_unscaled: 0.3683 (0.7444)  labels_decoder_unscaled: 0.4277 (0.7925)  time: 0.0728  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:53  loss: 0.8630 (1.1386)  labels_encoder: 0.5589 (0.7436)  labels_decoder: 0.3326 (0.3950)  labels_encoder_unscaled: 0.5589 (0.7436)  labels_decoder_unscaled: 0.6652 (0.7900)  time: 0.0630  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:49  loss: 1.7464 (1.1447)  labels_encoder: 1.1506 (0.7455)  labels_decoder: 0.6970 (0.3992)  labels_encoder_unscaled: 1.1506 (0.7455)  labels_decoder_unscaled: 1.3941 (0.7985)  time: 0.0586  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:46  loss: 0.7344 (1.1639)  labels_encoder: 0.5185 (0.7581)  labels_decoder: 0.3213 (0.4057)  labels_encoder_unscaled: 0.5185 (0.7581)  labels_decoder_unscaled: 0.6425 (0.8115)  time: 0.0642  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:43  loss: 0.9817 (1.1511)  labels_encoder: 0.6787 (0.7499)  labels_decoder: 0.3030 (0.4012)  labels_encoder_unscaled: 0.6787 (0.7499)  labels_decoder_unscaled: 0.6059 (0.8025)  time: 0.0640  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:40  loss: 0.5424 (1.1320)  labels_encoder: 0.3203 (0.7362)  labels_decoder: 0.2569 (0.3958)  labels_encoder_unscaled: 0.3203 (0.7362)  labels_decoder_unscaled: 0.5139 (0.7916)  time: 0.0679  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:36  loss: 0.8096 (1.1248)  labels_encoder: 0.4625 (0.7321)  labels_decoder: 0.3213 (0.3927)  labels_encoder_unscaled: 0.4625 (0.7321)  labels_decoder_unscaled: 0.6426 (0.7854)  time: 0.0640  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:33  loss: 0.6659 (1.1270)  labels_encoder: 0.3757 (0.7347)  labels_decoder: 0.3100 (0.3924)  labels_encoder_unscaled: 0.3757 (0.7347)  labels_decoder_unscaled: 0.6200 (0.7848)  time: 0.0635  data: 0.0008  max mem: 3384
Test:  [1150/1613]  eta: 0:00:30  loss: 0.7053 (1.1163)  labels_encoder: 0.4246 (0.7270)  labels_decoder: 0.2863 (0.3894)  labels_encoder_unscaled: 0.4246 (0.7270)  labels_decoder_unscaled: 0.5726 (0.7788)  time: 0.0657  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:26  loss: 0.6168 (1.1233)  labels_encoder: 0.3980 (0.7312)  labels_decoder: 0.2699 (0.3921)  labels_encoder_unscaled: 0.3980 (0.7312)  labels_decoder_unscaled: 0.5399 (0.7842)  time: 0.0638  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:23  loss: 0.4481 (1.1224)  labels_encoder: 0.2138 (0.7298)  labels_decoder: 0.2244 (0.3926)  labels_encoder_unscaled: 0.2138 (0.7298)  labels_decoder_unscaled: 0.4489 (0.7852)  time: 0.0657  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:20  loss: 0.6627 (1.1118)  labels_encoder: 0.4150 (0.7222)  labels_decoder: 0.2477 (0.3896)  labels_encoder_unscaled: 0.4150 (0.7222)  labels_decoder_unscaled: 0.4955 (0.7792)  time: 0.0625  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:17  loss: 0.7679 (1.1265)  labels_encoder: 0.4905 (0.7334)  labels_decoder: 0.3086 (0.3931)  labels_encoder_unscaled: 0.4905 (0.7334)  labels_decoder_unscaled: 0.6171 (0.7862)  time: 0.0599  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:13  loss: 1.0468 (1.1218)  labels_encoder: 0.7185 (0.7299)  labels_decoder: 0.4128 (0.3919)  labels_encoder_unscaled: 0.7185 (0.7299)  labels_decoder_unscaled: 0.8256 (0.7838)  time: 0.0613  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.6471 (1.1334)  labels_encoder: 0.2967 (0.7369)  labels_decoder: 0.3025 (0.3965)  labels_encoder_unscaled: 0.2967 (0.7369)  labels_decoder_unscaled: 0.6050 (0.7930)  time: 0.0613  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.7071 (1.1438)  labels_encoder: 0.4396 (0.7443)  labels_decoder: 0.2632 (0.3994)  labels_encoder_unscaled: 0.4396 (0.7443)  labels_decoder_unscaled: 0.5264 (0.7989)  time: 0.0642  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:04  loss: 0.6804 (1.1379)  labels_encoder: 0.4443 (0.7407)  labels_decoder: 0.2813 (0.3971)  labels_encoder_unscaled: 0.4443 (0.7407)  labels_decoder_unscaled: 0.5626 (0.7942)  time: 0.0583  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.9306 (1.1298)  labels_encoder: 0.5768 (0.7349)  labels_decoder: 0.3476 (0.3949)  labels_encoder_unscaled: 0.5768 (0.7349)  labels_decoder_unscaled: 0.6952 (0.7898)  time: 0.0620  data: 0.0002  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6758 (1.1273)  labels_encoder: 0.4179 (0.7335)  labels_decoder: 0.2579 (0.3939)  labels_encoder_unscaled: 0.4179 (0.7335)  labels_decoder_unscaled: 0.5158 (0.7877)  time: 0.0482  data: 0.0001  max mem: 3384
Test: Total time: 0:01:43 (0.0644 s / it)
Averaged stats: loss: 0.6758 (1.1273)  labels_encoder: 0.4179 (0.7335)  labels_decoder: 0.2579 (0.3939)  labels_encoder_unscaled: 0.4179 (0.7335)  labels_decoder_unscaled: 0.5158 (0.7877)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet] mAP: 0.5728

dec_mAP all together: | 0.4529898643989669 |.
dec_mAP_pred | 0 : 0.4969710693348075 |.
dec_mAP_pred | 1 : 0.4885315232860841 |.
dec_mAP_pred | 2 : 0.4764212682145198 |.
dec_mAP_pred | 3 : 0.46279213735627306 |.
dec_mAP_pred | 4 : 0.448138877777765 |.
dec_mAP_pred | 5 : 0.4339748804043063 |.
dec_mAP_pred | 6 : 0.4200196916120051 |.
dec_mAP_pred | 7 : 0.40696022349366456 |.
all decoder map: | 0.4542 |.
BaseballPitch: 0.1606
BasketballDunk: 0.7677
Billiards: 0.3887
CleanAndJerk: 0.7525
CliffDiving: 0.8113
CricketBowling: 0.4436
CricketShot: 0.1872
Diving: 0.6791
FrisbeeCatch: 0.3478
GolfSwing: 0.5796
HammerThrow: 0.8549
HighJump: 0.6284
JavelinThrow: 0.7062
LongJump: 0.7901
PoleVault: 0.8553
Shotput: 0.6856
SoccerPenalty: 0.3486
TennisSwing: 0.5566
ThrowDiscus: 0.5979
VolleyballSpiking: 0.3137
Training time 0:22:47
