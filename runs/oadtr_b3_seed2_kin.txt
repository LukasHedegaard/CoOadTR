Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:kin
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:2
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  75.627 M, 99.827% Params, 2.513 GMac, 100.000% MACs, 
  (linear_encoding): Linear(4.195 M, 5.538% Params, 0.268 GMac, 10.682% MACs, in_features=4096, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 24.926% Params, 1.227 GMac, 48.829% MACs, 
    (net): Sequential(
      18.884 M, 24.926% Params, 1.227 GMac, 48.829% MACs, 
      (0): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.060% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 69.274% Params, 1.017 GMac, 40.480% MACs, 
    (layers): ModuleList(
      52.48 M, 69.274% Params, 1.017 GMac, 40.480% MACs, 
      (0): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.030% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2512946220.0
Model params: 75757612
Loaded data/thumos_kin_val.pickle
Loaded data/thumos_kin_test.pickle
Start training
Epoch: [1]  [   0/1405]  eta: 1:06:11  lr: 0.000100  loss: 4.7990 (4.7990)  labels_encoder: 3.1456 (3.1456)  labels_decoder: 1.6534 (1.6534)  labels_encoder_unscaled: 3.1456 (3.1456)  labels_decoder_unscaled: 3.3069 (3.3069)  time: 2.8267  data: 2.0080  max mem: 2596
Epoch: [1]  [  50/1405]  eta: 0:05:01  lr: 0.000100  loss: 0.8880 (1.5311)  labels_encoder: 0.5850 (0.9879)  labels_decoder: 0.3405 (0.5432)  labels_encoder_unscaled: 0.5850 (0.9879)  labels_decoder_unscaled: 0.6811 (1.0863)  time: 0.1542  data: 0.0003  max mem: 3463
Epoch: [1]  [ 100/1405]  eta: 0:04:07  lr: 0.000100  loss: 0.6935 (1.1640)  labels_encoder: 0.4217 (0.7440)  labels_decoder: 0.2716 (0.4200)  labels_encoder_unscaled: 0.4217 (0.7440)  labels_decoder_unscaled: 0.5431 (0.8400)  time: 0.1582  data: 0.0002  max mem: 3463
Epoch: [1]  [ 150/1405]  eta: 0:03:42  lr: 0.000100  loss: 0.6605 (1.0021)  labels_encoder: 0.3900 (0.6355)  labels_decoder: 0.2606 (0.3667)  labels_encoder_unscaled: 0.3900 (0.6355)  labels_decoder_unscaled: 0.5212 (0.7333)  time: 0.1530  data: 0.0002  max mem: 3463
Epoch: [1]  [ 200/1405]  eta: 0:03:25  lr: 0.000100  loss: 0.5962 (0.9109)  labels_encoder: 0.3641 (0.5731)  labels_decoder: 0.2173 (0.3378)  labels_encoder_unscaled: 0.3641 (0.5731)  labels_decoder_unscaled: 0.4346 (0.6756)  time: 0.1511  data: 0.0002  max mem: 3463
Epoch: [1]  [ 250/1405]  eta: 0:03:11  lr: 0.000100  loss: 0.6184 (0.8493)  labels_encoder: 0.3791 (0.5318)  labels_decoder: 0.2428 (0.3175)  labels_encoder_unscaled: 0.3791 (0.5318)  labels_decoder_unscaled: 0.4855 (0.6350)  time: 0.1403  data: 0.0002  max mem: 3463
Epoch: [1]  [ 300/1405]  eta: 0:02:59  lr: 0.000100  loss: 0.5167 (0.7994)  labels_encoder: 0.3183 (0.4981)  labels_decoder: 0.2032 (0.3013)  labels_encoder_unscaled: 0.3183 (0.4981)  labels_decoder_unscaled: 0.4065 (0.6027)  time: 0.1437  data: 0.0002  max mem: 3463
Epoch: [1]  [ 350/1405]  eta: 0:02:48  lr: 0.000100  loss: 0.5299 (0.7618)  labels_encoder: 0.3090 (0.4724)  labels_decoder: 0.2120 (0.2894)  labels_encoder_unscaled: 0.3090 (0.4724)  labels_decoder_unscaled: 0.4239 (0.5788)  time: 0.1463  data: 0.0002  max mem: 3463
Epoch: [1]  [ 400/1405]  eta: 0:02:38  lr: 0.000100  loss: 0.4831 (0.7284)  labels_encoder: 0.2847 (0.4494)  labels_decoder: 0.2047 (0.2790)  labels_encoder_unscaled: 0.2847 (0.4494)  labels_decoder_unscaled: 0.4095 (0.5580)  time: 0.1421  data: 0.0012  max mem: 3463
Epoch: [1]  [ 450/1405]  eta: 0:02:29  lr: 0.000100  loss: 0.4944 (0.7044)  labels_encoder: 0.3049 (0.4339)  labels_decoder: 0.2022 (0.2705)  labels_encoder_unscaled: 0.3049 (0.4339)  labels_decoder_unscaled: 0.4045 (0.5410)  time: 0.1397  data: 0.0002  max mem: 3463
Epoch: [1]  [ 500/1405]  eta: 0:02:20  lr: 0.000100  loss: 0.4626 (0.6828)  labels_encoder: 0.2750 (0.4189)  labels_decoder: 0.1911 (0.2639)  labels_encoder_unscaled: 0.2750 (0.4189)  labels_decoder_unscaled: 0.3821 (0.5279)  time: 0.1427  data: 0.0002  max mem: 3463
Epoch: [1]  [ 550/1405]  eta: 0:02:11  lr: 0.000100  loss: 0.5300 (0.6662)  labels_encoder: 0.3110 (0.4078)  labels_decoder: 0.2124 (0.2584)  labels_encoder_unscaled: 0.3110 (0.4078)  labels_decoder_unscaled: 0.4248 (0.5168)  time: 0.1442  data: 0.0002  max mem: 3463
Epoch: [1]  [ 600/1405]  eta: 0:02:02  lr: 0.000100  loss: 0.4205 (0.6478)  labels_encoder: 0.2459 (0.3954)  labels_decoder: 0.1684 (0.2525)  labels_encoder_unscaled: 0.2459 (0.3954)  labels_decoder_unscaled: 0.3368 (0.5050)  time: 0.1322  data: 0.0002  max mem: 3463
Epoch: [1]  [ 650/1405]  eta: 0:01:54  lr: 0.000100  loss: 0.4456 (0.6345)  labels_encoder: 0.2503 (0.3867)  labels_decoder: 0.1962 (0.2478)  labels_encoder_unscaled: 0.2503 (0.3867)  labels_decoder_unscaled: 0.3924 (0.4956)  time: 0.1490  data: 0.0002  max mem: 3463
Epoch: [1]  [ 700/1405]  eta: 0:01:46  lr: 0.000100  loss: 0.4162 (0.6227)  labels_encoder: 0.2325 (0.3787)  labels_decoder: 0.1795 (0.2440)  labels_encoder_unscaled: 0.2325 (0.3787)  labels_decoder_unscaled: 0.3590 (0.4879)  time: 0.1462  data: 0.0002  max mem: 3463
Epoch: [1]  [ 750/1405]  eta: 0:01:38  lr: 0.000100  loss: 0.4082 (0.6102)  labels_encoder: 0.2217 (0.3703)  labels_decoder: 0.1805 (0.2399)  labels_encoder_unscaled: 0.2217 (0.3703)  labels_decoder_unscaled: 0.3611 (0.4798)  time: 0.1472  data: 0.0002  max mem: 3463
Epoch: [1]  [ 800/1405]  eta: 0:01:31  lr: 0.000100  loss: 0.4054 (0.5994)  labels_encoder: 0.2264 (0.3630)  labels_decoder: 0.1760 (0.2364)  labels_encoder_unscaled: 0.2264 (0.3630)  labels_decoder_unscaled: 0.3521 (0.4729)  time: 0.1473  data: 0.0002  max mem: 3463
Epoch: [1]  [ 850/1405]  eta: 0:01:23  lr: 0.000100  loss: 0.4083 (0.5896)  labels_encoder: 0.2435 (0.3566)  labels_decoder: 0.1701 (0.2330)  labels_encoder_unscaled: 0.2435 (0.3566)  labels_decoder_unscaled: 0.3402 (0.4660)  time: 0.1448  data: 0.0002  max mem: 3463
Epoch: [1]  [ 900/1405]  eta: 0:01:15  lr: 0.000100  loss: 0.4252 (0.5801)  labels_encoder: 0.2361 (0.3498)  labels_decoder: 0.1838 (0.2302)  labels_encoder_unscaled: 0.2361 (0.3498)  labels_decoder_unscaled: 0.3676 (0.4605)  time: 0.1481  data: 0.0003  max mem: 3463
Epoch: [1]  [ 950/1405]  eta: 0:01:08  lr: 0.000100  loss: 0.3847 (0.5713)  labels_encoder: 0.2312 (0.3440)  labels_decoder: 0.1749 (0.2273)  labels_encoder_unscaled: 0.2312 (0.3440)  labels_decoder_unscaled: 0.3497 (0.4546)  time: 0.1465  data: 0.0002  max mem: 3463
Epoch: [1]  [1000/1405]  eta: 0:01:00  lr: 0.000100  loss: 0.4031 (0.5638)  labels_encoder: 0.2347 (0.3390)  labels_decoder: 0.1643 (0.2248)  labels_encoder_unscaled: 0.2347 (0.3390)  labels_decoder_unscaled: 0.3286 (0.4496)  time: 0.1492  data: 0.0003  max mem: 3463
Epoch: [1]  [1050/1405]  eta: 0:00:52  lr: 0.000100  loss: 0.3933 (0.5571)  labels_encoder: 0.2207 (0.3343)  labels_decoder: 0.1702 (0.2228)  labels_encoder_unscaled: 0.2207 (0.3343)  labels_decoder_unscaled: 0.3404 (0.4456)  time: 0.1476  data: 0.0003  max mem: 3463
Epoch: [1]  [1100/1405]  eta: 0:00:45  lr: 0.000100  loss: 0.4112 (0.5503)  labels_encoder: 0.2284 (0.3298)  labels_decoder: 0.1708 (0.2205)  labels_encoder_unscaled: 0.2284 (0.3298)  labels_decoder_unscaled: 0.3415 (0.4410)  time: 0.1461  data: 0.0002  max mem: 3463
Epoch: [1]  [1150/1405]  eta: 0:00:38  lr: 0.000100  loss: 0.4251 (0.5447)  labels_encoder: 0.2468 (0.3263)  labels_decoder: 0.1689 (0.2185)  labels_encoder_unscaled: 0.2468 (0.3263)  labels_decoder_unscaled: 0.3379 (0.4369)  time: 0.1465  data: 0.0002  max mem: 3463
Epoch: [1]  [1200/1405]  eta: 0:00:30  lr: 0.000100  loss: 0.3448 (0.5380)  labels_encoder: 0.1882 (0.3217)  labels_decoder: 0.1526 (0.2162)  labels_encoder_unscaled: 0.1882 (0.3217)  labels_decoder_unscaled: 0.3052 (0.4325)  time: 0.1445  data: 0.0003  max mem: 3463
Epoch: [1]  [1250/1405]  eta: 0:00:23  lr: 0.000100  loss: 0.3524 (0.5316)  labels_encoder: 0.1945 (0.3175)  labels_decoder: 0.1624 (0.2141)  labels_encoder_unscaled: 0.1945 (0.3175)  labels_decoder_unscaled: 0.3247 (0.4282)  time: 0.1468  data: 0.0002  max mem: 3463
Epoch: [1]  [1300/1405]  eta: 0:00:15  lr: 0.000100  loss: 0.3674 (0.5261)  labels_encoder: 0.2192 (0.3140)  labels_decoder: 0.1511 (0.2121)  labels_encoder_unscaled: 0.2192 (0.3140)  labels_decoder_unscaled: 0.3021 (0.4242)  time: 0.1461  data: 0.0003  max mem: 3463
Epoch: [1]  [1350/1405]  eta: 0:00:08  lr: 0.000100  loss: 0.3672 (0.5208)  labels_encoder: 0.2212 (0.3104)  labels_decoder: 0.1533 (0.2103)  labels_encoder_unscaled: 0.2212 (0.3104)  labels_decoder_unscaled: 0.3065 (0.4207)  time: 0.1447  data: 0.0002  max mem: 3463
Epoch: [1]  [1400/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3387 (0.5152)  labels_encoder: 0.1915 (0.3067)  labels_decoder: 0.1488 (0.2085)  labels_encoder_unscaled: 0.1915 (0.3067)  labels_decoder_unscaled: 0.2977 (0.4170)  time: 0.1307  data: 0.0003  max mem: 3463
Epoch: [1]  [1404/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3387 (0.5146)  labels_encoder: 0.1915 (0.3063)  labels_decoder: 0.1488 (0.2083)  labels_encoder_unscaled: 0.1915 (0.3063)  labels_decoder_unscaled: 0.2977 (0.4166)  time: 0.1272  data: 0.0003  max mem: 3463
Epoch: [1] Total time: 0:03:28 (0.1485 s / it)
Averaged stats: lr: 0.000100  loss: 0.3387 (0.5146)  labels_encoder: 0.1915 (0.3063)  labels_decoder: 0.1488 (0.2083)  labels_encoder_unscaled: 0.1915 (0.3063)  labels_decoder_unscaled: 0.2977 (0.4166)
Test:  [   0/1613]  eta: 0:42:22  loss: 0.2622 (0.2622)  labels_encoder: 0.1270 (0.1270)  labels_decoder: 0.1352 (0.1352)  labels_encoder_unscaled: 0.1270 (0.1270)  labels_decoder_unscaled: 0.2704 (0.2704)  time: 1.5764  data: 1.5093  max mem: 3463
Test:  [  50/1613]  eta: 0:02:23  loss: 0.5647 (0.8378)  labels_encoder: 0.3145 (0.5288)  labels_decoder: 0.2572 (0.3090)  labels_encoder_unscaled: 0.3145 (0.5288)  labels_decoder_unscaled: 0.5143 (0.6181)  time: 0.0597  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:01:55  loss: 0.6264 (0.8601)  labels_encoder: 0.3379 (0.5761)  labels_decoder: 0.2156 (0.2840)  labels_encoder_unscaled: 0.3379 (0.5761)  labels_decoder_unscaled: 0.4313 (0.5680)  time: 0.0637  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:43  loss: 0.5673 (0.7982)  labels_encoder: 0.4224 (0.5270)  labels_decoder: 0.1449 (0.2712)  labels_encoder_unscaled: 0.4224 (0.5270)  labels_decoder_unscaled: 0.2898 (0.5425)  time: 0.0583  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:36  loss: 0.8500 (0.8653)  labels_encoder: 0.5014 (0.5666)  labels_decoder: 0.3590 (0.2987)  labels_encoder_unscaled: 0.5014 (0.5666)  labels_decoder_unscaled: 0.7181 (0.5974)  time: 0.0585  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:31  loss: 0.3749 (0.9015)  labels_encoder: 0.2066 (0.5878)  labels_decoder: 0.0936 (0.3137)  labels_encoder_unscaled: 0.2066 (0.5878)  labels_decoder_unscaled: 0.1873 (0.6274)  time: 0.0621  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:26  loss: 0.8066 (0.9005)  labels_encoder: 0.4754 (0.5845)  labels_decoder: 0.3071 (0.3160)  labels_encoder_unscaled: 0.4754 (0.5845)  labels_decoder_unscaled: 0.6141 (0.6321)  time: 0.0595  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:22  loss: 0.9863 (0.9040)  labels_encoder: 0.5994 (0.5863)  labels_decoder: 0.3832 (0.3177)  labels_encoder_unscaled: 0.5994 (0.5863)  labels_decoder_unscaled: 0.7664 (0.6355)  time: 0.0574  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:18  loss: 0.8794 (0.9721)  labels_encoder: 0.5464 (0.6321)  labels_decoder: 0.3354 (0.3399)  labels_encoder_unscaled: 0.5464 (0.6321)  labels_decoder_unscaled: 0.6707 (0.6798)  time: 0.0619  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:14  loss: 0.8629 (1.0423)  labels_encoder: 0.5425 (0.6771)  labels_decoder: 0.3204 (0.3652)  labels_encoder_unscaled: 0.5425 (0.6771)  labels_decoder_unscaled: 0.6408 (0.7304)  time: 0.0583  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:10  loss: 0.4498 (1.0032)  labels_encoder: 0.2113 (0.6498)  labels_decoder: 0.1934 (0.3534)  labels_encoder_unscaled: 0.2113 (0.6498)  labels_decoder_unscaled: 0.3867 (0.7068)  time: 0.0592  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:06  loss: 0.6949 (0.9944)  labels_encoder: 0.4436 (0.6447)  labels_decoder: 0.2513 (0.3497)  labels_encoder_unscaled: 0.4436 (0.6447)  labels_decoder_unscaled: 0.5026 (0.6995)  time: 0.0574  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:03  loss: 0.5855 (1.0686)  labels_encoder: 0.3321 (0.7040)  labels_decoder: 0.2356 (0.3645)  labels_encoder_unscaled: 0.3321 (0.7040)  labels_decoder_unscaled: 0.4712 (0.7291)  time: 0.0650  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:00  loss: 0.6985 (1.0511)  labels_encoder: 0.3594 (0.6883)  labels_decoder: 0.3532 (0.3628)  labels_encoder_unscaled: 0.3594 (0.6883)  labels_decoder_unscaled: 0.7063 (0.7256)  time: 0.0610  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:00:56  loss: 0.5643 (1.0244)  labels_encoder: 0.3595 (0.6701)  labels_decoder: 0.2085 (0.3544)  labels_encoder_unscaled: 0.3595 (0.6701)  labels_decoder_unscaled: 0.4169 (0.7087)  time: 0.0603  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:00:53  loss: 0.5829 (1.0003)  labels_encoder: 0.2880 (0.6533)  labels_decoder: 0.1885 (0.3470)  labels_encoder_unscaled: 0.2880 (0.6533)  labels_decoder_unscaled: 0.3770 (0.6939)  time: 0.0567  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:50  loss: 0.6068 (0.9856)  labels_encoder: 0.2848 (0.6443)  labels_decoder: 0.2098 (0.3414)  labels_encoder_unscaled: 0.2848 (0.6443)  labels_decoder_unscaled: 0.4197 (0.6827)  time: 0.0591  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:47  loss: 1.0225 (0.9907)  labels_encoder: 0.5575 (0.6445)  labels_decoder: 0.3459 (0.3462)  labels_encoder_unscaled: 0.5575 (0.6445)  labels_decoder_unscaled: 0.6918 (0.6925)  time: 0.0577  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:43  loss: 0.6018 (0.9834)  labels_encoder: 0.3397 (0.6371)  labels_decoder: 0.2621 (0.3462)  labels_encoder_unscaled: 0.3397 (0.6371)  labels_decoder_unscaled: 0.5243 (0.6924)  time: 0.0585  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:40  loss: 0.8734 (0.9774)  labels_encoder: 0.5654 (0.6330)  labels_decoder: 0.3317 (0.3443)  labels_encoder_unscaled: 0.5654 (0.6330)  labels_decoder_unscaled: 0.6634 (0.6887)  time: 0.0646  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:37  loss: 0.7292 (0.9739)  labels_encoder: 0.4398 (0.6298)  labels_decoder: 0.2733 (0.3441)  labels_encoder_unscaled: 0.4398 (0.6298)  labels_decoder_unscaled: 0.5467 (0.6883)  time: 0.0607  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:34  loss: 0.9673 (0.9868)  labels_encoder: 0.6627 (0.6405)  labels_decoder: 0.3457 (0.3463)  labels_encoder_unscaled: 0.6627 (0.6405)  labels_decoder_unscaled: 0.6914 (0.6926)  time: 0.0602  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:31  loss: 0.3872 (0.9759)  labels_encoder: 0.2413 (0.6330)  labels_decoder: 0.1880 (0.3429)  labels_encoder_unscaled: 0.2413 (0.6330)  labels_decoder_unscaled: 0.3759 (0.6857)  time: 0.0558  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:28  loss: 0.7266 (0.9707)  labels_encoder: 0.4913 (0.6297)  labels_decoder: 0.2218 (0.3410)  labels_encoder_unscaled: 0.4913 (0.6297)  labels_decoder_unscaled: 0.4436 (0.6820)  time: 0.0591  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:25  loss: 0.6391 (0.9732)  labels_encoder: 0.3280 (0.6309)  labels_decoder: 0.2087 (0.3424)  labels_encoder_unscaled: 0.3280 (0.6309)  labels_decoder_unscaled: 0.4173 (0.6848)  time: 0.0577  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:22  loss: 0.5205 (0.9766)  labels_encoder: 0.2729 (0.6336)  labels_decoder: 0.2229 (0.3430)  labels_encoder_unscaled: 0.2729 (0.6336)  labels_decoder_unscaled: 0.4458 (0.6860)  time: 0.0589  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5441 (0.9693)  labels_encoder: 0.2884 (0.6278)  labels_decoder: 0.2585 (0.3415)  labels_encoder_unscaled: 0.2884 (0.6278)  labels_decoder_unscaled: 0.5170 (0.6830)  time: 0.0572  data: 0.0009  max mem: 3463
Test:  [1350/1613]  eta: 0:00:16  loss: 1.0781 (0.9710)  labels_encoder: 0.8152 (0.6290)  labels_decoder: 0.4283 (0.3420)  labels_encoder_unscaled: 0.8152 (0.6290)  labels_decoder_unscaled: 0.8565 (0.6840)  time: 0.0593  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:12  loss: 0.7883 (0.9753)  labels_encoder: 0.5127 (0.6326)  labels_decoder: 0.2974 (0.3428)  labels_encoder_unscaled: 0.5127 (0.6326)  labels_decoder_unscaled: 0.5949 (0.6855)  time: 0.0580  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:09  loss: 0.7021 (0.9888)  labels_encoder: 0.4463 (0.6426)  labels_decoder: 0.2724 (0.3462)  labels_encoder_unscaled: 0.4463 (0.6426)  labels_decoder_unscaled: 0.5448 (0.6924)  time: 0.0587  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:06  loss: 0.5280 (0.9954)  labels_encoder: 0.3125 (0.6481)  labels_decoder: 0.1751 (0.3473)  labels_encoder_unscaled: 0.3125 (0.6481)  labels_decoder_unscaled: 0.3501 (0.6946)  time: 0.0793  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:03  loss: 0.7543 (0.9924)  labels_encoder: 0.4743 (0.6464)  labels_decoder: 0.2725 (0.3459)  labels_encoder_unscaled: 0.4743 (0.6464)  labels_decoder_unscaled: 0.5451 (0.6918)  time: 0.0594  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8391 (0.9904)  labels_encoder: 0.5230 (0.6442)  labels_decoder: 0.3112 (0.3462)  labels_encoder_unscaled: 0.5230 (0.6442)  labels_decoder_unscaled: 0.6224 (0.6924)  time: 0.0540  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5689 (0.9888)  labels_encoder: 0.3401 (0.6433)  labels_decoder: 0.2288 (0.3454)  labels_encoder_unscaled: 0.3401 (0.6433)  labels_decoder_unscaled: 0.4577 (0.6909)  time: 0.0440  data: 0.0001  max mem: 3463
Test: Total time: 0:01:38 (0.0608 s / it)
Averaged stats: loss: 0.5689 (0.9888)  labels_encoder: 0.3401 (0.6433)  labels_decoder: 0.2288 (0.3454)  labels_encoder_unscaled: 0.3401 (0.6433)  labels_decoder_unscaled: 0.4577 (0.6909)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-kin] mAP: 0.6383

dec_mAP all together: | 0.5119910261739167 |.
dec_mAP_pred | 0 : 0.5723099164905205 |.
dec_mAP_pred | 1 : 0.5593163532758779 |.
dec_mAP_pred | 2 : 0.5429532073800357 |.
dec_mAP_pred | 3 : 0.5241505004848309 |.
dec_mAP_pred | 4 : 0.5050163643414745 |.
dec_mAP_pred | 5 : 0.48640947227738146 |.
dec_mAP_pred | 6 : 0.46848561226745317 |.
dec_mAP_pred | 7 : 0.45151973350859437 |.
all decoder map: | 0.5138 |.
BaseballPitch: 0.4750
BasketballDunk: 0.8144
Billiards: 0.2784
CleanAndJerk: 0.7545
CliffDiving: 0.8383
CricketBowling: 0.4659
CricketShot: 0.3324
Diving: 0.8576
FrisbeeCatch: 0.3494
GolfSwing: 0.7593
HammerThrow: 0.8748
HighJump: 0.7572
JavelinThrow: 0.7723
LongJump: 0.7888
PoleVault: 0.8700
Shotput: 0.7491
SoccerPenalty: 0.4647
TennisSwing: 0.5219
ThrowDiscus: 0.6295
VolleyballSpiking: 0.4126
Epoch: [2]  [   0/1405]  eta: 0:42:46  lr: 0.000010  loss: 0.3194 (0.3194)  labels_encoder: 0.1524 (0.1524)  labels_decoder: 0.1670 (0.1670)  labels_encoder_unscaled: 0.1524 (0.1524)  labels_decoder_unscaled: 0.3340 (0.3340)  time: 1.8264  data: 1.6542  max mem: 3463
Epoch: [2]  [  50/1405]  eta: 0:03:57  lr: 0.000010  loss: 0.2910 (0.3087)  labels_encoder: 0.1531 (0.1694)  labels_decoder: 0.1270 (0.1394)  labels_encoder_unscaled: 0.1531 (0.1694)  labels_decoder_unscaled: 0.2540 (0.2788)  time: 0.1413  data: 0.0002  max mem: 3463
Epoch: [2]  [ 100/1405]  eta: 0:03:27  lr: 0.000010  loss: 0.2662 (0.2968)  labels_encoder: 0.1353 (0.1618)  labels_decoder: 0.1273 (0.1350)  labels_encoder_unscaled: 0.1353 (0.1618)  labels_decoder_unscaled: 0.2546 (0.2700)  time: 0.1430  data: 0.0002  max mem: 3463
Epoch: [2]  [ 150/1405]  eta: 0:03:13  lr: 0.000010  loss: 0.2675 (0.2917)  labels_encoder: 0.1493 (0.1584)  labels_decoder: 0.1261 (0.1334)  labels_encoder_unscaled: 0.1493 (0.1584)  labels_decoder_unscaled: 0.2521 (0.2667)  time: 0.1451  data: 0.0002  max mem: 3463
Epoch: [2]  [ 200/1405]  eta: 0:03:02  lr: 0.000010  loss: 0.2592 (0.2910)  labels_encoder: 0.1474 (0.1574)  labels_decoder: 0.1276 (0.1336)  labels_encoder_unscaled: 0.1474 (0.1574)  labels_decoder_unscaled: 0.2552 (0.2671)  time: 0.1413  data: 0.0002  max mem: 3463
Epoch: [2]  [ 250/1405]  eta: 0:02:53  lr: 0.000010  loss: 0.2652 (0.2891)  labels_encoder: 0.1387 (0.1563)  labels_decoder: 0.1234 (0.1328)  labels_encoder_unscaled: 0.1387 (0.1563)  labels_decoder_unscaled: 0.2468 (0.2656)  time: 0.1456  data: 0.0002  max mem: 3463
Epoch: [2]  [ 300/1405]  eta: 0:02:44  lr: 0.000010  loss: 0.2739 (0.2893)  labels_encoder: 0.1572 (0.1567)  labels_decoder: 0.1277 (0.1326)  labels_encoder_unscaled: 0.1572 (0.1567)  labels_decoder_unscaled: 0.2554 (0.2652)  time: 0.1448  data: 0.0002  max mem: 3463
Epoch: [2]  [ 350/1405]  eta: 0:02:36  lr: 0.000010  loss: 0.2743 (0.2885)  labels_encoder: 0.1403 (0.1560)  labels_decoder: 0.1272 (0.1325)  labels_encoder_unscaled: 0.1403 (0.1560)  labels_decoder_unscaled: 0.2543 (0.2650)  time: 0.1415  data: 0.0003  max mem: 3463
Epoch: [2]  [ 400/1405]  eta: 0:02:27  lr: 0.000010  loss: 0.2801 (0.2870)  labels_encoder: 0.1481 (0.1549)  labels_decoder: 0.1330 (0.1321)  labels_encoder_unscaled: 0.1481 (0.1549)  labels_decoder_unscaled: 0.2659 (0.2642)  time: 0.1428  data: 0.0002  max mem: 3463
Epoch: [2]  [ 450/1405]  eta: 0:02:19  lr: 0.000010  loss: 0.2680 (0.2854)  labels_encoder: 0.1367 (0.1537)  labels_decoder: 0.1200 (0.1318)  labels_encoder_unscaled: 0.1367 (0.1537)  labels_decoder_unscaled: 0.2400 (0.2636)  time: 0.1398  data: 0.0002  max mem: 3463
Epoch: [2]  [ 500/1405]  eta: 0:02:11  lr: 0.000010  loss: 0.2679 (0.2848)  labels_encoder: 0.1453 (0.1530)  labels_decoder: 0.1338 (0.1318)  labels_encoder_unscaled: 0.1453 (0.1530)  labels_decoder_unscaled: 0.2677 (0.2636)  time: 0.1378  data: 0.0002  max mem: 3463
Epoch: [2]  [ 550/1405]  eta: 0:02:04  lr: 0.000010  loss: 0.2794 (0.2837)  labels_encoder: 0.1434 (0.1522)  labels_decoder: 0.1308 (0.1315)  labels_encoder_unscaled: 0.1434 (0.1522)  labels_decoder_unscaled: 0.2616 (0.2630)  time: 0.1380  data: 0.0002  max mem: 3463
Epoch: [2]  [ 600/1405]  eta: 0:01:56  lr: 0.000010  loss: 0.2572 (0.2819)  labels_encoder: 0.1307 (0.1513)  labels_decoder: 0.1149 (0.1306)  labels_encoder_unscaled: 0.1307 (0.1513)  labels_decoder_unscaled: 0.2298 (0.2612)  time: 0.1437  data: 0.0002  max mem: 3463
Epoch: [2]  [ 650/1405]  eta: 0:01:49  lr: 0.000010  loss: 0.2713 (0.2812)  labels_encoder: 0.1349 (0.1507)  labels_decoder: 0.1351 (0.1305)  labels_encoder_unscaled: 0.1349 (0.1507)  labels_decoder_unscaled: 0.2703 (0.2610)  time: 0.1453  data: 0.0002  max mem: 3463
Epoch: [2]  [ 700/1405]  eta: 0:01:42  lr: 0.000010  loss: 0.2777 (0.2807)  labels_encoder: 0.1437 (0.1503)  labels_decoder: 0.1237 (0.1304)  labels_encoder_unscaled: 0.1437 (0.1503)  labels_decoder_unscaled: 0.2475 (0.2609)  time: 0.1434  data: 0.0002  max mem: 3463
Epoch: [2]  [ 750/1405]  eta: 0:01:34  lr: 0.000010  loss: 0.2449 (0.2798)  labels_encoder: 0.1364 (0.1498)  labels_decoder: 0.1227 (0.1300)  labels_encoder_unscaled: 0.1364 (0.1498)  labels_decoder_unscaled: 0.2454 (0.2600)  time: 0.1458  data: 0.0003  max mem: 3463
Epoch: [2]  [ 800/1405]  eta: 0:01:27  lr: 0.000010  loss: 0.2422 (0.2785)  labels_encoder: 0.1218 (0.1490)  labels_decoder: 0.1294 (0.1295)  labels_encoder_unscaled: 0.1218 (0.1490)  labels_decoder_unscaled: 0.2588 (0.2591)  time: 0.1428  data: 0.0002  max mem: 3463
Epoch: [2]  [ 850/1405]  eta: 0:01:20  lr: 0.000010  loss: 0.2526 (0.2776)  labels_encoder: 0.1236 (0.1483)  labels_decoder: 0.1227 (0.1293)  labels_encoder_unscaled: 0.1236 (0.1483)  labels_decoder_unscaled: 0.2454 (0.2585)  time: 0.1457  data: 0.0002  max mem: 3463
Epoch: [2]  [ 900/1405]  eta: 0:01:13  lr: 0.000010  loss: 0.2622 (0.2770)  labels_encoder: 0.1487 (0.1478)  labels_decoder: 0.1253 (0.1291)  labels_encoder_unscaled: 0.1487 (0.1478)  labels_decoder_unscaled: 0.2506 (0.2583)  time: 0.1466  data: 0.0002  max mem: 3463
Epoch: [2]  [ 950/1405]  eta: 0:01:05  lr: 0.000010  loss: 0.2452 (0.2758)  labels_encoder: 0.1232 (0.1470)  labels_decoder: 0.1172 (0.1288)  labels_encoder_unscaled: 0.1232 (0.1470)  labels_decoder_unscaled: 0.2345 (0.2575)  time: 0.1462  data: 0.0003  max mem: 3463
Epoch: [2]  [1000/1405]  eta: 0:00:58  lr: 0.000010  loss: 0.2479 (0.2750)  labels_encoder: 0.1347 (0.1465)  labels_decoder: 0.1111 (0.1284)  labels_encoder_unscaled: 0.1347 (0.1465)  labels_decoder_unscaled: 0.2222 (0.2568)  time: 0.1459  data: 0.0003  max mem: 3463
Epoch: [2]  [1050/1405]  eta: 0:00:51  lr: 0.000010  loss: 0.2571 (0.2746)  labels_encoder: 0.1347 (0.1463)  labels_decoder: 0.1236 (0.1283)  labels_encoder_unscaled: 0.1347 (0.1463)  labels_decoder_unscaled: 0.2472 (0.2566)  time: 0.1459  data: 0.0003  max mem: 3463
Epoch: [2]  [1100/1405]  eta: 0:00:44  lr: 0.000010  loss: 0.2678 (0.2740)  labels_encoder: 0.1374 (0.1461)  labels_decoder: 0.1257 (0.1280)  labels_encoder_unscaled: 0.1374 (0.1461)  labels_decoder_unscaled: 0.2514 (0.2559)  time: 0.1471  data: 0.0002  max mem: 3463
Epoch: [2]  [1150/1405]  eta: 0:00:36  lr: 0.000010  loss: 0.2501 (0.2734)  labels_encoder: 0.1339 (0.1457)  labels_decoder: 0.1190 (0.1277)  labels_encoder_unscaled: 0.1339 (0.1457)  labels_decoder_unscaled: 0.2380 (0.2554)  time: 0.1449  data: 0.0003  max mem: 3463
Epoch: [2]  [1200/1405]  eta: 0:00:29  lr: 0.000010  loss: 0.2437 (0.2726)  labels_encoder: 0.1183 (0.1451)  labels_decoder: 0.1190 (0.1275)  labels_encoder_unscaled: 0.1183 (0.1451)  labels_decoder_unscaled: 0.2380 (0.2550)  time: 0.1468  data: 0.0002  max mem: 3463
Epoch: [2]  [1250/1405]  eta: 0:00:22  lr: 0.000010  loss: 0.2470 (0.2715)  labels_encoder: 0.1229 (0.1443)  labels_decoder: 0.1186 (0.1272)  labels_encoder_unscaled: 0.1229 (0.1443)  labels_decoder_unscaled: 0.2372 (0.2544)  time: 0.1526  data: 0.0003  max mem: 3463
Epoch: [2]  [1300/1405]  eta: 0:00:15  lr: 0.000010  loss: 0.2212 (0.2708)  labels_encoder: 0.1208 (0.1440)  labels_decoder: 0.1068 (0.1268)  labels_encoder_unscaled: 0.1208 (0.1440)  labels_decoder_unscaled: 0.2135 (0.2536)  time: 0.1497  data: 0.0003  max mem: 3463
Epoch: [2]  [1350/1405]  eta: 0:00:08  lr: 0.000010  loss: 0.2249 (0.2700)  labels_encoder: 0.1142 (0.1436)  labels_decoder: 0.1125 (0.1264)  labels_encoder_unscaled: 0.1142 (0.1436)  labels_decoder_unscaled: 0.2251 (0.2528)  time: 0.1517  data: 0.0003  max mem: 3463
Epoch: [2]  [1400/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2558 (0.2694)  labels_encoder: 0.1340 (0.1432)  labels_decoder: 0.1198 (0.1262)  labels_encoder_unscaled: 0.1340 (0.1432)  labels_decoder_unscaled: 0.2395 (0.2524)  time: 0.1374  data: 0.0004  max mem: 3463
Epoch: [2]  [1404/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2506 (0.2693)  labels_encoder: 0.1298 (0.1432)  labels_decoder: 0.1109 (0.1261)  labels_encoder_unscaled: 0.1298 (0.1432)  labels_decoder_unscaled: 0.2219 (0.2523)  time: 0.1312  data: 0.0003  max mem: 3463
Epoch: [2] Total time: 0:03:25 (0.1460 s / it)
Averaged stats: lr: 0.000010  loss: 0.2506 (0.2693)  labels_encoder: 0.1298 (0.1432)  labels_decoder: 0.1109 (0.1261)  labels_encoder_unscaled: 0.1298 (0.1432)  labels_decoder_unscaled: 0.2219 (0.2523)
Test:  [   0/1613]  eta: 0:50:23  loss: 0.3821 (0.3821)  labels_encoder: 0.2056 (0.2056)  labels_decoder: 0.1765 (0.1765)  labels_encoder_unscaled: 0.2056 (0.2056)  labels_decoder_unscaled: 0.3531 (0.3531)  time: 1.8744  data: 1.7970  max mem: 3463
Test:  [  50/1613]  eta: 0:02:35  loss: 0.5035 (0.8112)  labels_encoder: 0.3090 (0.5068)  labels_decoder: 0.2397 (0.3044)  labels_encoder_unscaled: 0.3090 (0.5068)  labels_decoder_unscaled: 0.4794 (0.6087)  time: 0.0598  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:01:55  loss: 0.5676 (0.7700)  labels_encoder: 0.3332 (0.4982)  labels_decoder: 0.1836 (0.2718)  labels_encoder_unscaled: 0.3332 (0.4982)  labels_decoder_unscaled: 0.3673 (0.5435)  time: 0.0540  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:42  loss: 0.7089 (0.7442)  labels_encoder: 0.5068 (0.4733)  labels_decoder: 0.2729 (0.2709)  labels_encoder_unscaled: 0.5068 (0.4733)  labels_decoder_unscaled: 0.5457 (0.5419)  time: 0.0632  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:36  loss: 0.8441 (0.8719)  labels_encoder: 0.4711 (0.5550)  labels_decoder: 0.3582 (0.3169)  labels_encoder_unscaled: 0.4711 (0.5550)  labels_decoder_unscaled: 0.7164 (0.6337)  time: 0.0640  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:30  loss: 0.9660 (0.9200)  labels_encoder: 0.5262 (0.5811)  labels_decoder: 0.3669 (0.3389)  labels_encoder_unscaled: 0.5262 (0.5811)  labels_decoder_unscaled: 0.7339 (0.6779)  time: 0.0553  data: 0.0001  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:25  loss: 0.6104 (0.8987)  labels_encoder: 0.3632 (0.5673)  labels_decoder: 0.2472 (0.3314)  labels_encoder_unscaled: 0.3632 (0.5673)  labels_decoder_unscaled: 0.4945 (0.6628)  time: 0.0579  data: 0.0001  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:21  loss: 1.1430 (0.9309)  labels_encoder: 0.6496 (0.5920)  labels_decoder: 0.4462 (0.3389)  labels_encoder_unscaled: 0.6496 (0.5920)  labels_decoder_unscaled: 0.8925 (0.6777)  time: 0.0564  data: 0.0001  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:17  loss: 0.7934 (0.9892)  labels_encoder: 0.4380 (0.6323)  labels_decoder: 0.2939 (0.3569)  labels_encoder_unscaled: 0.4380 (0.6323)  labels_decoder_unscaled: 0.5879 (0.7137)  time: 0.0580  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:13  loss: 0.7823 (1.0590)  labels_encoder: 0.5451 (0.6812)  labels_decoder: 0.2595 (0.3778)  labels_encoder_unscaled: 0.5451 (0.6812)  labels_decoder_unscaled: 0.5191 (0.7556)  time: 0.0592  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:10  loss: 0.4140 (1.0182)  labels_encoder: 0.1756 (0.6527)  labels_decoder: 0.1778 (0.3655)  labels_encoder_unscaled: 0.1756 (0.6527)  labels_decoder_unscaled: 0.3557 (0.7310)  time: 0.0624  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:06  loss: 0.5733 (1.0009)  labels_encoder: 0.3174 (0.6419)  labels_decoder: 0.2149 (0.3590)  labels_encoder_unscaled: 0.3174 (0.6419)  labels_decoder_unscaled: 0.4298 (0.7179)  time: 0.0583  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:03  loss: 0.6726 (1.0582)  labels_encoder: 0.3550 (0.6888)  labels_decoder: 0.2890 (0.3693)  labels_encoder_unscaled: 0.3550 (0.6888)  labels_decoder_unscaled: 0.5780 (0.7386)  time: 0.0560  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:00:59  loss: 1.1353 (1.0633)  labels_encoder: 0.6902 (0.6900)  labels_decoder: 0.4349 (0.3733)  labels_encoder_unscaled: 0.6902 (0.6900)  labels_decoder_unscaled: 0.8698 (0.7466)  time: 0.0566  data: 0.0001  max mem: 3463
Test:  [ 700/1613]  eta: 0:00:56  loss: 0.5824 (1.0404)  labels_encoder: 0.3678 (0.6738)  labels_decoder: 0.2143 (0.3666)  labels_encoder_unscaled: 0.3678 (0.6738)  labels_decoder_unscaled: 0.4287 (0.7333)  time: 0.0582  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:00:53  loss: 0.5898 (1.0150)  labels_encoder: 0.2956 (0.6553)  labels_decoder: 0.2145 (0.3596)  labels_encoder_unscaled: 0.2956 (0.6553)  labels_decoder_unscaled: 0.4291 (0.7193)  time: 0.0609  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:50  loss: 0.4432 (1.0011)  labels_encoder: 0.2831 (0.6467)  labels_decoder: 0.1930 (0.3544)  labels_encoder_unscaled: 0.2831 (0.6467)  labels_decoder_unscaled: 0.3861 (0.7089)  time: 0.0665  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:47  loss: 0.9355 (1.0101)  labels_encoder: 0.5958 (0.6494)  labels_decoder: 0.3620 (0.3607)  labels_encoder_unscaled: 0.5958 (0.6494)  labels_decoder_unscaled: 0.7241 (0.7214)  time: 0.0607  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:44  loss: 0.6562 (0.9928)  labels_encoder: 0.3613 (0.6358)  labels_decoder: 0.2744 (0.3570)  labels_encoder_unscaled: 0.3613 (0.6358)  labels_decoder_unscaled: 0.5489 (0.7140)  time: 0.0581  data: 0.0001  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:40  loss: 0.8104 (0.9812)  labels_encoder: 0.4854 (0.6275)  labels_decoder: 0.3158 (0.3537)  labels_encoder_unscaled: 0.4854 (0.6275)  labels_decoder_unscaled: 0.6317 (0.7074)  time: 0.0573  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:37  loss: 0.7074 (0.9690)  labels_encoder: 0.4430 (0.6188)  labels_decoder: 0.2780 (0.3502)  labels_encoder_unscaled: 0.4430 (0.6188)  labels_decoder_unscaled: 0.5559 (0.7004)  time: 0.0577  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:34  loss: 1.0346 (0.9765)  labels_encoder: 0.6839 (0.6248)  labels_decoder: 0.3439 (0.3517)  labels_encoder_unscaled: 0.6839 (0.6248)  labels_decoder_unscaled: 0.6878 (0.7034)  time: 0.0585  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:31  loss: 0.3896 (0.9688)  labels_encoder: 0.2140 (0.6201)  labels_decoder: 0.1790 (0.3488)  labels_encoder_unscaled: 0.2140 (0.6201)  labels_decoder_unscaled: 0.3579 (0.6976)  time: 0.0664  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:28  loss: 0.7083 (0.9700)  labels_encoder: 0.5643 (0.6203)  labels_decoder: 0.2369 (0.3497)  labels_encoder_unscaled: 0.5643 (0.6203)  labels_decoder_unscaled: 0.4738 (0.6993)  time: 0.0607  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:25  loss: 0.5124 (0.9788)  labels_encoder: 0.2646 (0.6257)  labels_decoder: 0.2031 (0.3531)  labels_encoder_unscaled: 0.2646 (0.6257)  labels_decoder_unscaled: 0.4063 (0.7063)  time: 0.0622  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:22  loss: 0.4374 (0.9772)  labels_encoder: 0.2599 (0.6244)  labels_decoder: 0.2053 (0.3527)  labels_encoder_unscaled: 0.2599 (0.6244)  labels_decoder_unscaled: 0.4106 (0.7055)  time: 0.0615  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5086 (0.9668)  labels_encoder: 0.2877 (0.6168)  labels_decoder: 0.2288 (0.3500)  labels_encoder_unscaled: 0.2877 (0.6168)  labels_decoder_unscaled: 0.4577 (0.7000)  time: 0.0621  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:16  loss: 0.9866 (0.9687)  labels_encoder: 0.5908 (0.6182)  labels_decoder: 0.3703 (0.3505)  labels_encoder_unscaled: 0.5908 (0.6182)  labels_decoder_unscaled: 0.7406 (0.7009)  time: 0.0613  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:13  loss: 0.7803 (0.9764)  labels_encoder: 0.4631 (0.6237)  labels_decoder: 0.2849 (0.3527)  labels_encoder_unscaled: 0.4631 (0.6237)  labels_decoder_unscaled: 0.5697 (0.7053)  time: 0.0593  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:10  loss: 0.5634 (0.9769)  labels_encoder: 0.2695 (0.6239)  labels_decoder: 0.2167 (0.3530)  labels_encoder_unscaled: 0.2695 (0.6239)  labels_decoder_unscaled: 0.4335 (0.7061)  time: 0.0587  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:06  loss: 0.5480 (0.9763)  labels_encoder: 0.3024 (0.6235)  labels_decoder: 0.2077 (0.3528)  labels_encoder_unscaled: 0.3024 (0.6235)  labels_decoder_unscaled: 0.4154 (0.7057)  time: 0.0579  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:03  loss: 0.7915 (0.9747)  labels_encoder: 0.4812 (0.6226)  labels_decoder: 0.2905 (0.3520)  labels_encoder_unscaled: 0.4812 (0.6226)  labels_decoder_unscaled: 0.5810 (0.7041)  time: 0.0616  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8868 (0.9712)  labels_encoder: 0.5076 (0.6198)  labels_decoder: 0.3717 (0.3514)  labels_encoder_unscaled: 0.5076 (0.6198)  labels_decoder_unscaled: 0.7434 (0.7027)  time: 0.0578  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6332 (0.9697)  labels_encoder: 0.3625 (0.6191)  labels_decoder: 0.2629 (0.3506)  labels_encoder_unscaled: 0.3625 (0.6191)  labels_decoder_unscaled: 0.5258 (0.7012)  time: 0.0479  data: 0.0001  max mem: 3463
Test: Total time: 0:01:38 (0.0613 s / it)
Averaged stats: loss: 0.6332 (0.9697)  labels_encoder: 0.3625 (0.6191)  labels_decoder: 0.2629 (0.3506)  labels_encoder_unscaled: 0.3625 (0.6191)  labels_decoder_unscaled: 0.5258 (0.7012)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-kin] mAP: 0.6419

dec_mAP all together: | 0.5062019733475728 |.
dec_mAP_pred | 0 : 0.5538007607379671 |.
dec_mAP_pred | 1 : 0.5455905100788521 |.
dec_mAP_pred | 2 : 0.532941991180597 |.
dec_mAP_pred | 3 : 0.5176187630566929 |.
dec_mAP_pred | 4 : 0.501067823332073 |.
dec_mAP_pred | 5 : 0.48459042421967463 |.
dec_mAP_pred | 6 : 0.4684062282224325 |.
dec_mAP_pred | 7 : 0.45283449597120845 |.
all decoder map: | 0.5071 |.
BaseballPitch: 0.4009
BasketballDunk: 0.8190
Billiards: 0.2803
CleanAndJerk: 0.7455
CliffDiving: 0.8311
CricketBowling: 0.4773
CricketShot: 0.2994
Diving: 0.8565
FrisbeeCatch: 0.4244
GolfSwing: 0.7925
HammerThrow: 0.8674
HighJump: 0.7975
JavelinThrow: 0.7668
LongJump: 0.7766
PoleVault: 0.8721
Shotput: 0.7449
SoccerPenalty: 0.4595
TennisSwing: 0.5530
ThrowDiscus: 0.6149
VolleyballSpiking: 0.4582
Epoch: [3]  [   0/1405]  eta: 0:42:11  lr: 0.000001  loss: 0.3195 (0.3195)  labels_encoder: 0.1945 (0.1945)  labels_decoder: 0.1251 (0.1251)  labels_encoder_unscaled: 0.1945 (0.1945)  labels_decoder_unscaled: 0.2501 (0.2501)  time: 1.8017  data: 1.6419  max mem: 3463
Epoch: [3]  [  50/1405]  eta: 0:03:40  lr: 0.000001  loss: 0.2377 (0.2404)  labels_encoder: 0.1171 (0.1255)  labels_decoder: 0.1156 (0.1148)  labels_encoder_unscaled: 0.1171 (0.1255)  labels_decoder_unscaled: 0.2311 (0.2297)  time: 0.1262  data: 0.0002  max mem: 3463
Epoch: [3]  [ 100/1405]  eta: 0:03:14  lr: 0.000001  loss: 0.2337 (0.2399)  labels_encoder: 0.1205 (0.1259)  labels_decoder: 0.1077 (0.1140)  labels_encoder_unscaled: 0.1205 (0.1259)  labels_decoder_unscaled: 0.2155 (0.2281)  time: 0.1394  data: 0.0002  max mem: 3463
Epoch: [3]  [ 150/1405]  eta: 0:03:02  lr: 0.000001  loss: 0.2325 (0.2381)  labels_encoder: 0.1128 (0.1241)  labels_decoder: 0.1133 (0.1140)  labels_encoder_unscaled: 0.1128 (0.1241)  labels_decoder_unscaled: 0.2266 (0.2280)  time: 0.1348  data: 0.0002  max mem: 3463
Epoch: [3]  [ 200/1405]  eta: 0:02:54  lr: 0.000001  loss: 0.2456 (0.2409)  labels_encoder: 0.1278 (0.1255)  labels_decoder: 0.1166 (0.1154)  labels_encoder_unscaled: 0.1278 (0.1255)  labels_decoder_unscaled: 0.2333 (0.2308)  time: 0.1443  data: 0.0002  max mem: 3463
Epoch: [3]  [ 250/1405]  eta: 0:02:47  lr: 0.000001  loss: 0.2321 (0.2388)  labels_encoder: 0.1095 (0.1233)  labels_decoder: 0.1165 (0.1155)  labels_encoder_unscaled: 0.1095 (0.1233)  labels_decoder_unscaled: 0.2330 (0.2310)  time: 0.1444  data: 0.0002  max mem: 3463
Epoch: [3]  [ 300/1405]  eta: 0:02:39  lr: 0.000001  loss: 0.2103 (0.2377)  labels_encoder: 0.0973 (0.1224)  labels_decoder: 0.1059 (0.1153)  labels_encoder_unscaled: 0.0973 (0.1224)  labels_decoder_unscaled: 0.2118 (0.2307)  time: 0.1432  data: 0.0002  max mem: 3463
Epoch: [3]  [ 350/1405]  eta: 0:02:32  lr: 0.000001  loss: 0.2441 (0.2397)  labels_encoder: 0.1199 (0.1239)  labels_decoder: 0.1143 (0.1158)  labels_encoder_unscaled: 0.1199 (0.1239)  labels_decoder_unscaled: 0.2286 (0.2317)  time: 0.1455  data: 0.0002  max mem: 3463
Epoch: [3]  [ 400/1405]  eta: 0:02:24  lr: 0.000001  loss: 0.2457 (0.2396)  labels_encoder: 0.1205 (0.1233)  labels_decoder: 0.1200 (0.1163)  labels_encoder_unscaled: 0.1205 (0.1233)  labels_decoder_unscaled: 0.2400 (0.2326)  time: 0.1425  data: 0.0002  max mem: 3463
Epoch: [3]  [ 450/1405]  eta: 0:02:17  lr: 0.000001  loss: 0.2366 (0.2398)  labels_encoder: 0.1136 (0.1235)  labels_decoder: 0.1141 (0.1163)  labels_encoder_unscaled: 0.1136 (0.1235)  labels_decoder_unscaled: 0.2283 (0.2326)  time: 0.1412  data: 0.0002  max mem: 3463
Epoch: [3]  [ 500/1405]  eta: 0:02:10  lr: 0.000001  loss: 0.2177 (0.2389)  labels_encoder: 0.1012 (0.1229)  labels_decoder: 0.1182 (0.1160)  labels_encoder_unscaled: 0.1012 (0.1229)  labels_decoder_unscaled: 0.2363 (0.2320)  time: 0.1445  data: 0.0002  max mem: 3463
Epoch: [3]  [ 550/1405]  eta: 0:02:03  lr: 0.000001  loss: 0.2368 (0.2387)  labels_encoder: 0.1238 (0.1229)  labels_decoder: 0.1175 (0.1158)  labels_encoder_unscaled: 0.1238 (0.1229)  labels_decoder_unscaled: 0.2350 (0.2316)  time: 0.1450  data: 0.0002  max mem: 3463
Epoch: [3]  [ 600/1405]  eta: 0:01:55  lr: 0.000001  loss: 0.2469 (0.2379)  labels_encoder: 0.1227 (0.1222)  labels_decoder: 0.1201 (0.1158)  labels_encoder_unscaled: 0.1227 (0.1222)  labels_decoder_unscaled: 0.2403 (0.2316)  time: 0.1414  data: 0.0002  max mem: 3463
Epoch: [3]  [ 650/1405]  eta: 0:01:48  lr: 0.000001  loss: 0.2095 (0.2373)  labels_encoder: 0.1021 (0.1216)  labels_decoder: 0.1074 (0.1157)  labels_encoder_unscaled: 0.1021 (0.1216)  labels_decoder_unscaled: 0.2147 (0.2315)  time: 0.1399  data: 0.0002  max mem: 3463
Epoch: [3]  [ 700/1405]  eta: 0:01:41  lr: 0.000001  loss: 0.2314 (0.2370)  labels_encoder: 0.1051 (0.1213)  labels_decoder: 0.1260 (0.1157)  labels_encoder_unscaled: 0.1051 (0.1213)  labels_decoder_unscaled: 0.2520 (0.2313)  time: 0.1397  data: 0.0002  max mem: 3463
Epoch: [3]  [ 750/1405]  eta: 0:01:33  lr: 0.000001  loss: 0.2375 (0.2377)  labels_encoder: 0.1231 (0.1219)  labels_decoder: 0.1135 (0.1158)  labels_encoder_unscaled: 0.1231 (0.1219)  labels_decoder_unscaled: 0.2270 (0.2316)  time: 0.1388  data: 0.0002  max mem: 3463
Epoch: [3]  [ 800/1405]  eta: 0:01:26  lr: 0.000001  loss: 0.2294 (0.2376)  labels_encoder: 0.1042 (0.1218)  labels_decoder: 0.1157 (0.1158)  labels_encoder_unscaled: 0.1042 (0.1218)  labels_decoder_unscaled: 0.2313 (0.2316)  time: 0.1425  data: 0.0002  max mem: 3463
Epoch: [3]  [ 850/1405]  eta: 0:01:19  lr: 0.000001  loss: 0.2246 (0.2374)  labels_encoder: 0.1209 (0.1220)  labels_decoder: 0.1012 (0.1154)  labels_encoder_unscaled: 0.1209 (0.1220)  labels_decoder_unscaled: 0.2024 (0.2308)  time: 0.1425  data: 0.0002  max mem: 3463
Epoch: [3]  [ 900/1405]  eta: 0:01:12  lr: 0.000001  loss: 0.2122 (0.2372)  labels_encoder: 0.1076 (0.1218)  labels_decoder: 0.1156 (0.1155)  labels_encoder_unscaled: 0.1076 (0.1218)  labels_decoder_unscaled: 0.2312 (0.2309)  time: 0.1433  data: 0.0002  max mem: 3463
Epoch: [3]  [ 950/1405]  eta: 0:01:05  lr: 0.000001  loss: 0.2282 (0.2371)  labels_encoder: 0.1098 (0.1215)  labels_decoder: 0.1149 (0.1156)  labels_encoder_unscaled: 0.1098 (0.1215)  labels_decoder_unscaled: 0.2299 (0.2311)  time: 0.1428  data: 0.0002  max mem: 3463
Epoch: [3]  [1000/1405]  eta: 0:00:57  lr: 0.000001  loss: 0.2326 (0.2373)  labels_encoder: 0.1129 (0.1217)  labels_decoder: 0.1178 (0.1156)  labels_encoder_unscaled: 0.1129 (0.1217)  labels_decoder_unscaled: 0.2356 (0.2312)  time: 0.1412  data: 0.0002  max mem: 3463
Epoch: [3]  [1050/1405]  eta: 0:00:50  lr: 0.000001  loss: 0.2118 (0.2371)  labels_encoder: 0.1139 (0.1217)  labels_decoder: 0.1094 (0.1153)  labels_encoder_unscaled: 0.1139 (0.1217)  labels_decoder_unscaled: 0.2188 (0.2307)  time: 0.1433  data: 0.0002  max mem: 3463
Epoch: [3]  [1100/1405]  eta: 0:00:43  lr: 0.000001  loss: 0.2303 (0.2369)  labels_encoder: 0.1145 (0.1216)  labels_decoder: 0.1105 (0.1153)  labels_encoder_unscaled: 0.1145 (0.1216)  labels_decoder_unscaled: 0.2210 (0.2306)  time: 0.1414  data: 0.0002  max mem: 3463
Epoch: [3]  [1150/1405]  eta: 0:00:36  lr: 0.000001  loss: 0.2385 (0.2367)  labels_encoder: 0.1174 (0.1214)  labels_decoder: 0.1103 (0.1153)  labels_encoder_unscaled: 0.1174 (0.1214)  labels_decoder_unscaled: 0.2206 (0.2305)  time: 0.1406  data: 0.0002  max mem: 3463
Epoch: [3]  [1200/1405]  eta: 0:00:29  lr: 0.000001  loss: 0.2237 (0.2371)  labels_encoder: 0.1257 (0.1218)  labels_decoder: 0.1113 (0.1153)  labels_encoder_unscaled: 0.1257 (0.1218)  labels_decoder_unscaled: 0.2225 (0.2307)  time: 0.1329  data: 0.0003  max mem: 3463
Epoch: [3]  [1250/1405]  eta: 0:00:22  lr: 0.000001  loss: 0.2235 (0.2369)  labels_encoder: 0.1082 (0.1216)  labels_decoder: 0.1153 (0.1153)  labels_encoder_unscaled: 0.1082 (0.1216)  labels_decoder_unscaled: 0.2307 (0.2306)  time: 0.1347  data: 0.0002  max mem: 3463
Epoch: [3]  [1300/1405]  eta: 0:00:14  lr: 0.000001  loss: 0.2293 (0.2366)  labels_encoder: 0.1087 (0.1214)  labels_decoder: 0.1132 (0.1152)  labels_encoder_unscaled: 0.1087 (0.1214)  labels_decoder_unscaled: 0.2263 (0.2305)  time: 0.1424  data: 0.0002  max mem: 3463
Epoch: [3]  [1350/1405]  eta: 0:00:07  lr: 0.000001  loss: 0.1991 (0.2365)  labels_encoder: 0.0968 (0.1213)  labels_decoder: 0.1104 (0.1152)  labels_encoder_unscaled: 0.0968 (0.1213)  labels_decoder_unscaled: 0.2208 (0.2304)  time: 0.1451  data: 0.0002  max mem: 3463
Epoch: [3]  [1400/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2563 (0.2365)  labels_encoder: 0.1393 (0.1214)  labels_decoder: 0.1153 (0.1151)  labels_encoder_unscaled: 0.1393 (0.1214)  labels_decoder_unscaled: 0.2305 (0.2302)  time: 0.1289  data: 0.0002  max mem: 3463
Epoch: [3]  [1404/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2310 (0.2365)  labels_encoder: 0.1204 (0.1214)  labels_decoder: 0.1125 (0.1151)  labels_encoder_unscaled: 0.1204 (0.1214)  labels_decoder_unscaled: 0.2250 (0.2302)  time: 0.1238  data: 0.0002  max mem: 3463
Epoch: [3] Total time: 0:03:20 (0.1427 s / it)
Averaged stats: lr: 0.000001  loss: 0.2310 (0.2365)  labels_encoder: 0.1204 (0.1214)  labels_decoder: 0.1125 (0.1151)  labels_encoder_unscaled: 0.1204 (0.1214)  labels_decoder_unscaled: 0.2250 (0.2302)
Test:  [   0/1613]  eta: 0:44:39  loss: 0.4526 (0.4526)  labels_encoder: 0.2560 (0.2560)  labels_decoder: 0.1966 (0.1966)  labels_encoder_unscaled: 0.2560 (0.2560)  labels_decoder_unscaled: 0.3932 (0.3932)  time: 1.6612  data: 1.5935  max mem: 3463
Test:  [  50/1613]  eta: 0:02:38  loss: 0.5412 (0.8769)  labels_encoder: 0.2721 (0.5576)  labels_decoder: 0.2612 (0.3193)  labels_encoder_unscaled: 0.2721 (0.5576)  labels_decoder_unscaled: 0.5224 (0.6387)  time: 0.0614  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:03  loss: 0.4924 (0.8019)  labels_encoder: 0.3310 (0.5274)  labels_decoder: 0.1424 (0.2745)  labels_encoder_unscaled: 0.3310 (0.5274)  labels_decoder_unscaled: 0.2849 (0.5490)  time: 0.0632  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:48  loss: 0.7035 (0.7585)  labels_encoder: 0.4402 (0.4897)  labels_decoder: 0.2180 (0.2688)  labels_encoder_unscaled: 0.4402 (0.4897)  labels_decoder_unscaled: 0.4361 (0.5377)  time: 0.0574  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:40  loss: 0.8627 (0.8873)  labels_encoder: 0.4878 (0.5712)  labels_decoder: 0.3646 (0.3161)  labels_encoder_unscaled: 0.4878 (0.5712)  labels_decoder_unscaled: 0.7292 (0.6323)  time: 0.0611  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:34  loss: 0.8807 (0.9350)  labels_encoder: 0.4510 (0.5970)  labels_decoder: 0.3674 (0.3380)  labels_encoder_unscaled: 0.4510 (0.5970)  labels_decoder_unscaled: 0.7347 (0.6759)  time: 0.0650  data: 0.0013  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:29  loss: 0.7042 (0.9221)  labels_encoder: 0.4290 (0.5887)  labels_decoder: 0.2752 (0.3334)  labels_encoder_unscaled: 0.4290 (0.5887)  labels_decoder_unscaled: 0.5503 (0.6669)  time: 0.0608  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:24  loss: 1.1930 (0.9559)  labels_encoder: 0.7361 (0.6122)  labels_decoder: 0.4690 (0.3437)  labels_encoder_unscaled: 0.7361 (0.6122)  labels_decoder_unscaled: 0.9381 (0.6874)  time: 0.0592  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:20  loss: 0.8081 (1.0207)  labels_encoder: 0.4488 (0.6562)  labels_decoder: 0.3135 (0.3645)  labels_encoder_unscaled: 0.4488 (0.6562)  labels_decoder_unscaled: 0.6270 (0.7289)  time: 0.0622  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:16  loss: 0.7923 (1.0956)  labels_encoder: 0.5393 (0.7087)  labels_decoder: 0.3173 (0.3869)  labels_encoder_unscaled: 0.5393 (0.7087)  labels_decoder_unscaled: 0.6346 (0.7738)  time: 0.0601  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:12  loss: 0.4202 (1.0531)  labels_encoder: 0.1993 (0.6786)  labels_decoder: 0.1767 (0.3745)  labels_encoder_unscaled: 0.1993 (0.6786)  labels_decoder_unscaled: 0.3534 (0.7490)  time: 0.0657  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:09  loss: 0.5946 (1.0351)  labels_encoder: 0.3604 (0.6665)  labels_decoder: 0.2207 (0.3685)  labels_encoder_unscaled: 0.3604 (0.6665)  labels_decoder_unscaled: 0.4414 (0.7371)  time: 0.0694  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:06  loss: 0.7076 (1.0888)  labels_encoder: 0.3805 (0.7136)  labels_decoder: 0.3173 (0.3752)  labels_encoder_unscaled: 0.3805 (0.7136)  labels_decoder_unscaled: 0.6346 (0.7504)  time: 0.0631  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:02  loss: 1.1019 (1.0916)  labels_encoder: 0.6093 (0.7122)  labels_decoder: 0.4325 (0.3793)  labels_encoder_unscaled: 0.6093 (0.7122)  labels_decoder_unscaled: 0.8650 (0.7587)  time: 0.0608  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:00:58  loss: 0.5809 (1.0676)  labels_encoder: 0.3359 (0.6949)  labels_decoder: 0.2308 (0.3727)  labels_encoder_unscaled: 0.3359 (0.6949)  labels_decoder_unscaled: 0.4615 (0.7454)  time: 0.0596  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:00:55  loss: 0.6574 (1.0426)  labels_encoder: 0.3269 (0.6761)  labels_decoder: 0.2365 (0.3665)  labels_encoder_unscaled: 0.3269 (0.6761)  labels_decoder_unscaled: 0.4729 (0.7330)  time: 0.0579  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:51  loss: 0.4484 (1.0289)  labels_encoder: 0.2977 (0.6673)  labels_decoder: 0.2093 (0.3616)  labels_encoder_unscaled: 0.2977 (0.6673)  labels_decoder_unscaled: 0.4186 (0.7233)  time: 0.0645  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:48  loss: 0.9387 (1.0379)  labels_encoder: 0.5994 (0.6698)  labels_decoder: 0.3841 (0.3681)  labels_encoder_unscaled: 0.5994 (0.6698)  labels_decoder_unscaled: 0.7682 (0.7362)  time: 0.0615  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:45  loss: 0.6835 (1.0196)  labels_encoder: 0.3942 (0.6557)  labels_decoder: 0.2820 (0.3639)  labels_encoder_unscaled: 0.3942 (0.6557)  labels_decoder_unscaled: 0.5640 (0.7279)  time: 0.0616  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:42  loss: 0.9769 (1.0119)  labels_encoder: 0.5834 (0.6499)  labels_decoder: 0.3252 (0.3620)  labels_encoder_unscaled: 0.5834 (0.6499)  labels_decoder_unscaled: 0.6504 (0.7239)  time: 0.0582  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:38  loss: 0.7716 (1.0011)  labels_encoder: 0.4910 (0.6416)  labels_decoder: 0.3020 (0.3595)  labels_encoder_unscaled: 0.4910 (0.6416)  labels_decoder_unscaled: 0.6040 (0.7191)  time: 0.0600  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:35  loss: 1.0476 (1.0096)  labels_encoder: 0.6833 (0.6485)  labels_decoder: 0.3456 (0.3611)  labels_encoder_unscaled: 0.6833 (0.6485)  labels_decoder_unscaled: 0.6912 (0.7222)  time: 0.0649  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:32  loss: 0.4491 (1.0043)  labels_encoder: 0.2371 (0.6453)  labels_decoder: 0.2095 (0.3590)  labels_encoder_unscaled: 0.2371 (0.6453)  labels_decoder_unscaled: 0.4190 (0.7179)  time: 0.0610  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:29  loss: 0.5534 (0.9998)  labels_encoder: 0.4570 (0.6423)  labels_decoder: 0.1993 (0.3575)  labels_encoder_unscaled: 0.4570 (0.6423)  labels_decoder_unscaled: 0.3985 (0.7150)  time: 0.0598  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:25  loss: 0.5027 (1.0072)  labels_encoder: 0.2698 (0.6467)  labels_decoder: 0.2052 (0.3605)  labels_encoder_unscaled: 0.2698 (0.6467)  labels_decoder_unscaled: 0.4105 (0.7211)  time: 0.0580  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:22  loss: 0.4899 (1.0069)  labels_encoder: 0.2749 (0.6464)  labels_decoder: 0.2084 (0.3605)  labels_encoder_unscaled: 0.2749 (0.6464)  labels_decoder_unscaled: 0.4168 (0.7210)  time: 0.0597  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5835 (0.9982)  labels_encoder: 0.3337 (0.6397)  labels_decoder: 0.2498 (0.3585)  labels_encoder_unscaled: 0.3337 (0.6397)  labels_decoder_unscaled: 0.4996 (0.7170)  time: 0.0592  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:16  loss: 0.9966 (1.0000)  labels_encoder: 0.5555 (0.6411)  labels_decoder: 0.3677 (0.3589)  labels_encoder_unscaled: 0.5555 (0.6411)  labels_decoder_unscaled: 0.7354 (0.7177)  time: 0.0583  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:13  loss: 0.9561 (1.0087)  labels_encoder: 0.5796 (0.6469)  labels_decoder: 0.3251 (0.3618)  labels_encoder_unscaled: 0.5796 (0.6469)  labels_decoder_unscaled: 0.6501 (0.7236)  time: 0.0598  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:10  loss: 0.5637 (1.0120)  labels_encoder: 0.2433 (0.6490)  labels_decoder: 0.2050 (0.3630)  labels_encoder_unscaled: 0.2433 (0.6490)  labels_decoder_unscaled: 0.4100 (0.7260)  time: 0.0584  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:07  loss: 0.4290 (1.0107)  labels_encoder: 0.2678 (0.6481)  labels_decoder: 0.1701 (0.3626)  labels_encoder_unscaled: 0.2678 (0.6481)  labels_decoder_unscaled: 0.3402 (0.7252)  time: 0.0577  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:03  loss: 0.8104 (1.0089)  labels_encoder: 0.5034 (0.6474)  labels_decoder: 0.2983 (0.3615)  labels_encoder_unscaled: 0.5034 (0.6474)  labels_decoder_unscaled: 0.5966 (0.7230)  time: 0.0580  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 1.0141 (1.0057)  labels_encoder: 0.5767 (0.6447)  labels_decoder: 0.4154 (0.3610)  labels_encoder_unscaled: 0.5767 (0.6447)  labels_decoder_unscaled: 0.8308 (0.7221)  time: 0.0574  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6068 (1.0041)  labels_encoder: 0.2938 (0.6439)  labels_decoder: 0.2692 (0.3602)  labels_encoder_unscaled: 0.2938 (0.6439)  labels_decoder_unscaled: 0.5385 (0.7204)  time: 0.0479  data: 0.0001  max mem: 3463
Test: Total time: 0:01:40 (0.0621 s / it)
Averaged stats: loss: 0.6068 (1.0041)  labels_encoder: 0.2938 (0.6439)  labels_decoder: 0.2692 (0.3602)  labels_encoder_unscaled: 0.2938 (0.6439)  labels_decoder_unscaled: 0.5385 (0.7204)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-kin] mAP: 0.6407

dec_mAP all together: | 0.5049113894945619 |.
dec_mAP_pred | 0 : 0.5536047172133719 |.
dec_mAP_pred | 1 : 0.5449213921730977 |.
dec_mAP_pred | 2 : 0.5318459530833242 |.
dec_mAP_pred | 3 : 0.5162844932588853 |.
dec_mAP_pred | 4 : 0.4995531273363921 |.
dec_mAP_pred | 5 : 0.4829256538890244 |.
dec_mAP_pred | 6 : 0.4665920626809384 |.
dec_mAP_pred | 7 : 0.4508712793996776 |.
all decoder map: | 0.5058 |.
BaseballPitch: 0.3960
BasketballDunk: 0.8160
Billiards: 0.2796
CleanAndJerk: 0.7456
CliffDiving: 0.8284
CricketBowling: 0.4802
CricketShot: 0.2941
Diving: 0.8654
FrisbeeCatch: 0.4427
GolfSwing: 0.7865
HammerThrow: 0.8652
HighJump: 0.7944
JavelinThrow: 0.7605
LongJump: 0.7816
PoleVault: 0.8741
Shotput: 0.7312
SoccerPenalty: 0.4556
TennisSwing: 0.5611
ThrowDiscus: 0.5950
VolleyballSpiking: 0.4609
Epoch: [4]  [   0/1405]  eta: 0:42:23  lr: 0.000000  loss: 0.1834 (0.1834)  labels_encoder: 0.0824 (0.0824)  labels_decoder: 0.1010 (0.1010)  labels_encoder_unscaled: 0.0824 (0.0824)  labels_decoder_unscaled: 0.2020 (0.2020)  time: 1.8104  data: 1.6401  max mem: 3463
Epoch: [4]  [  50/1405]  eta: 0:03:47  lr: 0.000000  loss: 0.2256 (0.2323)  labels_encoder: 0.1148 (0.1194)  labels_decoder: 0.1103 (0.1128)  labels_encoder_unscaled: 0.1148 (0.1194)  labels_decoder_unscaled: 0.2207 (0.2257)  time: 0.1308  data: 0.0002  max mem: 3463
Epoch: [4]  [ 100/1405]  eta: 0:03:11  lr: 0.000000  loss: 0.2189 (0.2298)  labels_encoder: 0.1129 (0.1176)  labels_decoder: 0.1091 (0.1122)  labels_encoder_unscaled: 0.1129 (0.1176)  labels_decoder_unscaled: 0.2182 (0.2245)  time: 0.1258  data: 0.0002  max mem: 3463
Epoch: [4]  [ 150/1405]  eta: 0:02:57  lr: 0.000000  loss: 0.2426 (0.2342)  labels_encoder: 0.1342 (0.1203)  labels_decoder: 0.1102 (0.1139)  labels_encoder_unscaled: 0.1342 (0.1203)  labels_decoder_unscaled: 0.2204 (0.2277)  time: 0.1328  data: 0.0002  max mem: 3463
Epoch: [4]  [ 200/1405]  eta: 0:02:48  lr: 0.000000  loss: 0.2197 (0.2338)  labels_encoder: 0.1100 (0.1204)  labels_decoder: 0.1118 (0.1134)  labels_encoder_unscaled: 0.1100 (0.1204)  labels_decoder_unscaled: 0.2237 (0.2269)  time: 0.1432  data: 0.0002  max mem: 3463
Epoch: [4]  [ 250/1405]  eta: 0:02:42  lr: 0.000000  loss: 0.2299 (0.2325)  labels_encoder: 0.1082 (0.1196)  labels_decoder: 0.1127 (0.1129)  labels_encoder_unscaled: 0.1082 (0.1196)  labels_decoder_unscaled: 0.2255 (0.2258)  time: 0.1436  data: 0.0002  max mem: 3463
Epoch: [4]  [ 300/1405]  eta: 0:02:35  lr: 0.000000  loss: 0.2353 (0.2336)  labels_encoder: 0.1208 (0.1205)  labels_decoder: 0.1089 (0.1130)  labels_encoder_unscaled: 0.1208 (0.1205)  labels_decoder_unscaled: 0.2178 (0.2261)  time: 0.1410  data: 0.0002  max mem: 3463
Epoch: [4]  [ 350/1405]  eta: 0:02:28  lr: 0.000000  loss: 0.2160 (0.2335)  labels_encoder: 0.1052 (0.1210)  labels_decoder: 0.1089 (0.1124)  labels_encoder_unscaled: 0.1052 (0.1210)  labels_decoder_unscaled: 0.2179 (0.2249)  time: 0.1430  data: 0.0002  max mem: 3463
Epoch: [4]  [ 400/1405]  eta: 0:02:21  lr: 0.000000  loss: 0.2112 (0.2325)  labels_encoder: 0.1061 (0.1201)  labels_decoder: 0.1089 (0.1125)  labels_encoder_unscaled: 0.1061 (0.1201)  labels_decoder_unscaled: 0.2178 (0.2250)  time: 0.1439  data: 0.0002  max mem: 3463
Epoch: [4]  [ 450/1405]  eta: 0:02:15  lr: 0.000000  loss: 0.2229 (0.2325)  labels_encoder: 0.1132 (0.1194)  labels_decoder: 0.1177 (0.1131)  labels_encoder_unscaled: 0.1132 (0.1194)  labels_decoder_unscaled: 0.2355 (0.2262)  time: 0.1423  data: 0.0002  max mem: 3463
Epoch: [4]  [ 500/1405]  eta: 0:02:08  lr: 0.000000  loss: 0.2132 (0.2310)  labels_encoder: 0.1031 (0.1183)  labels_decoder: 0.1091 (0.1127)  labels_encoder_unscaled: 0.1031 (0.1183)  labels_decoder_unscaled: 0.2181 (0.2255)  time: 0.1445  data: 0.0002  max mem: 3463
Epoch: [4]  [ 550/1405]  eta: 0:02:01  lr: 0.000000  loss: 0.2286 (0.2305)  labels_encoder: 0.1032 (0.1181)  labels_decoder: 0.1092 (0.1124)  labels_encoder_unscaled: 0.1032 (0.1181)  labels_decoder_unscaled: 0.2184 (0.2249)  time: 0.1448  data: 0.0002  max mem: 3463
Epoch: [4]  [ 600/1405]  eta: 0:01:54  lr: 0.000000  loss: 0.2154 (0.2305)  labels_encoder: 0.1051 (0.1180)  labels_decoder: 0.1044 (0.1125)  labels_encoder_unscaled: 0.1051 (0.1180)  labels_decoder_unscaled: 0.2089 (0.2249)  time: 0.1445  data: 0.0002  max mem: 3463
Epoch: [4]  [ 650/1405]  eta: 0:01:47  lr: 0.000000  loss: 0.2278 (0.2304)  labels_encoder: 0.1050 (0.1178)  labels_decoder: 0.1096 (0.1126)  labels_encoder_unscaled: 0.1050 (0.1178)  labels_decoder_unscaled: 0.2193 (0.2251)  time: 0.1450  data: 0.0002  max mem: 3463
Epoch: [4]  [ 700/1405]  eta: 0:01:40  lr: 0.000000  loss: 0.2133 (0.2297)  labels_encoder: 0.1009 (0.1173)  labels_decoder: 0.1107 (0.1124)  labels_encoder_unscaled: 0.1009 (0.1173)  labels_decoder_unscaled: 0.2214 (0.2248)  time: 0.1443  data: 0.0003  max mem: 3463
Epoch: [4]  [ 750/1405]  eta: 0:01:33  lr: 0.000000  loss: 0.2335 (0.2305)  labels_encoder: 0.1076 (0.1176)  labels_decoder: 0.1181 (0.1128)  labels_encoder_unscaled: 0.1076 (0.1176)  labels_decoder_unscaled: 0.2362 (0.2257)  time: 0.1449  data: 0.0003  max mem: 3463
Epoch: [4]  [ 800/1405]  eta: 0:01:26  lr: 0.000000  loss: 0.2429 (0.2312)  labels_encoder: 0.1117 (0.1180)  labels_decoder: 0.1231 (0.1132)  labels_encoder_unscaled: 0.1117 (0.1180)  labels_decoder_unscaled: 0.2462 (0.2265)  time: 0.1425  data: 0.0002  max mem: 3463
Epoch: [4]  [ 850/1405]  eta: 0:01:19  lr: 0.000000  loss: 0.2366 (0.2316)  labels_encoder: 0.1268 (0.1183)  labels_decoder: 0.1143 (0.1133)  labels_encoder_unscaled: 0.1268 (0.1183)  labels_decoder_unscaled: 0.2286 (0.2267)  time: 0.1458  data: 0.0003  max mem: 3463
Epoch: [4]  [ 900/1405]  eta: 0:01:12  lr: 0.000000  loss: 0.2340 (0.2326)  labels_encoder: 0.1114 (0.1192)  labels_decoder: 0.1146 (0.1135)  labels_encoder_unscaled: 0.1114 (0.1192)  labels_decoder_unscaled: 0.2292 (0.2270)  time: 0.1431  data: 0.0002  max mem: 3463
Epoch: [4]  [ 950/1405]  eta: 0:01:05  lr: 0.000000  loss: 0.2093 (0.2322)  labels_encoder: 0.1146 (0.1186)  labels_decoder: 0.1161 (0.1136)  labels_encoder_unscaled: 0.1146 (0.1186)  labels_decoder_unscaled: 0.2321 (0.2271)  time: 0.1424  data: 0.0002  max mem: 3463
Epoch: [4]  [1000/1405]  eta: 0:00:57  lr: 0.000000  loss: 0.2377 (0.2326)  labels_encoder: 0.1190 (0.1189)  labels_decoder: 0.1120 (0.1137)  labels_encoder_unscaled: 0.1190 (0.1189)  labels_decoder_unscaled: 0.2239 (0.2274)  time: 0.1368  data: 0.0002  max mem: 3463
Epoch: [4]  [1050/1405]  eta: 0:00:50  lr: 0.000000  loss: 0.2137 (0.2324)  labels_encoder: 0.1068 (0.1188)  labels_decoder: 0.1073 (0.1137)  labels_encoder_unscaled: 0.1068 (0.1188)  labels_decoder_unscaled: 0.2146 (0.2273)  time: 0.1354  data: 0.0002  max mem: 3463
Epoch: [4]  [1100/1405]  eta: 0:00:43  lr: 0.000000  loss: 0.2338 (0.2326)  labels_encoder: 0.1078 (0.1186)  labels_decoder: 0.1198 (0.1139)  labels_encoder_unscaled: 0.1078 (0.1186)  labels_decoder_unscaled: 0.2396 (0.2279)  time: 0.1406  data: 0.0002  max mem: 3463
Epoch: [4]  [1150/1405]  eta: 0:00:36  lr: 0.000000  loss: 0.2452 (0.2331)  labels_encoder: 0.1279 (0.1189)  labels_decoder: 0.1204 (0.1142)  labels_encoder_unscaled: 0.1279 (0.1189)  labels_decoder_unscaled: 0.2408 (0.2283)  time: 0.1434  data: 0.0002  max mem: 3463
Epoch: [4]  [1200/1405]  eta: 0:00:29  lr: 0.000000  loss: 0.2375 (0.2334)  labels_encoder: 0.1211 (0.1192)  labels_decoder: 0.1135 (0.1142)  labels_encoder_unscaled: 0.1211 (0.1192)  labels_decoder_unscaled: 0.2270 (0.2284)  time: 0.1438  data: 0.0002  max mem: 3463
Epoch: [4]  [1250/1405]  eta: 0:00:22  lr: 0.000000  loss: 0.2386 (0.2337)  labels_encoder: 0.1271 (0.1196)  labels_decoder: 0.1048 (0.1141)  labels_encoder_unscaled: 0.1271 (0.1196)  labels_decoder_unscaled: 0.2095 (0.2283)  time: 0.1354  data: 0.0002  max mem: 3463
Epoch: [4]  [1300/1405]  eta: 0:00:14  lr: 0.000000  loss: 0.2223 (0.2337)  labels_encoder: 0.1153 (0.1196)  labels_decoder: 0.1081 (0.1141)  labels_encoder_unscaled: 0.1153 (0.1196)  labels_decoder_unscaled: 0.2163 (0.2282)  time: 0.1484  data: 0.0003  max mem: 3463
Epoch: [4]  [1350/1405]  eta: 0:00:07  lr: 0.000000  loss: 0.2204 (0.2335)  labels_encoder: 0.1021 (0.1194)  labels_decoder: 0.1132 (0.1140)  labels_encoder_unscaled: 0.1021 (0.1194)  labels_decoder_unscaled: 0.2264 (0.2281)  time: 0.1450  data: 0.0003  max mem: 3463
Epoch: [4]  [1400/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2224 (0.2331)  labels_encoder: 0.1090 (0.1192)  labels_decoder: 0.1134 (0.1139)  labels_encoder_unscaled: 0.1090 (0.1192)  labels_decoder_unscaled: 0.2268 (0.2279)  time: 0.1321  data: 0.0003  max mem: 3463
Epoch: [4]  [1404/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2224 (0.2330)  labels_encoder: 0.1094 (0.1191)  labels_decoder: 0.1131 (0.1139)  labels_encoder_unscaled: 0.1094 (0.1191)  labels_decoder_unscaled: 0.2262 (0.2278)  time: 0.1267  data: 0.0003  max mem: 3463
Epoch: [4] Total time: 0:03:20 (0.1428 s / it)
Averaged stats: lr: 0.000000  loss: 0.2224 (0.2330)  labels_encoder: 0.1094 (0.1191)  labels_decoder: 0.1131 (0.1139)  labels_encoder_unscaled: 0.1094 (0.1191)  labels_decoder_unscaled: 0.2262 (0.2278)
Test:  [   0/1613]  eta: 0:49:16  loss: 0.4715 (0.4715)  labels_encoder: 0.2643 (0.2643)  labels_decoder: 0.2072 (0.2072)  labels_encoder_unscaled: 0.2643 (0.2643)  labels_decoder_unscaled: 0.4143 (0.4143)  time: 1.8327  data: 1.7655  max mem: 3463
Test:  [  50/1613]  eta: 0:02:30  loss: 0.5682 (0.9016)  labels_encoder: 0.2982 (0.5769)  labels_decoder: 0.2750 (0.3247)  labels_encoder_unscaled: 0.2982 (0.5769)  labels_decoder_unscaled: 0.5500 (0.6493)  time: 0.0590  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:01:57  loss: 0.5235 (0.8087)  labels_encoder: 0.3101 (0.5322)  labels_decoder: 0.1579 (0.2765)  labels_encoder_unscaled: 0.3101 (0.5322)  labels_decoder_unscaled: 0.3158 (0.5530)  time: 0.0572  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:44  loss: 0.6640 (0.7615)  labels_encoder: 0.4104 (0.4915)  labels_decoder: 0.2287 (0.2700)  labels_encoder_unscaled: 0.4104 (0.4915)  labels_decoder_unscaled: 0.4574 (0.5399)  time: 0.0637  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:36  loss: 0.8633 (0.8897)  labels_encoder: 0.4875 (0.5723)  labels_decoder: 0.3646 (0.3174)  labels_encoder_unscaled: 0.4875 (0.5723)  labels_decoder_unscaled: 0.7292 (0.6348)  time: 0.0603  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:32  loss: 0.8898 (0.9374)  labels_encoder: 0.4614 (0.5984)  labels_decoder: 0.3789 (0.3391)  labels_encoder_unscaled: 0.4614 (0.5984)  labels_decoder_unscaled: 0.7577 (0.6781)  time: 0.0700  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:28  loss: 0.7222 (0.9308)  labels_encoder: 0.4798 (0.5946)  labels_decoder: 0.2798 (0.3362)  labels_encoder_unscaled: 0.4798 (0.5946)  labels_decoder_unscaled: 0.5596 (0.6724)  time: 0.0617  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:23  loss: 1.1549 (0.9635)  labels_encoder: 0.7434 (0.6175)  labels_decoder: 0.4736 (0.3460)  labels_encoder_unscaled: 0.7434 (0.6175)  labels_decoder_unscaled: 0.9472 (0.6921)  time: 0.0603  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:20  loss: 0.8080 (1.0239)  labels_encoder: 0.4473 (0.6589)  labels_decoder: 0.3144 (0.3650)  labels_encoder_unscaled: 0.4473 (0.6589)  labels_decoder_unscaled: 0.6288 (0.7299)  time: 0.0662  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:17  loss: 0.8489 (1.1002)  labels_encoder: 0.5837 (0.7127)  labels_decoder: 0.3185 (0.3876)  labels_encoder_unscaled: 0.5837 (0.7127)  labels_decoder_unscaled: 0.6369 (0.7751)  time: 0.0659  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:13  loss: 0.3832 (1.0568)  labels_encoder: 0.1978 (0.6819)  labels_decoder: 0.1710 (0.3750)  labels_encoder_unscaled: 0.1978 (0.6819)  labels_decoder_unscaled: 0.3420 (0.7500)  time: 0.0671  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:09  loss: 0.5964 (1.0404)  labels_encoder: 0.3750 (0.6704)  labels_decoder: 0.2205 (0.3700)  labels_encoder_unscaled: 0.3750 (0.6704)  labels_decoder_unscaled: 0.4410 (0.7400)  time: 0.0603  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:06  loss: 0.7456 (1.0886)  labels_encoder: 0.4157 (0.7133)  labels_decoder: 0.3299 (0.3753)  labels_encoder_unscaled: 0.4157 (0.7133)  labels_decoder_unscaled: 0.6598 (0.7507)  time: 0.0597  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:03  loss: 1.1491 (1.0912)  labels_encoder: 0.6640 (0.7119)  labels_decoder: 0.4486 (0.3793)  labels_encoder_unscaled: 0.6640 (0.7119)  labels_decoder_unscaled: 0.8972 (0.7586)  time: 0.0612  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:00:59  loss: 0.5647 (1.0668)  labels_encoder: 0.3370 (0.6944)  labels_decoder: 0.2285 (0.3724)  labels_encoder_unscaled: 0.3370 (0.6944)  labels_decoder_unscaled: 0.4571 (0.7448)  time: 0.0610  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:00:55  loss: 0.7071 (1.0424)  labels_encoder: 0.3605 (0.6761)  labels_decoder: 0.2442 (0.3663)  labels_encoder_unscaled: 0.3605 (0.6761)  labels_decoder_unscaled: 0.4885 (0.7326)  time: 0.0579  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:52  loss: 0.4435 (1.0286)  labels_encoder: 0.2965 (0.6672)  labels_decoder: 0.2029 (0.3614)  labels_encoder_unscaled: 0.2965 (0.6672)  labels_decoder_unscaled: 0.4058 (0.7228)  time: 0.0601  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:49  loss: 0.9028 (1.0390)  labels_encoder: 0.5546 (0.6707)  labels_decoder: 0.3921 (0.3683)  labels_encoder_unscaled: 0.5546 (0.6707)  labels_decoder_unscaled: 0.7842 (0.7366)  time: 0.0676  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:45  loss: 0.6692 (1.0207)  labels_encoder: 0.3888 (0.6566)  labels_decoder: 0.2804 (0.3641)  labels_encoder_unscaled: 0.3888 (0.6566)  labels_decoder_unscaled: 0.5609 (0.7283)  time: 0.0676  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:42  loss: 0.9830 (1.0139)  labels_encoder: 0.6109 (0.6515)  labels_decoder: 0.3262 (0.3624)  labels_encoder_unscaled: 0.6109 (0.6515)  labels_decoder_unscaled: 0.6523 (0.7248)  time: 0.0678  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:39  loss: 0.7256 (1.0027)  labels_encoder: 0.4382 (0.6429)  labels_decoder: 0.2874 (0.3598)  labels_encoder_unscaled: 0.4382 (0.6429)  labels_decoder_unscaled: 0.5748 (0.7196)  time: 0.0597  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:36  loss: 1.0391 (1.0113)  labels_encoder: 0.6775 (0.6500)  labels_decoder: 0.3464 (0.3613)  labels_encoder_unscaled: 0.6775 (0.6500)  labels_decoder_unscaled: 0.6929 (0.7227)  time: 0.0616  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:32  loss: 0.4220 (1.0066)  labels_encoder: 0.2267 (0.6473)  labels_decoder: 0.1953 (0.3593)  labels_encoder_unscaled: 0.2267 (0.6473)  labels_decoder_unscaled: 0.3905 (0.7186)  time: 0.0577  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:29  loss: 0.5163 (1.0020)  labels_encoder: 0.4253 (0.6441)  labels_decoder: 0.1777 (0.3579)  labels_encoder_unscaled: 0.4253 (0.6441)  labels_decoder_unscaled: 0.3553 (0.7158)  time: 0.0594  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:26  loss: 0.5082 (1.0093)  labels_encoder: 0.2619 (0.6484)  labels_decoder: 0.2109 (0.3609)  labels_encoder_unscaled: 0.2619 (0.6484)  labels_decoder_unscaled: 0.4218 (0.7219)  time: 0.0656  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:23  loss: 0.5231 (1.0098)  labels_encoder: 0.2896 (0.6487)  labels_decoder: 0.2082 (0.3612)  labels_encoder_unscaled: 0.2896 (0.6487)  labels_decoder_unscaled: 0.4164 (0.7223)  time: 0.0621  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:19  loss: 0.6191 (1.0017)  labels_encoder: 0.3571 (0.6424)  labels_decoder: 0.2593 (0.3594)  labels_encoder_unscaled: 0.3571 (0.6424)  labels_decoder_unscaled: 0.5186 (0.7187)  time: 0.0584  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:16  loss: 0.9632 (1.0035)  labels_encoder: 0.5461 (0.6438)  labels_decoder: 0.3743 (0.3597)  labels_encoder_unscaled: 0.5461 (0.6438)  labels_decoder_unscaled: 0.7485 (0.7193)  time: 0.0587  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:13  loss: 1.0063 (1.0128)  labels_encoder: 0.6111 (0.6500)  labels_decoder: 0.3616 (0.3628)  labels_encoder_unscaled: 0.6111 (0.6500)  labels_decoder_unscaled: 0.7232 (0.7256)  time: 0.0604  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:10  loss: 0.5612 (1.0169)  labels_encoder: 0.2475 (0.6526)  labels_decoder: 0.2099 (0.3643)  labels_encoder_unscaled: 0.2475 (0.6526)  labels_decoder_unscaled: 0.4199 (0.7286)  time: 0.0630  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:07  loss: 0.4438 (1.0141)  labels_encoder: 0.2809 (0.6508)  labels_decoder: 0.1769 (0.3634)  labels_encoder_unscaled: 0.2809 (0.6508)  labels_decoder_unscaled: 0.3538 (0.7267)  time: 0.0622  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:04  loss: 0.8117 (1.0128)  labels_encoder: 0.5052 (0.6504)  labels_decoder: 0.2939 (0.3624)  labels_encoder_unscaled: 0.5052 (0.6504)  labels_decoder_unscaled: 0.5879 (0.7248)  time: 0.0634  data: 0.0006  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 1.0134 (1.0099)  labels_encoder: 0.5731 (0.6479)  labels_decoder: 0.4139 (0.3620)  labels_encoder_unscaled: 0.5731 (0.6479)  labels_decoder_unscaled: 0.8277 (0.7240)  time: 0.0606  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6038 (1.0085)  labels_encoder: 0.2852 (0.6472)  labels_decoder: 0.2734 (0.3612)  labels_encoder_unscaled: 0.2852 (0.6472)  labels_decoder_unscaled: 0.5469 (0.7225)  time: 0.0499  data: 0.0001  max mem: 3463
Test: Total time: 0:01:42 (0.0636 s / it)
Averaged stats: loss: 0.6038 (1.0085)  labels_encoder: 0.2852 (0.6472)  labels_decoder: 0.2734 (0.3612)  labels_encoder_unscaled: 0.2852 (0.6472)  labels_decoder_unscaled: 0.5469 (0.7225)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-kin] mAP: 0.6401

dec_mAP all together: | 0.5044176947669212 |.
dec_mAP_pred | 0 : 0.5527952173329055 |.
dec_mAP_pred | 1 : 0.544214746076438 |.
dec_mAP_pred | 2 : 0.5312198771751819 |.
dec_mAP_pred | 3 : 0.5157697849985928 |.
dec_mAP_pred | 4 : 0.4991317288994545 |.
dec_mAP_pred | 5 : 0.4825683733948079 |.
dec_mAP_pred | 6 : 0.46631465290710555 |.
dec_mAP_pred | 7 : 0.4506218253711933 |.
all decoder map: | 0.5053 |.
BaseballPitch: 0.3963
BasketballDunk: 0.8158
Billiards: 0.2796
CleanAndJerk: 0.7458
CliffDiving: 0.8274
CricketBowling: 0.4801
CricketShot: 0.2936
Diving: 0.8650
FrisbeeCatch: 0.4455
GolfSwing: 0.7860
HammerThrow: 0.8641
HighJump: 0.7918
JavelinThrow: 0.7598
LongJump: 0.7836
PoleVault: 0.8731
Shotput: 0.7276
SoccerPenalty: 0.4548
TennisSwing: 0.5605
ThrowDiscus: 0.5907
VolleyballSpiking: 0.4601
Training time 0:22:38
