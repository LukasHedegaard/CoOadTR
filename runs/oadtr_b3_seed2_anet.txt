Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet
dim_feature:3072
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:2
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  74.578 M, 99.825% Params, 2.446 GMac, 100.000% MACs, 
  (linear_encoding): Linear(3.147 M, 4.212% Params, 0.201 GMac, 8.231% MACs, in_features=3072, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 25.276% Params, 1.227 GMac, 50.169% MACs, 
    (net): Sequential(
      18.884 M, 25.276% Params, 1.227 GMac, 50.169% MACs, 
      (0): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.616% Params, 0.273 GMac, 11.147% MACs, 
            (qkv): Linear(3.146 M, 4.211% Params, 0.204 GMac, 8.360% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
        (fn): PreNorm(
          2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
            (net): Sequential(
              2.099 M, 2.810% Params, 0.136 GMac, 5.576% MACs, 
              (0): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.060% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 70.246% Params, 1.017 GMac, 41.591% MACs, 
    (layers): ModuleList(
      52.48 M, 70.246% Params, 1.017 GMac, 41.591% MACs, 
      (0): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 14.049% Params, 0.203 GMac, 8.318% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.034 GMac, 1.372% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.620% Params, 0.153 GMac, 6.259% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.405% Params, 0.068 GMac, 2.787% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.405% Params, 0.008 GMac, 0.343% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.030% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2445837356.0
Model params: 74709036
Loaded data/thumos_anet_val.pickle
Loaded data/thumos_anet_test.pickle
Start training
Epoch: [1]  [   0/1405]  eta: 0:50:19  lr: 0.000100  loss: 4.5965 (4.5965)  labels_encoder: 3.0263 (3.0263)  labels_decoder: 1.5702 (1.5702)  labels_encoder_unscaled: 3.0263 (3.0263)  labels_decoder_unscaled: 3.1403 (3.1403)  time: 2.1491  data: 1.5319  max mem: 2528
Epoch: [1]  [  50/1405]  eta: 0:04:13  lr: 0.000100  loss: 1.0364 (1.5567)  labels_encoder: 0.6845 (1.0147)  labels_decoder: 0.3635 (0.5420)  labels_encoder_unscaled: 0.6845 (1.0147)  labels_decoder_unscaled: 0.7271 (1.0840)  time: 0.1330  data: 0.0003  max mem: 3384
Epoch: [1]  [ 100/1405]  eta: 0:03:30  lr: 0.000100  loss: 0.7549 (1.1915)  labels_encoder: 0.4615 (0.7664)  labels_decoder: 0.2707 (0.4251)  labels_encoder_unscaled: 0.4615 (0.7664)  labels_decoder_unscaled: 0.5414 (0.8503)  time: 0.1332  data: 0.0003  max mem: 3384
Epoch: [1]  [ 150/1405]  eta: 0:03:10  lr: 0.000100  loss: 0.7844 (1.0475)  labels_encoder: 0.4907 (0.6700)  labels_decoder: 0.2634 (0.3775)  labels_encoder_unscaled: 0.4907 (0.6700)  labels_decoder_unscaled: 0.5268 (0.7550)  time: 0.1338  data: 0.0003  max mem: 3384
Epoch: [1]  [ 200/1405]  eta: 0:02:57  lr: 0.000100  loss: 0.6594 (0.9573)  labels_encoder: 0.4048 (0.6093)  labels_decoder: 0.2374 (0.3480)  labels_encoder_unscaled: 0.4048 (0.6093)  labels_decoder_unscaled: 0.4749 (0.6960)  time: 0.1328  data: 0.0003  max mem: 3384
Epoch: [1]  [ 250/1405]  eta: 0:02:47  lr: 0.000100  loss: 0.6179 (0.8955)  labels_encoder: 0.3779 (0.5679)  labels_decoder: 0.2326 (0.3276)  labels_encoder_unscaled: 0.3779 (0.5679)  labels_decoder_unscaled: 0.4652 (0.6552)  time: 0.1332  data: 0.0002  max mem: 3384
Epoch: [1]  [ 300/1405]  eta: 0:02:38  lr: 0.000100  loss: 0.5633 (0.8467)  labels_encoder: 0.3475 (0.5352)  labels_decoder: 0.2084 (0.3115)  labels_encoder_unscaled: 0.3475 (0.5352)  labels_decoder_unscaled: 0.4169 (0.6231)  time: 0.1374  data: 0.0003  max mem: 3384
Epoch: [1]  [ 350/1405]  eta: 0:02:30  lr: 0.000100  loss: 0.5693 (0.8087)  labels_encoder: 0.3284 (0.5086)  labels_decoder: 0.2327 (0.3001)  labels_encoder_unscaled: 0.3284 (0.5086)  labels_decoder_unscaled: 0.4654 (0.6003)  time: 0.1385  data: 0.0003  max mem: 3384
Epoch: [1]  [ 400/1405]  eta: 0:02:22  lr: 0.000100  loss: 0.5640 (0.7792)  labels_encoder: 0.3320 (0.4884)  labels_decoder: 0.2223 (0.2908)  labels_encoder_unscaled: 0.3320 (0.4884)  labels_decoder_unscaled: 0.4446 (0.5816)  time: 0.1375  data: 0.0003  max mem: 3384
Epoch: [1]  [ 450/1405]  eta: 0:02:14  lr: 0.000100  loss: 0.5110 (0.7525)  labels_encoder: 0.2916 (0.4696)  labels_decoder: 0.2047 (0.2829)  labels_encoder_unscaled: 0.2916 (0.4696)  labels_decoder_unscaled: 0.4094 (0.5658)  time: 0.1354  data: 0.0003  max mem: 3384
Epoch: [1]  [ 500/1405]  eta: 0:02:07  lr: 0.000100  loss: 0.4895 (0.7309)  labels_encoder: 0.2834 (0.4551)  labels_decoder: 0.2011 (0.2759)  labels_encoder_unscaled: 0.2834 (0.4551)  labels_decoder_unscaled: 0.4023 (0.5518)  time: 0.1346  data: 0.0003  max mem: 3384
Epoch: [1]  [ 550/1405]  eta: 0:01:59  lr: 0.000100  loss: 0.4572 (0.7120)  labels_encoder: 0.2695 (0.4421)  labels_decoder: 0.1848 (0.2699)  labels_encoder_unscaled: 0.2695 (0.4421)  labels_decoder_unscaled: 0.3695 (0.5399)  time: 0.1341  data: 0.0003  max mem: 3384
Epoch: [1]  [ 600/1405]  eta: 0:01:52  lr: 0.000100  loss: 0.5280 (0.6969)  labels_encoder: 0.2966 (0.4315)  labels_decoder: 0.2195 (0.2654)  labels_encoder_unscaled: 0.2966 (0.4315)  labels_decoder_unscaled: 0.4389 (0.5308)  time: 0.1360  data: 0.0003  max mem: 3384
Epoch: [1]  [ 650/1405]  eta: 0:01:45  lr: 0.000100  loss: 0.4659 (0.6814)  labels_encoder: 0.2648 (0.4209)  labels_decoder: 0.2025 (0.2605)  labels_encoder_unscaled: 0.2648 (0.4209)  labels_decoder_unscaled: 0.4050 (0.5211)  time: 0.1339  data: 0.0003  max mem: 3384
Epoch: [1]  [ 700/1405]  eta: 0:01:37  lr: 0.000100  loss: 0.4408 (0.6667)  labels_encoder: 0.2678 (0.4107)  labels_decoder: 0.1953 (0.2561)  labels_encoder_unscaled: 0.2678 (0.4107)  labels_decoder_unscaled: 0.3907 (0.5121)  time: 0.1366  data: 0.0003  max mem: 3384
Epoch: [1]  [ 750/1405]  eta: 0:01:30  lr: 0.000100  loss: 0.4683 (0.6542)  labels_encoder: 0.2778 (0.4021)  labels_decoder: 0.1911 (0.2521)  labels_encoder_unscaled: 0.2778 (0.4021)  labels_decoder_unscaled: 0.3823 (0.5042)  time: 0.1318  data: 0.0003  max mem: 3384
Epoch: [1]  [ 800/1405]  eta: 0:01:23  lr: 0.000100  loss: 0.4184 (0.6414)  labels_encoder: 0.2565 (0.3935)  labels_decoder: 0.1755 (0.2479)  labels_encoder_unscaled: 0.2565 (0.3935)  labels_decoder_unscaled: 0.3511 (0.4958)  time: 0.1327  data: 0.0003  max mem: 3384
Epoch: [1]  [ 850/1405]  eta: 0:01:16  lr: 0.000100  loss: 0.4384 (0.6299)  labels_encoder: 0.2627 (0.3858)  labels_decoder: 0.1832 (0.2441)  labels_encoder_unscaled: 0.2627 (0.3858)  labels_decoder_unscaled: 0.3663 (0.4882)  time: 0.1327  data: 0.0002  max mem: 3384
Epoch: [1]  [ 900/1405]  eta: 0:01:09  lr: 0.000100  loss: 0.4149 (0.6193)  labels_encoder: 0.2308 (0.3783)  labels_decoder: 0.1765 (0.2410)  labels_encoder_unscaled: 0.2308 (0.3783)  labels_decoder_unscaled: 0.3531 (0.4820)  time: 0.1348  data: 0.0003  max mem: 3384
Epoch: [1]  [ 950/1405]  eta: 0:01:02  lr: 0.000100  loss: 0.4418 (0.6098)  labels_encoder: 0.2494 (0.3719)  labels_decoder: 0.1954 (0.2378)  labels_encoder_unscaled: 0.2494 (0.3719)  labels_decoder_unscaled: 0.3907 (0.4757)  time: 0.1341  data: 0.0003  max mem: 3384
Epoch: [1]  [1000/1405]  eta: 0:00:55  lr: 0.000100  loss: 0.4729 (0.6014)  labels_encoder: 0.2844 (0.3661)  labels_decoder: 0.1946 (0.2353)  labels_encoder_unscaled: 0.2844 (0.3661)  labels_decoder_unscaled: 0.3891 (0.4707)  time: 0.1342  data: 0.0002  max mem: 3384
Epoch: [1]  [1050/1405]  eta: 0:00:48  lr: 0.000100  loss: 0.4258 (0.5934)  labels_encoder: 0.2606 (0.3607)  labels_decoder: 0.1593 (0.2327)  labels_encoder_unscaled: 0.2606 (0.3607)  labels_decoder_unscaled: 0.3185 (0.4655)  time: 0.1343  data: 0.0003  max mem: 3384
Epoch: [1]  [1100/1405]  eta: 0:00:41  lr: 0.000100  loss: 0.3928 (0.5856)  labels_encoder: 0.2214 (0.3556)  labels_decoder: 0.1714 (0.2301)  labels_encoder_unscaled: 0.2214 (0.3556)  labels_decoder_unscaled: 0.3427 (0.4602)  time: 0.1334  data: 0.0003  max mem: 3384
Epoch: [1]  [1150/1405]  eta: 0:00:34  lr: 0.000100  loss: 0.4399 (0.5789)  labels_encoder: 0.2622 (0.3511)  labels_decoder: 0.1830 (0.2277)  labels_encoder_unscaled: 0.2622 (0.3511)  labels_decoder_unscaled: 0.3660 (0.4555)  time: 0.1366  data: 0.0003  max mem: 3384
Epoch: [1]  [1200/1405]  eta: 0:00:28  lr: 0.000100  loss: 0.4081 (0.5714)  labels_encoder: 0.2298 (0.3460)  labels_decoder: 0.1721 (0.2254)  labels_encoder_unscaled: 0.2298 (0.3460)  labels_decoder_unscaled: 0.3442 (0.4508)  time: 0.1412  data: 0.0002  max mem: 3384
Epoch: [1]  [1250/1405]  eta: 0:00:21  lr: 0.000100  loss: 0.3998 (0.5649)  labels_encoder: 0.2293 (0.3414)  labels_decoder: 0.1697 (0.2235)  labels_encoder_unscaled: 0.2293 (0.3414)  labels_decoder_unscaled: 0.3394 (0.4470)  time: 0.1381  data: 0.0003  max mem: 3384
Epoch: [1]  [1300/1405]  eta: 0:00:14  lr: 0.000100  loss: 0.4157 (0.5593)  labels_encoder: 0.2249 (0.3376)  labels_decoder: 0.1704 (0.2217)  labels_encoder_unscaled: 0.2249 (0.3376)  labels_decoder_unscaled: 0.3409 (0.4434)  time: 0.1362  data: 0.0003  max mem: 3384
Epoch: [1]  [1350/1405]  eta: 0:00:07  lr: 0.000100  loss: 0.3757 (0.5528)  labels_encoder: 0.2158 (0.3333)  labels_decoder: 0.1599 (0.2195)  labels_encoder_unscaled: 0.2158 (0.3333)  labels_decoder_unscaled: 0.3199 (0.4390)  time: 0.1380  data: 0.0002  max mem: 3384
Epoch: [1]  [1400/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3756 (0.5471)  labels_encoder: 0.2247 (0.3293)  labels_decoder: 0.1667 (0.2178)  labels_encoder_unscaled: 0.2247 (0.3293)  labels_decoder_unscaled: 0.3334 (0.4355)  time: 0.1224  data: 0.0003  max mem: 3384
Epoch: [1]  [1404/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3720 (0.5465)  labels_encoder: 0.2180 (0.3289)  labels_decoder: 0.1659 (0.2176)  labels_encoder_unscaled: 0.2180 (0.3289)  labels_decoder_unscaled: 0.3318 (0.4352)  time: 0.1218  data: 0.0003  max mem: 3384
Epoch: [1] Total time: 0:03:12 (0.1370 s / it)
Averaged stats: lr: 0.000100  loss: 0.3720 (0.5465)  labels_encoder: 0.2180 (0.3289)  labels_decoder: 0.1659 (0.2176)  labels_encoder_unscaled: 0.2180 (0.3289)  labels_decoder_unscaled: 0.3318 (0.4352)
Test:  [   0/1613]  eta: 0:43:03  loss: 0.7793 (0.7793)  labels_encoder: 0.5457 (0.5457)  labels_decoder: 0.2335 (0.2335)  labels_encoder_unscaled: 0.5457 (0.5457)  labels_decoder_unscaled: 0.4671 (0.4671)  time: 1.6018  data: 1.5352  max mem: 3384
Test:  [  50/1613]  eta: 0:02:23  loss: 0.4634 (1.0197)  labels_encoder: 0.2760 (0.6421)  labels_decoder: 0.2210 (0.3776)  labels_encoder_unscaled: 0.2760 (0.6421)  labels_decoder_unscaled: 0.4421 (0.7552)  time: 0.0596  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:54  loss: 0.3180 (0.8254)  labels_encoder: 0.2327 (0.5342)  labels_decoder: 0.1110 (0.2912)  labels_encoder_unscaled: 0.2327 (0.5342)  labels_decoder_unscaled: 0.2221 (0.5824)  time: 0.0588  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:42  loss: 1.1693 (0.8616)  labels_encoder: 0.7411 (0.5487)  labels_decoder: 0.4563 (0.3129)  labels_encoder_unscaled: 0.7411 (0.5487)  labels_decoder_unscaled: 0.9126 (0.6258)  time: 0.0579  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:36  loss: 0.9583 (0.9134)  labels_encoder: 0.5799 (0.5859)  labels_decoder: 0.3557 (0.3275)  labels_encoder_unscaled: 0.5799 (0.5859)  labels_decoder_unscaled: 0.7113 (0.6550)  time: 0.0618  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:31  loss: 0.6489 (0.9626)  labels_encoder: 0.3795 (0.6135)  labels_decoder: 0.2695 (0.3492)  labels_encoder_unscaled: 0.3795 (0.6135)  labels_decoder_unscaled: 0.5389 (0.6983)  time: 0.0609  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:26  loss: 0.5875 (0.9653)  labels_encoder: 0.3346 (0.6105)  labels_decoder: 0.2349 (0.3548)  labels_encoder_unscaled: 0.3346 (0.6105)  labels_decoder_unscaled: 0.4698 (0.7096)  time: 0.0597  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:22  loss: 1.3594 (0.9825)  labels_encoder: 0.7996 (0.6197)  labels_decoder: 0.4838 (0.3628)  labels_encoder_unscaled: 0.7996 (0.6197)  labels_decoder_unscaled: 0.9676 (0.7256)  time: 0.0601  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:18  loss: 0.6978 (1.0816)  labels_encoder: 0.3826 (0.6901)  labels_decoder: 0.3469 (0.3915)  labels_encoder_unscaled: 0.3826 (0.6901)  labels_decoder_unscaled: 0.6939 (0.7830)  time: 0.0640  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:14  loss: 1.0194 (1.1690)  labels_encoder: 0.6968 (0.7507)  labels_decoder: 0.2742 (0.4183)  labels_encoder_unscaled: 0.6968 (0.7507)  labels_decoder_unscaled: 0.5483 (0.8367)  time: 0.0589  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:10  loss: 0.3379 (1.1145)  labels_encoder: 0.1613 (0.7132)  labels_decoder: 0.1691 (0.4014)  labels_encoder_unscaled: 0.1613 (0.7132)  labels_decoder_unscaled: 0.3382 (0.8027)  time: 0.0615  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:07  loss: 0.9349 (1.1082)  labels_encoder: 0.7225 (0.7098)  labels_decoder: 0.2946 (0.3984)  labels_encoder_unscaled: 0.7225 (0.7098)  labels_decoder_unscaled: 0.5892 (0.7969)  time: 0.0563  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:03  loss: 1.4607 (1.1379)  labels_encoder: 0.9493 (0.7381)  labels_decoder: 0.4687 (0.3998)  labels_encoder_unscaled: 0.9493 (0.7381)  labels_decoder_unscaled: 0.9373 (0.7996)  time: 0.0599  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:00  loss: 0.7179 (1.1249)  labels_encoder: 0.4189 (0.7267)  labels_decoder: 0.3722 (0.3981)  labels_encoder_unscaled: 0.4189 (0.7267)  labels_decoder_unscaled: 0.7444 (0.7963)  time: 0.0628  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:00:57  loss: 0.5415 (1.1029)  labels_encoder: 0.3568 (0.7116)  labels_decoder: 0.2394 (0.3913)  labels_encoder_unscaled: 0.3568 (0.7116)  labels_decoder_unscaled: 0.4788 (0.7827)  time: 0.0626  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:54  loss: 0.7991 (1.0892)  labels_encoder: 0.4372 (0.7006)  labels_decoder: 0.3619 (0.3886)  labels_encoder_unscaled: 0.4372 (0.7006)  labels_decoder_unscaled: 0.7239 (0.7771)  time: 0.0611  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:50  loss: 0.7644 (1.0924)  labels_encoder: 0.4520 (0.7052)  labels_decoder: 0.2547 (0.3871)  labels_encoder_unscaled: 0.4520 (0.7052)  labels_decoder_unscaled: 0.5093 (0.7742)  time: 0.0629  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:47  loss: 1.7537 (1.1018)  labels_encoder: 1.0669 (0.7099)  labels_decoder: 0.6868 (0.3918)  labels_encoder_unscaled: 1.0669 (0.7099)  labels_decoder_unscaled: 1.3737 (0.7837)  time: 0.0610  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:44  loss: 0.7820 (1.1165)  labels_encoder: 0.3993 (0.7195)  labels_decoder: 0.3237 (0.3970)  labels_encoder_unscaled: 0.3993 (0.7195)  labels_decoder_unscaled: 0.6474 (0.7940)  time: 0.0552  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:41  loss: 1.1045 (1.1225)  labels_encoder: 0.7292 (0.7225)  labels_decoder: 0.3459 (0.4000)  labels_encoder_unscaled: 0.7292 (0.7225)  labels_decoder_unscaled: 0.6918 (0.8001)  time: 0.0626  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:38  loss: 0.6798 (1.1049)  labels_encoder: 0.3579 (0.7104)  labels_decoder: 0.3020 (0.3945)  labels_encoder_unscaled: 0.3579 (0.7104)  labels_decoder_unscaled: 0.6040 (0.7891)  time: 0.0594  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:35  loss: 0.9797 (1.1063)  labels_encoder: 0.6156 (0.7121)  labels_decoder: 0.3788 (0.3942)  labels_encoder_unscaled: 0.6156 (0.7121)  labels_decoder_unscaled: 0.7577 (0.7885)  time: 0.0638  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:31  loss: 0.5850 (1.0888)  labels_encoder: 0.3592 (0.7010)  labels_decoder: 0.2369 (0.3878)  labels_encoder_unscaled: 0.3592 (0.7010)  labels_decoder_unscaled: 0.4738 (0.7756)  time: 0.0635  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:28  loss: 0.6329 (1.0816)  labels_encoder: 0.4980 (0.6954)  labels_decoder: 0.2134 (0.3863)  labels_encoder_unscaled: 0.4980 (0.6954)  labels_decoder_unscaled: 0.4268 (0.7725)  time: 0.0614  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:25  loss: 0.5940 (1.0914)  labels_encoder: 0.3111 (0.7002)  labels_decoder: 0.2957 (0.3912)  labels_encoder_unscaled: 0.3111 (0.7002)  labels_decoder_unscaled: 0.5914 (0.7823)  time: 0.0626  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:22  loss: 0.5666 (1.0942)  labels_encoder: 0.2975 (0.7002)  labels_decoder: 0.2402 (0.3940)  labels_encoder_unscaled: 0.2975 (0.7002)  labels_decoder_unscaled: 0.4804 (0.7879)  time: 0.0579  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:19  loss: 0.6228 (1.0839)  labels_encoder: 0.3599 (0.6925)  labels_decoder: 0.2589 (0.3914)  labels_encoder_unscaled: 0.3599 (0.6925)  labels_decoder_unscaled: 0.5179 (0.7829)  time: 0.0610  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:16  loss: 1.1676 (1.0932)  labels_encoder: 0.7129 (0.6997)  labels_decoder: 0.4114 (0.3936)  labels_encoder_unscaled: 0.7129 (0.6997)  labels_decoder_unscaled: 0.8227 (0.7871)  time: 0.0630  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:13  loss: 0.9497 (1.0920)  labels_encoder: 0.5510 (0.6982)  labels_decoder: 0.3949 (0.3938)  labels_encoder_unscaled: 0.5510 (0.6982)  labels_decoder_unscaled: 0.7898 (0.7877)  time: 0.0627  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.7009 (1.1003)  labels_encoder: 0.3935 (0.7022)  labels_decoder: 0.3615 (0.3981)  labels_encoder_unscaled: 0.3935 (0.7022)  labels_decoder_unscaled: 0.7231 (0.7962)  time: 0.0594  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:06  loss: 0.6782 (1.1128)  labels_encoder: 0.3628 (0.7094)  labels_decoder: 0.2698 (0.4034)  labels_encoder_unscaled: 0.3628 (0.7094)  labels_decoder_unscaled: 0.5396 (0.8068)  time: 0.0608  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:03  loss: 0.8015 (1.1071)  labels_encoder: 0.4506 (0.7055)  labels_decoder: 0.3509 (0.4017)  labels_encoder_unscaled: 0.4506 (0.7055)  labels_decoder_unscaled: 0.7018 (0.8033)  time: 0.0586  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.6353 (1.0974)  labels_encoder: 0.3899 (0.6986)  labels_decoder: 0.2795 (0.3989)  labels_encoder_unscaled: 0.3899 (0.6986)  labels_decoder_unscaled: 0.5589 (0.7978)  time: 0.0569  data: 0.0010  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.4880 (1.0948)  labels_encoder: 0.2078 (0.6970)  labels_decoder: 0.2795 (0.3978)  labels_encoder_unscaled: 0.2078 (0.6970)  labels_decoder_unscaled: 0.5589 (0.7956)  time: 0.0434  data: 0.0001  max mem: 3384
Test: Total time: 0:01:39 (0.0620 s / it)
Averaged stats: loss: 0.4880 (1.0948)  labels_encoder: 0.2078 (0.6970)  labels_decoder: 0.2795 (0.3978)  labels_encoder_unscaled: 0.2078 (0.6970)  labels_decoder_unscaled: 0.5589 (0.7956)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet] mAP: 0.5593

dec_mAP all together: | 0.4444080759434564 |.
dec_mAP_pred | 0 : 0.49659482362335405 |.
dec_mAP_pred | 1 : 0.48519841117080603 |.
dec_mAP_pred | 2 : 0.47022902292692026 |.
dec_mAP_pred | 3 : 0.45435701276049995 |.
dec_mAP_pred | 4 : 0.4380686171081466 |.
dec_mAP_pred | 5 : 0.422215175688126 |.
dec_mAP_pred | 6 : 0.4069466916498115 |.
dec_mAP_pred | 7 : 0.3928350040349534 |.
all decoder map: | 0.4458 |.
BaseballPitch: 0.2203
BasketballDunk: 0.7662
Billiards: 0.3679
CleanAndJerk: 0.7484
CliffDiving: 0.8275
CricketBowling: 0.3614
CricketShot: 0.1718
Diving: 0.7159
FrisbeeCatch: 0.3895
GolfSwing: 0.4194
HammerThrow: 0.8401
HighJump: 0.6386
JavelinThrow: 0.7186
LongJump: 0.7953
PoleVault: 0.8575
Shotput: 0.6791
SoccerPenalty: 0.3414
TennisSwing: 0.4483
ThrowDiscus: 0.6121
VolleyballSpiking: 0.2659
Epoch: [2]  [   0/1405]  eta: 0:38:25  lr: 0.000010  loss: 0.2721 (0.2721)  labels_encoder: 0.1333 (0.1333)  labels_decoder: 0.1388 (0.1388)  labels_encoder_unscaled: 0.1333 (0.1333)  labels_decoder_unscaled: 0.2776 (0.2776)  time: 1.6412  data: 1.4422  max mem: 3384
Epoch: [2]  [  50/1405]  eta: 0:03:44  lr: 0.000010  loss: 0.2774 (0.3152)  labels_encoder: 0.1405 (0.1682)  labels_decoder: 0.1449 (0.1470)  labels_encoder_unscaled: 0.1405 (0.1682)  labels_decoder_unscaled: 0.2898 (0.2940)  time: 0.1387  data: 0.0002  max mem: 3384
Epoch: [2]  [ 100/1405]  eta: 0:03:18  lr: 0.000010  loss: 0.2946 (0.3041)  labels_encoder: 0.1524 (0.1616)  labels_decoder: 0.1407 (0.1426)  labels_encoder_unscaled: 0.1524 (0.1616)  labels_decoder_unscaled: 0.2813 (0.2851)  time: 0.1385  data: 0.0003  max mem: 3384
Epoch: [2]  [ 150/1405]  eta: 0:03:05  lr: 0.000010  loss: 0.2997 (0.3037)  labels_encoder: 0.1695 (0.1623)  labels_decoder: 0.1309 (0.1413)  labels_encoder_unscaled: 0.1695 (0.1623)  labels_decoder_unscaled: 0.2619 (0.2827)  time: 0.1370  data: 0.0002  max mem: 3384
Epoch: [2]  [ 200/1405]  eta: 0:02:54  lr: 0.000010  loss: 0.2701 (0.3012)  labels_encoder: 0.1467 (0.1623)  labels_decoder: 0.1248 (0.1390)  labels_encoder_unscaled: 0.1467 (0.1623)  labels_decoder_unscaled: 0.2497 (0.2779)  time: 0.1371  data: 0.0002  max mem: 3384
Epoch: [2]  [ 250/1405]  eta: 0:02:44  lr: 0.000010  loss: 0.3049 (0.3040)  labels_encoder: 0.1655 (0.1642)  labels_decoder: 0.1360 (0.1397)  labels_encoder_unscaled: 0.1655 (0.1642)  labels_decoder_unscaled: 0.2719 (0.2795)  time: 0.1331  data: 0.0002  max mem: 3384
Epoch: [2]  [ 300/1405]  eta: 0:02:35  lr: 0.000010  loss: 0.2691 (0.3016)  labels_encoder: 0.1465 (0.1630)  labels_decoder: 0.1283 (0.1386)  labels_encoder_unscaled: 0.1465 (0.1630)  labels_decoder_unscaled: 0.2565 (0.2772)  time: 0.1341  data: 0.0003  max mem: 3384
Epoch: [2]  [ 350/1405]  eta: 0:02:27  lr: 0.000010  loss: 0.2859 (0.2997)  labels_encoder: 0.1506 (0.1620)  labels_decoder: 0.1280 (0.1377)  labels_encoder_unscaled: 0.1506 (0.1620)  labels_decoder_unscaled: 0.2561 (0.2754)  time: 0.1356  data: 0.0002  max mem: 3384
Epoch: [2]  [ 400/1405]  eta: 0:02:19  lr: 0.000010  loss: 0.2633 (0.2971)  labels_encoder: 0.1325 (0.1603)  labels_decoder: 0.1325 (0.1368)  labels_encoder_unscaled: 0.1325 (0.1603)  labels_decoder_unscaled: 0.2649 (0.2737)  time: 0.1331  data: 0.0003  max mem: 3384
Epoch: [2]  [ 450/1405]  eta: 0:02:12  lr: 0.000010  loss: 0.2892 (0.2965)  labels_encoder: 0.1605 (0.1601)  labels_decoder: 0.1335 (0.1363)  labels_encoder_unscaled: 0.1605 (0.1601)  labels_decoder_unscaled: 0.2670 (0.2727)  time: 0.1350  data: 0.0002  max mem: 3384
Epoch: [2]  [ 500/1405]  eta: 0:02:05  lr: 0.000010  loss: 0.2881 (0.2950)  labels_encoder: 0.1420 (0.1591)  labels_decoder: 0.1287 (0.1358)  labels_encoder_unscaled: 0.1420 (0.1591)  labels_decoder_unscaled: 0.2574 (0.2717)  time: 0.1362  data: 0.0002  max mem: 3384
Epoch: [2]  [ 550/1405]  eta: 0:01:57  lr: 0.000010  loss: 0.2887 (0.2936)  labels_encoder: 0.1577 (0.1583)  labels_decoder: 0.1307 (0.1352)  labels_encoder_unscaled: 0.1577 (0.1583)  labels_decoder_unscaled: 0.2614 (0.2705)  time: 0.1321  data: 0.0002  max mem: 3384
Epoch: [2]  [ 600/1405]  eta: 0:01:50  lr: 0.000010  loss: 0.2680 (0.2922)  labels_encoder: 0.1435 (0.1574)  labels_decoder: 0.1298 (0.1348)  labels_encoder_unscaled: 0.1435 (0.1574)  labels_decoder_unscaled: 0.2597 (0.2697)  time: 0.1376  data: 0.0002  max mem: 3384
Epoch: [2]  [ 650/1405]  eta: 0:01:43  lr: 0.000010  loss: 0.2737 (0.2910)  labels_encoder: 0.1424 (0.1564)  labels_decoder: 0.1272 (0.1346)  labels_encoder_unscaled: 0.1424 (0.1564)  labels_decoder_unscaled: 0.2544 (0.2691)  time: 0.1301  data: 0.0002  max mem: 3384
Epoch: [2]  [ 700/1405]  eta: 0:01:36  lr: 0.000010  loss: 0.2758 (0.2901)  labels_encoder: 0.1355 (0.1558)  labels_decoder: 0.1322 (0.1343)  labels_encoder_unscaled: 0.1355 (0.1558)  labels_decoder_unscaled: 0.2644 (0.2686)  time: 0.1297  data: 0.0003  max mem: 3384
Epoch: [2]  [ 750/1405]  eta: 0:01:29  lr: 0.000010  loss: 0.2445 (0.2889)  labels_encoder: 0.1283 (0.1553)  labels_decoder: 0.1157 (0.1336)  labels_encoder_unscaled: 0.1283 (0.1553)  labels_decoder_unscaled: 0.2314 (0.2672)  time: 0.1361  data: 0.0003  max mem: 3384
Epoch: [2]  [ 800/1405]  eta: 0:01:22  lr: 0.000010  loss: 0.2847 (0.2886)  labels_encoder: 0.1542 (0.1555)  labels_decoder: 0.1211 (0.1332)  labels_encoder_unscaled: 0.1542 (0.1555)  labels_decoder_unscaled: 0.2423 (0.2664)  time: 0.1353  data: 0.0002  max mem: 3384
Epoch: [2]  [ 850/1405]  eta: 0:01:15  lr: 0.000010  loss: 0.2460 (0.2873)  labels_encoder: 0.1220 (0.1543)  labels_decoder: 0.1276 (0.1330)  labels_encoder_unscaled: 0.1220 (0.1543)  labels_decoder_unscaled: 0.2553 (0.2660)  time: 0.1284  data: 0.0002  max mem: 3384
Epoch: [2]  [ 900/1405]  eta: 0:01:08  lr: 0.000010  loss: 0.2542 (0.2863)  labels_encoder: 0.1482 (0.1536)  labels_decoder: 0.1248 (0.1327)  labels_encoder_unscaled: 0.1482 (0.1536)  labels_decoder_unscaled: 0.2496 (0.2654)  time: 0.1328  data: 0.0003  max mem: 3384
Epoch: [2]  [ 950/1405]  eta: 0:01:02  lr: 0.000010  loss: 0.2633 (0.2857)  labels_encoder: 0.1344 (0.1533)  labels_decoder: 0.1276 (0.1324)  labels_encoder_unscaled: 0.1344 (0.1533)  labels_decoder_unscaled: 0.2552 (0.2648)  time: 0.1341  data: 0.0002  max mem: 3384
Epoch: [2]  [1000/1405]  eta: 0:00:55  lr: 0.000010  loss: 0.2672 (0.2854)  labels_encoder: 0.1443 (0.1530)  labels_decoder: 0.1279 (0.1323)  labels_encoder_unscaled: 0.1443 (0.1530)  labels_decoder_unscaled: 0.2557 (0.2647)  time: 0.1353  data: 0.0003  max mem: 3384
Epoch: [2]  [1050/1405]  eta: 0:00:48  lr: 0.000010  loss: 0.2533 (0.2843)  labels_encoder: 0.1251 (0.1523)  labels_decoder: 0.1224 (0.1320)  labels_encoder_unscaled: 0.1251 (0.1523)  labels_decoder_unscaled: 0.2447 (0.2640)  time: 0.1394  data: 0.0003  max mem: 3384
Epoch: [2]  [1100/1405]  eta: 0:00:41  lr: 0.000010  loss: 0.2608 (0.2835)  labels_encoder: 0.1243 (0.1518)  labels_decoder: 0.1221 (0.1317)  labels_encoder_unscaled: 0.1243 (0.1518)  labels_decoder_unscaled: 0.2442 (0.2635)  time: 0.1347  data: 0.0003  max mem: 3384
Epoch: [2]  [1150/1405]  eta: 0:00:34  lr: 0.000010  loss: 0.2676 (0.2828)  labels_encoder: 0.1378 (0.1514)  labels_decoder: 0.1292 (0.1314)  labels_encoder_unscaled: 0.1378 (0.1514)  labels_decoder_unscaled: 0.2583 (0.2629)  time: 0.1343  data: 0.0002  max mem: 3384
Epoch: [2]  [1200/1405]  eta: 0:00:27  lr: 0.000010  loss: 0.2585 (0.2816)  labels_encoder: 0.1210 (0.1505)  labels_decoder: 0.1283 (0.1311)  labels_encoder_unscaled: 0.1210 (0.1505)  labels_decoder_unscaled: 0.2566 (0.2621)  time: 0.1383  data: 0.0002  max mem: 3384
Epoch: [2]  [1250/1405]  eta: 0:00:21  lr: 0.000010  loss: 0.2422 (0.2806)  labels_encoder: 0.1285 (0.1499)  labels_decoder: 0.1165 (0.1308)  labels_encoder_unscaled: 0.1285 (0.1499)  labels_decoder_unscaled: 0.2330 (0.2616)  time: 0.1366  data: 0.0002  max mem: 3384
Epoch: [2]  [1300/1405]  eta: 0:00:14  lr: 0.000010  loss: 0.2760 (0.2799)  labels_encoder: 0.1440 (0.1494)  labels_decoder: 0.1243 (0.1305)  labels_encoder_unscaled: 0.1440 (0.1494)  labels_decoder_unscaled: 0.2486 (0.2609)  time: 0.1343  data: 0.0002  max mem: 3384
Epoch: [2]  [1350/1405]  eta: 0:00:07  lr: 0.000010  loss: 0.2348 (0.2787)  labels_encoder: 0.1128 (0.1486)  labels_decoder: 0.1149 (0.1301)  labels_encoder_unscaled: 0.1128 (0.1486)  labels_decoder_unscaled: 0.2297 (0.2602)  time: 0.1332  data: 0.0002  max mem: 3384
Epoch: [2]  [1400/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2795 (0.2783)  labels_encoder: 0.1462 (0.1482)  labels_decoder: 0.1295 (0.1300)  labels_encoder_unscaled: 0.1462 (0.1482)  labels_decoder_unscaled: 0.2591 (0.2601)  time: 0.1259  data: 0.0003  max mem: 3384
Epoch: [2]  [1404/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2795 (0.2782)  labels_encoder: 0.1689 (0.1482)  labels_decoder: 0.1295 (0.1300)  labels_encoder_unscaled: 0.1689 (0.1482)  labels_decoder_unscaled: 0.2591 (0.2600)  time: 0.1236  data: 0.0003  max mem: 3384
Epoch: [2] Total time: 0:03:11 (0.1362 s / it)
Averaged stats: lr: 0.000010  loss: 0.2795 (0.2782)  labels_encoder: 0.1689 (0.1482)  labels_decoder: 0.1295 (0.1300)  labels_encoder_unscaled: 0.1689 (0.1482)  labels_decoder_unscaled: 0.2591 (0.2600)
Test:  [   0/1613]  eta: 0:37:54  loss: 0.2919 (0.2919)  labels_encoder: 0.1975 (0.1975)  labels_decoder: 0.0944 (0.0944)  labels_encoder_unscaled: 0.1975 (0.1975)  labels_decoder_unscaled: 0.1889 (0.1889)  time: 1.4098  data: 1.3397  max mem: 3384
Test:  [  50/1613]  eta: 0:02:23  loss: 0.5165 (1.0439)  labels_encoder: 0.2890 (0.6801)  labels_decoder: 0.2393 (0.3638)  labels_encoder_unscaled: 0.2890 (0.6801)  labels_decoder_unscaled: 0.4786 (0.7276)  time: 0.0590  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:57  loss: 0.2680 (0.7968)  labels_encoder: 0.1887 (0.5164)  labels_decoder: 0.0485 (0.2804)  labels_encoder_unscaled: 0.1887 (0.5164)  labels_decoder_unscaled: 0.0971 (0.5607)  time: 0.0663  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:49  loss: 0.8296 (0.7605)  labels_encoder: 0.5214 (0.4844)  labels_decoder: 0.3180 (0.2761)  labels_encoder_unscaled: 0.5214 (0.4844)  labels_decoder_unscaled: 0.6359 (0.5522)  time: 0.0692  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:43  loss: 1.1386 (0.9449)  labels_encoder: 0.7632 (0.6158)  labels_decoder: 0.4082 (0.3291)  labels_encoder_unscaled: 0.7632 (0.6158)  labels_decoder_unscaled: 0.8165 (0.6582)  time: 0.0702  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:39  loss: 0.6751 (0.9911)  labels_encoder: 0.3829 (0.6408)  labels_decoder: 0.2561 (0.3503)  labels_encoder_unscaled: 0.3829 (0.6408)  labels_decoder_unscaled: 0.5121 (0.7006)  time: 0.0711  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:33  loss: 0.5361 (1.0055)  labels_encoder: 0.3338 (0.6550)  labels_decoder: 0.2097 (0.3505)  labels_encoder_unscaled: 0.3338 (0.6550)  labels_decoder_unscaled: 0.4194 (0.7010)  time: 0.0654  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:30  loss: 1.0006 (0.9986)  labels_encoder: 0.6305 (0.6456)  labels_decoder: 0.3907 (0.3530)  labels_encoder_unscaled: 0.6305 (0.6456)  labels_decoder_unscaled: 0.7815 (0.7060)  time: 0.0751  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:26  loss: 0.7576 (1.1511)  labels_encoder: 0.4202 (0.7575)  labels_decoder: 0.3323 (0.3936)  labels_encoder_unscaled: 0.4202 (0.7575)  labels_decoder_unscaled: 0.6646 (0.7871)  time: 0.0654  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:22  loss: 0.8835 (1.2342)  labels_encoder: 0.5130 (0.8133)  labels_decoder: 0.3432 (0.4208)  labels_encoder_unscaled: 0.5130 (0.8133)  labels_decoder_unscaled: 0.6864 (0.8417)  time: 0.0646  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:18  loss: 0.3579 (1.1748)  labels_encoder: 0.1820 (0.7717)  labels_decoder: 0.1712 (0.4031)  labels_encoder_unscaled: 0.1820 (0.7717)  labels_decoder_unscaled: 0.3424 (0.8062)  time: 0.0663  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:14  loss: 0.9192 (1.1671)  labels_encoder: 0.6317 (0.7642)  labels_decoder: 0.3194 (0.4029)  labels_encoder_unscaled: 0.6317 (0.7642)  labels_decoder_unscaled: 0.6388 (0.8058)  time: 0.0661  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:10  loss: 1.9844 (1.2092)  labels_encoder: 1.1934 (0.7983)  labels_decoder: 0.5161 (0.4109)  labels_encoder_unscaled: 1.1934 (0.7983)  labels_decoder_unscaled: 1.0322 (0.8217)  time: 0.0624  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:06  loss: 0.7178 (1.1940)  labels_encoder: 0.3091 (0.7828)  labels_decoder: 0.3565 (0.4112)  labels_encoder_unscaled: 0.3091 (0.7828)  labels_decoder_unscaled: 0.7129 (0.8224)  time: 0.0700  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:01:02  loss: 0.5488 (1.1663)  labels_encoder: 0.3316 (0.7638)  labels_decoder: 0.2207 (0.4025)  labels_encoder_unscaled: 0.3316 (0.7638)  labels_decoder_unscaled: 0.4413 (0.8050)  time: 0.0679  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:59  loss: 0.6427 (1.1405)  labels_encoder: 0.3354 (0.7457)  labels_decoder: 0.2732 (0.3948)  labels_encoder_unscaled: 0.3354 (0.7457)  labels_decoder_unscaled: 0.5465 (0.7896)  time: 0.0670  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:55  loss: 1.0572 (1.1362)  labels_encoder: 0.7009 (0.7438)  labels_decoder: 0.3522 (0.3924)  labels_encoder_unscaled: 0.7009 (0.7438)  labels_decoder_unscaled: 0.7045 (0.7848)  time: 0.0649  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:52  loss: 1.5326 (1.1393)  labels_encoder: 1.0914 (0.7443)  labels_decoder: 0.4945 (0.3950)  labels_encoder_unscaled: 1.0914 (0.7443)  labels_decoder_unscaled: 0.9889 (0.7901)  time: 0.0648  data: 0.0002  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:48  loss: 0.8161 (1.1624)  labels_encoder: 0.4768 (0.7606)  labels_decoder: 0.3131 (0.4018)  labels_encoder_unscaled: 0.4768 (0.7606)  labels_decoder_unscaled: 0.6262 (0.8036)  time: 0.0628  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:45  loss: 1.0611 (1.1514)  labels_encoder: 0.6067 (0.7525)  labels_decoder: 0.3111 (0.3989)  labels_encoder_unscaled: 0.6067 (0.7525)  labels_decoder_unscaled: 0.6221 (0.7979)  time: 0.0640  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:41  loss: 0.4870 (1.1344)  labels_encoder: 0.2589 (0.7406)  labels_decoder: 0.2305 (0.3938)  labels_encoder_unscaled: 0.2589 (0.7406)  labels_decoder_unscaled: 0.4610 (0.7876)  time: 0.0620  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:38  loss: 0.9306 (1.1272)  labels_encoder: 0.5282 (0.7359)  labels_decoder: 0.3268 (0.3913)  labels_encoder_unscaled: 0.5282 (0.7359)  labels_decoder_unscaled: 0.6535 (0.7826)  time: 0.0709  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:34  loss: 0.8496 (1.1297)  labels_encoder: 0.6400 (0.7382)  labels_decoder: 0.3448 (0.3915)  labels_encoder_unscaled: 0.6400 (0.7382)  labels_decoder_unscaled: 0.6896 (0.7830)  time: 0.0625  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:31  loss: 0.7062 (1.1199)  labels_encoder: 0.4129 (0.7312)  labels_decoder: 0.3006 (0.3887)  labels_encoder_unscaled: 0.4129 (0.7312)  labels_decoder_unscaled: 0.6012 (0.7774)  time: 0.0619  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:27  loss: 0.5331 (1.1229)  labels_encoder: 0.3213 (0.7323)  labels_decoder: 0.2204 (0.3906)  labels_encoder_unscaled: 0.3213 (0.7323)  labels_decoder_unscaled: 0.4408 (0.7811)  time: 0.0606  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:24  loss: 0.5844 (1.1233)  labels_encoder: 0.3128 (0.7323)  labels_decoder: 0.2650 (0.3910)  labels_encoder_unscaled: 0.3128 (0.7323)  labels_decoder_unscaled: 0.5299 (0.7820)  time: 0.0641  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:20  loss: 0.5551 (1.1126)  labels_encoder: 0.3669 (0.7248)  labels_decoder: 0.2300 (0.3878)  labels_encoder_unscaled: 0.3669 (0.7248)  labels_decoder_unscaled: 0.4600 (0.7755)  time: 0.0640  data: 0.0002  max mem: 3384
Test:  [1350/1613]  eta: 0:00:17  loss: 0.8889 (1.1292)  labels_encoder: 0.5671 (0.7366)  labels_decoder: 0.3494 (0.3926)  labels_encoder_unscaled: 0.5671 (0.7366)  labels_decoder_unscaled: 0.6988 (0.7852)  time: 0.0599  data: 0.0002  max mem: 3384
Test:  [1400/1613]  eta: 0:00:14  loss: 0.9661 (1.1264)  labels_encoder: 0.6352 (0.7344)  labels_decoder: 0.3666 (0.3920)  labels_encoder_unscaled: 0.6352 (0.7344)  labels_decoder_unscaled: 0.7331 (0.7840)  time: 0.0680  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.6443 (1.1395)  labels_encoder: 0.3425 (0.7421)  labels_decoder: 0.3351 (0.3974)  labels_encoder_unscaled: 0.3425 (0.7421)  labels_decoder_unscaled: 0.6703 (0.7948)  time: 0.0651  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.7858 (1.1593)  labels_encoder: 0.4980 (0.7563)  labels_decoder: 0.2913 (0.4030)  labels_encoder_unscaled: 0.4980 (0.7563)  labels_decoder_unscaled: 0.5826 (0.8061)  time: 0.0599  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:04  loss: 0.7730 (1.1547)  labels_encoder: 0.4616 (0.7539)  labels_decoder: 0.2969 (0.4008)  labels_encoder_unscaled: 0.4616 (0.7539)  labels_decoder_unscaled: 0.5938 (0.8016)  time: 0.0658  data: 0.0011  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.9064 (1.1462)  labels_encoder: 0.5390 (0.7477)  labels_decoder: 0.3585 (0.3985)  labels_encoder_unscaled: 0.5390 (0.7477)  labels_decoder_unscaled: 0.7170 (0.7971)  time: 0.0636  data: 0.0001  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7610 (1.1438)  labels_encoder: 0.4647 (0.7464)  labels_decoder: 0.2962 (0.3974)  labels_encoder_unscaled: 0.4647 (0.7464)  labels_decoder_unscaled: 0.5924 (0.7948)  time: 0.0458  data: 0.0001  max mem: 3384
Test: Total time: 0:01:47 (0.0665 s / it)
Averaged stats: loss: 0.7610 (1.1438)  labels_encoder: 0.4647 (0.7464)  labels_decoder: 0.2962 (0.3974)  labels_encoder_unscaled: 0.4647 (0.7464)  labels_decoder_unscaled: 0.5924 (0.7948)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet] mAP: 0.5704

dec_mAP all together: | 0.44999346232938836 |.
dec_mAP_pred | 0 : 0.4932008429202203 |.
dec_mAP_pred | 1 : 0.4851356025472072 |.
dec_mAP_pred | 2 : 0.4730594949456493 |.
dec_mAP_pred | 3 : 0.45954281902374533 |.
dec_mAP_pred | 4 : 0.44496865126025203 |.
dec_mAP_pred | 5 : 0.4307759785574728 |.
dec_mAP_pred | 6 : 0.41667291470097495 |.
dec_mAP_pred | 7 : 0.40376991293076514 |.
all decoder map: | 0.4509 |.
BaseballPitch: 0.2198
BasketballDunk: 0.7605
Billiards: 0.4044
CleanAndJerk: 0.7416
CliffDiving: 0.8069
CricketBowling: 0.4225
CricketShot: 0.1778
Diving: 0.6962
FrisbeeCatch: 0.3848
GolfSwing: 0.5614
HammerThrow: 0.8553
HighJump: 0.5999
JavelinThrow: 0.7005
LongJump: 0.7815
PoleVault: 0.8622
Shotput: 0.6730
SoccerPenalty: 0.3612
TennisSwing: 0.5571
ThrowDiscus: 0.5850
VolleyballSpiking: 0.2559
Epoch: [3]  [   0/1405]  eta: 0:36:29  lr: 0.000001  loss: 0.2575 (0.2575)  labels_encoder: 0.1226 (0.1226)  labels_decoder: 0.1349 (0.1349)  labels_encoder_unscaled: 0.1226 (0.1226)  labels_decoder_unscaled: 0.2698 (0.2698)  time: 1.5580  data: 1.4186  max mem: 3384
Epoch: [3]  [  50/1405]  eta: 0:03:42  lr: 0.000001  loss: 0.2112 (0.2446)  labels_encoder: 0.1014 (0.1233)  labels_decoder: 0.1079 (0.1213)  labels_encoder_unscaled: 0.1014 (0.1233)  labels_decoder_unscaled: 0.2159 (0.2426)  time: 0.1390  data: 0.0002  max mem: 3384
Epoch: [3]  [ 100/1405]  eta: 0:03:17  lr: 0.000001  loss: 0.2487 (0.2460)  labels_encoder: 0.1196 (0.1261)  labels_decoder: 0.1176 (0.1198)  labels_encoder_unscaled: 0.1196 (0.1261)  labels_decoder_unscaled: 0.2352 (0.2396)  time: 0.1351  data: 0.0002  max mem: 3384
Epoch: [3]  [ 150/1405]  eta: 0:03:02  lr: 0.000001  loss: 0.2512 (0.2489)  labels_encoder: 0.1200 (0.1287)  labels_decoder: 0.1108 (0.1202)  labels_encoder_unscaled: 0.1200 (0.1287)  labels_decoder_unscaled: 0.2215 (0.2405)  time: 0.1330  data: 0.0002  max mem: 3384
Epoch: [3]  [ 200/1405]  eta: 0:02:51  lr: 0.000001  loss: 0.2409 (0.2477)  labels_encoder: 0.1193 (0.1279)  labels_decoder: 0.1167 (0.1198)  labels_encoder_unscaled: 0.1193 (0.1279)  labels_decoder_unscaled: 0.2335 (0.2395)  time: 0.1343  data: 0.0002  max mem: 3384
Epoch: [3]  [ 250/1405]  eta: 0:02:43  lr: 0.000001  loss: 0.2548 (0.2470)  labels_encoder: 0.1344 (0.1274)  labels_decoder: 0.1250 (0.1195)  labels_encoder_unscaled: 0.1344 (0.1274)  labels_decoder_unscaled: 0.2501 (0.2391)  time: 0.1409  data: 0.0003  max mem: 3384
Epoch: [3]  [ 300/1405]  eta: 0:02:34  lr: 0.000001  loss: 0.2516 (0.2474)  labels_encoder: 0.1304 (0.1274)  labels_decoder: 0.1185 (0.1200)  labels_encoder_unscaled: 0.1304 (0.1274)  labels_decoder_unscaled: 0.2370 (0.2401)  time: 0.1345  data: 0.0002  max mem: 3384
Epoch: [3]  [ 350/1405]  eta: 0:02:26  lr: 0.000001  loss: 0.2222 (0.2461)  labels_encoder: 0.1065 (0.1259)  labels_decoder: 0.1127 (0.1202)  labels_encoder_unscaled: 0.1065 (0.1259)  labels_decoder_unscaled: 0.2254 (0.2403)  time: 0.1337  data: 0.0002  max mem: 3384
Epoch: [3]  [ 400/1405]  eta: 0:02:19  lr: 0.000001  loss: 0.2428 (0.2465)  labels_encoder: 0.1286 (0.1268)  labels_decoder: 0.1100 (0.1196)  labels_encoder_unscaled: 0.1286 (0.1268)  labels_decoder_unscaled: 0.2199 (0.2392)  time: 0.1348  data: 0.0002  max mem: 3384
Epoch: [3]  [ 450/1405]  eta: 0:02:12  lr: 0.000001  loss: 0.2390 (0.2453)  labels_encoder: 0.1144 (0.1258)  labels_decoder: 0.1164 (0.1195)  labels_encoder_unscaled: 0.1144 (0.1258)  labels_decoder_unscaled: 0.2328 (0.2390)  time: 0.1397  data: 0.0003  max mem: 3384
Epoch: [3]  [ 500/1405]  eta: 0:02:05  lr: 0.000001  loss: 0.2205 (0.2452)  labels_encoder: 0.1165 (0.1258)  labels_decoder: 0.1126 (0.1193)  labels_encoder_unscaled: 0.1165 (0.1258)  labels_decoder_unscaled: 0.2253 (0.2387)  time: 0.1338  data: 0.0002  max mem: 3384
Epoch: [3]  [ 550/1405]  eta: 0:01:58  lr: 0.000001  loss: 0.2481 (0.2448)  labels_encoder: 0.1384 (0.1257)  labels_decoder: 0.1063 (0.1191)  labels_encoder_unscaled: 0.1384 (0.1257)  labels_decoder_unscaled: 0.2126 (0.2381)  time: 0.1320  data: 0.0002  max mem: 3384
Epoch: [3]  [ 600/1405]  eta: 0:01:51  lr: 0.000001  loss: 0.2487 (0.2449)  labels_encoder: 0.1268 (0.1257)  labels_decoder: 0.1225 (0.1191)  labels_encoder_unscaled: 0.1268 (0.1257)  labels_decoder_unscaled: 0.2451 (0.2383)  time: 0.1363  data: 0.0002  max mem: 3384
Epoch: [3]  [ 650/1405]  eta: 0:01:44  lr: 0.000001  loss: 0.2350 (0.2444)  labels_encoder: 0.1208 (0.1256)  labels_decoder: 0.1171 (0.1188)  labels_encoder_unscaled: 0.1208 (0.1256)  labels_decoder_unscaled: 0.2341 (0.2376)  time: 0.1357  data: 0.0003  max mem: 3384
Epoch: [3]  [ 700/1405]  eta: 0:01:36  lr: 0.000001  loss: 0.2417 (0.2442)  labels_encoder: 0.1234 (0.1254)  labels_decoder: 0.1131 (0.1188)  labels_encoder_unscaled: 0.1234 (0.1254)  labels_decoder_unscaled: 0.2261 (0.2375)  time: 0.1298  data: 0.0002  max mem: 3384
Epoch: [3]  [ 750/1405]  eta: 0:01:30  lr: 0.000001  loss: 0.2198 (0.2436)  labels_encoder: 0.1080 (0.1250)  labels_decoder: 0.1150 (0.1186)  labels_encoder_unscaled: 0.1080 (0.1250)  labels_decoder_unscaled: 0.2300 (0.2372)  time: 0.1420  data: 0.0003  max mem: 3384
Epoch: [3]  [ 800/1405]  eta: 0:01:23  lr: 0.000001  loss: 0.2377 (0.2434)  labels_encoder: 0.1311 (0.1249)  labels_decoder: 0.1196 (0.1185)  labels_encoder_unscaled: 0.1311 (0.1249)  labels_decoder_unscaled: 0.2393 (0.2370)  time: 0.1340  data: 0.0011  max mem: 3384
Epoch: [3]  [ 850/1405]  eta: 0:01:16  lr: 0.000001  loss: 0.2448 (0.2430)  labels_encoder: 0.1178 (0.1245)  labels_decoder: 0.1219 (0.1185)  labels_encoder_unscaled: 0.1178 (0.1245)  labels_decoder_unscaled: 0.2437 (0.2370)  time: 0.1349  data: 0.0003  max mem: 3384
Epoch: [3]  [ 900/1405]  eta: 0:01:09  lr: 0.000001  loss: 0.2451 (0.2432)  labels_encoder: 0.1240 (0.1248)  labels_decoder: 0.1174 (0.1184)  labels_encoder_unscaled: 0.1240 (0.1248)  labels_decoder_unscaled: 0.2347 (0.2368)  time: 0.1339  data: 0.0002  max mem: 3384
Epoch: [3]  [ 950/1405]  eta: 0:01:02  lr: 0.000001  loss: 0.2315 (0.2430)  labels_encoder: 0.1232 (0.1248)  labels_decoder: 0.1053 (0.1182)  labels_encoder_unscaled: 0.1232 (0.1248)  labels_decoder_unscaled: 0.2106 (0.2364)  time: 0.1368  data: 0.0002  max mem: 3384
Epoch: [3]  [1000/1405]  eta: 0:00:55  lr: 0.000001  loss: 0.2503 (0.2428)  labels_encoder: 0.1210 (0.1245)  labels_decoder: 0.1129 (0.1182)  labels_encoder_unscaled: 0.1210 (0.1245)  labels_decoder_unscaled: 0.2258 (0.2364)  time: 0.1318  data: 0.0002  max mem: 3384
Epoch: [3]  [1050/1405]  eta: 0:00:48  lr: 0.000001  loss: 0.2521 (0.2432)  labels_encoder: 0.1236 (0.1249)  labels_decoder: 0.1219 (0.1183)  labels_encoder_unscaled: 0.1236 (0.1249)  labels_decoder_unscaled: 0.2438 (0.2366)  time: 0.1317  data: 0.0003  max mem: 3384
Epoch: [3]  [1100/1405]  eta: 0:00:41  lr: 0.000001  loss: 0.2153 (0.2430)  labels_encoder: 0.1039 (0.1248)  labels_decoder: 0.1066 (0.1182)  labels_encoder_unscaled: 0.1039 (0.1248)  labels_decoder_unscaled: 0.2131 (0.2365)  time: 0.1341  data: 0.0002  max mem: 3384
Epoch: [3]  [1150/1405]  eta: 0:00:34  lr: 0.000001  loss: 0.2176 (0.2430)  labels_encoder: 0.1168 (0.1248)  labels_decoder: 0.1123 (0.1182)  labels_encoder_unscaled: 0.1168 (0.1248)  labels_decoder_unscaled: 0.2245 (0.2365)  time: 0.1347  data: 0.0002  max mem: 3384
Epoch: [3]  [1200/1405]  eta: 0:00:27  lr: 0.000001  loss: 0.2304 (0.2428)  labels_encoder: 0.1142 (0.1246)  labels_decoder: 0.1196 (0.1182)  labels_encoder_unscaled: 0.1142 (0.1246)  labels_decoder_unscaled: 0.2392 (0.2364)  time: 0.1283  data: 0.0003  max mem: 3384
Epoch: [3]  [1250/1405]  eta: 0:00:21  lr: 0.000001  loss: 0.2166 (0.2428)  labels_encoder: 0.1188 (0.1247)  labels_decoder: 0.1110 (0.1181)  labels_encoder_unscaled: 0.1188 (0.1247)  labels_decoder_unscaled: 0.2221 (0.2361)  time: 0.1319  data: 0.0002  max mem: 3384
Epoch: [3]  [1300/1405]  eta: 0:00:14  lr: 0.000001  loss: 0.2474 (0.2429)  labels_encoder: 0.1306 (0.1247)  labels_decoder: 0.1137 (0.1181)  labels_encoder_unscaled: 0.1306 (0.1247)  labels_decoder_unscaled: 0.2274 (0.2363)  time: 0.1301  data: 0.0002  max mem: 3384
Epoch: [3]  [1350/1405]  eta: 0:00:07  lr: 0.000001  loss: 0.2372 (0.2429)  labels_encoder: 0.1295 (0.1248)  labels_decoder: 0.1078 (0.1181)  labels_encoder_unscaled: 0.1295 (0.1248)  labels_decoder_unscaled: 0.2156 (0.2361)  time: 0.1342  data: 0.0002  max mem: 3384
Epoch: [3]  [1400/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2507 (0.2429)  labels_encoder: 0.1300 (0.1248)  labels_decoder: 0.1236 (0.1181)  labels_encoder_unscaled: 0.1300 (0.1248)  labels_decoder_unscaled: 0.2471 (0.2363)  time: 0.1239  data: 0.0003  max mem: 3384
Epoch: [3]  [1404/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2323 (0.2429)  labels_encoder: 0.1300 (0.1248)  labels_decoder: 0.1203 (0.1181)  labels_encoder_unscaled: 0.1300 (0.1248)  labels_decoder_unscaled: 0.2406 (0.2363)  time: 0.1215  data: 0.0003  max mem: 3384
Epoch: [3] Total time: 0:03:10 (0.1355 s / it)
Averaged stats: lr: 0.000001  loss: 0.2323 (0.2429)  labels_encoder: 0.1300 (0.1248)  labels_decoder: 0.1203 (0.1181)  labels_encoder_unscaled: 0.1300 (0.1248)  labels_decoder_unscaled: 0.2406 (0.2363)
Test:  [   0/1613]  eta: 0:36:37  loss: 0.5025 (0.5025)  labels_encoder: 0.3091 (0.3091)  labels_decoder: 0.1934 (0.1934)  labels_encoder_unscaled: 0.3091 (0.3091)  labels_decoder_unscaled: 0.3868 (0.3868)  time: 1.3627  data: 1.2624  max mem: 3384
Test:  [  50/1613]  eta: 0:02:11  loss: 0.4618 (1.0736)  labels_encoder: 0.2852 (0.6979)  labels_decoder: 0.2284 (0.3757)  labels_encoder_unscaled: 0.2852 (0.6979)  labels_decoder_unscaled: 0.4567 (0.7514)  time: 0.0514  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:45  loss: 0.2619 (0.8126)  labels_encoder: 0.1720 (0.5260)  labels_decoder: 0.0614 (0.2866)  labels_encoder_unscaled: 0.1720 (0.5260)  labels_decoder_unscaled: 0.1229 (0.5732)  time: 0.0553  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:37  loss: 0.8762 (0.7793)  labels_encoder: 0.5000 (0.5001)  labels_decoder: 0.3194 (0.2792)  labels_encoder_unscaled: 0.5000 (0.5001)  labels_decoder_unscaled: 0.6388 (0.5583)  time: 0.0645  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:34  loss: 0.9747 (0.9478)  labels_encoder: 0.6094 (0.6166)  labels_decoder: 0.3629 (0.3312)  labels_encoder_unscaled: 0.6094 (0.6166)  labels_decoder_unscaled: 0.7257 (0.6623)  time: 0.0646  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:30  loss: 0.7281 (0.9880)  labels_encoder: 0.3644 (0.6388)  labels_decoder: 0.2493 (0.3491)  labels_encoder_unscaled: 0.3644 (0.6388)  labels_decoder_unscaled: 0.4986 (0.6983)  time: 0.0704  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:27  loss: 0.5371 (1.0053)  labels_encoder: 0.2993 (0.6519)  labels_decoder: 0.2103 (0.3534)  labels_encoder_unscaled: 0.2993 (0.6519)  labels_decoder_unscaled: 0.4206 (0.7068)  time: 0.0675  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:23  loss: 1.0138 (1.0015)  labels_encoder: 0.6056 (0.6441)  labels_decoder: 0.4413 (0.3574)  labels_encoder_unscaled: 0.6056 (0.6441)  labels_decoder_unscaled: 0.8827 (0.7149)  time: 0.0611  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:20  loss: 0.7482 (1.1431)  labels_encoder: 0.4115 (0.7469)  labels_decoder: 0.3257 (0.3962)  labels_encoder_unscaled: 0.4115 (0.7469)  labels_decoder_unscaled: 0.6515 (0.7925)  time: 0.0661  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:17  loss: 0.8122 (1.2242)  labels_encoder: 0.5278 (0.8019)  labels_decoder: 0.2890 (0.4223)  labels_encoder_unscaled: 0.5278 (0.8019)  labels_decoder_unscaled: 0.5779 (0.8447)  time: 0.0781  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:14  loss: 0.3717 (1.1681)  labels_encoder: 0.1973 (0.7621)  labels_decoder: 0.1744 (0.4059)  labels_encoder_unscaled: 0.1973 (0.7621)  labels_decoder_unscaled: 0.3489 (0.8119)  time: 0.0727  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:10  loss: 0.9997 (1.1705)  labels_encoder: 0.6430 (0.7609)  labels_decoder: 0.3935 (0.4096)  labels_encoder_unscaled: 0.6430 (0.7609)  labels_decoder_unscaled: 0.7871 (0.8191)  time: 0.0672  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:07  loss: 2.0974 (1.2116)  labels_encoder: 1.3212 (0.7943)  labels_decoder: 0.4882 (0.4172)  labels_encoder_unscaled: 1.3212 (0.7943)  labels_decoder_unscaled: 0.9764 (0.8344)  time: 0.0666  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:04  loss: 0.7366 (1.1949)  labels_encoder: 0.3401 (0.7781)  labels_decoder: 0.3712 (0.4168)  labels_encoder_unscaled: 0.3401 (0.7781)  labels_decoder_unscaled: 0.7424 (0.8336)  time: 0.0746  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:01:01  loss: 0.5297 (1.1665)  labels_encoder: 0.3133 (0.7587)  labels_decoder: 0.2163 (0.4078)  labels_encoder_unscaled: 0.3133 (0.7587)  labels_decoder_unscaled: 0.4326 (0.8156)  time: 0.0650  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:57  loss: 0.6721 (1.1409)  labels_encoder: 0.3529 (0.7410)  labels_decoder: 0.2717 (0.3998)  labels_encoder_unscaled: 0.3529 (0.7410)  labels_decoder_unscaled: 0.5434 (0.7996)  time: 0.0615  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:54  loss: 0.9541 (1.1344)  labels_encoder: 0.5361 (0.7377)  labels_decoder: 0.3830 (0.3967)  labels_encoder_unscaled: 0.5361 (0.7377)  labels_decoder_unscaled: 0.7659 (0.7934)  time: 0.0700  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:51  loss: 2.0948 (1.1441)  labels_encoder: 1.3864 (0.7430)  labels_decoder: 0.6144 (0.4011)  labels_encoder_unscaled: 1.3864 (0.7430)  labels_decoder_unscaled: 1.2288 (0.8022)  time: 0.0639  data: 0.0001  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:47  loss: 0.9102 (1.1697)  labels_encoder: 0.4966 (0.7609)  labels_decoder: 0.3371 (0.4087)  labels_encoder_unscaled: 0.4966 (0.7609)  labels_decoder_unscaled: 0.6742 (0.8175)  time: 0.0644  data: 0.0002  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:44  loss: 0.8771 (1.1578)  labels_encoder: 0.5270 (0.7526)  labels_decoder: 0.2937 (0.4052)  labels_encoder_unscaled: 0.5270 (0.7526)  labels_decoder_unscaled: 0.5874 (0.8104)  time: 0.0665  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:41  loss: 0.4818 (1.1388)  labels_encoder: 0.2697 (0.7393)  labels_decoder: 0.2177 (0.3995)  labels_encoder_unscaled: 0.2697 (0.7393)  labels_decoder_unscaled: 0.4354 (0.7990)  time: 0.0697  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:37  loss: 0.9099 (1.1318)  labels_encoder: 0.5399 (0.7352)  labels_decoder: 0.3120 (0.3966)  labels_encoder_unscaled: 0.5399 (0.7352)  labels_decoder_unscaled: 0.6239 (0.7931)  time: 0.0693  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:34  loss: 0.7952 (1.1336)  labels_encoder: 0.4777 (0.7368)  labels_decoder: 0.3655 (0.3968)  labels_encoder_unscaled: 0.4777 (0.7368)  labels_decoder_unscaled: 0.7311 (0.7937)  time: 0.0625  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:31  loss: 0.7828 (1.1229)  labels_encoder: 0.4640 (0.7294)  labels_decoder: 0.3117 (0.3935)  labels_encoder_unscaled: 0.4640 (0.7294)  labels_decoder_unscaled: 0.6235 (0.7870)  time: 0.0630  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:27  loss: 0.5795 (1.1288)  labels_encoder: 0.3456 (0.7324)  labels_decoder: 0.2302 (0.3964)  labels_encoder_unscaled: 0.3456 (0.7324)  labels_decoder_unscaled: 0.4604 (0.7929)  time: 0.0659  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:24  loss: 0.4925 (1.1279)  labels_encoder: 0.2864 (0.7315)  labels_decoder: 0.1902 (0.3964)  labels_encoder_unscaled: 0.2864 (0.7315)  labels_decoder_unscaled: 0.3804 (0.7928)  time: 0.0611  data: 0.0001  max mem: 3384
Test:  [1300/1613]  eta: 0:00:20  loss: 0.5448 (1.1174)  labels_encoder: 0.3501 (0.7242)  labels_decoder: 0.2182 (0.3932)  labels_encoder_unscaled: 0.3501 (0.7242)  labels_decoder_unscaled: 0.4364 (0.7864)  time: 0.0596  data: 0.0001  max mem: 3384
Test:  [1350/1613]  eta: 0:00:17  loss: 0.7805 (1.1330)  labels_encoder: 0.4836 (0.7350)  labels_decoder: 0.3290 (0.3979)  labels_encoder_unscaled: 0.4836 (0.7350)  labels_decoder_unscaled: 0.6580 (0.7959)  time: 0.0631  data: 0.0001  max mem: 3384
Test:  [1400/1613]  eta: 0:00:14  loss: 1.1189 (1.1315)  labels_encoder: 0.7207 (0.7337)  labels_decoder: 0.4042 (0.3978)  labels_encoder_unscaled: 0.7207 (0.7337)  labels_decoder_unscaled: 0.8084 (0.7956)  time: 0.0588  data: 0.0002  max mem: 3384
Test:  [1450/1613]  eta: 0:00:10  loss: 0.6317 (1.1463)  labels_encoder: 0.3370 (0.7424)  labels_decoder: 0.3357 (0.4039)  labels_encoder_unscaled: 0.3370 (0.7424)  labels_decoder_unscaled: 0.6715 (0.8079)  time: 0.0573  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.6433 (1.1597)  labels_encoder: 0.4150 (0.7518)  labels_decoder: 0.2660 (0.4079)  labels_encoder_unscaled: 0.4150 (0.7518)  labels_decoder_unscaled: 0.5319 (0.8158)  time: 0.0651  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:04  loss: 0.7698 (1.1561)  labels_encoder: 0.4213 (0.7504)  labels_decoder: 0.2831 (0.4057)  labels_encoder_unscaled: 0.4213 (0.7504)  labels_decoder_unscaled: 0.5662 (0.8115)  time: 0.0609  data: 0.0002  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.9634 (1.1483)  labels_encoder: 0.6006 (0.7446)  labels_decoder: 0.3615 (0.4036)  labels_encoder_unscaled: 0.6006 (0.7446)  labels_decoder_unscaled: 0.7229 (0.8073)  time: 0.0618  data: 0.0001  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8345 (1.1459)  labels_encoder: 0.4846 (0.7433)  labels_decoder: 0.3500 (0.4025)  labels_encoder_unscaled: 0.4846 (0.7433)  labels_decoder_unscaled: 0.6999 (0.8051)  time: 0.0550  data: 0.0001  max mem: 3384
Test: Total time: 0:01:46 (0.0661 s / it)
Averaged stats: loss: 0.8345 (1.1459)  labels_encoder: 0.4846 (0.7433)  labels_decoder: 0.3500 (0.4025)  labels_encoder_unscaled: 0.4846 (0.7433)  labels_decoder_unscaled: 0.6999 (0.8051)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet] mAP: 0.5709

dec_mAP all together: | 0.44959074711029706 |.
dec_mAP_pred | 0 : 0.4925348280437354 |.
dec_mAP_pred | 1 : 0.4844823904094895 |.
dec_mAP_pred | 2 : 0.47246152200066865 |.
dec_mAP_pred | 3 : 0.4588909674625943 |.
dec_mAP_pred | 4 : 0.4443830380301429 |.
dec_mAP_pred | 5 : 0.4303692326390303 |.
dec_mAP_pred | 6 : 0.41639270091690295 |.
dec_mAP_pred | 7 : 0.40350653726916175 |.
all decoder map: | 0.4504 |.
BaseballPitch: 0.2166
BasketballDunk: 0.7654
Billiards: 0.4050
CleanAndJerk: 0.7406
CliffDiving: 0.8010
CricketBowling: 0.4244
CricketShot: 0.1767
Diving: 0.6891
FrisbeeCatch: 0.4019
GolfSwing: 0.5575
HammerThrow: 0.8564
HighJump: 0.6124
JavelinThrow: 0.7068
LongJump: 0.7843
PoleVault: 0.8626
Shotput: 0.6703
SoccerPenalty: 0.3600
TennisSwing: 0.5522
ThrowDiscus: 0.5889
VolleyballSpiking: 0.2462
Epoch: [4]  [   0/1405]  eta: 0:38:40  lr: 0.000000  loss: 0.2212 (0.2212)  labels_encoder: 0.0986 (0.0986)  labels_decoder: 0.1227 (0.1227)  labels_encoder_unscaled: 0.0986 (0.0986)  labels_decoder_unscaled: 0.2454 (0.2454)  time: 1.6519  data: 1.4909  max mem: 3384
Epoch: [4]  [  50/1405]  eta: 0:03:50  lr: 0.000000  loss: 0.2342 (0.2372)  labels_encoder: 0.1187 (0.1178)  labels_decoder: 0.1212 (0.1194)  labels_encoder_unscaled: 0.1187 (0.1178)  labels_decoder_unscaled: 0.2425 (0.2389)  time: 0.1423  data: 0.0003  max mem: 3384
Epoch: [4]  [ 100/1405]  eta: 0:03:25  lr: 0.000000  loss: 0.2426 (0.2399)  labels_encoder: 0.1223 (0.1212)  labels_decoder: 0.1195 (0.1187)  labels_encoder_unscaled: 0.1223 (0.1212)  labels_decoder_unscaled: 0.2391 (0.2373)  time: 0.1417  data: 0.0003  max mem: 3384
Epoch: [4]  [ 150/1405]  eta: 0:03:08  lr: 0.000000  loss: 0.2345 (0.2414)  labels_encoder: 0.1076 (0.1225)  labels_decoder: 0.1090 (0.1189)  labels_encoder_unscaled: 0.1076 (0.1225)  labels_decoder_unscaled: 0.2180 (0.2378)  time: 0.1364  data: 0.0002  max mem: 3384
Epoch: [4]  [ 200/1405]  eta: 0:02:58  lr: 0.000000  loss: 0.2345 (0.2430)  labels_encoder: 0.1160 (0.1249)  labels_decoder: 0.1109 (0.1180)  labels_encoder_unscaled: 0.1160 (0.1249)  labels_decoder_unscaled: 0.2219 (0.2361)  time: 0.1397  data: 0.0002  max mem: 3384
Epoch: [4]  [ 250/1405]  eta: 0:02:47  lr: 0.000000  loss: 0.2398 (0.2451)  labels_encoder: 0.1211 (0.1262)  labels_decoder: 0.1183 (0.1188)  labels_encoder_unscaled: 0.1211 (0.1262)  labels_decoder_unscaled: 0.2365 (0.2377)  time: 0.1328  data: 0.0003  max mem: 3384
Epoch: [4]  [ 300/1405]  eta: 0:02:38  lr: 0.000000  loss: 0.2273 (0.2433)  labels_encoder: 0.1250 (0.1252)  labels_decoder: 0.1107 (0.1181)  labels_encoder_unscaled: 0.1250 (0.1252)  labels_decoder_unscaled: 0.2215 (0.2362)  time: 0.1420  data: 0.0003  max mem: 3384
Epoch: [4]  [ 350/1405]  eta: 0:02:30  lr: 0.000000  loss: 0.2388 (0.2426)  labels_encoder: 0.1153 (0.1247)  labels_decoder: 0.1192 (0.1178)  labels_encoder_unscaled: 0.1153 (0.1247)  labels_decoder_unscaled: 0.2384 (0.2357)  time: 0.1418  data: 0.0002  max mem: 3384
Epoch: [4]  [ 400/1405]  eta: 0:02:21  lr: 0.000000  loss: 0.2136 (0.2414)  labels_encoder: 0.0994 (0.1234)  labels_decoder: 0.1182 (0.1180)  labels_encoder_unscaled: 0.0994 (0.1234)  labels_decoder_unscaled: 0.2364 (0.2359)  time: 0.1316  data: 0.0002  max mem: 3384
Epoch: [4]  [ 450/1405]  eta: 0:02:13  lr: 0.000000  loss: 0.2195 (0.2393)  labels_encoder: 0.1105 (0.1221)  labels_decoder: 0.1074 (0.1172)  labels_encoder_unscaled: 0.1105 (0.1221)  labels_decoder_unscaled: 0.2149 (0.2345)  time: 0.1369  data: 0.0002  max mem: 3384
Epoch: [4]  [ 500/1405]  eta: 0:02:06  lr: 0.000000  loss: 0.2226 (0.2396)  labels_encoder: 0.1125 (0.1224)  labels_decoder: 0.1160 (0.1172)  labels_encoder_unscaled: 0.1125 (0.1224)  labels_decoder_unscaled: 0.2321 (0.2343)  time: 0.1339  data: 0.0002  max mem: 3384
Epoch: [4]  [ 550/1405]  eta: 0:01:59  lr: 0.000000  loss: 0.2107 (0.2392)  labels_encoder: 0.1070 (0.1226)  labels_decoder: 0.1058 (0.1166)  labels_encoder_unscaled: 0.1070 (0.1226)  labels_decoder_unscaled: 0.2116 (0.2332)  time: 0.1392  data: 0.0002  max mem: 3384
Epoch: [4]  [ 600/1405]  eta: 0:01:52  lr: 0.000000  loss: 0.2305 (0.2395)  labels_encoder: 0.1045 (0.1227)  labels_decoder: 0.1102 (0.1168)  labels_encoder_unscaled: 0.1045 (0.1227)  labels_decoder_unscaled: 0.2205 (0.2336)  time: 0.1381  data: 0.0002  max mem: 3384
Epoch: [4]  [ 650/1405]  eta: 0:01:44  lr: 0.000000  loss: 0.2358 (0.2392)  labels_encoder: 0.1179 (0.1224)  labels_decoder: 0.1104 (0.1167)  labels_encoder_unscaled: 0.1179 (0.1224)  labels_decoder_unscaled: 0.2208 (0.2334)  time: 0.1365  data: 0.0003  max mem: 3384
Epoch: [4]  [ 700/1405]  eta: 0:01:37  lr: 0.000000  loss: 0.2366 (0.2395)  labels_encoder: 0.1131 (0.1226)  labels_decoder: 0.1182 (0.1169)  labels_encoder_unscaled: 0.1131 (0.1226)  labels_decoder_unscaled: 0.2364 (0.2339)  time: 0.1345  data: 0.0003  max mem: 3384
Epoch: [4]  [ 750/1405]  eta: 0:01:30  lr: 0.000000  loss: 0.2135 (0.2396)  labels_encoder: 0.1172 (0.1226)  labels_decoder: 0.1170 (0.1171)  labels_encoder_unscaled: 0.1172 (0.1226)  labels_decoder_unscaled: 0.2339 (0.2341)  time: 0.1340  data: 0.0003  max mem: 3384
Epoch: [4]  [ 800/1405]  eta: 0:01:23  lr: 0.000000  loss: 0.2500 (0.2402)  labels_encoder: 0.1153 (0.1228)  labels_decoder: 0.1174 (0.1174)  labels_encoder_unscaled: 0.1153 (0.1228)  labels_decoder_unscaled: 0.2348 (0.2348)  time: 0.1331  data: 0.0002  max mem: 3384
Epoch: [4]  [ 850/1405]  eta: 0:01:16  lr: 0.000000  loss: 0.2329 (0.2397)  labels_encoder: 0.1190 (0.1225)  labels_decoder: 0.1158 (0.1172)  labels_encoder_unscaled: 0.1190 (0.1225)  labels_decoder_unscaled: 0.2317 (0.2345)  time: 0.1366  data: 0.0003  max mem: 3384
Epoch: [4]  [ 900/1405]  eta: 0:01:09  lr: 0.000000  loss: 0.2260 (0.2396)  labels_encoder: 0.1091 (0.1225)  labels_decoder: 0.1121 (0.1171)  labels_encoder_unscaled: 0.1091 (0.1225)  labels_decoder_unscaled: 0.2243 (0.2341)  time: 0.1312  data: 0.0002  max mem: 3384
Epoch: [4]  [ 950/1405]  eta: 0:01:02  lr: 0.000000  loss: 0.2399 (0.2395)  labels_encoder: 0.1188 (0.1224)  labels_decoder: 0.1143 (0.1171)  labels_encoder_unscaled: 0.1188 (0.1224)  labels_decoder_unscaled: 0.2285 (0.2342)  time: 0.1328  data: 0.0003  max mem: 3384
Epoch: [4]  [1000/1405]  eta: 0:00:55  lr: 0.000000  loss: 0.2362 (0.2399)  labels_encoder: 0.1296 (0.1229)  labels_decoder: 0.1068 (0.1170)  labels_encoder_unscaled: 0.1296 (0.1229)  labels_decoder_unscaled: 0.2136 (0.2340)  time: 0.1390  data: 0.0002  max mem: 3384
Epoch: [4]  [1050/1405]  eta: 0:00:48  lr: 0.000000  loss: 0.2334 (0.2399)  labels_encoder: 0.1165 (0.1230)  labels_decoder: 0.1172 (0.1170)  labels_encoder_unscaled: 0.1165 (0.1230)  labels_decoder_unscaled: 0.2345 (0.2340)  time: 0.1284  data: 0.0002  max mem: 3384
Epoch: [4]  [1100/1405]  eta: 0:00:41  lr: 0.000000  loss: 0.2432 (0.2404)  labels_encoder: 0.1284 (0.1233)  labels_decoder: 0.1109 (0.1170)  labels_encoder_unscaled: 0.1284 (0.1233)  labels_decoder_unscaled: 0.2217 (0.2341)  time: 0.1400  data: 0.0002  max mem: 3384
Epoch: [4]  [1150/1405]  eta: 0:00:34  lr: 0.000000  loss: 0.2310 (0.2403)  labels_encoder: 0.1166 (0.1232)  labels_decoder: 0.1134 (0.1171)  labels_encoder_unscaled: 0.1166 (0.1232)  labels_decoder_unscaled: 0.2268 (0.2341)  time: 0.1333  data: 0.0003  max mem: 3384
Epoch: [4]  [1200/1405]  eta: 0:00:28  lr: 0.000000  loss: 0.2365 (0.2401)  labels_encoder: 0.1100 (0.1231)  labels_decoder: 0.1126 (0.1170)  labels_encoder_unscaled: 0.1100 (0.1231)  labels_decoder_unscaled: 0.2253 (0.2339)  time: 0.1361  data: 0.0002  max mem: 3384
Epoch: [4]  [1250/1405]  eta: 0:00:21  lr: 0.000000  loss: 0.2159 (0.2397)  labels_encoder: 0.1037 (0.1227)  labels_decoder: 0.1201 (0.1170)  labels_encoder_unscaled: 0.1037 (0.1227)  labels_decoder_unscaled: 0.2402 (0.2340)  time: 0.1324  data: 0.0002  max mem: 3384
Epoch: [4]  [1300/1405]  eta: 0:00:14  lr: 0.000000  loss: 0.2327 (0.2399)  labels_encoder: 0.1119 (0.1228)  labels_decoder: 0.1214 (0.1171)  labels_encoder_unscaled: 0.1119 (0.1228)  labels_decoder_unscaled: 0.2428 (0.2343)  time: 0.1321  data: 0.0002  max mem: 3384
Epoch: [4]  [1350/1405]  eta: 0:00:07  lr: 0.000000  loss: 0.2259 (0.2394)  labels_encoder: 0.1162 (0.1225)  labels_decoder: 0.1055 (0.1169)  labels_encoder_unscaled: 0.1162 (0.1225)  labels_decoder_unscaled: 0.2109 (0.2338)  time: 0.1343  data: 0.0003  max mem: 3384
Epoch: [4]  [1400/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2278 (0.2391)  labels_encoder: 0.1046 (0.1223)  labels_decoder: 0.1131 (0.1168)  labels_encoder_unscaled: 0.1046 (0.1223)  labels_decoder_unscaled: 0.2262 (0.2337)  time: 0.1261  data: 0.0003  max mem: 3384
Epoch: [4]  [1404/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2293 (0.2391)  labels_encoder: 0.1075 (0.1222)  labels_decoder: 0.1171 (0.1169)  labels_encoder_unscaled: 0.1075 (0.1222)  labels_decoder_unscaled: 0.2342 (0.2337)  time: 0.1207  data: 0.0003  max mem: 3384
Epoch: [4] Total time: 0:03:12 (0.1369 s / it)
Averaged stats: lr: 0.000000  loss: 0.2293 (0.2391)  labels_encoder: 0.1075 (0.1222)  labels_decoder: 0.1171 (0.1169)  labels_encoder_unscaled: 0.1075 (0.1222)  labels_decoder_unscaled: 0.2342 (0.2337)
Test:  [   0/1613]  eta: 0:42:21  loss: 0.4714 (0.4714)  labels_encoder: 0.2828 (0.2828)  labels_decoder: 0.1886 (0.1886)  labels_encoder_unscaled: 0.2828 (0.2828)  labels_decoder_unscaled: 0.3771 (0.3771)  time: 1.5757  data: 1.5058  max mem: 3384
Test:  [  50/1613]  eta: 0:02:28  loss: 0.4637 (1.0695)  labels_encoder: 0.2849 (0.6960)  labels_decoder: 0.2301 (0.3735)  labels_encoder_unscaled: 0.2849 (0.6960)  labels_decoder_unscaled: 0.4602 (0.7470)  time: 0.0623  data: 0.0002  max mem: 3384
Test:  [ 100/1613]  eta: 0:01:55  loss: 0.2703 (0.8125)  labels_encoder: 0.1806 (0.5260)  labels_decoder: 0.0616 (0.2864)  labels_encoder_unscaled: 0.1806 (0.5260)  labels_decoder_unscaled: 0.1233 (0.5729)  time: 0.0576  data: 0.0002  max mem: 3384
Test:  [ 150/1613]  eta: 0:01:44  loss: 0.8528 (0.7780)  labels_encoder: 0.5272 (0.4982)  labels_decoder: 0.3153 (0.2798)  labels_encoder_unscaled: 0.5272 (0.4982)  labels_decoder_unscaled: 0.6306 (0.5595)  time: 0.0627  data: 0.0002  max mem: 3384
Test:  [ 200/1613]  eta: 0:01:38  loss: 0.9989 (0.9520)  labels_encoder: 0.6346 (0.6183)  labels_decoder: 0.3693 (0.3337)  labels_encoder_unscaled: 0.6346 (0.6183)  labels_decoder_unscaled: 0.7386 (0.6674)  time: 0.0653  data: 0.0002  max mem: 3384
Test:  [ 250/1613]  eta: 0:01:35  loss: 0.7140 (0.9948)  labels_encoder: 0.3650 (0.6427)  labels_decoder: 0.2625 (0.3522)  labels_encoder_unscaled: 0.3650 (0.6427)  labels_decoder_unscaled: 0.5250 (0.7044)  time: 0.0693  data: 0.0002  max mem: 3384
Test:  [ 300/1613]  eta: 0:01:32  loss: 0.5388 (1.0105)  labels_encoder: 0.3019 (0.6551)  labels_decoder: 0.2111 (0.3554)  labels_encoder_unscaled: 0.3019 (0.6551)  labels_decoder_unscaled: 0.4222 (0.7109)  time: 0.0775  data: 0.0002  max mem: 3384
Test:  [ 350/1613]  eta: 0:01:28  loss: 1.0165 (1.0055)  labels_encoder: 0.6275 (0.6465)  labels_decoder: 0.4491 (0.3590)  labels_encoder_unscaled: 0.6275 (0.6465)  labels_decoder_unscaled: 0.8982 (0.7179)  time: 0.0716  data: 0.0002  max mem: 3384
Test:  [ 400/1613]  eta: 0:01:24  loss: 0.7509 (1.1526)  labels_encoder: 0.4144 (0.7536)  labels_decoder: 0.3292 (0.3991)  labels_encoder_unscaled: 0.4144 (0.7536)  labels_decoder_unscaled: 0.6584 (0.7982)  time: 0.0607  data: 0.0002  max mem: 3384
Test:  [ 450/1613]  eta: 0:01:20  loss: 0.7985 (1.2330)  labels_encoder: 0.5196 (0.8080)  labels_decoder: 0.2886 (0.4249)  labels_encoder_unscaled: 0.5196 (0.8080)  labels_decoder_unscaled: 0.5772 (0.8499)  time: 0.0641  data: 0.0002  max mem: 3384
Test:  [ 500/1613]  eta: 0:01:17  loss: 0.3666 (1.1759)  labels_encoder: 0.1917 (0.7677)  labels_decoder: 0.1749 (0.4082)  labels_encoder_unscaled: 0.1917 (0.7677)  labels_decoder_unscaled: 0.3499 (0.8164)  time: 0.0734  data: 0.0002  max mem: 3384
Test:  [ 550/1613]  eta: 0:01:14  loss: 0.9533 (1.1756)  labels_encoder: 0.6218 (0.7649)  labels_decoder: 0.3830 (0.4107)  labels_encoder_unscaled: 0.6218 (0.7649)  labels_decoder_unscaled: 0.7659 (0.8214)  time: 0.0643  data: 0.0002  max mem: 3384
Test:  [ 600/1613]  eta: 0:01:10  loss: 2.0347 (1.2162)  labels_encoder: 1.2753 (0.7983)  labels_decoder: 0.4870 (0.4178)  labels_encoder_unscaled: 1.2753 (0.7983)  labels_decoder_unscaled: 0.9740 (0.8357)  time: 0.0743  data: 0.0002  max mem: 3384
Test:  [ 650/1613]  eta: 0:01:06  loss: 0.7465 (1.2005)  labels_encoder: 0.3381 (0.7827)  labels_decoder: 0.3690 (0.4178)  labels_encoder_unscaled: 0.3381 (0.7827)  labels_decoder_unscaled: 0.7379 (0.8355)  time: 0.0669  data: 0.0002  max mem: 3384
Test:  [ 700/1613]  eta: 0:01:03  loss: 0.5165 (1.1713)  labels_encoder: 0.3175 (0.7628)  labels_decoder: 0.2121 (0.4085)  labels_encoder_unscaled: 0.3175 (0.7628)  labels_decoder_unscaled: 0.4242 (0.8170)  time: 0.0684  data: 0.0002  max mem: 3384
Test:  [ 750/1613]  eta: 0:00:59  loss: 0.6767 (1.1461)  labels_encoder: 0.3572 (0.7455)  labels_decoder: 0.2734 (0.4006)  labels_encoder_unscaled: 0.3572 (0.7455)  labels_decoder_unscaled: 0.5468 (0.8012)  time: 0.0659  data: 0.0002  max mem: 3384
Test:  [ 800/1613]  eta: 0:00:56  loss: 1.0069 (1.1409)  labels_encoder: 0.5760 (0.7429)  labels_decoder: 0.3815 (0.3980)  labels_encoder_unscaled: 0.5760 (0.7429)  labels_decoder_unscaled: 0.7631 (0.7960)  time: 0.1057  data: 0.0002  max mem: 3384
Test:  [ 850/1613]  eta: 0:00:53  loss: 2.0263 (1.1497)  labels_encoder: 1.4312 (0.7474)  labels_decoder: 0.6195 (0.4022)  labels_encoder_unscaled: 1.4312 (0.7474)  labels_decoder_unscaled: 1.2389 (0.8045)  time: 0.0663  data: 0.0001  max mem: 3384
Test:  [ 900/1613]  eta: 0:00:49  loss: 0.9289 (1.1749)  labels_encoder: 0.4986 (0.7652)  labels_decoder: 0.3403 (0.4097)  labels_encoder_unscaled: 0.4986 (0.7652)  labels_decoder_unscaled: 0.6807 (0.8194)  time: 0.0611  data: 0.0001  max mem: 3384
Test:  [ 950/1613]  eta: 0:00:45  loss: 0.8945 (1.1638)  labels_encoder: 0.5406 (0.7574)  labels_decoder: 0.3079 (0.4063)  labels_encoder_unscaled: 0.5406 (0.7574)  labels_decoder_unscaled: 0.6157 (0.8127)  time: 0.0629  data: 0.0002  max mem: 3384
Test:  [1000/1613]  eta: 0:00:41  loss: 0.4840 (1.1447)  labels_encoder: 0.2724 (0.7441)  labels_decoder: 0.2170 (0.4006)  labels_encoder_unscaled: 0.2724 (0.7441)  labels_decoder_unscaled: 0.4339 (0.8012)  time: 0.0636  data: 0.0002  max mem: 3384
Test:  [1050/1613]  eta: 0:00:38  loss: 0.9112 (1.1381)  labels_encoder: 0.5366 (0.7402)  labels_decoder: 0.3063 (0.3979)  labels_encoder_unscaled: 0.5366 (0.7402)  labels_decoder_unscaled: 0.6125 (0.7958)  time: 0.0718  data: 0.0002  max mem: 3384
Test:  [1100/1613]  eta: 0:00:35  loss: 0.7766 (1.1403)  labels_encoder: 0.5046 (0.7421)  labels_decoder: 0.3629 (0.3982)  labels_encoder_unscaled: 0.5046 (0.7421)  labels_decoder_unscaled: 0.7258 (0.7964)  time: 0.0639  data: 0.0002  max mem: 3384
Test:  [1150/1613]  eta: 0:00:31  loss: 0.8068 (1.1296)  labels_encoder: 0.4587 (0.7347)  labels_decoder: 0.3127 (0.3949)  labels_encoder_unscaled: 0.4587 (0.7347)  labels_decoder_unscaled: 0.6253 (0.7898)  time: 0.0661  data: 0.0002  max mem: 3384
Test:  [1200/1613]  eta: 0:00:28  loss: 0.5695 (1.1347)  labels_encoder: 0.3470 (0.7372)  labels_decoder: 0.2279 (0.3975)  labels_encoder_unscaled: 0.3470 (0.7372)  labels_decoder_unscaled: 0.4558 (0.7950)  time: 0.0666  data: 0.0002  max mem: 3384
Test:  [1250/1613]  eta: 0:00:24  loss: 0.4836 (1.1336)  labels_encoder: 0.2866 (0.7362)  labels_decoder: 0.1895 (0.3974)  labels_encoder_unscaled: 0.2866 (0.7362)  labels_decoder_unscaled: 0.3789 (0.7948)  time: 0.0675  data: 0.0002  max mem: 3384
Test:  [1300/1613]  eta: 0:00:21  loss: 0.5580 (1.1231)  labels_encoder: 0.3626 (0.7290)  labels_decoder: 0.2211 (0.3942)  labels_encoder_unscaled: 0.3626 (0.7290)  labels_decoder_unscaled: 0.4422 (0.7884)  time: 0.0574  data: 0.0001  max mem: 3384
Test:  [1350/1613]  eta: 0:00:18  loss: 0.7939 (1.1388)  labels_encoder: 0.4912 (0.7400)  labels_decoder: 0.3335 (0.3988)  labels_encoder_unscaled: 0.4912 (0.7400)  labels_decoder_unscaled: 0.6670 (0.7977)  time: 0.0627  data: 0.0001  max mem: 3384
Test:  [1400/1613]  eta: 0:00:14  loss: 1.0958 (1.1366)  labels_encoder: 0.7015 (0.7382)  labels_decoder: 0.4023 (0.3984)  labels_encoder_unscaled: 0.7015 (0.7382)  labels_decoder_unscaled: 0.8046 (0.7968)  time: 0.0625  data: 0.0001  max mem: 3384
Test:  [1450/1613]  eta: 0:00:11  loss: 0.6290 (1.1498)  labels_encoder: 0.3357 (0.7459)  labels_decoder: 0.3252 (0.4038)  labels_encoder_unscaled: 0.3357 (0.7459)  labels_decoder_unscaled: 0.6505 (0.8077)  time: 0.0586  data: 0.0002  max mem: 3384
Test:  [1500/1613]  eta: 0:00:07  loss: 0.6551 (1.1640)  labels_encoder: 0.4182 (0.7559)  labels_decoder: 0.2716 (0.4081)  labels_encoder_unscaled: 0.4182 (0.7559)  labels_decoder_unscaled: 0.5431 (0.8162)  time: 0.0668  data: 0.0002  max mem: 3384
Test:  [1550/1613]  eta: 0:00:04  loss: 0.7924 (1.1603)  labels_encoder: 0.4336 (0.7544)  labels_decoder: 0.2950 (0.4060)  labels_encoder_unscaled: 0.4336 (0.7544)  labels_decoder_unscaled: 0.5899 (0.8119)  time: 0.0616  data: 0.0008  max mem: 3384
Test:  [1600/1613]  eta: 0:00:00  loss: 0.9718 (1.1526)  labels_encoder: 0.5940 (0.7487)  labels_decoder: 0.3593 (0.4039)  labels_encoder_unscaled: 0.5940 (0.7487)  labels_decoder_unscaled: 0.7187 (0.8078)  time: 0.0603  data: 0.0001  max mem: 3384
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8087 (1.1502)  labels_encoder: 0.4743 (0.7474)  labels_decoder: 0.3344 (0.4028)  labels_encoder_unscaled: 0.4743 (0.7474)  labels_decoder_unscaled: 0.6688 (0.8055)  time: 0.0509  data: 0.0001  max mem: 3384
Test: Total time: 0:01:48 (0.0676 s / it)
Averaged stats: loss: 0.8087 (1.1502)  labels_encoder: 0.4743 (0.7474)  labels_decoder: 0.3344 (0.4028)  labels_encoder_unscaled: 0.4743 (0.7474)  labels_decoder_unscaled: 0.6688 (0.8055)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet] mAP: 0.5708

dec_mAP all together: | 0.44950609406921416 |.
dec_mAP_pred | 0 : 0.4923218817876266 |.
dec_mAP_pred | 1 : 0.4843541789805183 |.
dec_mAP_pred | 2 : 0.472358011161751 |.
dec_mAP_pred | 3 : 0.4587990760111126 |.
dec_mAP_pred | 4 : 0.44431266183630036 |.
dec_mAP_pred | 5 : 0.43029168806463003 |.
dec_mAP_pred | 6 : 0.41637695745585557 |.
dec_mAP_pred | 7 : 0.4035473323360189 |.
all decoder map: | 0.4503 |.
BaseballPitch: 0.2146
BasketballDunk: 0.7646
Billiards: 0.4048
CleanAndJerk: 0.7423
CliffDiving: 0.8008
CricketBowling: 0.4245
CricketShot: 0.1763
Diving: 0.6883
FrisbeeCatch: 0.4031
GolfSwing: 0.5595
HammerThrow: 0.8560
HighJump: 0.6117
JavelinThrow: 0.7052
LongJump: 0.7822
PoleVault: 0.8628
Shotput: 0.6708
SoccerPenalty: 0.3567
TennisSwing: 0.5534
ThrowDiscus: 0.5904
VolleyballSpiking: 0.2478
Training time 0:22:17
