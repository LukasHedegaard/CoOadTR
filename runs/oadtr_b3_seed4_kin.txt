Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:kin
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:4
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  75.627 M, 99.827% Params, 2.513 GMac, 100.000% MACs, 
  (linear_encoding): Linear(4.195 M, 5.538% Params, 0.268 GMac, 10.682% MACs, in_features=4096, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 24.926% Params, 1.227 GMac, 48.829% MACs, 
    (net): Sequential(
      18.884 M, 24.926% Params, 1.227 GMac, 48.829% MACs, 
      (0): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.060% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 69.274% Params, 1.017 GMac, 40.480% MACs, 
    (layers): ModuleList(
      52.48 M, 69.274% Params, 1.017 GMac, 40.480% MACs, 
      (0): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.030% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2512946220.0
Model params: 75757612
Loaded data/thumos_kin_val.pickle
Loaded data/thumos_kin_test.pickle
Start training
Epoch: [1]  [   0/1404]  eta: 1:22:53  lr: 0.000100  loss: 4.8791 (4.8791)  labels_encoder: 3.4210 (3.4210)  labels_decoder: 1.4581 (1.4581)  labels_encoder_unscaled: 3.4210 (3.4210)  labels_decoder_unscaled: 2.9163 (2.9163)  time: 3.5427  data: 2.3418  max mem: 2596
Epoch: [1]  [  50/1404]  eta: 0:04:46  lr: 0.000100  loss: 1.0080 (1.5043)  labels_encoder: 0.6184 (0.9809)  labels_decoder: 0.3797 (0.5234)  labels_encoder_unscaled: 0.6184 (0.9809)  labels_decoder_unscaled: 0.7594 (1.0468)  time: 0.1393  data: 0.0003  max mem: 3463
Epoch: [1]  [ 100/1404]  eta: 0:03:50  lr: 0.000100  loss: 0.6583 (1.1376)  labels_encoder: 0.4095 (0.7325)  labels_decoder: 0.2690 (0.4051)  labels_encoder_unscaled: 0.4095 (0.7325)  labels_decoder_unscaled: 0.5380 (0.8101)  time: 0.1414  data: 0.0003  max mem: 3463
Epoch: [1]  [ 150/1404]  eta: 0:03:29  lr: 0.000100  loss: 0.6471 (0.9804)  labels_encoder: 0.3938 (0.6230)  labels_decoder: 0.2597 (0.3574)  labels_encoder_unscaled: 0.3938 (0.6230)  labels_decoder_unscaled: 0.5195 (0.7148)  time: 0.1476  data: 0.0003  max mem: 3463
Epoch: [1]  [ 200/1404]  eta: 0:03:15  lr: 0.000100  loss: 0.5373 (0.8870)  labels_encoder: 0.3169 (0.5593)  labels_decoder: 0.2287 (0.3277)  labels_encoder_unscaled: 0.3169 (0.5593)  labels_decoder_unscaled: 0.4573 (0.6554)  time: 0.1472  data: 0.0003  max mem: 3463
Epoch: [1]  [ 250/1404]  eta: 0:03:03  lr: 0.000100  loss: 0.5544 (0.8260)  labels_encoder: 0.3404 (0.5184)  labels_decoder: 0.2111 (0.3075)  labels_encoder_unscaled: 0.3404 (0.5184)  labels_decoder_unscaled: 0.4222 (0.6151)  time: 0.1449  data: 0.0003  max mem: 3463
Epoch: [1]  [ 300/1404]  eta: 0:02:53  lr: 0.000100  loss: 0.5678 (0.7828)  labels_encoder: 0.3276 (0.4890)  labels_decoder: 0.2246 (0.2938)  labels_encoder_unscaled: 0.3276 (0.4890)  labels_decoder_unscaled: 0.4491 (0.5876)  time: 0.1502  data: 0.0003  max mem: 3463
Epoch: [1]  [ 350/1404]  eta: 0:02:44  lr: 0.000100  loss: 0.5309 (0.7494)  labels_encoder: 0.3425 (0.4668)  labels_decoder: 0.2121 (0.2826)  labels_encoder_unscaled: 0.3425 (0.4668)  labels_decoder_unscaled: 0.4242 (0.5653)  time: 0.1466  data: 0.0003  max mem: 3463
Epoch: [1]  [ 400/1404]  eta: 0:02:36  lr: 0.000100  loss: 0.5182 (0.7238)  labels_encoder: 0.3027 (0.4495)  labels_decoder: 0.2205 (0.2744)  labels_encoder_unscaled: 0.3027 (0.4495)  labels_decoder_unscaled: 0.4409 (0.5487)  time: 0.1658  data: 0.0003  max mem: 3463
Epoch: [1]  [ 450/1404]  eta: 0:02:28  lr: 0.000100  loss: 0.4826 (0.6981)  labels_encoder: 0.2699 (0.4319)  labels_decoder: 0.2060 (0.2663)  labels_encoder_unscaled: 0.2699 (0.4319)  labels_decoder_unscaled: 0.4119 (0.5326)  time: 0.1499  data: 0.0003  max mem: 3463
Epoch: [1]  [ 500/1404]  eta: 0:02:20  lr: 0.000100  loss: 0.4936 (0.6791)  labels_encoder: 0.2873 (0.4192)  labels_decoder: 0.1917 (0.2599)  labels_encoder_unscaled: 0.2873 (0.4192)  labels_decoder_unscaled: 0.3834 (0.5197)  time: 0.1524  data: 0.0003  max mem: 3463
Epoch: [1]  [ 550/1404]  eta: 0:02:11  lr: 0.000100  loss: 0.4363 (0.6615)  labels_encoder: 0.2576 (0.4071)  labels_decoder: 0.1920 (0.2544)  labels_encoder_unscaled: 0.2576 (0.4071)  labels_decoder_unscaled: 0.3840 (0.5088)  time: 0.1512  data: 0.0003  max mem: 3463
Epoch: [1]  [ 600/1404]  eta: 0:02:03  lr: 0.000100  loss: 0.4493 (0.6461)  labels_encoder: 0.2713 (0.3966)  labels_decoder: 0.1792 (0.2495)  labels_encoder_unscaled: 0.2713 (0.3966)  labels_decoder_unscaled: 0.3584 (0.4989)  time: 0.1524  data: 0.0003  max mem: 3463
Epoch: [1]  [ 650/1404]  eta: 0:01:56  lr: 0.000100  loss: 0.4793 (0.6326)  labels_encoder: 0.2902 (0.3876)  labels_decoder: 0.1891 (0.2450)  labels_encoder_unscaled: 0.2902 (0.3876)  labels_decoder_unscaled: 0.3783 (0.4900)  time: 0.1519  data: 0.0003  max mem: 3463
Epoch: [1]  [ 700/1404]  eta: 0:01:48  lr: 0.000100  loss: 0.4504 (0.6206)  labels_encoder: 0.2511 (0.3795)  labels_decoder: 0.1927 (0.2411)  labels_encoder_unscaled: 0.2511 (0.3795)  labels_decoder_unscaled: 0.3854 (0.4822)  time: 0.1520  data: 0.0003  max mem: 3463
Epoch: [1]  [ 750/1404]  eta: 0:01:40  lr: 0.000100  loss: 0.4366 (0.6095)  labels_encoder: 0.2564 (0.3720)  labels_decoder: 0.1864 (0.2375)  labels_encoder_unscaled: 0.2564 (0.3720)  labels_decoder_unscaled: 0.3728 (0.4750)  time: 0.1477  data: 0.0003  max mem: 3463
Epoch: [1]  [ 800/1404]  eta: 0:01:32  lr: 0.000100  loss: 0.4090 (0.5989)  labels_encoder: 0.2362 (0.3649)  labels_decoder: 0.1867 (0.2341)  labels_encoder_unscaled: 0.2362 (0.3649)  labels_decoder_unscaled: 0.3735 (0.4681)  time: 0.1526  data: 0.0003  max mem: 3463
Epoch: [1]  [ 850/1404]  eta: 0:01:24  lr: 0.000100  loss: 0.4079 (0.5889)  labels_encoder: 0.2377 (0.3580)  labels_decoder: 0.1757 (0.2309)  labels_encoder_unscaled: 0.2377 (0.3580)  labels_decoder_unscaled: 0.3515 (0.4619)  time: 0.1534  data: 0.0003  max mem: 3463
Epoch: [1]  [ 900/1404]  eta: 0:01:17  lr: 0.000100  loss: 0.4060 (0.5795)  labels_encoder: 0.2317 (0.3515)  labels_decoder: 0.1716 (0.2280)  labels_encoder_unscaled: 0.2317 (0.3515)  labels_decoder_unscaled: 0.3432 (0.4560)  time: 0.1525  data: 0.0003  max mem: 3463
Epoch: [1]  [ 950/1404]  eta: 0:01:09  lr: 0.000100  loss: 0.4172 (0.5708)  labels_encoder: 0.2286 (0.3456)  labels_decoder: 0.1751 (0.2252)  labels_encoder_unscaled: 0.2286 (0.3456)  labels_decoder_unscaled: 0.3502 (0.4504)  time: 0.1529  data: 0.0003  max mem: 3463
Epoch: [1]  [1000/1404]  eta: 0:01:01  lr: 0.000100  loss: 0.3754 (0.5615)  labels_encoder: 0.2085 (0.3390)  labels_decoder: 0.1665 (0.2224)  labels_encoder_unscaled: 0.2085 (0.3390)  labels_decoder_unscaled: 0.3330 (0.4449)  time: 0.1510  data: 0.0003  max mem: 3463
Epoch: [1]  [1050/1404]  eta: 0:00:54  lr: 0.000100  loss: 0.3707 (0.5537)  labels_encoder: 0.2227 (0.3338)  labels_decoder: 0.1529 (0.2200)  labels_encoder_unscaled: 0.2227 (0.3338)  labels_decoder_unscaled: 0.3059 (0.4399)  time: 0.1510  data: 0.0003  max mem: 3463
Epoch: [1]  [1100/1404]  eta: 0:00:46  lr: 0.000100  loss: 0.4234 (0.5474)  labels_encoder: 0.2455 (0.3295)  labels_decoder: 0.1808 (0.2179)  labels_encoder_unscaled: 0.2455 (0.3295)  labels_decoder_unscaled: 0.3615 (0.4358)  time: 0.1506  data: 0.0003  max mem: 3463
Epoch: [1]  [1150/1404]  eta: 0:00:38  lr: 0.000100  loss: 0.3992 (0.5405)  labels_encoder: 0.2219 (0.3247)  labels_decoder: 0.1690 (0.2157)  labels_encoder_unscaled: 0.2219 (0.3247)  labels_decoder_unscaled: 0.3379 (0.4315)  time: 0.1512  data: 0.0003  max mem: 3463
Epoch: [1]  [1200/1404]  eta: 0:00:31  lr: 0.000100  loss: 0.3589 (0.5336)  labels_encoder: 0.2062 (0.3202)  labels_decoder: 0.1581 (0.2134)  labels_encoder_unscaled: 0.2062 (0.3202)  labels_decoder_unscaled: 0.3162 (0.4267)  time: 0.1495  data: 0.0003  max mem: 3463
Epoch: [1]  [1250/1404]  eta: 0:00:23  lr: 0.000100  loss: 0.3785 (0.5279)  labels_encoder: 0.2133 (0.3162)  labels_decoder: 0.1644 (0.2117)  labels_encoder_unscaled: 0.2133 (0.3162)  labels_decoder_unscaled: 0.3289 (0.4234)  time: 0.1515  data: 0.0003  max mem: 3463
Epoch: [1]  [1300/1404]  eta: 0:00:15  lr: 0.000100  loss: 0.3568 (0.5219)  labels_encoder: 0.1977 (0.3122)  labels_decoder: 0.1629 (0.2098)  labels_encoder_unscaled: 0.1977 (0.3122)  labels_decoder_unscaled: 0.3258 (0.4195)  time: 0.1492  data: 0.0003  max mem: 3463
Epoch: [1]  [1350/1404]  eta: 0:00:08  lr: 0.000100  loss: 0.3486 (0.5160)  labels_encoder: 0.1876 (0.3082)  labels_decoder: 0.1498 (0.2078)  labels_encoder_unscaled: 0.1876 (0.3082)  labels_decoder_unscaled: 0.2995 (0.4157)  time: 0.1602  data: 0.0003  max mem: 3463
Epoch: [1]  [1400/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.4073 (0.5111)  labels_encoder: 0.2397 (0.3047)  labels_decoder: 0.1656 (0.2063)  labels_encoder_unscaled: 0.2397 (0.3047)  labels_decoder_unscaled: 0.3311 (0.4126)  time: 0.1435  data: 0.0004  max mem: 3463
Epoch: [1]  [1403/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3987 (0.5107)  labels_encoder: 0.2332 (0.3045)  labels_decoder: 0.1655 (0.2062)  labels_encoder_unscaled: 0.2332 (0.3045)  labels_decoder_unscaled: 0.3311 (0.4124)  time: 0.1388  data: 0.0003  max mem: 3463
Epoch: [1] Total time: 0:03:35 (0.1532 s / it)
Averaged stats: lr: 0.000100  loss: 0.3987 (0.5107)  labels_encoder: 0.2332 (0.3045)  labels_decoder: 0.1655 (0.2062)  labels_encoder_unscaled: 0.2332 (0.3045)  labels_decoder_unscaled: 0.3311 (0.4124)
Test:  [   0/1613]  eta: 0:42:27  loss: 2.5957 (2.5957)  labels_encoder: 1.7367 (1.7367)  labels_decoder: 0.8591 (0.8591)  labels_encoder_unscaled: 1.7367 (1.7367)  labels_decoder_unscaled: 1.7182 (1.7182)  time: 1.5792  data: 1.4806  max mem: 3463
Test:  [  50/1613]  eta: 0:03:00  loss: 0.4626 (0.8920)  labels_encoder: 0.2147 (0.5524)  labels_decoder: 0.2394 (0.3396)  labels_encoder_unscaled: 0.2147 (0.5524)  labels_decoder_unscaled: 0.4789 (0.6791)  time: 0.0765  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:24  loss: 0.6235 (0.7837)  labels_encoder: 0.3232 (0.5145)  labels_decoder: 0.1219 (0.2692)  labels_encoder_unscaled: 0.3232 (0.5145)  labels_decoder_unscaled: 0.2437 (0.5384)  time: 0.0744  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:02:09  loss: 0.5784 (0.7405)  labels_encoder: 0.4885 (0.4854)  labels_decoder: 0.0843 (0.2552)  labels_encoder_unscaled: 0.4885 (0.4854)  labels_decoder_unscaled: 0.1686 (0.5103)  time: 0.0744  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:59  loss: 0.9247 (0.8010)  labels_encoder: 0.5450 (0.5185)  labels_decoder: 0.3681 (0.2825)  labels_encoder_unscaled: 0.5450 (0.5185)  labels_decoder_unscaled: 0.7361 (0.5649)  time: 0.0779  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:51  loss: 0.6558 (0.8660)  labels_encoder: 0.3230 (0.5535)  labels_decoder: 0.4008 (0.3126)  labels_encoder_unscaled: 0.3230 (0.5535)  labels_decoder_unscaled: 0.8016 (0.6252)  time: 0.0698  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:45  loss: 0.6352 (0.8628)  labels_encoder: 0.3476 (0.5489)  labels_decoder: 0.2712 (0.3139)  labels_encoder_unscaled: 0.3476 (0.5489)  labels_decoder_unscaled: 0.5425 (0.6278)  time: 0.0835  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:40  loss: 1.0099 (0.9008)  labels_encoder: 0.5245 (0.5789)  labels_decoder: 0.4675 (0.3219)  labels_encoder_unscaled: 0.5245 (0.5789)  labels_decoder_unscaled: 0.9350 (0.6439)  time: 0.0739  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:35  loss: 0.6852 (0.9574)  labels_encoder: 0.4117 (0.6181)  labels_decoder: 0.2927 (0.3393)  labels_encoder_unscaled: 0.4117 (0.6181)  labels_decoder_unscaled: 0.5854 (0.6785)  time: 0.0769  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:31  loss: 0.7735 (1.0258)  labels_encoder: 0.5530 (0.6661)  labels_decoder: 0.2745 (0.3598)  labels_encoder_unscaled: 0.5530 (0.6661)  labels_decoder_unscaled: 0.5489 (0.7196)  time: 0.0715  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:26  loss: 0.4339 (0.9950)  labels_encoder: 0.2232 (0.6429)  labels_decoder: 0.2496 (0.3522)  labels_encoder_unscaled: 0.2232 (0.6429)  labels_decoder_unscaled: 0.4993 (0.7043)  time: 0.0759  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:22  loss: 0.8046 (0.9832)  labels_encoder: 0.5851 (0.6371)  labels_decoder: 0.2195 (0.3461)  labels_encoder_unscaled: 0.5851 (0.6371)  labels_decoder_unscaled: 0.4389 (0.6923)  time: 0.0740  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:18  loss: 0.5589 (1.0978)  labels_encoder: 0.3300 (0.7285)  labels_decoder: 0.1936 (0.3694)  labels_encoder_unscaled: 0.3300 (0.7285)  labels_decoder_unscaled: 0.3873 (0.7387)  time: 0.0739  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:14  loss: 1.6316 (1.1073)  labels_encoder: 0.9355 (0.7312)  labels_decoder: 0.6532 (0.3761)  labels_encoder_unscaled: 0.9355 (0.7312)  labels_decoder_unscaled: 1.3065 (0.7522)  time: 0.0796  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:01:10  loss: 0.4469 (1.0774)  labels_encoder: 0.2807 (0.7098)  labels_decoder: 0.1940 (0.3676)  labels_encoder_unscaled: 0.2807 (0.7098)  labels_decoder_unscaled: 0.3880 (0.7352)  time: 0.0679  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:01:05  loss: 0.6436 (1.0552)  labels_encoder: 0.3194 (0.6920)  labels_decoder: 0.3352 (0.3632)  labels_encoder_unscaled: 0.3194 (0.6920)  labels_decoder_unscaled: 0.6704 (0.7264)  time: 0.0672  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:01:02  loss: 0.7472 (1.0442)  labels_encoder: 0.3925 (0.6835)  labels_decoder: 0.3548 (0.3607)  labels_encoder_unscaled: 0.3925 (0.6835)  labels_decoder_unscaled: 0.7096 (0.7213)  time: 0.0773  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:58  loss: 0.9735 (1.0449)  labels_encoder: 0.6590 (0.6809)  labels_decoder: 0.3543 (0.3640)  labels_encoder_unscaled: 0.6590 (0.6809)  labels_decoder_unscaled: 0.7087 (0.7280)  time: 0.0688  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:54  loss: 0.6648 (1.0265)  labels_encoder: 0.3677 (0.6669)  labels_decoder: 0.2727 (0.3596)  labels_encoder_unscaled: 0.3677 (0.6669)  labels_decoder_unscaled: 0.5453 (0.7192)  time: 0.0746  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:50  loss: 1.3145 (1.0325)  labels_encoder: 0.8636 (0.6692)  labels_decoder: 0.4570 (0.3633)  labels_encoder_unscaled: 0.8636 (0.6692)  labels_decoder_unscaled: 0.9140 (0.7265)  time: 0.0635  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:46  loss: 0.8302 (1.0229)  labels_encoder: 0.5082 (0.6632)  labels_decoder: 0.2890 (0.3597)  labels_encoder_unscaled: 0.5082 (0.6632)  labels_decoder_unscaled: 0.5781 (0.7194)  time: 0.0646  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:42  loss: 0.9858 (1.0382)  labels_encoder: 0.6415 (0.6746)  labels_decoder: 0.3907 (0.3636)  labels_encoder_unscaled: 0.6415 (0.6746)  labels_decoder_unscaled: 0.7815 (0.7272)  time: 0.0664  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:38  loss: 0.3983 (1.0410)  labels_encoder: 0.2938 (0.6774)  labels_decoder: 0.2194 (0.3636)  labels_encoder_unscaled: 0.2938 (0.6774)  labels_decoder_unscaled: 0.4388 (0.7272)  time: 0.0574  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:34  loss: 0.8055 (1.0361)  labels_encoder: 0.4816 (0.6749)  labels_decoder: 0.3150 (0.3611)  labels_encoder_unscaled: 0.4816 (0.6749)  labels_decoder_unscaled: 0.6300 (0.7223)  time: 0.0609  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:30  loss: 0.6213 (1.0485)  labels_encoder: 0.3705 (0.6838)  labels_decoder: 0.2422 (0.3647)  labels_encoder_unscaled: 0.3705 (0.6838)  labels_decoder_unscaled: 0.4843 (0.7295)  time: 0.0537  data: 0.0001  max mem: 3463
Test:  [1250/1613]  eta: 0:00:26  loss: 0.4752 (1.0431)  labels_encoder: 0.2939 (0.6801)  labels_decoder: 0.2257 (0.3630)  labels_encoder_unscaled: 0.2939 (0.6801)  labels_decoder_unscaled: 0.4514 (0.7260)  time: 0.0628  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:22  loss: 0.5366 (1.0319)  labels_encoder: 0.3336 (0.6708)  labels_decoder: 0.2946 (0.3612)  labels_encoder_unscaled: 0.3336 (0.6708)  labels_decoder_unscaled: 0.5892 (0.7223)  time: 0.0652  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:18  loss: 1.0985 (1.0396)  labels_encoder: 0.7526 (0.6757)  labels_decoder: 0.3525 (0.3640)  labels_encoder_unscaled: 0.7526 (0.6757)  labels_decoder_unscaled: 0.7049 (0.7279)  time: 0.0699  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:15  loss: 0.7314 (1.0334)  labels_encoder: 0.4322 (0.6711)  labels_decoder: 0.2974 (0.3623)  labels_encoder_unscaled: 0.4322 (0.6711)  labels_decoder_unscaled: 0.5948 (0.7246)  time: 0.0663  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:11  loss: 0.5565 (1.0367)  labels_encoder: 0.3438 (0.6736)  labels_decoder: 0.2823 (0.3631)  labels_encoder_unscaled: 0.3438 (0.6736)  labels_decoder_unscaled: 0.5645 (0.7262)  time: 0.0641  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:08  loss: 0.5065 (1.0317)  labels_encoder: 0.3410 (0.6719)  labels_decoder: 0.1673 (0.3598)  labels_encoder_unscaled: 0.3410 (0.6719)  labels_decoder_unscaled: 0.3346 (0.7196)  time: 0.0608  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:04  loss: 0.9423 (1.0296)  labels_encoder: 0.6595 (0.6710)  labels_decoder: 0.3055 (0.3586)  labels_encoder_unscaled: 0.6595 (0.6710)  labels_decoder_unscaled: 0.6110 (0.7172)  time: 0.0649  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.7311 (1.0230)  labels_encoder: 0.4719 (0.6662)  labels_decoder: 0.2403 (0.3569)  labels_encoder_unscaled: 0.4719 (0.6662)  labels_decoder_unscaled: 0.4806 (0.7137)  time: 0.0671  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.4667 (1.0211)  labels_encoder: 0.2860 (0.6653)  labels_decoder: 0.1535 (0.3559)  labels_encoder_unscaled: 0.2860 (0.6653)  labels_decoder_unscaled: 0.3071 (0.7117)  time: 0.0551  data: 0.0001  max mem: 3463
Test: Total time: 0:01:54 (0.0713 s / it)
Averaged stats: loss: 0.4667 (1.0211)  labels_encoder: 0.2860 (0.6653)  labels_decoder: 0.1535 (0.3559)  labels_encoder_unscaled: 0.2860 (0.6653)  labels_decoder_unscaled: 0.3071 (0.7117)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-kin] mAP: 0.6480

dec_mAP all together: | 0.5361222730380704 |.
dec_mAP_pred | 0 : 0.5988588020682809 |.
dec_mAP_pred | 1 : 0.585759810414608 |.
dec_mAP_pred | 2 : 0.5679056338138182 |.
dec_mAP_pred | 3 : 0.5487571188889891 |.
dec_mAP_pred | 4 : 0.5292652287893838 |.
dec_mAP_pred | 5 : 0.5097219984032336 |.
dec_mAP_pred | 6 : 0.49081705409571397 |.
dec_mAP_pred | 7 : 0.4731281590955897 |.
all decoder map: | 0.5380 |.
BaseballPitch: 0.4850
BasketballDunk: 0.8093
Billiards: 0.2508
CleanAndJerk: 0.7318
CliffDiving: 0.8673
CricketBowling: 0.4862
CricketShot: 0.2830
Diving: 0.8615
FrisbeeCatch: 0.4934
GolfSwing: 0.7789
HammerThrow: 0.8674
HighJump: 0.7440
JavelinThrow: 0.7543
LongJump: 0.7778
PoleVault: 0.9025
Shotput: 0.7348
SoccerPenalty: 0.4006
TennisSwing: 0.5747
ThrowDiscus: 0.6971
VolleyballSpiking: 0.4589
Epoch: [2]  [   0/1404]  eta: 0:43:39  lr: 0.000010  loss: 0.3761 (0.3761)  labels_encoder: 0.2030 (0.2030)  labels_decoder: 0.1731 (0.1731)  labels_encoder_unscaled: 0.2030 (0.2030)  labels_decoder_unscaled: 0.3461 (0.3461)  time: 1.8660  data: 1.6328  max mem: 3463
Epoch: [2]  [  50/1404]  eta: 0:04:10  lr: 0.000010  loss: 0.2991 (0.3038)  labels_encoder: 0.1652 (0.1649)  labels_decoder: 0.1387 (0.1388)  labels_encoder_unscaled: 0.1652 (0.1649)  labels_decoder_unscaled: 0.2773 (0.2777)  time: 0.1437  data: 0.0003  max mem: 3463
Epoch: [2]  [ 100/1404]  eta: 0:03:33  lr: 0.000010  loss: 0.2932 (0.3046)  labels_encoder: 0.1626 (0.1674)  labels_decoder: 0.1348 (0.1373)  labels_encoder_unscaled: 0.1626 (0.1674)  labels_decoder_unscaled: 0.2697 (0.2745)  time: 0.1429  data: 0.0003  max mem: 3463
Epoch: [2]  [ 150/1404]  eta: 0:03:18  lr: 0.000010  loss: 0.2654 (0.2962)  labels_encoder: 0.1433 (0.1616)  labels_decoder: 0.1184 (0.1346)  labels_encoder_unscaled: 0.1433 (0.1616)  labels_decoder_unscaled: 0.2368 (0.2692)  time: 0.1479  data: 0.0003  max mem: 3463
Epoch: [2]  [ 200/1404]  eta: 0:03:07  lr: 0.000010  loss: 0.2573 (0.2909)  labels_encoder: 0.1446 (0.1570)  labels_decoder: 0.1241 (0.1339)  labels_encoder_unscaled: 0.1446 (0.1570)  labels_decoder_unscaled: 0.2482 (0.2679)  time: 0.1505  data: 0.0003  max mem: 3463
Epoch: [2]  [ 250/1404]  eta: 0:02:58  lr: 0.000010  loss: 0.2749 (0.2912)  labels_encoder: 0.1472 (0.1572)  labels_decoder: 0.1337 (0.1340)  labels_encoder_unscaled: 0.1472 (0.1572)  labels_decoder_unscaled: 0.2673 (0.2681)  time: 0.1492  data: 0.0003  max mem: 3463
Epoch: [2]  [ 300/1404]  eta: 0:02:50  lr: 0.000010  loss: 0.2862 (0.2898)  labels_encoder: 0.1524 (0.1561)  labels_decoder: 0.1324 (0.1337)  labels_encoder_unscaled: 0.1524 (0.1561)  labels_decoder_unscaled: 0.2647 (0.2674)  time: 0.1515  data: 0.0003  max mem: 3463
Epoch: [2]  [ 350/1404]  eta: 0:02:41  lr: 0.000010  loss: 0.2739 (0.2886)  labels_encoder: 0.1381 (0.1554)  labels_decoder: 0.1263 (0.1332)  labels_encoder_unscaled: 0.1381 (0.1554)  labels_decoder_unscaled: 0.2526 (0.2664)  time: 0.1464  data: 0.0003  max mem: 3463
Epoch: [2]  [ 400/1404]  eta: 0:02:34  lr: 0.000010  loss: 0.2533 (0.2863)  labels_encoder: 0.1336 (0.1544)  labels_decoder: 0.1187 (0.1318)  labels_encoder_unscaled: 0.1336 (0.1544)  labels_decoder_unscaled: 0.2374 (0.2637)  time: 0.1544  data: 0.0003  max mem: 3463
Epoch: [2]  [ 450/1404]  eta: 0:02:25  lr: 0.000010  loss: 0.2860 (0.2851)  labels_encoder: 0.1501 (0.1535)  labels_decoder: 0.1323 (0.1315)  labels_encoder_unscaled: 0.1501 (0.1535)  labels_decoder_unscaled: 0.2646 (0.2631)  time: 0.1515  data: 0.0003  max mem: 3463
Epoch: [2]  [ 500/1404]  eta: 0:02:18  lr: 0.000010  loss: 0.2739 (0.2833)  labels_encoder: 0.1434 (0.1524)  labels_decoder: 0.1254 (0.1309)  labels_encoder_unscaled: 0.1434 (0.1524)  labels_decoder_unscaled: 0.2508 (0.2619)  time: 0.1503  data: 0.0003  max mem: 3463
Epoch: [2]  [ 550/1404]  eta: 0:02:10  lr: 0.000010  loss: 0.2825 (0.2816)  labels_encoder: 0.1470 (0.1515)  labels_decoder: 0.1192 (0.1300)  labels_encoder_unscaled: 0.1470 (0.1515)  labels_decoder_unscaled: 0.2384 (0.2600)  time: 0.1510  data: 0.0003  max mem: 3463
Epoch: [2]  [ 600/1404]  eta: 0:02:02  lr: 0.000010  loss: 0.2579 (0.2800)  labels_encoder: 0.1298 (0.1504)  labels_decoder: 0.1194 (0.1296)  labels_encoder_unscaled: 0.1298 (0.1504)  labels_decoder_unscaled: 0.2389 (0.2592)  time: 0.1510  data: 0.0003  max mem: 3463
Epoch: [2]  [ 650/1404]  eta: 0:01:55  lr: 0.000010  loss: 0.2495 (0.2786)  labels_encoder: 0.1351 (0.1493)  labels_decoder: 0.1237 (0.1293)  labels_encoder_unscaled: 0.1351 (0.1493)  labels_decoder_unscaled: 0.2475 (0.2586)  time: 0.1554  data: 0.0003  max mem: 3463
Epoch: [2]  [ 700/1404]  eta: 0:01:47  lr: 0.000010  loss: 0.2427 (0.2769)  labels_encoder: 0.1283 (0.1482)  labels_decoder: 0.1104 (0.1287)  labels_encoder_unscaled: 0.1283 (0.1482)  labels_decoder_unscaled: 0.2209 (0.2573)  time: 0.1524  data: 0.0003  max mem: 3463
Epoch: [2]  [ 750/1404]  eta: 0:01:39  lr: 0.000010  loss: 0.2515 (0.2757)  labels_encoder: 0.1309 (0.1476)  labels_decoder: 0.1122 (0.1281)  labels_encoder_unscaled: 0.1309 (0.1476)  labels_decoder_unscaled: 0.2243 (0.2561)  time: 0.1521  data: 0.0003  max mem: 3463
Epoch: [2]  [ 800/1404]  eta: 0:01:32  lr: 0.000010  loss: 0.2707 (0.2745)  labels_encoder: 0.1527 (0.1470)  labels_decoder: 0.1154 (0.1275)  labels_encoder_unscaled: 0.1527 (0.1470)  labels_decoder_unscaled: 0.2307 (0.2550)  time: 0.1520  data: 0.0003  max mem: 3463
Epoch: [2]  [ 850/1404]  eta: 0:01:24  lr: 0.000010  loss: 0.2331 (0.2739)  labels_encoder: 0.1287 (0.1465)  labels_decoder: 0.1159 (0.1273)  labels_encoder_unscaled: 0.1287 (0.1465)  labels_decoder_unscaled: 0.2317 (0.2547)  time: 0.1514  data: 0.0003  max mem: 3463
Epoch: [2]  [ 900/1404]  eta: 0:01:16  lr: 0.000010  loss: 0.2681 (0.2739)  labels_encoder: 0.1401 (0.1465)  labels_decoder: 0.1207 (0.1274)  labels_encoder_unscaled: 0.1401 (0.1465)  labels_decoder_unscaled: 0.2414 (0.2547)  time: 0.1502  data: 0.0003  max mem: 3463
Epoch: [2]  [ 950/1404]  eta: 0:01:09  lr: 0.000010  loss: 0.2725 (0.2737)  labels_encoder: 0.1544 (0.1466)  labels_decoder: 0.1210 (0.1272)  labels_encoder_unscaled: 0.1544 (0.1466)  labels_decoder_unscaled: 0.2420 (0.2543)  time: 0.1534  data: 0.0003  max mem: 3463
Epoch: [2]  [1000/1404]  eta: 0:01:01  lr: 0.000010  loss: 0.2697 (0.2733)  labels_encoder: 0.1307 (0.1461)  labels_decoder: 0.1248 (0.1272)  labels_encoder_unscaled: 0.1307 (0.1461)  labels_decoder_unscaled: 0.2497 (0.2544)  time: 0.1480  data: 0.0003  max mem: 3463
Epoch: [2]  [1050/1404]  eta: 0:00:53  lr: 0.000010  loss: 0.2602 (0.2729)  labels_encoder: 0.1411 (0.1459)  labels_decoder: 0.1267 (0.1270)  labels_encoder_unscaled: 0.1411 (0.1459)  labels_decoder_unscaled: 0.2533 (0.2540)  time: 0.1560  data: 0.0003  max mem: 3463
Epoch: [2]  [1100/1404]  eta: 0:00:46  lr: 0.000010  loss: 0.2482 (0.2722)  labels_encoder: 0.1285 (0.1455)  labels_decoder: 0.1136 (0.1267)  labels_encoder_unscaled: 0.1285 (0.1455)  labels_decoder_unscaled: 0.2272 (0.2535)  time: 0.1559  data: 0.0003  max mem: 3463
Epoch: [2]  [1150/1404]  eta: 0:00:38  lr: 0.000010  loss: 0.2492 (0.2718)  labels_encoder: 0.1364 (0.1453)  labels_decoder: 0.1139 (0.1265)  labels_encoder_unscaled: 0.1364 (0.1453)  labels_decoder_unscaled: 0.2277 (0.2529)  time: 0.1539  data: 0.0003  max mem: 3463
Epoch: [2]  [1200/1404]  eta: 0:00:31  lr: 0.000010  loss: 0.2500 (0.2713)  labels_encoder: 0.1235 (0.1449)  labels_decoder: 0.1218 (0.1263)  labels_encoder_unscaled: 0.1235 (0.1449)  labels_decoder_unscaled: 0.2435 (0.2527)  time: 0.1607  data: 0.0003  max mem: 3463
Epoch: [2]  [1250/1404]  eta: 0:00:23  lr: 0.000010  loss: 0.2628 (0.2710)  labels_encoder: 0.1371 (0.1449)  labels_decoder: 0.1186 (0.1261)  labels_encoder_unscaled: 0.1371 (0.1449)  labels_decoder_unscaled: 0.2371 (0.2522)  time: 0.1580  data: 0.0003  max mem: 3463
Epoch: [2]  [1300/1404]  eta: 0:00:15  lr: 0.000010  loss: 0.2335 (0.2699)  labels_encoder: 0.1128 (0.1442)  labels_decoder: 0.1176 (0.1257)  labels_encoder_unscaled: 0.1128 (0.1442)  labels_decoder_unscaled: 0.2351 (0.2515)  time: 0.1596  data: 0.0003  max mem: 3463
Epoch: [2]  [1350/1404]  eta: 0:00:08  lr: 0.000010  loss: 0.2270 (0.2689)  labels_encoder: 0.1179 (0.1435)  labels_decoder: 0.1097 (0.1255)  labels_encoder_unscaled: 0.1179 (0.1435)  labels_decoder_unscaled: 0.2195 (0.2509)  time: 0.1588  data: 0.0003  max mem: 3463
Epoch: [2]  [1400/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2369 (0.2684)  labels_encoder: 0.1087 (0.1430)  labels_decoder: 0.1227 (0.1254)  labels_encoder_unscaled: 0.1087 (0.1430)  labels_decoder_unscaled: 0.2454 (0.2508)  time: 0.1384  data: 0.0004  max mem: 3463
Epoch: [2]  [1403/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2545 (0.2684)  labels_encoder: 0.1341 (0.1430)  labels_decoder: 0.1227 (0.1254)  labels_encoder_unscaled: 0.1341 (0.1430)  labels_decoder_unscaled: 0.2454 (0.2508)  time: 0.1332  data: 0.0003  max mem: 3463
Epoch: [2] Total time: 0:03:35 (0.1537 s / it)
Averaged stats: lr: 0.000010  loss: 0.2545 (0.2684)  labels_encoder: 0.1341 (0.1430)  labels_decoder: 0.1227 (0.1254)  labels_encoder_unscaled: 0.1341 (0.1430)  labels_decoder_unscaled: 0.2454 (0.2508)
Test:  [   0/1613]  eta: 0:50:53  loss: 1.5373 (1.5373)  labels_encoder: 1.0049 (1.0049)  labels_decoder: 0.5324 (0.5324)  labels_encoder_unscaled: 1.0049 (1.0049)  labels_decoder_unscaled: 1.0647 (1.0647)  time: 1.8928  data: 1.8158  max mem: 3463
Test:  [  50/1613]  eta: 0:02:52  loss: 0.4717 (0.9186)  labels_encoder: 0.3265 (0.5752)  labels_decoder: 0.2377 (0.3434)  labels_encoder_unscaled: 0.3265 (0.5752)  labels_decoder_unscaled: 0.4755 (0.6867)  time: 0.0694  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:19  loss: 0.5111 (0.7888)  labels_encoder: 0.2874 (0.5154)  labels_decoder: 0.1438 (0.2733)  labels_encoder_unscaled: 0.2874 (0.5154)  labels_decoder_unscaled: 0.2875 (0.5466)  time: 0.0734  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:02:06  loss: 0.7472 (0.7448)  labels_encoder: 0.5667 (0.4814)  labels_decoder: 0.1805 (0.2634)  labels_encoder_unscaled: 0.5667 (0.4814)  labels_decoder_unscaled: 0.3610 (0.5268)  time: 0.0786  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:58  loss: 0.8565 (0.8483)  labels_encoder: 0.4762 (0.5428)  labels_decoder: 0.3658 (0.3055)  labels_encoder_unscaled: 0.4762 (0.5428)  labels_decoder_unscaled: 0.7317 (0.6110)  time: 0.0753  data: 0.0004  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:52  loss: 0.7111 (0.9144)  labels_encoder: 0.3792 (0.5834)  labels_decoder: 0.3518 (0.3310)  labels_encoder_unscaled: 0.3792 (0.5834)  labels_decoder_unscaled: 0.7036 (0.6620)  time: 0.0800  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:47  loss: 0.8029 (0.9226)  labels_encoder: 0.4700 (0.5849)  labels_decoder: 0.3329 (0.3377)  labels_encoder_unscaled: 0.4700 (0.5849)  labels_decoder_unscaled: 0.6657 (0.6754)  time: 0.0758  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:42  loss: 1.2401 (0.9567)  labels_encoder: 0.7184 (0.6096)  labels_decoder: 0.4821 (0.3471)  labels_encoder_unscaled: 0.7184 (0.6096)  labels_decoder_unscaled: 0.9642 (0.6943)  time: 0.0769  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:37  loss: 0.7377 (1.0209)  labels_encoder: 0.4162 (0.6539)  labels_decoder: 0.3111 (0.3670)  labels_encoder_unscaled: 0.4162 (0.6539)  labels_decoder_unscaled: 0.6221 (0.7339)  time: 0.0759  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:32  loss: 0.9580 (1.1064)  labels_encoder: 0.6793 (0.7144)  labels_decoder: 0.2968 (0.3920)  labels_encoder_unscaled: 0.6793 (0.7144)  labels_decoder_unscaled: 0.5936 (0.7839)  time: 0.0755  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:28  loss: 0.3471 (1.0619)  labels_encoder: 0.1756 (0.6824)  labels_decoder: 0.1791 (0.3796)  labels_encoder_unscaled: 0.1756 (0.6824)  labels_decoder_unscaled: 0.3582 (0.7591)  time: 0.0770  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:23  loss: 0.6510 (1.0444)  labels_encoder: 0.3736 (0.6715)  labels_decoder: 0.2307 (0.3730)  labels_encoder_unscaled: 0.3736 (0.6715)  labels_decoder_unscaled: 0.4614 (0.7459)  time: 0.0674  data: 0.0001  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:18  loss: 0.7456 (1.0959)  labels_encoder: 0.4211 (0.7121)  labels_decoder: 0.2630 (0.3838)  labels_encoder_unscaled: 0.4211 (0.7121)  labels_decoder_unscaled: 0.5261 (0.7676)  time: 0.0654  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:13  loss: 1.4434 (1.1020)  labels_encoder: 0.8849 (0.7137)  labels_decoder: 0.5147 (0.3884)  labels_encoder_unscaled: 0.8849 (0.7137)  labels_decoder_unscaled: 1.0294 (0.7767)  time: 0.0643  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:01:09  loss: 0.5118 (1.0743)  labels_encoder: 0.2843 (0.6943)  labels_decoder: 0.2361 (0.3800)  labels_encoder_unscaled: 0.2843 (0.6943)  labels_decoder_unscaled: 0.4721 (0.7600)  time: 0.0661  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:01:05  loss: 0.6879 (1.0533)  labels_encoder: 0.4673 (0.6798)  labels_decoder: 0.2567 (0.3735)  labels_encoder_unscaled: 0.4673 (0.6798)  labels_decoder_unscaled: 0.5134 (0.7470)  time: 0.0626  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:01:00  loss: 0.4782 (1.0402)  labels_encoder: 0.2579 (0.6714)  labels_decoder: 0.2203 (0.3688)  labels_encoder_unscaled: 0.2579 (0.6714)  labels_decoder_unscaled: 0.4406 (0.7377)  time: 0.0704  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:56  loss: 1.2019 (1.0481)  labels_encoder: 0.6671 (0.6738)  labels_decoder: 0.4547 (0.3744)  labels_encoder_unscaled: 0.6671 (0.6738)  labels_decoder_unscaled: 0.9094 (0.7487)  time: 0.0674  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:52  loss: 0.5637 (1.0287)  labels_encoder: 0.2752 (0.6586)  labels_decoder: 0.2714 (0.3701)  labels_encoder_unscaled: 0.2752 (0.6586)  labels_decoder_unscaled: 0.5428 (0.7401)  time: 0.0717  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:49  loss: 0.9948 (1.0322)  labels_encoder: 0.7032 (0.6610)  labels_decoder: 0.3516 (0.3712)  labels_encoder_unscaled: 0.7032 (0.6610)  labels_decoder_unscaled: 0.7032 (0.7423)  time: 0.0674  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:45  loss: 0.5396 (1.0177)  labels_encoder: 0.3266 (0.6509)  labels_decoder: 0.2722 (0.3669)  labels_encoder_unscaled: 0.3266 (0.6509)  labels_decoder_unscaled: 0.5444 (0.7337)  time: 0.0629  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:41  loss: 0.9414 (1.0243)  labels_encoder: 0.5908 (0.6562)  labels_decoder: 0.3546 (0.3681)  labels_encoder_unscaled: 0.5908 (0.6562)  labels_decoder_unscaled: 0.7092 (0.7362)  time: 0.0710  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:37  loss: 0.3728 (1.0181)  labels_encoder: 0.1954 (0.6526)  labels_decoder: 0.2051 (0.3655)  labels_encoder_unscaled: 0.1954 (0.6526)  labels_decoder_unscaled: 0.4101 (0.7309)  time: 0.0652  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:33  loss: 0.5784 (1.0100)  labels_encoder: 0.4383 (0.6477)  labels_decoder: 0.1982 (0.3623)  labels_encoder_unscaled: 0.4383 (0.6477)  labels_decoder_unscaled: 0.3963 (0.7247)  time: 0.0684  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:30  loss: 0.5561 (1.0190)  labels_encoder: 0.2839 (0.6541)  labels_decoder: 0.2194 (0.3649)  labels_encoder_unscaled: 0.2839 (0.6541)  labels_decoder_unscaled: 0.4388 (0.7298)  time: 0.0728  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:26  loss: 0.5779 (1.0195)  labels_encoder: 0.3043 (0.6545)  labels_decoder: 0.2199 (0.3650)  labels_encoder_unscaled: 0.3043 (0.6545)  labels_decoder_unscaled: 0.4397 (0.7299)  time: 0.0744  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:22  loss: 0.6604 (1.0118)  labels_encoder: 0.3975 (0.6481)  labels_decoder: 0.3354 (0.3637)  labels_encoder_unscaled: 0.3975 (0.6481)  labels_decoder_unscaled: 0.6709 (0.7274)  time: 0.0756  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:19  loss: 1.0646 (1.0178)  labels_encoder: 0.6990 (0.6522)  labels_decoder: 0.4057 (0.3657)  labels_encoder_unscaled: 0.6990 (0.6522)  labels_decoder_unscaled: 0.8115 (0.7314)  time: 0.0741  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:15  loss: 0.7962 (1.0232)  labels_encoder: 0.5259 (0.6560)  labels_decoder: 0.2932 (0.3672)  labels_encoder_unscaled: 0.5259 (0.6560)  labels_decoder_unscaled: 0.5864 (0.7344)  time: 0.0780  data: 0.0020  max mem: 3463
Test:  [1450/1613]  eta: 0:00:11  loss: 0.6094 (1.0292)  labels_encoder: 0.2785 (0.6595)  labels_decoder: 0.2453 (0.3696)  labels_encoder_unscaled: 0.2785 (0.6595)  labels_decoder_unscaled: 0.4905 (0.7393)  time: 0.0718  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:08  loss: 0.3716 (1.0253)  labels_encoder: 0.2358 (0.6574)  labels_decoder: 0.1566 (0.3679)  labels_encoder_unscaled: 0.2358 (0.6574)  labels_decoder_unscaled: 0.3131 (0.7359)  time: 0.0732  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:04  loss: 0.9605 (1.0288)  labels_encoder: 0.6286 (0.6607)  labels_decoder: 0.3085 (0.3681)  labels_encoder_unscaled: 0.6286 (0.6607)  labels_decoder_unscaled: 0.6171 (0.7361)  time: 0.0705  data: 0.0006  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.7787 (1.0226)  labels_encoder: 0.4960 (0.6560)  labels_decoder: 0.3076 (0.3666)  labels_encoder_unscaled: 0.4960 (0.6560)  labels_decoder_unscaled: 0.6153 (0.7333)  time: 0.0660  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6877 (1.0210)  labels_encoder: 0.3583 (0.6551)  labels_decoder: 0.2827 (0.3659)  labels_encoder_unscaled: 0.3583 (0.6551)  labels_decoder_unscaled: 0.5655 (0.7318)  time: 0.0522  data: 0.0001  max mem: 3463
Test: Total time: 0:01:57 (0.0731 s / it)
Averaged stats: loss: 0.6877 (1.0210)  labels_encoder: 0.3583 (0.6551)  labels_decoder: 0.2827 (0.3659)  labels_encoder_unscaled: 0.3583 (0.6551)  labels_decoder_unscaled: 0.5655 (0.7318)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-kin] mAP: 0.6418

dec_mAP all together: | 0.5114799437738106 |.
dec_mAP_pred | 0 : 0.5620122664959821 |.
dec_mAP_pred | 1 : 0.5525302649747517 |.
dec_mAP_pred | 2 : 0.5384271839198675 |.
dec_mAP_pred | 3 : 0.5229654314449128 |.
dec_mAP_pred | 4 : 0.506420034985483 |.
dec_mAP_pred | 5 : 0.4894202520512546 |.
dec_mAP_pred | 6 : 0.47287761204813095 |.
dec_mAP_pred | 7 : 0.4570038223716713 |.
all decoder map: | 0.5127 |.
BaseballPitch: 0.3587
BasketballDunk: 0.8153
Billiards: 0.2663
CleanAndJerk: 0.7453
CliffDiving: 0.8637
CricketBowling: 0.4620
CricketShot: 0.2784
Diving: 0.8623
FrisbeeCatch: 0.4736
GolfSwing: 0.7730
HammerThrow: 0.8687
HighJump: 0.7756
JavelinThrow: 0.7605
LongJump: 0.7822
PoleVault: 0.8721
Shotput: 0.7062
SoccerPenalty: 0.4705
TennisSwing: 0.5833
ThrowDiscus: 0.6612
VolleyballSpiking: 0.4568
Epoch: [3]  [   0/1404]  eta: 0:45:49  lr: 0.000001  loss: 0.2195 (0.2195)  labels_encoder: 0.1052 (0.1052)  labels_decoder: 0.1143 (0.1143)  labels_encoder_unscaled: 0.1052 (0.1052)  labels_decoder_unscaled: 0.2286 (0.2286)  time: 1.9581  data: 1.7563  max mem: 3463
Epoch: [3]  [  50/1404]  eta: 0:04:07  lr: 0.000001  loss: 0.2317 (0.2371)  labels_encoder: 0.1217 (0.1211)  labels_decoder: 0.1157 (0.1160)  labels_encoder_unscaled: 0.1217 (0.1211)  labels_decoder_unscaled: 0.2315 (0.2320)  time: 0.1401  data: 0.0003  max mem: 3463
Epoch: [3]  [ 100/1404]  eta: 0:03:30  lr: 0.000001  loss: 0.2074 (0.2345)  labels_encoder: 0.1013 (0.1195)  labels_decoder: 0.1100 (0.1149)  labels_encoder_unscaled: 0.1013 (0.1195)  labels_decoder_unscaled: 0.2200 (0.2298)  time: 0.1418  data: 0.0003  max mem: 3463
Epoch: [3]  [ 150/1404]  eta: 0:03:16  lr: 0.000001  loss: 0.2438 (0.2393)  labels_encoder: 0.1260 (0.1238)  labels_decoder: 0.1158 (0.1155)  labels_encoder_unscaled: 0.1260 (0.1238)  labels_decoder_unscaled: 0.2316 (0.2310)  time: 0.1492  data: 0.0003  max mem: 3463
Epoch: [3]  [ 200/1404]  eta: 0:03:06  lr: 0.000001  loss: 0.2249 (0.2361)  labels_encoder: 0.1022 (0.1210)  labels_decoder: 0.1101 (0.1151)  labels_encoder_unscaled: 0.1022 (0.1210)  labels_decoder_unscaled: 0.2202 (0.2302)  time: 0.1499  data: 0.0003  max mem: 3463
Epoch: [3]  [ 250/1404]  eta: 0:02:57  lr: 0.000001  loss: 0.2296 (0.2382)  labels_encoder: 0.1141 (0.1223)  labels_decoder: 0.1183 (0.1160)  labels_encoder_unscaled: 0.1141 (0.1223)  labels_decoder_unscaled: 0.2366 (0.2319)  time: 0.1517  data: 0.0003  max mem: 3463
Epoch: [3]  [ 300/1404]  eta: 0:02:49  lr: 0.000001  loss: 0.2171 (0.2358)  labels_encoder: 0.1155 (0.1208)  labels_decoder: 0.1075 (0.1150)  labels_encoder_unscaled: 0.1155 (0.1208)  labels_decoder_unscaled: 0.2151 (0.2301)  time: 0.1498  data: 0.0003  max mem: 3463
Epoch: [3]  [ 350/1404]  eta: 0:02:41  lr: 0.000001  loss: 0.2164 (0.2352)  labels_encoder: 0.1119 (0.1202)  labels_decoder: 0.1138 (0.1150)  labels_encoder_unscaled: 0.1119 (0.1202)  labels_decoder_unscaled: 0.2276 (0.2300)  time: 0.1427  data: 0.0002  max mem: 3463
Epoch: [3]  [ 400/1404]  eta: 0:02:32  lr: 0.000001  loss: 0.2166 (0.2348)  labels_encoder: 0.1111 (0.1196)  labels_decoder: 0.1144 (0.1153)  labels_encoder_unscaled: 0.1111 (0.1196)  labels_decoder_unscaled: 0.2287 (0.2305)  time: 0.1486  data: 0.0003  max mem: 3463
Epoch: [3]  [ 450/1404]  eta: 0:02:24  lr: 0.000001  loss: 0.2492 (0.2365)  labels_encoder: 0.1524 (0.1209)  labels_decoder: 0.1196 (0.1156)  labels_encoder_unscaled: 0.1524 (0.1209)  labels_decoder_unscaled: 0.2393 (0.2311)  time: 0.1410  data: 0.0003  max mem: 3463
Epoch: [3]  [ 500/1404]  eta: 0:02:16  lr: 0.000001  loss: 0.2315 (0.2368)  labels_encoder: 0.1232 (0.1214)  labels_decoder: 0.1083 (0.1154)  labels_encoder_unscaled: 0.1232 (0.1214)  labels_decoder_unscaled: 0.2166 (0.2307)  time: 0.1515  data: 0.0003  max mem: 3463
Epoch: [3]  [ 550/1404]  eta: 0:02:09  lr: 0.000001  loss: 0.2405 (0.2365)  labels_encoder: 0.1266 (0.1211)  labels_decoder: 0.1114 (0.1154)  labels_encoder_unscaled: 0.1266 (0.1211)  labels_decoder_unscaled: 0.2229 (0.2308)  time: 0.1480  data: 0.0003  max mem: 3463
Epoch: [3]  [ 600/1404]  eta: 0:02:01  lr: 0.000001  loss: 0.2329 (0.2360)  labels_encoder: 0.1228 (0.1210)  labels_decoder: 0.1039 (0.1151)  labels_encoder_unscaled: 0.1228 (0.1210)  labels_decoder_unscaled: 0.2077 (0.2301)  time: 0.1517  data: 0.0003  max mem: 3463
Epoch: [3]  [ 650/1404]  eta: 0:01:53  lr: 0.000001  loss: 0.2340 (0.2360)  labels_encoder: 0.1202 (0.1210)  labels_decoder: 0.1138 (0.1150)  labels_encoder_unscaled: 0.1202 (0.1210)  labels_decoder_unscaled: 0.2276 (0.2300)  time: 0.1527  data: 0.0003  max mem: 3463
Epoch: [3]  [ 700/1404]  eta: 0:01:46  lr: 0.000001  loss: 0.2311 (0.2363)  labels_encoder: 0.1231 (0.1213)  labels_decoder: 0.1088 (0.1150)  labels_encoder_unscaled: 0.1231 (0.1213)  labels_decoder_unscaled: 0.2177 (0.2301)  time: 0.1530  data: 0.0003  max mem: 3463
Epoch: [3]  [ 750/1404]  eta: 0:01:38  lr: 0.000001  loss: 0.2284 (0.2365)  labels_encoder: 0.1103 (0.1217)  labels_decoder: 0.1080 (0.1148)  labels_encoder_unscaled: 0.1103 (0.1217)  labels_decoder_unscaled: 0.2160 (0.2296)  time: 0.1501  data: 0.0003  max mem: 3463
Epoch: [3]  [ 800/1404]  eta: 0:01:31  lr: 0.000001  loss: 0.2537 (0.2366)  labels_encoder: 0.1236 (0.1217)  labels_decoder: 0.1234 (0.1149)  labels_encoder_unscaled: 0.1236 (0.1217)  labels_decoder_unscaled: 0.2468 (0.2298)  time: 0.1502  data: 0.0003  max mem: 3463
Epoch: [3]  [ 850/1404]  eta: 0:01:23  lr: 0.000001  loss: 0.2295 (0.2368)  labels_encoder: 0.1168 (0.1219)  labels_decoder: 0.1104 (0.1149)  labels_encoder_unscaled: 0.1168 (0.1219)  labels_decoder_unscaled: 0.2209 (0.2298)  time: 0.1468  data: 0.0003  max mem: 3463
Epoch: [3]  [ 900/1404]  eta: 0:01:16  lr: 0.000001  loss: 0.2237 (0.2366)  labels_encoder: 0.1035 (0.1217)  labels_decoder: 0.1149 (0.1149)  labels_encoder_unscaled: 0.1035 (0.1217)  labels_decoder_unscaled: 0.2298 (0.2297)  time: 0.1585  data: 0.0003  max mem: 3463
Epoch: [3]  [ 950/1404]  eta: 0:01:08  lr: 0.000001  loss: 0.2481 (0.2369)  labels_encoder: 0.1291 (0.1221)  labels_decoder: 0.1208 (0.1148)  labels_encoder_unscaled: 0.1291 (0.1221)  labels_decoder_unscaled: 0.2417 (0.2296)  time: 0.1573  data: 0.0003  max mem: 3463
Epoch: [3]  [1000/1404]  eta: 0:01:01  lr: 0.000001  loss: 0.2312 (0.2366)  labels_encoder: 0.1249 (0.1218)  labels_decoder: 0.1077 (0.1148)  labels_encoder_unscaled: 0.1249 (0.1218)  labels_decoder_unscaled: 0.2154 (0.2296)  time: 0.1566  data: 0.0003  max mem: 3463
Epoch: [3]  [1050/1404]  eta: 0:00:53  lr: 0.000001  loss: 0.2229 (0.2364)  labels_encoder: 0.1182 (0.1216)  labels_decoder: 0.1083 (0.1147)  labels_encoder_unscaled: 0.1182 (0.1216)  labels_decoder_unscaled: 0.2166 (0.2295)  time: 0.1564  data: 0.0003  max mem: 3463
Epoch: [3]  [1100/1404]  eta: 0:00:46  lr: 0.000001  loss: 0.2295 (0.2365)  labels_encoder: 0.1170 (0.1216)  labels_decoder: 0.1107 (0.1149)  labels_encoder_unscaled: 0.1170 (0.1216)  labels_decoder_unscaled: 0.2214 (0.2299)  time: 0.1548  data: 0.0003  max mem: 3463
Epoch: [3]  [1150/1404]  eta: 0:00:38  lr: 0.000001  loss: 0.2304 (0.2363)  labels_encoder: 0.1102 (0.1214)  labels_decoder: 0.1138 (0.1148)  labels_encoder_unscaled: 0.1102 (0.1214)  labels_decoder_unscaled: 0.2276 (0.2297)  time: 0.1522  data: 0.0003  max mem: 3463
Epoch: [3]  [1200/1404]  eta: 0:00:31  lr: 0.000001  loss: 0.2301 (0.2363)  labels_encoder: 0.1168 (0.1215)  labels_decoder: 0.1075 (0.1148)  labels_encoder_unscaled: 0.1168 (0.1215)  labels_decoder_unscaled: 0.2151 (0.2296)  time: 0.1592  data: 0.0003  max mem: 3463
Epoch: [3]  [1250/1404]  eta: 0:00:23  lr: 0.000001  loss: 0.2453 (0.2364)  labels_encoder: 0.1304 (0.1216)  labels_decoder: 0.1144 (0.1148)  labels_encoder_unscaled: 0.1304 (0.1216)  labels_decoder_unscaled: 0.2287 (0.2296)  time: 0.1530  data: 0.0003  max mem: 3463
Epoch: [3]  [1300/1404]  eta: 0:00:15  lr: 0.000001  loss: 0.2272 (0.2363)  labels_encoder: 0.1060 (0.1216)  labels_decoder: 0.1152 (0.1147)  labels_encoder_unscaled: 0.1060 (0.1216)  labels_decoder_unscaled: 0.2305 (0.2295)  time: 0.1519  data: 0.0003  max mem: 3463
Epoch: [3]  [1350/1404]  eta: 0:00:08  lr: 0.000001  loss: 0.2213 (0.2361)  labels_encoder: 0.1066 (0.1215)  labels_decoder: 0.1111 (0.1146)  labels_encoder_unscaled: 0.1066 (0.1215)  labels_decoder_unscaled: 0.2221 (0.2292)  time: 0.1522  data: 0.0003  max mem: 3463
Epoch: [3]  [1400/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2487 (0.2365)  labels_encoder: 0.1213 (0.1218)  labels_decoder: 0.1216 (0.1148)  labels_encoder_unscaled: 0.1213 (0.1218)  labels_decoder_unscaled: 0.2433 (0.2295)  time: 0.1427  data: 0.0004  max mem: 3463
Epoch: [3]  [1403/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2522 (0.2367)  labels_encoder: 0.1311 (0.1219)  labels_decoder: 0.1191 (0.1148)  labels_encoder_unscaled: 0.1311 (0.1219)  labels_decoder_unscaled: 0.2382 (0.2295)  time: 0.1396  data: 0.0003  max mem: 3463
Epoch: [3] Total time: 0:03:34 (0.1527 s / it)
Averaged stats: lr: 0.000001  loss: 0.2522 (0.2367)  labels_encoder: 0.1311 (0.1219)  labels_decoder: 0.1191 (0.1148)  labels_encoder_unscaled: 0.1311 (0.1219)  labels_decoder_unscaled: 0.2382 (0.2295)
Test:  [   0/1613]  eta: 0:47:05  loss: 0.9574 (0.9574)  labels_encoder: 0.5625 (0.5625)  labels_decoder: 0.3948 (0.3948)  labels_encoder_unscaled: 0.5625 (0.5625)  labels_decoder_unscaled: 0.7897 (0.7897)  time: 1.7514  data: 1.5991  max mem: 3463
Test:  [  50/1613]  eta: 0:02:58  loss: 0.4538 (0.8615)  labels_encoder: 0.2764 (0.5323)  labels_decoder: 0.1939 (0.3292)  labels_encoder_unscaled: 0.2764 (0.5323)  labels_decoder_unscaled: 0.3878 (0.6585)  time: 0.0777  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:22  loss: 0.4739 (0.7495)  labels_encoder: 0.2754 (0.4855)  labels_decoder: 0.1371 (0.2640)  labels_encoder_unscaled: 0.2754 (0.4855)  labels_decoder_unscaled: 0.2742 (0.5279)  time: 0.0715  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:02:08  loss: 0.8060 (0.7189)  labels_encoder: 0.5673 (0.4605)  labels_decoder: 0.2216 (0.2584)  labels_encoder_unscaled: 0.5673 (0.4605)  labels_decoder_unscaled: 0.4432 (0.5168)  time: 0.0764  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:55  loss: 0.8694 (0.8323)  labels_encoder: 0.4858 (0.5288)  labels_decoder: 0.3622 (0.3035)  labels_encoder_unscaled: 0.4858 (0.5288)  labels_decoder_unscaled: 0.7244 (0.6070)  time: 0.0652  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:47  loss: 0.6934 (0.8970)  labels_encoder: 0.3491 (0.5679)  labels_decoder: 0.3466 (0.3291)  labels_encoder_unscaled: 0.3491 (0.5679)  labels_decoder_unscaled: 0.6932 (0.6581)  time: 0.0641  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:41  loss: 0.6451 (0.8913)  labels_encoder: 0.4031 (0.5626)  labels_decoder: 0.2535 (0.3287)  labels_encoder_unscaled: 0.4031 (0.5626)  labels_decoder_unscaled: 0.5069 (0.6574)  time: 0.0714  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:36  loss: 1.1330 (0.9228)  labels_encoder: 0.6362 (0.5860)  labels_decoder: 0.5181 (0.3369)  labels_encoder_unscaled: 0.6362 (0.5860)  labels_decoder_unscaled: 1.0363 (0.6737)  time: 0.0681  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:31  loss: 0.7007 (0.9989)  labels_encoder: 0.3815 (0.6379)  labels_decoder: 0.3122 (0.3610)  labels_encoder_unscaled: 0.3815 (0.6379)  labels_decoder_unscaled: 0.6244 (0.7220)  time: 0.0731  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:26  loss: 0.7758 (1.0823)  labels_encoder: 0.5587 (0.6975)  labels_decoder: 0.2818 (0.3848)  labels_encoder_unscaled: 0.5587 (0.6975)  labels_decoder_unscaled: 0.5637 (0.7697)  time: 0.0719  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:22  loss: 0.3216 (1.0385)  labels_encoder: 0.1809 (0.6664)  labels_decoder: 0.1549 (0.3720)  labels_encoder_unscaled: 0.1809 (0.6664)  labels_decoder_unscaled: 0.3097 (0.7441)  time: 0.0685  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:17  loss: 0.6137 (1.0197)  labels_encoder: 0.3595 (0.6543)  labels_decoder: 0.2066 (0.3654)  labels_encoder_unscaled: 0.3595 (0.6543)  labels_decoder_unscaled: 0.4132 (0.7308)  time: 0.0633  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:13  loss: 0.8004 (1.0643)  labels_encoder: 0.4480 (0.6914)  labels_decoder: 0.3012 (0.3728)  labels_encoder_unscaled: 0.4480 (0.6914)  labels_decoder_unscaled: 0.6025 (0.7457)  time: 0.0646  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:09  loss: 1.5012 (1.0744)  labels_encoder: 0.8995 (0.6955)  labels_decoder: 0.5348 (0.3789)  labels_encoder_unscaled: 0.8995 (0.6955)  labels_decoder_unscaled: 1.0696 (0.7577)  time: 0.0663  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:01:05  loss: 0.5210 (1.0491)  labels_encoder: 0.2883 (0.6776)  labels_decoder: 0.2364 (0.3715)  labels_encoder_unscaled: 0.2883 (0.6776)  labels_decoder_unscaled: 0.4728 (0.7429)  time: 0.0654  data: 0.0014  max mem: 3463
Test:  [ 750/1613]  eta: 0:01:01  loss: 0.7474 (1.0294)  labels_encoder: 0.5057 (0.6637)  labels_decoder: 0.2778 (0.3657)  labels_encoder_unscaled: 0.5057 (0.6637)  labels_decoder_unscaled: 0.5556 (0.7314)  time: 0.0638  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:57  loss: 0.5316 (1.0158)  labels_encoder: 0.2757 (0.6548)  labels_decoder: 0.2429 (0.3610)  labels_encoder_unscaled: 0.2757 (0.6548)  labels_decoder_unscaled: 0.4859 (0.7220)  time: 0.0781  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:54  loss: 1.2280 (1.0241)  labels_encoder: 0.6047 (0.6571)  labels_decoder: 0.4535 (0.3671)  labels_encoder_unscaled: 0.6047 (0.6571)  labels_decoder_unscaled: 0.9070 (0.7341)  time: 0.0724  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:50  loss: 0.5240 (1.0063)  labels_encoder: 0.2797 (0.6433)  labels_decoder: 0.2632 (0.3630)  labels_encoder_unscaled: 0.2797 (0.6433)  labels_decoder_unscaled: 0.5265 (0.7260)  time: 0.0777  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:47  loss: 0.9165 (1.0015)  labels_encoder: 0.5666 (0.6393)  labels_decoder: 0.3333 (0.3622)  labels_encoder_unscaled: 0.5666 (0.6393)  labels_decoder_unscaled: 0.6665 (0.7244)  time: 0.0769  data: 0.0012  max mem: 3463
Test:  [1000/1613]  eta: 0:00:43  loss: 0.5253 (0.9869)  labels_encoder: 0.3149 (0.6291)  labels_decoder: 0.2656 (0.3578)  labels_encoder_unscaled: 0.3149 (0.6291)  labels_decoder_unscaled: 0.5311 (0.7155)  time: 0.0722  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:40  loss: 0.9617 (0.9928)  labels_encoder: 0.6052 (0.6338)  labels_decoder: 0.3411 (0.3590)  labels_encoder_unscaled: 0.6052 (0.6338)  labels_decoder_unscaled: 0.6822 (0.7180)  time: 0.0710  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:36  loss: 0.3895 (0.9881)  labels_encoder: 0.1960 (0.6316)  labels_decoder: 0.2047 (0.3565)  labels_encoder_unscaled: 0.1960 (0.6316)  labels_decoder_unscaled: 0.4095 (0.7130)  time: 0.0779  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:33  loss: 0.5256 (0.9824)  labels_encoder: 0.4045 (0.6283)  labels_decoder: 0.1955 (0.3542)  labels_encoder_unscaled: 0.4045 (0.6283)  labels_decoder_unscaled: 0.3909 (0.7083)  time: 0.0744  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:29  loss: 0.5117 (0.9902)  labels_encoder: 0.2607 (0.6335)  labels_decoder: 0.2325 (0.3567)  labels_encoder_unscaled: 0.2607 (0.6335)  labels_decoder_unscaled: 0.4649 (0.7134)  time: 0.0742  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:26  loss: 0.5457 (0.9895)  labels_encoder: 0.2862 (0.6332)  labels_decoder: 0.1950 (0.3563)  labels_encoder_unscaled: 0.2862 (0.6332)  labels_decoder_unscaled: 0.3901 (0.7126)  time: 0.0702  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:22  loss: 0.5992 (0.9812)  labels_encoder: 0.3742 (0.6270)  labels_decoder: 0.3003 (0.3543)  labels_encoder_unscaled: 0.3742 (0.6270)  labels_decoder_unscaled: 0.6006 (0.7086)  time: 0.0699  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:18  loss: 1.1097 (0.9868)  labels_encoder: 0.6766 (0.6311)  labels_decoder: 0.3848 (0.3557)  labels_encoder_unscaled: 0.6766 (0.6311)  labels_decoder_unscaled: 0.7695 (0.7114)  time: 0.0735  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:15  loss: 0.8042 (0.9947)  labels_encoder: 0.5297 (0.6365)  labels_decoder: 0.2911 (0.3582)  labels_encoder_unscaled: 0.5297 (0.6365)  labels_decoder_unscaled: 0.5822 (0.7164)  time: 0.0709  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:11  loss: 0.5989 (1.0010)  labels_encoder: 0.2516 (0.6404)  labels_decoder: 0.2223 (0.3606)  labels_encoder_unscaled: 0.2516 (0.6404)  labels_decoder_unscaled: 0.4446 (0.7212)  time: 0.0721  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:08  loss: 0.4115 (0.9994)  labels_encoder: 0.2645 (0.6398)  labels_decoder: 0.1682 (0.3596)  labels_encoder_unscaled: 0.2645 (0.6398)  labels_decoder_unscaled: 0.3364 (0.7191)  time: 0.0726  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:04  loss: 0.8446 (1.0014)  labels_encoder: 0.5200 (0.6417)  labels_decoder: 0.2970 (0.3596)  labels_encoder_unscaled: 0.5200 (0.6417)  labels_decoder_unscaled: 0.5940 (0.7192)  time: 0.0722  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.7679 (0.9963)  labels_encoder: 0.4807 (0.6377)  labels_decoder: 0.3413 (0.3586)  labels_encoder_unscaled: 0.4807 (0.6377)  labels_decoder_unscaled: 0.6826 (0.7172)  time: 0.0731  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7171 (0.9945)  labels_encoder: 0.3758 (0.6367)  labels_decoder: 0.2872 (0.3578)  labels_encoder_unscaled: 0.3758 (0.6367)  labels_decoder_unscaled: 0.5744 (0.7156)  time: 0.0557  data: 0.0001  max mem: 3463
Test: Total time: 0:01:56 (0.0722 s / it)
Averaged stats: loss: 0.7171 (0.9945)  labels_encoder: 0.3758 (0.6367)  labels_decoder: 0.2872 (0.3578)  labels_encoder_unscaled: 0.3758 (0.6367)  labels_decoder_unscaled: 0.5744 (0.7156)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-kin] mAP: 0.6416

dec_mAP all together: | 0.5098861683927268 |.
dec_mAP_pred | 0 : 0.5581653115508629 |.
dec_mAP_pred | 1 : 0.5494648075194797 |.
dec_mAP_pred | 2 : 0.5360740242604318 |.
dec_mAP_pred | 3 : 0.5212506987264238 |.
dec_mAP_pred | 4 : 0.5051518411168843 |.
dec_mAP_pred | 5 : 0.4886495044253015 |.
dec_mAP_pred | 6 : 0.47248688050935145 |.
dec_mAP_pred | 7 : 0.45701069535528915 |.
all decoder map: | 0.5110 |.
BaseballPitch: 0.3452
BasketballDunk: 0.8140
Billiards: 0.2646
CleanAndJerk: 0.7450
CliffDiving: 0.8623
CricketBowling: 0.4602
CricketShot: 0.2742
Diving: 0.8623
FrisbeeCatch: 0.4863
GolfSwing: 0.7743
HammerThrow: 0.8690
HighJump: 0.7872
JavelinThrow: 0.7617
LongJump: 0.7822
PoleVault: 0.8660
Shotput: 0.7152
SoccerPenalty: 0.4707
TennisSwing: 0.5778
ThrowDiscus: 0.6612
VolleyballSpiking: 0.4527
Epoch: [4]  [   0/1404]  eta: 0:47:26  lr: 0.000000  loss: 0.2080 (0.2080)  labels_encoder: 0.0868 (0.0868)  labels_decoder: 0.1212 (0.1212)  labels_encoder_unscaled: 0.0868 (0.0868)  labels_decoder_unscaled: 0.2424 (0.2424)  time: 2.0275  data: 1.8651  max mem: 3463
Epoch: [4]  [  50/1404]  eta: 0:04:05  lr: 0.000000  loss: 0.2281 (0.2359)  labels_encoder: 0.1135 (0.1198)  labels_decoder: 0.1122 (0.1161)  labels_encoder_unscaled: 0.1135 (0.1198)  labels_decoder_unscaled: 0.2243 (0.2323)  time: 0.1377  data: 0.0003  max mem: 3463
Epoch: [4]  [ 100/1404]  eta: 0:03:32  lr: 0.000000  loss: 0.2209 (0.2294)  labels_encoder: 0.1066 (0.1152)  labels_decoder: 0.1132 (0.1142)  labels_encoder_unscaled: 0.1066 (0.1152)  labels_decoder_unscaled: 0.2264 (0.2283)  time: 0.1424  data: 0.0003  max mem: 3463
Epoch: [4]  [ 150/1404]  eta: 0:03:16  lr: 0.000000  loss: 0.2121 (0.2317)  labels_encoder: 0.1038 (0.1180)  labels_decoder: 0.1083 (0.1137)  labels_encoder_unscaled: 0.1038 (0.1180)  labels_decoder_unscaled: 0.2166 (0.2275)  time: 0.1401  data: 0.0003  max mem: 3463
Epoch: [4]  [ 200/1404]  eta: 0:03:06  lr: 0.000000  loss: 0.2071 (0.2284)  labels_encoder: 0.0961 (0.1161)  labels_decoder: 0.1004 (0.1123)  labels_encoder_unscaled: 0.0961 (0.1161)  labels_decoder_unscaled: 0.2009 (0.2246)  time: 0.1461  data: 0.0003  max mem: 3463
Epoch: [4]  [ 250/1404]  eta: 0:02:56  lr: 0.000000  loss: 0.2371 (0.2294)  labels_encoder: 0.1275 (0.1168)  labels_decoder: 0.1138 (0.1126)  labels_encoder_unscaled: 0.1275 (0.1168)  labels_decoder_unscaled: 0.2275 (0.2252)  time: 0.1488  data: 0.0003  max mem: 3463
Epoch: [4]  [ 300/1404]  eta: 0:02:48  lr: 0.000000  loss: 0.2284 (0.2293)  labels_encoder: 0.1154 (0.1168)  labels_decoder: 0.1140 (0.1125)  labels_encoder_unscaled: 0.1154 (0.1168)  labels_decoder_unscaled: 0.2280 (0.2250)  time: 0.1508  data: 0.0003  max mem: 3463
Epoch: [4]  [ 350/1404]  eta: 0:02:39  lr: 0.000000  loss: 0.2370 (0.2308)  labels_encoder: 0.1142 (0.1173)  labels_decoder: 0.1170 (0.1135)  labels_encoder_unscaled: 0.1142 (0.1173)  labels_decoder_unscaled: 0.2340 (0.2271)  time: 0.1465  data: 0.0002  max mem: 3463
Epoch: [4]  [ 400/1404]  eta: 0:02:32  lr: 0.000000  loss: 0.2395 (0.2326)  labels_encoder: 0.1305 (0.1188)  labels_decoder: 0.1150 (0.1138)  labels_encoder_unscaled: 0.1305 (0.1188)  labels_decoder_unscaled: 0.2300 (0.2276)  time: 0.1501  data: 0.0003  max mem: 3463
Epoch: [4]  [ 450/1404]  eta: 0:02:24  lr: 0.000000  loss: 0.2275 (0.2325)  labels_encoder: 0.1152 (0.1186)  labels_decoder: 0.1133 (0.1138)  labels_encoder_unscaled: 0.1152 (0.1186)  labels_decoder_unscaled: 0.2266 (0.2277)  time: 0.1510  data: 0.0003  max mem: 3463
Epoch: [4]  [ 500/1404]  eta: 0:02:17  lr: 0.000000  loss: 0.2085 (0.2317)  labels_encoder: 0.1025 (0.1181)  labels_decoder: 0.1023 (0.1136)  labels_encoder_unscaled: 0.1025 (0.1181)  labels_decoder_unscaled: 0.2047 (0.2271)  time: 0.1508  data: 0.0003  max mem: 3463
Epoch: [4]  [ 550/1404]  eta: 0:02:09  lr: 0.000000  loss: 0.2374 (0.2321)  labels_encoder: 0.1273 (0.1186)  labels_decoder: 0.1143 (0.1134)  labels_encoder_unscaled: 0.1273 (0.1186)  labels_decoder_unscaled: 0.2287 (0.2269)  time: 0.1514  data: 0.0003  max mem: 3463
Epoch: [4]  [ 600/1404]  eta: 0:02:01  lr: 0.000000  loss: 0.2353 (0.2331)  labels_encoder: 0.1160 (0.1194)  labels_decoder: 0.1137 (0.1137)  labels_encoder_unscaled: 0.1160 (0.1194)  labels_decoder_unscaled: 0.2274 (0.2274)  time: 0.1458  data: 0.0003  max mem: 3463
Epoch: [4]  [ 650/1404]  eta: 0:01:53  lr: 0.000000  loss: 0.2383 (0.2327)  labels_encoder: 0.1230 (0.1191)  labels_decoder: 0.1134 (0.1136)  labels_encoder_unscaled: 0.1230 (0.1191)  labels_decoder_unscaled: 0.2268 (0.2272)  time: 0.1515  data: 0.0003  max mem: 3463
Epoch: [4]  [ 700/1404]  eta: 0:01:46  lr: 0.000000  loss: 0.2225 (0.2322)  labels_encoder: 0.0994 (0.1188)  labels_decoder: 0.1062 (0.1134)  labels_encoder_unscaled: 0.0994 (0.1188)  labels_decoder_unscaled: 0.2123 (0.2268)  time: 0.1592  data: 0.0003  max mem: 3463
Epoch: [4]  [ 750/1404]  eta: 0:01:39  lr: 0.000000  loss: 0.2210 (0.2319)  labels_encoder: 0.1091 (0.1185)  labels_decoder: 0.1094 (0.1134)  labels_encoder_unscaled: 0.1091 (0.1185)  labels_decoder_unscaled: 0.2189 (0.2269)  time: 0.1595  data: 0.0003  max mem: 3463
Epoch: [4]  [ 800/1404]  eta: 0:01:32  lr: 0.000000  loss: 0.2416 (0.2323)  labels_encoder: 0.1186 (0.1188)  labels_decoder: 0.1200 (0.1136)  labels_encoder_unscaled: 0.1186 (0.1188)  labels_decoder_unscaled: 0.2400 (0.2271)  time: 0.1592  data: 0.0003  max mem: 3463
Epoch: [4]  [ 850/1404]  eta: 0:01:24  lr: 0.000000  loss: 0.2274 (0.2322)  labels_encoder: 0.0988 (0.1186)  labels_decoder: 0.1167 (0.1136)  labels_encoder_unscaled: 0.0988 (0.1186)  labels_decoder_unscaled: 0.2334 (0.2272)  time: 0.1578  data: 0.0003  max mem: 3463
Epoch: [4]  [ 900/1404]  eta: 0:01:17  lr: 0.000000  loss: 0.2369 (0.2323)  labels_encoder: 0.1209 (0.1187)  labels_decoder: 0.1134 (0.1136)  labels_encoder_unscaled: 0.1209 (0.1187)  labels_decoder_unscaled: 0.2267 (0.2272)  time: 0.1600  data: 0.0003  max mem: 3463
Epoch: [4]  [ 950/1404]  eta: 0:01:09  lr: 0.000000  loss: 0.2449 (0.2326)  labels_encoder: 0.1243 (0.1191)  labels_decoder: 0.1182 (0.1136)  labels_encoder_unscaled: 0.1243 (0.1191)  labels_decoder_unscaled: 0.2363 (0.2272)  time: 0.1630  data: 0.0003  max mem: 3463
Epoch: [4]  [1000/1404]  eta: 0:01:02  lr: 0.000000  loss: 0.2386 (0.2326)  labels_encoder: 0.1186 (0.1190)  labels_decoder: 0.1109 (0.1136)  labels_encoder_unscaled: 0.1186 (0.1190)  labels_decoder_unscaled: 0.2218 (0.2272)  time: 0.1543  data: 0.0003  max mem: 3463
Epoch: [4]  [1050/1404]  eta: 0:00:54  lr: 0.000000  loss: 0.2307 (0.2326)  labels_encoder: 0.1111 (0.1191)  labels_decoder: 0.1094 (0.1135)  labels_encoder_unscaled: 0.1111 (0.1191)  labels_decoder_unscaled: 0.2187 (0.2270)  time: 0.1565  data: 0.0003  max mem: 3463
Epoch: [4]  [1100/1404]  eta: 0:00:46  lr: 0.000000  loss: 0.2270 (0.2323)  labels_encoder: 0.1191 (0.1188)  labels_decoder: 0.1129 (0.1135)  labels_encoder_unscaled: 0.1191 (0.1188)  labels_decoder_unscaled: 0.2259 (0.2270)  time: 0.1583  data: 0.0003  max mem: 3463
Epoch: [4]  [1150/1404]  eta: 0:00:39  lr: 0.000000  loss: 0.2292 (0.2327)  labels_encoder: 0.1147 (0.1192)  labels_decoder: 0.1125 (0.1135)  labels_encoder_unscaled: 0.1147 (0.1192)  labels_decoder_unscaled: 0.2249 (0.2270)  time: 0.1597  data: 0.0003  max mem: 3463
Epoch: [4]  [1200/1404]  eta: 0:00:31  lr: 0.000000  loss: 0.2231 (0.2324)  labels_encoder: 0.1058 (0.1190)  labels_decoder: 0.1116 (0.1134)  labels_encoder_unscaled: 0.1058 (0.1190)  labels_decoder_unscaled: 0.2232 (0.2269)  time: 0.1591  data: 0.0003  max mem: 3463
Epoch: [4]  [1250/1404]  eta: 0:00:23  lr: 0.000000  loss: 0.2220 (0.2326)  labels_encoder: 0.1132 (0.1191)  labels_decoder: 0.1113 (0.1135)  labels_encoder_unscaled: 0.1132 (0.1191)  labels_decoder_unscaled: 0.2226 (0.2269)  time: 0.1602  data: 0.0002  max mem: 3463
Epoch: [4]  [1300/1404]  eta: 0:00:16  lr: 0.000000  loss: 0.2309 (0.2326)  labels_encoder: 0.1175 (0.1191)  labels_decoder: 0.1045 (0.1136)  labels_encoder_unscaled: 0.1175 (0.1191)  labels_decoder_unscaled: 0.2091 (0.2271)  time: 0.1520  data: 0.0003  max mem: 3463
Epoch: [4]  [1350/1404]  eta: 0:00:08  lr: 0.000000  loss: 0.2152 (0.2328)  labels_encoder: 0.1112 (0.1192)  labels_decoder: 0.1083 (0.1136)  labels_encoder_unscaled: 0.1112 (0.1192)  labels_decoder_unscaled: 0.2165 (0.2271)  time: 0.1447  data: 0.0002  max mem: 3463
Epoch: [4]  [1400/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2201 (0.2327)  labels_encoder: 0.1146 (0.1192)  labels_decoder: 0.1085 (0.1135)  labels_encoder_unscaled: 0.1146 (0.1192)  labels_decoder_unscaled: 0.2170 (0.2270)  time: 0.1309  data: 0.0003  max mem: 3463
Epoch: [4]  [1403/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2201 (0.2327)  labels_encoder: 0.1114 (0.1192)  labels_decoder: 0.1085 (0.1135)  labels_encoder_unscaled: 0.1114 (0.1192)  labels_decoder_unscaled: 0.2170 (0.2270)  time: 0.1266  data: 0.0003  max mem: 3463
Epoch: [4] Total time: 0:03:36 (0.1541 s / it)
Averaged stats: lr: 0.000000  loss: 0.2201 (0.2327)  labels_encoder: 0.1114 (0.1192)  labels_decoder: 0.1085 (0.1135)  labels_encoder_unscaled: 0.1114 (0.1192)  labels_decoder_unscaled: 0.2170 (0.2270)
Test:  [   0/1613]  eta: 0:51:43  loss: 0.9330 (0.9330)  labels_encoder: 0.5427 (0.5427)  labels_decoder: 0.3903 (0.3903)  labels_encoder_unscaled: 0.5427 (0.5427)  labels_decoder_unscaled: 0.7806 (0.7806)  time: 1.9242  data: 1.8379  max mem: 3463
Test:  [  50/1613]  eta: 0:02:41  loss: 0.4821 (0.8714)  labels_encoder: 0.3024 (0.5408)  labels_decoder: 0.1955 (0.3306)  labels_encoder_unscaled: 0.3024 (0.5408)  labels_decoder_unscaled: 0.3911 (0.6612)  time: 0.0696  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:08  loss: 0.4861 (0.7585)  labels_encoder: 0.2847 (0.4928)  labels_decoder: 0.1397 (0.2657)  labels_encoder_unscaled: 0.2847 (0.4928)  labels_decoder_unscaled: 0.2795 (0.5314)  time: 0.0666  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:54  loss: 0.7436 (0.7246)  labels_encoder: 0.5213 (0.4651)  labels_decoder: 0.2174 (0.2595)  labels_encoder_unscaled: 0.5213 (0.4651)  labels_decoder_unscaled: 0.4347 (0.5190)  time: 0.0663  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:46  loss: 0.8722 (0.8371)  labels_encoder: 0.4884 (0.5325)  labels_decoder: 0.3606 (0.3046)  labels_encoder_unscaled: 0.4884 (0.5325)  labels_decoder_unscaled: 0.7212 (0.6092)  time: 0.0638  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:41  loss: 0.6833 (0.9026)  labels_encoder: 0.3403 (0.5722)  labels_decoder: 0.3450 (0.3304)  labels_encoder_unscaled: 0.3403 (0.5722)  labels_decoder_unscaled: 0.6899 (0.6608)  time: 0.0760  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:37  loss: 0.6766 (0.9001)  labels_encoder: 0.4217 (0.5693)  labels_decoder: 0.2616 (0.3308)  labels_encoder_unscaled: 0.4217 (0.5693)  labels_decoder_unscaled: 0.5233 (0.6616)  time: 0.0676  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:33  loss: 1.1433 (0.9299)  labels_encoder: 0.6441 (0.5910)  labels_decoder: 0.5160 (0.3389)  labels_encoder_unscaled: 0.6441 (0.5910)  labels_decoder_unscaled: 1.0319 (0.6778)  time: 0.0702  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:28  loss: 0.7022 (1.0043)  labels_encoder: 0.3824 (0.6417)  labels_decoder: 0.3109 (0.3625)  labels_encoder_unscaled: 0.3824 (0.6417)  labels_decoder_unscaled: 0.6218 (0.7251)  time: 0.0659  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:24  loss: 0.7856 (1.0894)  labels_encoder: 0.5638 (0.7027)  labels_decoder: 0.2754 (0.3868)  labels_encoder_unscaled: 0.5638 (0.7027)  labels_decoder_unscaled: 0.5507 (0.7735)  time: 0.0708  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:20  loss: 0.3393 (1.0461)  labels_encoder: 0.1813 (0.6718)  labels_decoder: 0.1578 (0.3742)  labels_encoder_unscaled: 0.1813 (0.6718)  labels_decoder_unscaled: 0.3156 (0.7485)  time: 0.0699  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:16  loss: 0.6102 (1.0254)  labels_encoder: 0.3597 (0.6583)  labels_decoder: 0.2069 (0.3671)  labels_encoder_unscaled: 0.3597 (0.6583)  labels_decoder_unscaled: 0.4137 (0.7342)  time: 0.0692  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:12  loss: 0.8107 (1.0692)  labels_encoder: 0.4550 (0.6948)  labels_decoder: 0.3013 (0.3744)  labels_encoder_unscaled: 0.4550 (0.6948)  labels_decoder_unscaled: 0.6026 (0.7489)  time: 0.0694  data: 0.0015  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:09  loss: 1.4595 (1.0776)  labels_encoder: 0.8751 (0.6977)  labels_decoder: 0.5279 (0.3799)  labels_encoder_unscaled: 0.8751 (0.6977)  labels_decoder_unscaled: 1.0557 (0.7598)  time: 0.0738  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:01:05  loss: 0.5213 (1.0520)  labels_encoder: 0.2894 (0.6796)  labels_decoder: 0.2365 (0.3724)  labels_encoder_unscaled: 0.2894 (0.6796)  labels_decoder_unscaled: 0.4730 (0.7448)  time: 0.0730  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:01:02  loss: 0.7323 (1.0318)  labels_encoder: 0.4924 (0.6654)  labels_decoder: 0.2712 (0.3664)  labels_encoder_unscaled: 0.4924 (0.6654)  labels_decoder_unscaled: 0.5424 (0.7328)  time: 0.0778  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:58  loss: 0.5210 (1.0188)  labels_encoder: 0.2666 (0.6569)  labels_decoder: 0.2486 (0.3619)  labels_encoder_unscaled: 0.2666 (0.6569)  labels_decoder_unscaled: 0.4972 (0.7237)  time: 0.0783  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:55  loss: 1.2358 (1.0264)  labels_encoder: 0.6100 (0.6588)  labels_decoder: 0.4394 (0.3676)  labels_encoder_unscaled: 0.6100 (0.6588)  labels_decoder_unscaled: 0.8787 (0.7352)  time: 0.0737  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:51  loss: 0.5254 (1.0086)  labels_encoder: 0.2829 (0.6451)  labels_decoder: 0.2654 (0.3635)  labels_encoder_unscaled: 0.2829 (0.6451)  labels_decoder_unscaled: 0.5309 (0.7271)  time: 0.0719  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:48  loss: 0.9178 (1.0039)  labels_encoder: 0.5760 (0.6412)  labels_decoder: 0.3325 (0.3627)  labels_encoder_unscaled: 0.5760 (0.6412)  labels_decoder_unscaled: 0.6650 (0.7253)  time: 0.0762  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:44  loss: 0.5337 (0.9894)  labels_encoder: 0.3214 (0.6311)  labels_decoder: 0.2637 (0.3583)  labels_encoder_unscaled: 0.3214 (0.6311)  labels_decoder_unscaled: 0.5273 (0.7166)  time: 0.0766  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:41  loss: 0.9497 (0.9957)  labels_encoder: 0.6161 (0.6361)  labels_decoder: 0.3402 (0.3596)  labels_encoder_unscaled: 0.6161 (0.6361)  labels_decoder_unscaled: 0.6805 (0.7193)  time: 0.0781  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:37  loss: 0.3886 (0.9919)  labels_encoder: 0.1967 (0.6345)  labels_decoder: 0.2045 (0.3574)  labels_encoder_unscaled: 0.1967 (0.6345)  labels_decoder_unscaled: 0.4089 (0.7148)  time: 0.0740  data: 0.0013  max mem: 3463
Test:  [1150/1613]  eta: 0:00:33  loss: 0.5092 (0.9859)  labels_encoder: 0.3894 (0.6309)  labels_decoder: 0.1950 (0.3550)  labels_encoder_unscaled: 0.3894 (0.6309)  labels_decoder_unscaled: 0.3900 (0.7100)  time: 0.0741  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:30  loss: 0.5138 (0.9935)  labels_encoder: 0.2605 (0.6360)  labels_decoder: 0.2300 (0.3575)  labels_encoder_unscaled: 0.2605 (0.6360)  labels_decoder_unscaled: 0.4599 (0.7150)  time: 0.0760  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:26  loss: 0.5499 (0.9930)  labels_encoder: 0.2886 (0.6359)  labels_decoder: 0.1979 (0.3571)  labels_encoder_unscaled: 0.2886 (0.6359)  labels_decoder_unscaled: 0.3958 (0.7143)  time: 0.0711  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:22  loss: 0.6238 (0.9852)  labels_encoder: 0.3930 (0.6299)  labels_decoder: 0.3099 (0.3553)  labels_encoder_unscaled: 0.3930 (0.6299)  labels_decoder_unscaled: 0.6199 (0.7106)  time: 0.0708  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:19  loss: 1.1058 (0.9910)  labels_encoder: 0.6713 (0.6342)  labels_decoder: 0.3873 (0.3568)  labels_encoder_unscaled: 0.6713 (0.6342)  labels_decoder_unscaled: 0.7747 (0.7135)  time: 0.0696  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:15  loss: 0.7816 (0.9989)  labels_encoder: 0.5123 (0.6396)  labels_decoder: 0.2916 (0.3593)  labels_encoder_unscaled: 0.5123 (0.6396)  labels_decoder_unscaled: 0.5831 (0.7185)  time: 0.0703  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:11  loss: 0.5858 (1.0045)  labels_encoder: 0.2542 (0.6430)  labels_decoder: 0.2236 (0.3615)  labels_encoder_unscaled: 0.2542 (0.6430)  labels_decoder_unscaled: 0.4472 (0.7230)  time: 0.0741  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:08  loss: 0.4104 (1.0028)  labels_encoder: 0.2628 (0.6424)  labels_decoder: 0.1683 (0.3604)  labels_encoder_unscaled: 0.2628 (0.6424)  labels_decoder_unscaled: 0.3366 (0.7208)  time: 0.0786  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:04  loss: 0.8696 (1.0047)  labels_encoder: 0.5404 (0.6443)  labels_decoder: 0.2937 (0.3604)  labels_encoder_unscaled: 0.5404 (0.6443)  labels_decoder_unscaled: 0.5875 (0.7209)  time: 0.0752  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.7633 (0.9995)  labels_encoder: 0.4764 (0.6402)  labels_decoder: 0.3286 (0.3593)  labels_encoder_unscaled: 0.4764 (0.6402)  labels_decoder_unscaled: 0.6572 (0.7187)  time: 0.0703  data: 0.0013  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6824 (0.9977)  labels_encoder: 0.3538 (0.6391)  labels_decoder: 0.2869 (0.3585)  labels_encoder_unscaled: 0.3538 (0.6391)  labels_decoder_unscaled: 0.5738 (0.7171)  time: 0.0541  data: 0.0013  max mem: 3463
Test: Total time: 0:01:58 (0.0733 s / it)
Averaged stats: loss: 0.6824 (0.9977)  labels_encoder: 0.3538 (0.6391)  labels_decoder: 0.2869 (0.3585)  labels_encoder_unscaled: 0.3538 (0.6391)  labels_decoder_unscaled: 0.5738 (0.7171)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-kin] mAP: 0.6413

dec_mAP all together: | 0.509629138162961 |.
dec_mAP_pred | 0 : 0.5579736786949498 |.
dec_mAP_pred | 1 : 0.5492234118086656 |.
dec_mAP_pred | 2 : 0.5358014284510089 |.
dec_mAP_pred | 3 : 0.5209755847549846 |.
dec_mAP_pred | 4 : 0.5048611717102236 |.
dec_mAP_pred | 5 : 0.48834916068377804 |.
dec_mAP_pred | 6 : 0.4721959605710473 |.
dec_mAP_pred | 7 : 0.45673118860000167 |.
all decoder map: | 0.5108 |.
BaseballPitch: 0.3443
BasketballDunk: 0.8140
Billiards: 0.2644
CleanAndJerk: 0.7448
CliffDiving: 0.8622
CricketBowling: 0.4609
CricketShot: 0.2729
Diving: 0.8620
FrisbeeCatch: 0.4862
GolfSwing: 0.7738
HammerThrow: 0.8684
HighJump: 0.7879
JavelinThrow: 0.7609
LongJump: 0.7818
PoleVault: 0.8662
Shotput: 0.7137
SoccerPenalty: 0.4703
TennisSwing: 0.5775
ThrowDiscus: 0.6605
VolleyballSpiking: 0.4530
Training time 0:24:56
