Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:kin
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:3
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  75.627 M, 99.827% Params, 2.513 GMac, 100.000% MACs, 
  (linear_encoding): Linear(4.195 M, 5.538% Params, 0.268 GMac, 10.682% MACs, in_features=4096, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 24.926% Params, 1.227 GMac, 48.829% MACs, 
    (net): Sequential(
      18.884 M, 24.926% Params, 1.227 GMac, 48.829% MACs, 
      (0): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.538% Params, 0.273 GMac, 10.849% MACs, 
            (qkv): Linear(3.146 M, 4.152% Params, 0.204 GMac, 8.137% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
        (fn): PreNorm(
          2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
            (net): Sequential(
              2.099 M, 2.771% Params, 0.136 GMac, 5.427% MACs, 
              (0): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.060% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 69.274% Params, 1.017 GMac, 40.480% MACs, 
    (layers): ModuleList(
      52.48 M, 69.274% Params, 1.017 GMac, 40.480% MACs, 
      (0): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 13.855% Params, 0.203 GMac, 8.096% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.034 GMac, 1.335% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.542% Params, 0.153 GMac, 6.092% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.385% Params, 0.068 GMac, 2.712% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.385% Params, 0.008 GMac, 0.334% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.030% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2512946220.0
Model params: 75757612
Loaded data/thumos_kin_val.pickle
Loaded data/thumos_kin_test.pickle
Start training
Epoch: [1]  [   0/1406]  eta: 0:58:59  lr: 0.000100  loss: 5.3304 (5.3304)  labels_encoder: 3.6538 (3.6538)  labels_decoder: 1.6766 (1.6766)  labels_encoder_unscaled: 3.6538 (3.6538)  labels_decoder_unscaled: 3.3532 (3.3532)  time: 2.5172  data: 1.8298  max mem: 2596
Epoch: [1]  [  50/1406]  eta: 0:04:15  lr: 0.000100  loss: 1.0106 (1.5350)  labels_encoder: 0.6471 (0.9884)  labels_decoder: 0.3632 (0.5467)  labels_encoder_unscaled: 0.6471 (0.9884)  labels_decoder_unscaled: 0.7263 (1.0933)  time: 0.1272  data: 0.0003  max mem: 3463
Epoch: [1]  [ 100/1406]  eta: 0:03:35  lr: 0.000100  loss: 0.6875 (1.1512)  labels_encoder: 0.4149 (0.7310)  labels_decoder: 0.2571 (0.4203)  labels_encoder_unscaled: 0.4149 (0.7310)  labels_decoder_unscaled: 0.5142 (0.8405)  time: 0.1406  data: 0.0003  max mem: 3463
Epoch: [1]  [ 150/1406]  eta: 0:03:18  lr: 0.000100  loss: 0.6819 (1.0003)  labels_encoder: 0.4367 (0.6296)  labels_decoder: 0.2510 (0.3707)  labels_encoder_unscaled: 0.4367 (0.6296)  labels_decoder_unscaled: 0.5021 (0.7414)  time: 0.1393  data: 0.0003  max mem: 3463
Epoch: [1]  [ 200/1406]  eta: 0:03:04  lr: 0.000100  loss: 0.6345 (0.9090)  labels_encoder: 0.3919 (0.5707)  labels_decoder: 0.2356 (0.3383)  labels_encoder_unscaled: 0.3919 (0.5707)  labels_decoder_unscaled: 0.4712 (0.6766)  time: 0.1405  data: 0.0003  max mem: 3463
Epoch: [1]  [ 250/1406]  eta: 0:02:54  lr: 0.000100  loss: 0.5970 (0.8468)  labels_encoder: 0.3574 (0.5295)  labels_decoder: 0.2351 (0.3174)  labels_encoder_unscaled: 0.3574 (0.5295)  labels_decoder_unscaled: 0.4702 (0.6347)  time: 0.1422  data: 0.0003  max mem: 3463
Epoch: [1]  [ 300/1406]  eta: 0:02:45  lr: 0.000100  loss: 0.5512 (0.8006)  labels_encoder: 0.3227 (0.4981)  labels_decoder: 0.2257 (0.3025)  labels_encoder_unscaled: 0.3227 (0.4981)  labels_decoder_unscaled: 0.4515 (0.6051)  time: 0.1471  data: 0.0003  max mem: 3463
Epoch: [1]  [ 350/1406]  eta: 0:02:37  lr: 0.000100  loss: 0.5022 (0.7641)  labels_encoder: 0.2994 (0.4735)  labels_decoder: 0.2106 (0.2907)  labels_encoder_unscaled: 0.2994 (0.4735)  labels_decoder_unscaled: 0.4213 (0.5813)  time: 0.1470  data: 0.0003  max mem: 3463
Epoch: [1]  [ 400/1406]  eta: 0:02:29  lr: 0.000100  loss: 0.4833 (0.7352)  labels_encoder: 0.2874 (0.4546)  labels_decoder: 0.1978 (0.2805)  labels_encoder_unscaled: 0.2874 (0.4546)  labels_decoder_unscaled: 0.3956 (0.5611)  time: 0.1408  data: 0.0003  max mem: 3463
Epoch: [1]  [ 450/1406]  eta: 0:02:21  lr: 0.000100  loss: 0.4932 (0.7085)  labels_encoder: 0.2843 (0.4365)  labels_decoder: 0.1973 (0.2720)  labels_encoder_unscaled: 0.2843 (0.4365)  labels_decoder_unscaled: 0.3946 (0.5441)  time: 0.1429  data: 0.0010  max mem: 3463
Epoch: [1]  [ 500/1406]  eta: 0:02:14  lr: 0.000100  loss: 0.4890 (0.6880)  labels_encoder: 0.2921 (0.4231)  labels_decoder: 0.1969 (0.2649)  labels_encoder_unscaled: 0.2921 (0.4231)  labels_decoder_unscaled: 0.3937 (0.5297)  time: 0.1470  data: 0.0003  max mem: 3463
Epoch: [1]  [ 550/1406]  eta: 0:02:06  lr: 0.000100  loss: 0.4684 (0.6679)  labels_encoder: 0.2729 (0.4094)  labels_decoder: 0.1914 (0.2586)  labels_encoder_unscaled: 0.2729 (0.4094)  labels_decoder_unscaled: 0.3828 (0.5171)  time: 0.1478  data: 0.0003  max mem: 3463
Epoch: [1]  [ 600/1406]  eta: 0:01:58  lr: 0.000100  loss: 0.4511 (0.6523)  labels_encoder: 0.2781 (0.3989)  labels_decoder: 0.1818 (0.2533)  labels_encoder_unscaled: 0.2781 (0.3989)  labels_decoder_unscaled: 0.3637 (0.5067)  time: 0.1443  data: 0.0003  max mem: 3463
Epoch: [1]  [ 650/1406]  eta: 0:01:51  lr: 0.000100  loss: 0.4629 (0.6393)  labels_encoder: 0.2701 (0.3901)  labels_decoder: 0.1889 (0.2491)  labels_encoder_unscaled: 0.2701 (0.3901)  labels_decoder_unscaled: 0.3778 (0.4983)  time: 0.1422  data: 0.0003  max mem: 3463
Epoch: [1]  [ 700/1406]  eta: 0:01:43  lr: 0.000100  loss: 0.4406 (0.6260)  labels_encoder: 0.2608 (0.3811)  labels_decoder: 0.1870 (0.2449)  labels_encoder_unscaled: 0.2608 (0.3811)  labels_decoder_unscaled: 0.3740 (0.4898)  time: 0.1446  data: 0.0002  max mem: 3463
Epoch: [1]  [ 750/1406]  eta: 0:01:36  lr: 0.000100  loss: 0.4235 (0.6139)  labels_encoder: 0.2638 (0.3730)  labels_decoder: 0.1777 (0.2409)  labels_encoder_unscaled: 0.2638 (0.3730)  labels_decoder_unscaled: 0.3554 (0.4817)  time: 0.1435  data: 0.0003  max mem: 3463
Epoch: [1]  [ 800/1406]  eta: 0:01:28  lr: 0.000100  loss: 0.3815 (0.6035)  labels_encoder: 0.2184 (0.3660)  labels_decoder: 0.1748 (0.2375)  labels_encoder_unscaled: 0.2184 (0.3660)  labels_decoder_unscaled: 0.3496 (0.4750)  time: 0.1453  data: 0.0003  max mem: 3463
Epoch: [1]  [ 850/1406]  eta: 0:01:21  lr: 0.000100  loss: 0.3959 (0.5926)  labels_encoder: 0.2142 (0.3586)  labels_decoder: 0.1709 (0.2340)  labels_encoder_unscaled: 0.2142 (0.3586)  labels_decoder_unscaled: 0.3419 (0.4680)  time: 0.1462  data: 0.0003  max mem: 3463
Epoch: [1]  [ 900/1406]  eta: 0:01:14  lr: 0.000100  loss: 0.4063 (0.5828)  labels_encoder: 0.2417 (0.3522)  labels_decoder: 0.1659 (0.2306)  labels_encoder_unscaled: 0.2417 (0.3522)  labels_decoder_unscaled: 0.3318 (0.4612)  time: 0.1454  data: 0.0003  max mem: 3463
Epoch: [1]  [ 950/1406]  eta: 0:01:06  lr: 0.000100  loss: 0.3647 (0.5737)  labels_encoder: 0.2101 (0.3461)  labels_decoder: 0.1591 (0.2276)  labels_encoder_unscaled: 0.2101 (0.3461)  labels_decoder_unscaled: 0.3181 (0.4551)  time: 0.1485  data: 0.0003  max mem: 3463
Epoch: [1]  [1000/1406]  eta: 0:00:59  lr: 0.000100  loss: 0.3854 (0.5654)  labels_encoder: 0.2189 (0.3406)  labels_decoder: 0.1604 (0.2248)  labels_encoder_unscaled: 0.2189 (0.3406)  labels_decoder_unscaled: 0.3208 (0.4496)  time: 0.1483  data: 0.0003  max mem: 3463
Epoch: [1]  [1050/1406]  eta: 0:00:52  lr: 0.000100  loss: 0.4308 (0.5582)  labels_encoder: 0.2538 (0.3358)  labels_decoder: 0.1777 (0.2224)  labels_encoder_unscaled: 0.2538 (0.3358)  labels_decoder_unscaled: 0.3555 (0.4447)  time: 0.1443  data: 0.0002  max mem: 3463
Epoch: [1]  [1100/1406]  eta: 0:00:44  lr: 0.000100  loss: 0.3978 (0.5513)  labels_encoder: 0.2218 (0.3313)  labels_decoder: 0.1617 (0.2200)  labels_encoder_unscaled: 0.2218 (0.3313)  labels_decoder_unscaled: 0.3234 (0.4400)  time: 0.1474  data: 0.0003  max mem: 3463
Epoch: [1]  [1150/1406]  eta: 0:00:37  lr: 0.000100  loss: 0.3560 (0.5444)  labels_encoder: 0.1920 (0.3266)  labels_decoder: 0.1609 (0.2178)  labels_encoder_unscaled: 0.1920 (0.3266)  labels_decoder_unscaled: 0.3218 (0.4357)  time: 0.1474  data: 0.0003  max mem: 3463
Epoch: [1]  [1200/1406]  eta: 0:00:30  lr: 0.000100  loss: 0.3561 (0.5373)  labels_encoder: 0.1964 (0.3218)  labels_decoder: 0.1603 (0.2155)  labels_encoder_unscaled: 0.1964 (0.3218)  labels_decoder_unscaled: 0.3206 (0.4310)  time: 0.1461  data: 0.0003  max mem: 3463
Epoch: [1]  [1250/1406]  eta: 0:00:22  lr: 0.000100  loss: 0.3772 (0.5312)  labels_encoder: 0.2052 (0.3176)  labels_decoder: 0.1662 (0.2136)  labels_encoder_unscaled: 0.2052 (0.3176)  labels_decoder_unscaled: 0.3324 (0.4273)  time: 0.1472  data: 0.0003  max mem: 3463
Epoch: [1]  [1300/1406]  eta: 0:00:15  lr: 0.000100  loss: 0.3713 (0.5251)  labels_encoder: 0.2032 (0.3134)  labels_decoder: 0.1636 (0.2117)  labels_encoder_unscaled: 0.2032 (0.3134)  labels_decoder_unscaled: 0.3273 (0.4233)  time: 0.1483  data: 0.0003  max mem: 3463
Epoch: [1]  [1350/1406]  eta: 0:00:08  lr: 0.000100  loss: 0.3162 (0.5199)  labels_encoder: 0.1642 (0.3098)  labels_decoder: 0.1558 (0.2101)  labels_encoder_unscaled: 0.1642 (0.3098)  labels_decoder_unscaled: 0.3117 (0.4202)  time: 0.1391  data: 0.0002  max mem: 3463
Epoch: [1]  [1400/1406]  eta: 0:00:00  lr: 0.000100  loss: 0.3576 (0.5146)  labels_encoder: 0.2050 (0.3064)  labels_decoder: 0.1524 (0.2082)  labels_encoder_unscaled: 0.2050 (0.3064)  labels_decoder_unscaled: 0.3047 (0.4164)  time: 0.1304  data: 0.0003  max mem: 3463
Epoch: [1]  [1405/1406]  eta: 0:00:00  lr: 0.000100  loss: 0.3423 (0.5140)  labels_encoder: 0.1886 (0.3060)  labels_decoder: 0.1514 (0.2080)  labels_encoder_unscaled: 0.1886 (0.3060)  labels_decoder_unscaled: 0.3029 (0.4160)  time: 0.1246  data: 0.0003  max mem: 3463
Epoch: [1] Total time: 0:03:26 (0.1465 s / it)
Averaged stats: lr: 0.000100  loss: 0.3423 (0.5140)  labels_encoder: 0.1886 (0.3060)  labels_decoder: 0.1514 (0.2080)  labels_encoder_unscaled: 0.1886 (0.3060)  labels_decoder_unscaled: 0.3029 (0.4160)
Test:  [   0/1613]  eta: 0:48:09  loss: 0.5409 (0.5409)  labels_encoder: 0.4627 (0.4627)  labels_decoder: 0.0782 (0.0782)  labels_encoder_unscaled: 0.4627 (0.4627)  labels_decoder_unscaled: 0.1563 (0.1563)  time: 1.7916  data: 1.6899  max mem: 3463
Test:  [  50/1613]  eta: 0:02:33  loss: 0.5881 (0.9860)  labels_encoder: 0.3926 (0.6410)  labels_decoder: 0.2461 (0.3450)  labels_encoder_unscaled: 0.3926 (0.6410)  labels_decoder_unscaled: 0.4921 (0.6900)  time: 0.0627  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:00  loss: 0.4995 (0.8808)  labels_encoder: 0.2651 (0.5910)  labels_decoder: 0.1269 (0.2898)  labels_encoder_unscaled: 0.2651 (0.5910)  labels_decoder_unscaled: 0.2537 (0.5796)  time: 0.0630  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:49  loss: 0.8304 (0.8138)  labels_encoder: 0.5850 (0.5331)  labels_decoder: 0.3014 (0.2807)  labels_encoder_unscaled: 0.5850 (0.5331)  labels_decoder_unscaled: 0.6028 (0.5614)  time: 0.0678  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:43  loss: 0.8650 (0.8937)  labels_encoder: 0.5016 (0.5786)  labels_decoder: 0.3666 (0.3151)  labels_encoder_unscaled: 0.5016 (0.5786)  labels_decoder_unscaled: 0.7333 (0.6301)  time: 0.0741  data: 0.0014  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:39  loss: 0.6827 (0.8970)  labels_encoder: 0.3911 (0.5765)  labels_decoder: 0.2969 (0.3206)  labels_encoder_unscaled: 0.3911 (0.5765)  labels_decoder_unscaled: 0.5938 (0.6411)  time: 0.0732  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:34  loss: 1.3067 (0.9457)  labels_encoder: 0.8562 (0.6113)  labels_decoder: 0.3959 (0.3344)  labels_encoder_unscaled: 0.8562 (0.6113)  labels_decoder_unscaled: 0.7919 (0.6687)  time: 0.0650  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:29  loss: 1.1256 (0.9508)  labels_encoder: 0.6895 (0.6150)  labels_decoder: 0.4035 (0.3358)  labels_encoder_unscaled: 0.6895 (0.6150)  labels_decoder_unscaled: 0.8069 (0.6716)  time: 0.0706  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:24  loss: 0.5877 (1.0370)  labels_encoder: 0.3347 (0.6767)  labels_decoder: 0.3080 (0.3603)  labels_encoder_unscaled: 0.3347 (0.6767)  labels_decoder_unscaled: 0.6160 (0.7206)  time: 0.0587  data: 0.0009  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:19  loss: 0.8398 (1.1301)  labels_encoder: 0.5004 (0.7423)  labels_decoder: 0.3232 (0.3878)  labels_encoder_unscaled: 0.5004 (0.7423)  labels_decoder_unscaled: 0.6465 (0.7756)  time: 0.0668  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:16  loss: 0.3878 (1.0786)  labels_encoder: 0.2100 (0.7075)  labels_decoder: 0.1776 (0.3711)  labels_encoder_unscaled: 0.2100 (0.7075)  labels_decoder_unscaled: 0.3551 (0.7422)  time: 0.0659  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:12  loss: 0.6009 (1.0592)  labels_encoder: 0.3683 (0.6930)  labels_decoder: 0.2615 (0.3661)  labels_encoder_unscaled: 0.3683 (0.6930)  labels_decoder_unscaled: 0.5230 (0.7323)  time: 0.0603  data: 0.0010  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:08  loss: 0.9633 (1.1187)  labels_encoder: 0.5865 (0.7374)  labels_decoder: 0.3411 (0.3813)  labels_encoder_unscaled: 0.5865 (0.7374)  labels_decoder_unscaled: 0.6822 (0.7626)  time: 0.0615  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:04  loss: 0.4626 (1.1042)  labels_encoder: 0.2173 (0.7258)  labels_decoder: 0.2420 (0.3784)  labels_encoder_unscaled: 0.2173 (0.7258)  labels_decoder_unscaled: 0.4840 (0.7569)  time: 0.0601  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:01:00  loss: 0.6061 (1.0765)  labels_encoder: 0.3666 (0.7061)  labels_decoder: 0.2307 (0.3704)  labels_encoder_unscaled: 0.3666 (0.7061)  labels_decoder_unscaled: 0.4614 (0.7407)  time: 0.0646  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:00:57  loss: 0.3849 (1.0473)  labels_encoder: 0.2228 (0.6867)  labels_decoder: 0.1550 (0.3607)  labels_encoder_unscaled: 0.2228 (0.6867)  labels_decoder_unscaled: 0.3100 (0.7213)  time: 0.0621  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:53  loss: 0.6505 (1.0382)  labels_encoder: 0.3927 (0.6818)  labels_decoder: 0.2194 (0.3563)  labels_encoder_unscaled: 0.3927 (0.6818)  labels_decoder_unscaled: 0.4387 (0.7127)  time: 0.0601  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:50  loss: 0.7656 (1.0433)  labels_encoder: 0.4511 (0.6833)  labels_decoder: 0.3036 (0.3599)  labels_encoder_unscaled: 0.4511 (0.6833)  labels_decoder_unscaled: 0.6071 (0.7198)  time: 0.0623  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:46  loss: 0.6338 (1.0273)  labels_encoder: 0.3607 (0.6715)  labels_decoder: 0.2731 (0.3558)  labels_encoder_unscaled: 0.3607 (0.6715)  labels_decoder_unscaled: 0.5461 (0.7117)  time: 0.0679  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:43  loss: 0.9543 (1.0100)  labels_encoder: 0.5754 (0.6610)  labels_decoder: 0.2722 (0.3490)  labels_encoder_unscaled: 0.5754 (0.6610)  labels_decoder_unscaled: 0.5444 (0.6980)  time: 0.0636  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:40  loss: 0.6484 (0.9961)  labels_encoder: 0.3919 (0.6506)  labels_decoder: 0.2452 (0.3455)  labels_encoder_unscaled: 0.3919 (0.6506)  labels_decoder_unscaled: 0.4903 (0.6910)  time: 0.0633  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:36  loss: 1.1048 (1.0060)  labels_encoder: 0.7196 (0.6578)  labels_decoder: 0.3921 (0.3482)  labels_encoder_unscaled: 0.7196 (0.6578)  labels_decoder_unscaled: 0.7843 (0.6964)  time: 0.0605  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:33  loss: 0.4315 (0.9958)  labels_encoder: 0.2762 (0.6508)  labels_decoder: 0.1750 (0.3450)  labels_encoder_unscaled: 0.2762 (0.6508)  labels_decoder_unscaled: 0.3501 (0.6900)  time: 0.0606  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:30  loss: 0.7429 (0.9852)  labels_encoder: 0.5468 (0.6431)  labels_decoder: 0.2164 (0.3421)  labels_encoder_unscaled: 0.5468 (0.6431)  labels_decoder_unscaled: 0.4328 (0.6842)  time: 0.0610  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:26  loss: 0.5377 (0.9920)  labels_encoder: 0.3216 (0.6475)  labels_decoder: 0.2391 (0.3445)  labels_encoder_unscaled: 0.3216 (0.6475)  labels_decoder_unscaled: 0.4782 (0.6890)  time: 0.0636  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:23  loss: 0.3962 (0.9906)  labels_encoder: 0.2417 (0.6458)  labels_decoder: 0.1580 (0.3448)  labels_encoder_unscaled: 0.2417 (0.6458)  labels_decoder_unscaled: 0.3159 (0.6896)  time: 0.0661  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:20  loss: 0.5417 (0.9840)  labels_encoder: 0.3265 (0.6400)  labels_decoder: 0.2291 (0.3440)  labels_encoder_unscaled: 0.3265 (0.6400)  labels_decoder_unscaled: 0.4583 (0.6881)  time: 0.0577  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:17  loss: 1.0174 (0.9859)  labels_encoder: 0.6517 (0.6417)  labels_decoder: 0.3928 (0.3442)  labels_encoder_unscaled: 0.6517 (0.6417)  labels_decoder_unscaled: 0.7855 (0.6884)  time: 0.0629  data: 0.0014  max mem: 3463
Test:  [1400/1613]  eta: 0:00:13  loss: 1.1086 (0.9933)  labels_encoder: 0.6559 (0.6468)  labels_decoder: 0.4177 (0.3465)  labels_encoder_unscaled: 0.6559 (0.6468)  labels_decoder_unscaled: 0.8354 (0.6930)  time: 0.0612  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:10  loss: 0.3923 (0.9985)  labels_encoder: 0.2036 (0.6489)  labels_decoder: 0.2301 (0.3496)  labels_encoder_unscaled: 0.2036 (0.6489)  labels_decoder_unscaled: 0.4602 (0.6991)  time: 0.0552  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:07  loss: 0.9007 (1.0131)  labels_encoder: 0.5017 (0.6597)  labels_decoder: 0.2882 (0.3534)  labels_encoder_unscaled: 0.5017 (0.6597)  labels_decoder_unscaled: 0.5763 (0.7068)  time: 0.0847  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:04  loss: 0.6977 (1.0091)  labels_encoder: 0.4632 (0.6577)  labels_decoder: 0.2547 (0.3514)  labels_encoder_unscaled: 0.4632 (0.6577)  labels_decoder_unscaled: 0.5093 (0.7027)  time: 0.0530  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8354 (1.0066)  labels_encoder: 0.5503 (0.6558)  labels_decoder: 0.3467 (0.3508)  labels_encoder_unscaled: 0.5503 (0.6558)  labels_decoder_unscaled: 0.6934 (0.7017)  time: 0.0523  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6942 (1.0055)  labels_encoder: 0.4256 (0.6554)  labels_decoder: 0.2686 (0.3501)  labels_encoder_unscaled: 0.4256 (0.6554)  labels_decoder_unscaled: 0.5372 (0.7002)  time: 0.0480  data: 0.0001  max mem: 3463
Test: Total time: 0:01:42 (0.0638 s / it)
Averaged stats: loss: 0.6942 (1.0055)  labels_encoder: 0.4256 (0.6554)  labels_decoder: 0.2686 (0.3501)  labels_encoder_unscaled: 0.4256 (0.6554)  labels_decoder_unscaled: 0.5372 (0.7002)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-kin] mAP: 0.6400

dec_mAP all together: | 0.5213769640719266 |.
dec_mAP_pred | 0 : 0.581803995247842 |.
dec_mAP_pred | 1 : 0.5702005017033789 |.
dec_mAP_pred | 2 : 0.5535905792172305 |.
dec_mAP_pred | 3 : 0.5345498268445067 |.
dec_mAP_pred | 4 : 0.5148142047747644 |.
dec_mAP_pred | 5 : 0.49534739045030884 |.
dec_mAP_pred | 6 : 0.47684026349800235 |.
dec_mAP_pred | 7 : 0.4590450656595837 |.
all decoder map: | 0.5233 |.
BaseballPitch: 0.4336
BasketballDunk: 0.8065
Billiards: 0.3065
CleanAndJerk: 0.7460
CliffDiving: 0.8720
CricketBowling: 0.4351
CricketShot: 0.2159
Diving: 0.8461
FrisbeeCatch: 0.4898
GolfSwing: 0.7918
HammerThrow: 0.8698
HighJump: 0.6955
JavelinThrow: 0.7577
LongJump: 0.8241
PoleVault: 0.9046
Shotput: 0.7211
SoccerPenalty: 0.4533
TennisSwing: 0.5392
ThrowDiscus: 0.6738
VolleyballSpiking: 0.4169
Epoch: [2]  [   0/1406]  eta: 0:43:08  lr: 0.000010  loss: 0.3635 (0.3635)  labels_encoder: 0.1884 (0.1884)  labels_decoder: 0.1751 (0.1751)  labels_encoder_unscaled: 0.1884 (0.1884)  labels_decoder_unscaled: 0.3502 (0.3502)  time: 1.8414  data: 1.6896  max mem: 3463
Epoch: [2]  [  50/1406]  eta: 0:03:48  lr: 0.000010  loss: 0.2982 (0.3090)  labels_encoder: 0.1498 (0.1698)  labels_decoder: 0.1341 (0.1392)  labels_encoder_unscaled: 0.1498 (0.1698)  labels_decoder_unscaled: 0.2681 (0.2784)  time: 0.1337  data: 0.0003  max mem: 3463
Epoch: [2]  [ 100/1406]  eta: 0:03:20  lr: 0.000010  loss: 0.2595 (0.2937)  labels_encoder: 0.1354 (0.1593)  labels_decoder: 0.1283 (0.1344)  labels_encoder_unscaled: 0.1354 (0.1593)  labels_decoder_unscaled: 0.2567 (0.2688)  time: 0.1390  data: 0.0003  max mem: 3463
Epoch: [2]  [ 150/1406]  eta: 0:03:07  lr: 0.000010  loss: 0.2743 (0.2932)  labels_encoder: 0.1454 (0.1590)  labels_decoder: 0.1273 (0.1342)  labels_encoder_unscaled: 0.1454 (0.1590)  labels_decoder_unscaled: 0.2546 (0.2684)  time: 0.1438  data: 0.0003  max mem: 3463
Epoch: [2]  [ 200/1406]  eta: 0:02:56  lr: 0.000010  loss: 0.2823 (0.2920)  labels_encoder: 0.1511 (0.1582)  labels_decoder: 0.1256 (0.1338)  labels_encoder_unscaled: 0.1511 (0.1582)  labels_decoder_unscaled: 0.2513 (0.2675)  time: 0.1436  data: 0.0003  max mem: 3463
Epoch: [2]  [ 250/1406]  eta: 0:02:48  lr: 0.000010  loss: 0.2732 (0.2901)  labels_encoder: 0.1365 (0.1569)  labels_decoder: 0.1278 (0.1331)  labels_encoder_unscaled: 0.1365 (0.1569)  labels_decoder_unscaled: 0.2556 (0.2662)  time: 0.1469  data: 0.0003  max mem: 3463
Epoch: [2]  [ 300/1406]  eta: 0:02:41  lr: 0.000010  loss: 0.2807 (0.2881)  labels_encoder: 0.1529 (0.1551)  labels_decoder: 0.1283 (0.1330)  labels_encoder_unscaled: 0.1529 (0.1551)  labels_decoder_unscaled: 0.2566 (0.2659)  time: 0.1494  data: 0.0003  max mem: 3463
Epoch: [2]  [ 350/1406]  eta: 0:02:34  lr: 0.000010  loss: 0.2654 (0.2851)  labels_encoder: 0.1436 (0.1527)  labels_decoder: 0.1280 (0.1324)  labels_encoder_unscaled: 0.1436 (0.1527)  labels_decoder_unscaled: 0.2561 (0.2648)  time: 0.1462  data: 0.0002  max mem: 3463
Epoch: [2]  [ 400/1406]  eta: 0:02:27  lr: 0.000010  loss: 0.2857 (0.2847)  labels_encoder: 0.1571 (0.1526)  labels_decoder: 0.1323 (0.1321)  labels_encoder_unscaled: 0.1571 (0.1526)  labels_decoder_unscaled: 0.2647 (0.2642)  time: 0.1434  data: 0.0002  max mem: 3463
Epoch: [2]  [ 450/1406]  eta: 0:02:18  lr: 0.000010  loss: 0.2588 (0.2836)  labels_encoder: 0.1315 (0.1523)  labels_decoder: 0.1168 (0.1313)  labels_encoder_unscaled: 0.1315 (0.1523)  labels_decoder_unscaled: 0.2336 (0.2626)  time: 0.1303  data: 0.0003  max mem: 3463
Epoch: [2]  [ 500/1406]  eta: 0:02:10  lr: 0.000010  loss: 0.2682 (0.2818)  labels_encoder: 0.1344 (0.1509)  labels_decoder: 0.1246 (0.1310)  labels_encoder_unscaled: 0.1344 (0.1509)  labels_decoder_unscaled: 0.2492 (0.2620)  time: 0.1368  data: 0.0002  max mem: 3463
Epoch: [2]  [ 550/1406]  eta: 0:02:02  lr: 0.000010  loss: 0.2702 (0.2810)  labels_encoder: 0.1397 (0.1500)  labels_decoder: 0.1298 (0.1310)  labels_encoder_unscaled: 0.1397 (0.1500)  labels_decoder_unscaled: 0.2595 (0.2619)  time: 0.1355  data: 0.0002  max mem: 3463
Epoch: [2]  [ 600/1406]  eta: 0:01:55  lr: 0.000010  loss: 0.2522 (0.2799)  labels_encoder: 0.1332 (0.1493)  labels_decoder: 0.1203 (0.1307)  labels_encoder_unscaled: 0.1332 (0.1493)  labels_decoder_unscaled: 0.2406 (0.2613)  time: 0.1381  data: 0.0002  max mem: 3463
Epoch: [2]  [ 650/1406]  eta: 0:01:47  lr: 0.000010  loss: 0.2139 (0.2772)  labels_encoder: 0.1064 (0.1471)  labels_decoder: 0.1177 (0.1301)  labels_encoder_unscaled: 0.1064 (0.1471)  labels_decoder_unscaled: 0.2354 (0.2601)  time: 0.1340  data: 0.0002  max mem: 3463
Epoch: [2]  [ 700/1406]  eta: 0:01:40  lr: 0.000010  loss: 0.2816 (0.2764)  labels_encoder: 0.1527 (0.1466)  labels_decoder: 0.1257 (0.1298)  labels_encoder_unscaled: 0.1527 (0.1466)  labels_decoder_unscaled: 0.2515 (0.2596)  time: 0.1393  data: 0.0002  max mem: 3463
Epoch: [2]  [ 750/1406]  eta: 0:01:33  lr: 0.000010  loss: 0.2771 (0.2757)  labels_encoder: 0.1478 (0.1461)  labels_decoder: 0.1240 (0.1295)  labels_encoder_unscaled: 0.1478 (0.1461)  labels_decoder_unscaled: 0.2479 (0.2591)  time: 0.1434  data: 0.0002  max mem: 3463
Epoch: [2]  [ 800/1406]  eta: 0:01:26  lr: 0.000010  loss: 0.2411 (0.2746)  labels_encoder: 0.1182 (0.1454)  labels_decoder: 0.1181 (0.1291)  labels_encoder_unscaled: 0.1182 (0.1454)  labels_decoder_unscaled: 0.2362 (0.2582)  time: 0.1464  data: 0.0003  max mem: 3463
Epoch: [2]  [ 850/1406]  eta: 0:01:19  lr: 0.000010  loss: 0.2183 (0.2732)  labels_encoder: 0.0931 (0.1444)  labels_decoder: 0.1222 (0.1288)  labels_encoder_unscaled: 0.0931 (0.1444)  labels_decoder_unscaled: 0.2444 (0.2576)  time: 0.1453  data: 0.0003  max mem: 3463
Epoch: [2]  [ 900/1406]  eta: 0:01:12  lr: 0.000010  loss: 0.2653 (0.2728)  labels_encoder: 0.1324 (0.1444)  labels_decoder: 0.1227 (0.1284)  labels_encoder_unscaled: 0.1324 (0.1444)  labels_decoder_unscaled: 0.2455 (0.2568)  time: 0.1431  data: 0.0003  max mem: 3463
Epoch: [2]  [ 950/1406]  eta: 0:01:05  lr: 0.000010  loss: 0.2349 (0.2718)  labels_encoder: 0.1204 (0.1438)  labels_decoder: 0.1173 (0.1280)  labels_encoder_unscaled: 0.1204 (0.1438)  labels_decoder_unscaled: 0.2346 (0.2560)  time: 0.1444  data: 0.0003  max mem: 3463
Epoch: [2]  [1000/1406]  eta: 0:00:58  lr: 0.000010  loss: 0.2542 (0.2713)  labels_encoder: 0.1355 (0.1435)  labels_decoder: 0.1188 (0.1278)  labels_encoder_unscaled: 0.1355 (0.1435)  labels_decoder_unscaled: 0.2376 (0.2556)  time: 0.1449  data: 0.0002  max mem: 3463
Epoch: [2]  [1050/1406]  eta: 0:00:50  lr: 0.000010  loss: 0.2530 (0.2706)  labels_encoder: 0.1283 (0.1431)  labels_decoder: 0.1239 (0.1275)  labels_encoder_unscaled: 0.1283 (0.1431)  labels_decoder_unscaled: 0.2478 (0.2550)  time: 0.1427  data: 0.0002  max mem: 3463
Epoch: [2]  [1100/1406]  eta: 0:00:43  lr: 0.000010  loss: 0.2601 (0.2703)  labels_encoder: 0.1518 (0.1432)  labels_decoder: 0.1221 (0.1271)  labels_encoder_unscaled: 0.1518 (0.1432)  labels_decoder_unscaled: 0.2441 (0.2542)  time: 0.1405  data: 0.0002  max mem: 3463
Epoch: [2]  [1150/1406]  eta: 0:00:36  lr: 0.000010  loss: 0.2658 (0.2696)  labels_encoder: 0.1431 (0.1426)  labels_decoder: 0.1261 (0.1269)  labels_encoder_unscaled: 0.1431 (0.1426)  labels_decoder_unscaled: 0.2522 (0.2539)  time: 0.1419  data: 0.0003  max mem: 3463
Epoch: [2]  [1200/1406]  eta: 0:00:29  lr: 0.000010  loss: 0.2250 (0.2684)  labels_encoder: 0.1056 (0.1419)  labels_decoder: 0.1109 (0.1265)  labels_encoder_unscaled: 0.1056 (0.1419)  labels_decoder_unscaled: 0.2219 (0.2531)  time: 0.1427  data: 0.0003  max mem: 3463
Epoch: [2]  [1250/1406]  eta: 0:00:22  lr: 0.000010  loss: 0.2501 (0.2680)  labels_encoder: 0.1159 (0.1415)  labels_decoder: 0.1249 (0.1265)  labels_encoder_unscaled: 0.1159 (0.1415)  labels_decoder_unscaled: 0.2499 (0.2531)  time: 0.1370  data: 0.0002  max mem: 3463
Epoch: [2]  [1300/1406]  eta: 0:00:15  lr: 0.000010  loss: 0.2745 (0.2677)  labels_encoder: 0.1454 (0.1414)  labels_decoder: 0.1247 (0.1263)  labels_encoder_unscaled: 0.1454 (0.1414)  labels_decoder_unscaled: 0.2493 (0.2525)  time: 0.1438  data: 0.0003  max mem: 3463
Epoch: [2]  [1350/1406]  eta: 0:00:07  lr: 0.000010  loss: 0.2350 (0.2670)  labels_encoder: 0.1219 (0.1409)  labels_decoder: 0.1128 (0.1261)  labels_encoder_unscaled: 0.1219 (0.1409)  labels_decoder_unscaled: 0.2255 (0.2521)  time: 0.1444  data: 0.0003  max mem: 3463
Epoch: [2]  [1400/1406]  eta: 0:00:00  lr: 0.000010  loss: 0.2438 (0.2663)  labels_encoder: 0.1239 (0.1404)  labels_decoder: 0.1168 (0.1259)  labels_encoder_unscaled: 0.1239 (0.1404)  labels_decoder_unscaled: 0.2336 (0.2518)  time: 0.1320  data: 0.0002  max mem: 3463
Epoch: [2]  [1405/1406]  eta: 0:00:00  lr: 0.000010  loss: 0.2351 (0.2663)  labels_encoder: 0.1237 (0.1404)  labels_decoder: 0.1151 (0.1259)  labels_encoder_unscaled: 0.1237 (0.1404)  labels_decoder_unscaled: 0.2303 (0.2518)  time: 0.1254  data: 0.0002  max mem: 3463
Epoch: [2] Total time: 0:03:20 (0.1428 s / it)
Averaged stats: lr: 0.000010  loss: 0.2351 (0.2663)  labels_encoder: 0.1237 (0.1404)  labels_decoder: 0.1151 (0.1259)  labels_encoder_unscaled: 0.1237 (0.1404)  labels_decoder_unscaled: 0.2303 (0.2518)
Test:  [   0/1613]  eta: 0:50:50  loss: 0.8227 (0.8227)  labels_encoder: 0.5292 (0.5292)  labels_decoder: 0.2934 (0.2934)  labels_encoder_unscaled: 0.5292 (0.5292)  labels_decoder_unscaled: 0.5869 (0.5869)  time: 1.8911  data: 1.8231  max mem: 3463
Test:  [  50/1613]  eta: 0:02:37  loss: 0.5579 (0.8730)  labels_encoder: 0.3174 (0.5490)  labels_decoder: 0.2366 (0.3240)  labels_encoder_unscaled: 0.3174 (0.5490)  labels_decoder_unscaled: 0.4731 (0.6480)  time: 0.0603  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:03  loss: 0.4381 (0.7892)  labels_encoder: 0.2700 (0.5124)  labels_decoder: 0.1169 (0.2768)  labels_encoder_unscaled: 0.2700 (0.5124)  labels_decoder_unscaled: 0.2338 (0.5536)  time: 0.0624  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:50  loss: 0.7385 (0.7703)  labels_encoder: 0.6148 (0.4950)  labels_decoder: 0.2600 (0.2752)  labels_encoder_unscaled: 0.6148 (0.4950)  labels_decoder_unscaled: 0.5201 (0.5504)  time: 0.0609  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:41  loss: 0.8608 (0.8876)  labels_encoder: 0.4958 (0.5705)  labels_decoder: 0.3700 (0.3171)  labels_encoder_unscaled: 0.4958 (0.5705)  labels_decoder_unscaled: 0.7399 (0.6342)  time: 0.0605  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:35  loss: 0.7168 (0.9323)  labels_encoder: 0.3866 (0.5961)  labels_decoder: 0.3316 (0.3361)  labels_encoder_unscaled: 0.3866 (0.5961)  labels_decoder_unscaled: 0.6632 (0.6723)  time: 0.0637  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:31  loss: 0.6941 (0.9304)  labels_encoder: 0.4322 (0.5970)  labels_decoder: 0.2618 (0.3334)  labels_encoder_unscaled: 0.4322 (0.5970)  labels_decoder_unscaled: 0.5237 (0.6669)  time: 0.0675  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:25  loss: 1.2959 (0.9423)  labels_encoder: 0.6804 (0.6022)  labels_decoder: 0.4692 (0.3401)  labels_encoder_unscaled: 0.6804 (0.6022)  labels_decoder_unscaled: 0.9385 (0.6802)  time: 0.0600  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:21  loss: 0.7553 (1.0036)  labels_encoder: 0.3815 (0.6422)  labels_decoder: 0.3154 (0.3615)  labels_encoder_unscaled: 0.3815 (0.6422)  labels_decoder_unscaled: 0.6308 (0.7230)  time: 0.0599  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:17  loss: 0.8878 (1.0864)  labels_encoder: 0.6531 (0.7007)  labels_decoder: 0.3073 (0.3857)  labels_encoder_unscaled: 0.6531 (0.7007)  labels_decoder_unscaled: 0.6147 (0.7714)  time: 0.0592  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:13  loss: 0.3979 (1.0452)  labels_encoder: 0.2057 (0.6707)  labels_decoder: 0.2047 (0.3744)  labels_encoder_unscaled: 0.2057 (0.6707)  labels_decoder_unscaled: 0.4093 (0.7489)  time: 0.0622  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:10  loss: 0.6861 (1.0287)  labels_encoder: 0.4944 (0.6607)  labels_decoder: 0.2477 (0.3680)  labels_encoder_unscaled: 0.4944 (0.6607)  labels_decoder_unscaled: 0.4953 (0.7360)  time: 0.0606  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:06  loss: 0.7276 (1.1007)  labels_encoder: 0.3934 (0.7182)  labels_decoder: 0.2979 (0.3826)  labels_encoder_unscaled: 0.3934 (0.7182)  labels_decoder_unscaled: 0.5958 (0.7652)  time: 0.0580  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:02  loss: 1.0343 (1.1027)  labels_encoder: 0.5691 (0.7166)  labels_decoder: 0.4565 (0.3860)  labels_encoder_unscaled: 0.5691 (0.7166)  labels_decoder_unscaled: 0.9130 (0.7721)  time: 0.0672  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:00:59  loss: 0.5488 (1.0753)  labels_encoder: 0.3038 (0.6978)  labels_decoder: 0.1883 (0.3775)  labels_encoder_unscaled: 0.3038 (0.6978)  labels_decoder_unscaled: 0.3766 (0.7551)  time: 0.0621  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:00:55  loss: 0.6788 (1.0455)  labels_encoder: 0.3697 (0.6770)  labels_decoder: 0.1785 (0.3685)  labels_encoder_unscaled: 0.3697 (0.6770)  labels_decoder_unscaled: 0.3570 (0.7369)  time: 0.0586  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:52  loss: 0.5607 (1.0373)  labels_encoder: 0.3452 (0.6709)  labels_decoder: 0.2143 (0.3663)  labels_encoder_unscaled: 0.3452 (0.6709)  labels_decoder_unscaled: 0.4287 (0.7327)  time: 0.0618  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:49  loss: 0.8439 (1.0398)  labels_encoder: 0.4920 (0.6698)  labels_decoder: 0.3519 (0.3700)  labels_encoder_unscaled: 0.4920 (0.6698)  labels_decoder_unscaled: 0.7037 (0.7400)  time: 0.0613  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:45  loss: 0.6303 (1.0212)  labels_encoder: 0.3608 (0.6553)  labels_decoder: 0.2875 (0.3659)  labels_encoder_unscaled: 0.3608 (0.6553)  labels_decoder_unscaled: 0.5750 (0.7317)  time: 0.0565  data: 0.0001  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:42  loss: 0.9106 (1.0160)  labels_encoder: 0.5565 (0.6516)  labels_decoder: 0.3513 (0.3644)  labels_encoder_unscaled: 0.5565 (0.6516)  labels_decoder_unscaled: 0.7027 (0.7288)  time: 0.0603  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:38  loss: 0.5139 (0.9990)  labels_encoder: 0.2503 (0.6394)  labels_decoder: 0.2636 (0.3597)  labels_encoder_unscaled: 0.2503 (0.6394)  labels_decoder_unscaled: 0.5272 (0.7194)  time: 0.0579  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:35  loss: 1.0091 (1.0027)  labels_encoder: 0.6414 (0.6427)  labels_decoder: 0.3416 (0.3600)  labels_encoder_unscaled: 0.6414 (0.6427)  labels_decoder_unscaled: 0.6832 (0.7200)  time: 0.0574  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:32  loss: 0.3650 (0.9989)  labels_encoder: 0.2400 (0.6409)  labels_decoder: 0.1802 (0.3581)  labels_encoder_unscaled: 0.2400 (0.6409)  labels_decoder_unscaled: 0.3604 (0.7161)  time: 0.0566  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:29  loss: 0.8226 (0.9937)  labels_encoder: 0.5641 (0.6372)  labels_decoder: 0.2678 (0.3564)  labels_encoder_unscaled: 0.5641 (0.6372)  labels_decoder_unscaled: 0.5357 (0.7128)  time: 0.0652  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:26  loss: 0.5035 (1.0031)  labels_encoder: 0.2657 (0.6435)  labels_decoder: 0.2516 (0.3596)  labels_encoder_unscaled: 0.2657 (0.6435)  labels_decoder_unscaled: 0.5031 (0.7192)  time: 0.0645  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:22  loss: 0.5254 (1.0009)  labels_encoder: 0.2671 (0.6419)  labels_decoder: 0.2536 (0.3589)  labels_encoder_unscaled: 0.2671 (0.6419)  labels_decoder_unscaled: 0.5072 (0.7178)  time: 0.0602  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5228 (0.9906)  labels_encoder: 0.3158 (0.6345)  labels_decoder: 0.2472 (0.3561)  labels_encoder_unscaled: 0.3158 (0.6345)  labels_decoder_unscaled: 0.4944 (0.7122)  time: 0.0598  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:16  loss: 1.0526 (0.9943)  labels_encoder: 0.6808 (0.6377)  labels_decoder: 0.3883 (0.3566)  labels_encoder_unscaled: 0.6808 (0.6377)  labels_decoder_unscaled: 0.7766 (0.7133)  time: 0.0610  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:13  loss: 0.8032 (1.0025)  labels_encoder: 0.5079 (0.6433)  labels_decoder: 0.2725 (0.3593)  labels_encoder_unscaled: 0.5079 (0.6433)  labels_decoder_unscaled: 0.5450 (0.7185)  time: 0.0596  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:10  loss: 0.4725 (1.0002)  labels_encoder: 0.1774 (0.6417)  labels_decoder: 0.2135 (0.3585)  labels_encoder_unscaled: 0.1774 (0.6417)  labels_decoder_unscaled: 0.4271 (0.7170)  time: 0.0699  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:07  loss: 0.5205 (0.9967)  labels_encoder: 0.2914 (0.6391)  labels_decoder: 0.1876 (0.3576)  labels_encoder_unscaled: 0.2914 (0.6391)  labels_decoder_unscaled: 0.3753 (0.7152)  time: 0.0603  data: 0.0002  max mem: 3463
Test:  [1550/1613]  eta: 0:00:03  loss: 0.9494 (0.9946)  labels_encoder: 0.6082 (0.6385)  labels_decoder: 0.2988 (0.3560)  labels_encoder_unscaled: 0.6082 (0.6385)  labels_decoder_unscaled: 0.5976 (0.7121)  time: 0.0667  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.9016 (0.9906)  labels_encoder: 0.5195 (0.6352)  labels_decoder: 0.3354 (0.3553)  labels_encoder_unscaled: 0.5195 (0.6352)  labels_decoder_unscaled: 0.6709 (0.7107)  time: 0.0569  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5964 (0.9889)  labels_encoder: 0.2981 (0.6344)  labels_decoder: 0.2919 (0.3545)  labels_encoder_unscaled: 0.2981 (0.6344)  labels_decoder_unscaled: 0.5839 (0.7090)  time: 0.0462  data: 0.0001  max mem: 3463
Test: Total time: 0:01:41 (0.0628 s / it)
Averaged stats: loss: 0.5964 (0.9889)  labels_encoder: 0.2981 (0.6344)  labels_decoder: 0.2919 (0.3545)  labels_encoder_unscaled: 0.2981 (0.6344)  labels_decoder_unscaled: 0.5839 (0.7090)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-kin] mAP: 0.6470

dec_mAP all together: | 0.5169573120033509 |.
dec_mAP_pred | 0 : 0.5671190891116453 |.
dec_mAP_pred | 1 : 0.5585492958970106 |.
dec_mAP_pred | 2 : 0.5451517885567232 |.
dec_mAP_pred | 3 : 0.5291111019671765 |.
dec_mAP_pred | 4 : 0.5118503312580437 |.
dec_mAP_pred | 5 : 0.49462618367122035 |.
dec_mAP_pred | 6 : 0.47770850497291234 |.
dec_mAP_pred | 7 : 0.4615171528791935 |.
all decoder map: | 0.5182 |.
BaseballPitch: 0.4307
BasketballDunk: 0.8111
Billiards: 0.2883
CleanAndJerk: 0.7334
CliffDiving: 0.8616
CricketBowling: 0.4758
CricketShot: 0.2474
Diving: 0.8608
FrisbeeCatch: 0.4772
GolfSwing: 0.7821
HammerThrow: 0.8645
HighJump: 0.7675
JavelinThrow: 0.7778
LongJump: 0.7841
PoleVault: 0.8869
Shotput: 0.7453
SoccerPenalty: 0.4367
TennisSwing: 0.5772
ThrowDiscus: 0.6996
VolleyballSpiking: 0.4319
Epoch: [3]  [   0/1406]  eta: 0:46:43  lr: 0.000001  loss: 0.2499 (0.2499)  labels_encoder: 0.1255 (0.1255)  labels_decoder: 0.1243 (0.1243)  labels_encoder_unscaled: 0.1255 (0.1255)  labels_decoder_unscaled: 0.2487 (0.2487)  time: 1.9937  data: 1.8031  max mem: 3463
Epoch: [3]  [  50/1406]  eta: 0:04:02  lr: 0.000001  loss: 0.2464 (0.2440)  labels_encoder: 0.1359 (0.1280)  labels_decoder: 0.1185 (0.1160)  labels_encoder_unscaled: 0.1359 (0.1280)  labels_decoder_unscaled: 0.2370 (0.2320)  time: 0.1395  data: 0.0002  max mem: 3463
Epoch: [3]  [ 100/1406]  eta: 0:03:25  lr: 0.000001  loss: 0.2295 (0.2433)  labels_encoder: 0.1281 (0.1258)  labels_decoder: 0.1208 (0.1175)  labels_encoder_unscaled: 0.1281 (0.1258)  labels_decoder_unscaled: 0.2415 (0.2350)  time: 0.1378  data: 0.0002  max mem: 3463
Epoch: [3]  [ 150/1406]  eta: 0:03:09  lr: 0.000001  loss: 0.2099 (0.2377)  labels_encoder: 0.0972 (0.1215)  labels_decoder: 0.1058 (0.1162)  labels_encoder_unscaled: 0.0972 (0.1215)  labels_decoder_unscaled: 0.2116 (0.2324)  time: 0.1341  data: 0.0002  max mem: 3463
Epoch: [3]  [ 200/1406]  eta: 0:02:59  lr: 0.000001  loss: 0.2297 (0.2403)  labels_encoder: 0.1134 (0.1228)  labels_decoder: 0.1206 (0.1175)  labels_encoder_unscaled: 0.1134 (0.1228)  labels_decoder_unscaled: 0.2411 (0.2350)  time: 0.1440  data: 0.0003  max mem: 3463
Epoch: [3]  [ 250/1406]  eta: 0:02:50  lr: 0.000001  loss: 0.2200 (0.2384)  labels_encoder: 0.1046 (0.1217)  labels_decoder: 0.1128 (0.1167)  labels_encoder_unscaled: 0.1046 (0.1217)  labels_decoder_unscaled: 0.2256 (0.2335)  time: 0.1418  data: 0.0002  max mem: 3463
Epoch: [3]  [ 300/1406]  eta: 0:02:42  lr: 0.000001  loss: 0.2260 (0.2375)  labels_encoder: 0.1031 (0.1209)  labels_decoder: 0.1161 (0.1166)  labels_encoder_unscaled: 0.1031 (0.1209)  labels_decoder_unscaled: 0.2323 (0.2332)  time: 0.1413  data: 0.0002  max mem: 3463
Epoch: [3]  [ 350/1406]  eta: 0:02:34  lr: 0.000001  loss: 0.2297 (0.2380)  labels_encoder: 0.1202 (0.1215)  labels_decoder: 0.1074 (0.1164)  labels_encoder_unscaled: 0.1202 (0.1215)  labels_decoder_unscaled: 0.2148 (0.2329)  time: 0.1406  data: 0.0002  max mem: 3463
Epoch: [3]  [ 400/1406]  eta: 0:02:26  lr: 0.000001  loss: 0.2223 (0.2393)  labels_encoder: 0.1130 (0.1226)  labels_decoder: 0.1072 (0.1167)  labels_encoder_unscaled: 0.1130 (0.1226)  labels_decoder_unscaled: 0.2143 (0.2334)  time: 0.1468  data: 0.0003  max mem: 3463
Epoch: [3]  [ 450/1406]  eta: 0:02:19  lr: 0.000001  loss: 0.2235 (0.2394)  labels_encoder: 0.1079 (0.1224)  labels_decoder: 0.1115 (0.1169)  labels_encoder_unscaled: 0.1079 (0.1224)  labels_decoder_unscaled: 0.2229 (0.2339)  time: 0.1485  data: 0.0003  max mem: 3463
Epoch: [3]  [ 500/1406]  eta: 0:02:12  lr: 0.000001  loss: 0.2474 (0.2391)  labels_encoder: 0.1323 (0.1226)  labels_decoder: 0.1055 (0.1165)  labels_encoder_unscaled: 0.1323 (0.1226)  labels_decoder_unscaled: 0.2110 (0.2330)  time: 0.1441  data: 0.0003  max mem: 3463
Epoch: [3]  [ 550/1406]  eta: 0:02:04  lr: 0.000001  loss: 0.2256 (0.2382)  labels_encoder: 0.1170 (0.1221)  labels_decoder: 0.1140 (0.1160)  labels_encoder_unscaled: 0.1170 (0.1221)  labels_decoder_unscaled: 0.2280 (0.2321)  time: 0.1462  data: 0.0003  max mem: 3463
Epoch: [3]  [ 600/1406]  eta: 0:01:57  lr: 0.000001  loss: 0.2409 (0.2381)  labels_encoder: 0.1278 (0.1221)  labels_decoder: 0.1126 (0.1160)  labels_encoder_unscaled: 0.1278 (0.1221)  labels_decoder_unscaled: 0.2252 (0.2320)  time: 0.1444  data: 0.0002  max mem: 3463
Epoch: [3]  [ 650/1406]  eta: 0:01:50  lr: 0.000001  loss: 0.2332 (0.2381)  labels_encoder: 0.1149 (0.1222)  labels_decoder: 0.1190 (0.1159)  labels_encoder_unscaled: 0.1149 (0.1222)  labels_decoder_unscaled: 0.2380 (0.2319)  time: 0.1429  data: 0.0002  max mem: 3463
Epoch: [3]  [ 700/1406]  eta: 0:01:42  lr: 0.000001  loss: 0.2380 (0.2375)  labels_encoder: 0.1128 (0.1216)  labels_decoder: 0.1218 (0.1159)  labels_encoder_unscaled: 0.1128 (0.1216)  labels_decoder_unscaled: 0.2436 (0.2317)  time: 0.1447  data: 0.0003  max mem: 3463
Epoch: [3]  [ 750/1406]  eta: 0:01:35  lr: 0.000001  loss: 0.2041 (0.2366)  labels_encoder: 0.0956 (0.1210)  labels_decoder: 0.1039 (0.1156)  labels_encoder_unscaled: 0.0956 (0.1210)  labels_decoder_unscaled: 0.2077 (0.2313)  time: 0.1477  data: 0.0003  max mem: 3463
Epoch: [3]  [ 800/1406]  eta: 0:01:28  lr: 0.000001  loss: 0.2052 (0.2363)  labels_encoder: 0.1040 (0.1207)  labels_decoder: 0.1043 (0.1155)  labels_encoder_unscaled: 0.1040 (0.1207)  labels_decoder_unscaled: 0.2086 (0.2311)  time: 0.1426  data: 0.0002  max mem: 3463
Epoch: [3]  [ 850/1406]  eta: 0:01:20  lr: 0.000001  loss: 0.2106 (0.2363)  labels_encoder: 0.1032 (0.1207)  labels_decoder: 0.1047 (0.1156)  labels_encoder_unscaled: 0.1032 (0.1207)  labels_decoder_unscaled: 0.2094 (0.2313)  time: 0.1471  data: 0.0003  max mem: 3463
Epoch: [3]  [ 900/1406]  eta: 0:01:13  lr: 0.000001  loss: 0.2133 (0.2364)  labels_encoder: 0.1039 (0.1208)  labels_decoder: 0.1173 (0.1156)  labels_encoder_unscaled: 0.1039 (0.1208)  labels_decoder_unscaled: 0.2346 (0.2311)  time: 0.1484  data: 0.0003  max mem: 3463
Epoch: [3]  [ 950/1406]  eta: 0:01:06  lr: 0.000001  loss: 0.2050 (0.2357)  labels_encoder: 0.0969 (0.1204)  labels_decoder: 0.1083 (0.1153)  labels_encoder_unscaled: 0.0969 (0.1204)  labels_decoder_unscaled: 0.2167 (0.2306)  time: 0.1471  data: 0.0003  max mem: 3463
Epoch: [3]  [1000/1406]  eta: 0:00:59  lr: 0.000001  loss: 0.2337 (0.2356)  labels_encoder: 0.1091 (0.1202)  labels_decoder: 0.1178 (0.1154)  labels_encoder_unscaled: 0.1091 (0.1202)  labels_decoder_unscaled: 0.2355 (0.2308)  time: 0.1463  data: 0.0003  max mem: 3463
Epoch: [3]  [1050/1406]  eta: 0:00:51  lr: 0.000001  loss: 0.2433 (0.2359)  labels_encoder: 0.1277 (0.1204)  labels_decoder: 0.1156 (0.1155)  labels_encoder_unscaled: 0.1277 (0.1204)  labels_decoder_unscaled: 0.2312 (0.2310)  time: 0.1443  data: 0.0002  max mem: 3463
Epoch: [3]  [1100/1406]  eta: 0:00:44  lr: 0.000001  loss: 0.2237 (0.2357)  labels_encoder: 0.1148 (0.1203)  labels_decoder: 0.1098 (0.1154)  labels_encoder_unscaled: 0.1148 (0.1203)  labels_decoder_unscaled: 0.2197 (0.2307)  time: 0.1437  data: 0.0003  max mem: 3463
Epoch: [3]  [1150/1406]  eta: 0:00:37  lr: 0.000001  loss: 0.2348 (0.2357)  labels_encoder: 0.1200 (0.1203)  labels_decoder: 0.1208 (0.1154)  labels_encoder_unscaled: 0.1200 (0.1203)  labels_decoder_unscaled: 0.2415 (0.2308)  time: 0.1399  data: 0.0002  max mem: 3463
Epoch: [3]  [1200/1406]  eta: 0:00:30  lr: 0.000001  loss: 0.2281 (0.2356)  labels_encoder: 0.1102 (0.1203)  labels_decoder: 0.1117 (0.1154)  labels_encoder_unscaled: 0.1102 (0.1203)  labels_decoder_unscaled: 0.2233 (0.2307)  time: 0.1476  data: 0.0003  max mem: 3463
Epoch: [3]  [1250/1406]  eta: 0:00:22  lr: 0.000001  loss: 0.2169 (0.2355)  labels_encoder: 0.1085 (0.1201)  labels_decoder: 0.1127 (0.1153)  labels_encoder_unscaled: 0.1085 (0.1201)  labels_decoder_unscaled: 0.2255 (0.2307)  time: 0.1440  data: 0.0002  max mem: 3463
Epoch: [3]  [1300/1406]  eta: 0:00:15  lr: 0.000001  loss: 0.2142 (0.2350)  labels_encoder: 0.1082 (0.1198)  labels_decoder: 0.1073 (0.1152)  labels_encoder_unscaled: 0.1082 (0.1198)  labels_decoder_unscaled: 0.2146 (0.2304)  time: 0.1476  data: 0.0003  max mem: 3463
Epoch: [3]  [1350/1406]  eta: 0:00:08  lr: 0.000001  loss: 0.2299 (0.2348)  labels_encoder: 0.1178 (0.1196)  labels_decoder: 0.1150 (0.1152)  labels_encoder_unscaled: 0.1178 (0.1196)  labels_decoder_unscaled: 0.2301 (0.2303)  time: 0.1485  data: 0.0003  max mem: 3463
Epoch: [3]  [1400/1406]  eta: 0:00:00  lr: 0.000001  loss: 0.2097 (0.2343)  labels_encoder: 0.0998 (0.1193)  labels_decoder: 0.1083 (0.1150)  labels_encoder_unscaled: 0.0998 (0.1193)  labels_decoder_unscaled: 0.2166 (0.2300)  time: 0.1318  data: 0.0004  max mem: 3463
Epoch: [3]  [1405/1406]  eta: 0:00:00  lr: 0.000001  loss: 0.2250 (0.2343)  labels_encoder: 0.1040 (0.1193)  labels_decoder: 0.1084 (0.1150)  labels_encoder_unscaled: 0.1040 (0.1193)  labels_decoder_unscaled: 0.2167 (0.2300)  time: 0.1259  data: 0.0004  max mem: 3463
Epoch: [3] Total time: 0:03:24 (0.1458 s / it)
Averaged stats: lr: 0.000001  loss: 0.2250 (0.2343)  labels_encoder: 0.1040 (0.1193)  labels_decoder: 0.1084 (0.1150)  labels_encoder_unscaled: 0.1040 (0.1193)  labels_decoder_unscaled: 0.2167 (0.2300)
Test:  [   0/1613]  eta: 0:44:33  loss: 0.6193 (0.6193)  labels_encoder: 0.3903 (0.3903)  labels_decoder: 0.2290 (0.2290)  labels_encoder_unscaled: 0.3903 (0.3903)  labels_decoder_unscaled: 0.4580 (0.4580)  time: 1.6575  data: 1.5871  max mem: 3463
Test:  [  50/1613]  eta: 0:02:29  loss: 0.6148 (0.9438)  labels_encoder: 0.3692 (0.6023)  labels_decoder: 0.2465 (0.3415)  labels_encoder_unscaled: 0.3692 (0.6023)  labels_decoder_unscaled: 0.4930 (0.6830)  time: 0.0621  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:00  loss: 0.4251 (0.8177)  labels_encoder: 0.2647 (0.5355)  labels_decoder: 0.1057 (0.2822)  labels_encoder_unscaled: 0.2647 (0.5355)  labels_decoder_unscaled: 0.2115 (0.5645)  time: 0.0648  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:48  loss: 0.6609 (0.7787)  labels_encoder: 0.4544 (0.5024)  labels_decoder: 0.2153 (0.2763)  labels_encoder_unscaled: 0.4544 (0.5024)  labels_decoder_unscaled: 0.4307 (0.5525)  time: 0.0635  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:41  loss: 0.8603 (0.8899)  labels_encoder: 0.4911 (0.5730)  labels_decoder: 0.3725 (0.3169)  labels_encoder_unscaled: 0.4911 (0.5730)  labels_decoder_unscaled: 0.7451 (0.6339)  time: 0.0623  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:37  loss: 0.7123 (0.9340)  labels_encoder: 0.4140 (0.5973)  labels_decoder: 0.3287 (0.3366)  labels_encoder_unscaled: 0.4140 (0.5973)  labels_decoder_unscaled: 0.6575 (0.6733)  time: 0.0700  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:32  loss: 0.7859 (0.9498)  labels_encoder: 0.5219 (0.6104)  labels_decoder: 0.2788 (0.3394)  labels_encoder_unscaled: 0.5219 (0.6104)  labels_decoder_unscaled: 0.5576 (0.6788)  time: 0.0674  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:28  loss: 1.2357 (0.9645)  labels_encoder: 0.6797 (0.6191)  labels_decoder: 0.4830 (0.3455)  labels_encoder_unscaled: 0.6797 (0.6191)  labels_decoder_unscaled: 0.9660 (0.6909)  time: 0.0662  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:23  loss: 0.6282 (1.0239)  labels_encoder: 0.3231 (0.6581)  labels_decoder: 0.3051 (0.3658)  labels_encoder_unscaled: 0.3231 (0.6581)  labels_decoder_unscaled: 0.6102 (0.7317)  time: 0.0637  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:19  loss: 1.0805 (1.1137)  labels_encoder: 0.8113 (0.7221)  labels_decoder: 0.3135 (0.3916)  labels_encoder_unscaled: 0.8113 (0.7221)  labels_decoder_unscaled: 0.6269 (0.7833)  time: 0.0623  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:15  loss: 0.3304 (1.0671)  labels_encoder: 0.1746 (0.6890)  labels_decoder: 0.1724 (0.3781)  labels_encoder_unscaled: 0.1746 (0.6890)  labels_decoder_unscaled: 0.3447 (0.7563)  time: 0.0633  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:11  loss: 0.7135 (1.0525)  labels_encoder: 0.4932 (0.6796)  labels_decoder: 0.2400 (0.3729)  labels_encoder_unscaled: 0.4932 (0.6796)  labels_decoder_unscaled: 0.4800 (0.7457)  time: 0.0610  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:07  loss: 0.7163 (1.1172)  labels_encoder: 0.3950 (0.7321)  labels_decoder: 0.2932 (0.3852)  labels_encoder_unscaled: 0.3950 (0.7321)  labels_decoder_unscaled: 0.5864 (0.7703)  time: 0.0606  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:03  loss: 1.1530 (1.1213)  labels_encoder: 0.6302 (0.7320)  labels_decoder: 0.4764 (0.3892)  labels_encoder_unscaled: 0.6302 (0.7320)  labels_decoder_unscaled: 0.9527 (0.7785)  time: 0.0607  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:01:00  loss: 0.5278 (1.0944)  labels_encoder: 0.3094 (0.7134)  labels_decoder: 0.1882 (0.3810)  labels_encoder_unscaled: 0.3094 (0.7134)  labels_decoder_unscaled: 0.3764 (0.7620)  time: 0.0602  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:00:56  loss: 0.6660 (1.0653)  labels_encoder: 0.4403 (0.6928)  labels_decoder: 0.1982 (0.3724)  labels_encoder_unscaled: 0.4403 (0.6928)  labels_decoder_unscaled: 0.3963 (0.7448)  time: 0.0617  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:53  loss: 0.5901 (1.0536)  labels_encoder: 0.3259 (0.6844)  labels_decoder: 0.2256 (0.3692)  labels_encoder_unscaled: 0.3259 (0.6844)  labels_decoder_unscaled: 0.4512 (0.7385)  time: 0.0590  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:49  loss: 0.8484 (1.0572)  labels_encoder: 0.4894 (0.6837)  labels_decoder: 0.3590 (0.3735)  labels_encoder_unscaled: 0.4894 (0.6837)  labels_decoder_unscaled: 0.7181 (0.7470)  time: 0.0603  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:46  loss: 0.6412 (1.0380)  labels_encoder: 0.3738 (0.6691)  labels_decoder: 0.2675 (0.3689)  labels_encoder_unscaled: 0.3738 (0.6691)  labels_decoder_unscaled: 0.5349 (0.7378)  time: 0.0600  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:42  loss: 0.9085 (1.0303)  labels_encoder: 0.5719 (0.6636)  labels_decoder: 0.3466 (0.3666)  labels_encoder_unscaled: 0.5719 (0.6636)  labels_decoder_unscaled: 0.6932 (0.7333)  time: 0.0595  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:39  loss: 0.5543 (1.0141)  labels_encoder: 0.2861 (0.6518)  labels_decoder: 0.2681 (0.3623)  labels_encoder_unscaled: 0.2861 (0.6518)  labels_decoder_unscaled: 0.5362 (0.7245)  time: 0.0601  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:36  loss: 0.9901 (1.0156)  labels_encoder: 0.6492 (0.6539)  labels_decoder: 0.3414 (0.3618)  labels_encoder_unscaled: 0.6492 (0.6539)  labels_decoder_unscaled: 0.6828 (0.7235)  time: 0.0602  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:32  loss: 0.3660 (1.0115)  labels_encoder: 0.2238 (0.6518)  labels_decoder: 0.1535 (0.3597)  labels_encoder_unscaled: 0.2238 (0.6518)  labels_decoder_unscaled: 0.3070 (0.7194)  time: 0.0586  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:29  loss: 0.7791 (1.0044)  labels_encoder: 0.4712 (0.6468)  labels_decoder: 0.2218 (0.3575)  labels_encoder_unscaled: 0.4712 (0.6468)  labels_decoder_unscaled: 0.4435 (0.7151)  time: 0.0633  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:26  loss: 0.6071 (1.0137)  labels_encoder: 0.2834 (0.6528)  labels_decoder: 0.2474 (0.3610)  labels_encoder_unscaled: 0.2834 (0.6528)  labels_decoder_unscaled: 0.4949 (0.7219)  time: 0.0597  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:23  loss: 0.5144 (1.0135)  labels_encoder: 0.2654 (0.6526)  labels_decoder: 0.2176 (0.3609)  labels_encoder_unscaled: 0.2654 (0.6526)  labels_decoder_unscaled: 0.4352 (0.7218)  time: 0.0585  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:19  loss: 0.5851 (1.0045)  labels_encoder: 0.3621 (0.6457)  labels_decoder: 0.2611 (0.3587)  labels_encoder_unscaled: 0.3621 (0.6457)  labels_decoder_unscaled: 0.5221 (0.7175)  time: 0.0567  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:16  loss: 0.9869 (1.0076)  labels_encoder: 0.6247 (0.6484)  labels_decoder: 0.3622 (0.3592)  labels_encoder_unscaled: 0.6247 (0.6484)  labels_decoder_unscaled: 0.7244 (0.7184)  time: 0.0544  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:13  loss: 0.8876 (1.0159)  labels_encoder: 0.5945 (0.6540)  labels_decoder: 0.3289 (0.3619)  labels_encoder_unscaled: 0.5945 (0.6540)  labels_decoder_unscaled: 0.6578 (0.7237)  time: 0.0620  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:10  loss: 0.5064 (1.0179)  labels_encoder: 0.1820 (0.6553)  labels_decoder: 0.1944 (0.3626)  labels_encoder_unscaled: 0.1820 (0.6553)  labels_decoder_unscaled: 0.3887 (0.7251)  time: 0.0625  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:07  loss: 0.5200 (1.0145)  labels_encoder: 0.3226 (0.6531)  labels_decoder: 0.1860 (0.3614)  labels_encoder_unscaled: 0.3226 (0.6531)  labels_decoder_unscaled: 0.3721 (0.7228)  time: 0.0563  data: 0.0009  max mem: 3463
Test:  [1550/1613]  eta: 0:00:03  loss: 0.9201 (1.0122)  labels_encoder: 0.5902 (0.6523)  labels_decoder: 0.2996 (0.3599)  labels_encoder_unscaled: 0.5902 (0.6523)  labels_decoder_unscaled: 0.5992 (0.7198)  time: 0.0640  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8767 (1.0081)  labels_encoder: 0.5103 (0.6488)  labels_decoder: 0.3740 (0.3594)  labels_encoder_unscaled: 0.5103 (0.6488)  labels_decoder_unscaled: 0.7479 (0.7188)  time: 0.0581  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6496 (1.0066)  labels_encoder: 0.3052 (0.6479)  labels_decoder: 0.3018 (0.3587)  labels_encoder_unscaled: 0.3052 (0.6479)  labels_decoder_unscaled: 0.6037 (0.7174)  time: 0.0474  data: 0.0001  max mem: 3463
Test: Total time: 0:01:41 (0.0628 s / it)
Averaged stats: loss: 0.6496 (1.0066)  labels_encoder: 0.3052 (0.6479)  labels_decoder: 0.3018 (0.3587)  labels_encoder_unscaled: 0.3052 (0.6479)  labels_decoder_unscaled: 0.6037 (0.7174)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-kin] mAP: 0.6420

dec_mAP all together: | 0.5121389483993745 |.
dec_mAP_pred | 0 : 0.5607198046912438 |.
dec_mAP_pred | 1 : 0.5524773365442054 |.
dec_mAP_pred | 2 : 0.5396079781511587 |.
dec_mAP_pred | 3 : 0.5241326202853862 |.
dec_mAP_pred | 4 : 0.5072582036859001 |.
dec_mAP_pred | 5 : 0.4904640142848291 |.
dec_mAP_pred | 6 : 0.47384238683134966 |.
dec_mAP_pred | 7 : 0.4578848546191301 |.
all decoder map: | 0.5133 |.
BaseballPitch: 0.4095
BasketballDunk: 0.8116
Billiards: 0.2918
CleanAndJerk: 0.7350
CliffDiving: 0.8538
CricketBowling: 0.4644
CricketShot: 0.2399
Diving: 0.8571
FrisbeeCatch: 0.4756
GolfSwing: 0.7832
HammerThrow: 0.8613
HighJump: 0.7660
JavelinThrow: 0.7719
LongJump: 0.7831
PoleVault: 0.8821
Shotput: 0.7311
SoccerPenalty: 0.4274
TennisSwing: 0.5752
ThrowDiscus: 0.6925
VolleyballSpiking: 0.4268
Epoch: [4]  [   0/1406]  eta: 0:47:16  lr: 0.000000  loss: 0.3308 (0.3308)  labels_encoder: 0.1991 (0.1991)  labels_decoder: 0.1317 (0.1317)  labels_encoder_unscaled: 0.1991 (0.1991)  labels_decoder_unscaled: 0.2635 (0.2635)  time: 2.0172  data: 1.8432  max mem: 3463
Epoch: [4]  [  50/1406]  eta: 0:03:56  lr: 0.000000  loss: 0.2326 (0.2349)  labels_encoder: 0.1173 (0.1207)  labels_decoder: 0.1151 (0.1142)  labels_encoder_unscaled: 0.1173 (0.1207)  labels_decoder_unscaled: 0.2302 (0.2284)  time: 0.1362  data: 0.0002  max mem: 3463
Epoch: [4]  [ 100/1406]  eta: 0:03:23  lr: 0.000000  loss: 0.2468 (0.2323)  labels_encoder: 0.1270 (0.1184)  labels_decoder: 0.1199 (0.1139)  labels_encoder_unscaled: 0.1270 (0.1184)  labels_decoder_unscaled: 0.2397 (0.2278)  time: 0.1391  data: 0.0003  max mem: 3463
Epoch: [4]  [ 150/1406]  eta: 0:03:10  lr: 0.000000  loss: 0.2095 (0.2298)  labels_encoder: 0.1131 (0.1170)  labels_decoder: 0.1090 (0.1129)  labels_encoder_unscaled: 0.1131 (0.1170)  labels_decoder_unscaled: 0.2179 (0.2257)  time: 0.1411  data: 0.0002  max mem: 3463
Epoch: [4]  [ 200/1406]  eta: 0:03:00  lr: 0.000000  loss: 0.2238 (0.2281)  labels_encoder: 0.1092 (0.1167)  labels_decoder: 0.1042 (0.1114)  labels_encoder_unscaled: 0.1092 (0.1167)  labels_decoder_unscaled: 0.2083 (0.2227)  time: 0.1402  data: 0.0003  max mem: 3463
Epoch: [4]  [ 250/1406]  eta: 0:02:51  lr: 0.000000  loss: 0.2158 (0.2278)  labels_encoder: 0.1003 (0.1158)  labels_decoder: 0.1131 (0.1121)  labels_encoder_unscaled: 0.1003 (0.1158)  labels_decoder_unscaled: 0.2263 (0.2241)  time: 0.1410  data: 0.0002  max mem: 3463
Epoch: [4]  [ 300/1406]  eta: 0:02:44  lr: 0.000000  loss: 0.2248 (0.2293)  labels_encoder: 0.1091 (0.1166)  labels_decoder: 0.1113 (0.1126)  labels_encoder_unscaled: 0.1091 (0.1166)  labels_decoder_unscaled: 0.2227 (0.2253)  time: 0.1536  data: 0.0003  max mem: 3463
Epoch: [4]  [ 350/1406]  eta: 0:02:37  lr: 0.000000  loss: 0.2237 (0.2290)  labels_encoder: 0.1005 (0.1164)  labels_decoder: 0.1179 (0.1127)  labels_encoder_unscaled: 0.1005 (0.1164)  labels_decoder_unscaled: 0.2358 (0.2254)  time: 0.1531  data: 0.0003  max mem: 3463
Epoch: [4]  [ 400/1406]  eta: 0:02:30  lr: 0.000000  loss: 0.2165 (0.2293)  labels_encoder: 0.1017 (0.1162)  labels_decoder: 0.1126 (0.1131)  labels_encoder_unscaled: 0.1017 (0.1162)  labels_decoder_unscaled: 0.2252 (0.2262)  time: 0.1443  data: 0.0002  max mem: 3463
Epoch: [4]  [ 450/1406]  eta: 0:02:22  lr: 0.000000  loss: 0.2091 (0.2292)  labels_encoder: 0.1048 (0.1163)  labels_decoder: 0.1144 (0.1129)  labels_encoder_unscaled: 0.1048 (0.1163)  labels_decoder_unscaled: 0.2288 (0.2259)  time: 0.1438  data: 0.0002  max mem: 3463
Epoch: [4]  [ 500/1406]  eta: 0:02:14  lr: 0.000000  loss: 0.2210 (0.2288)  labels_encoder: 0.1054 (0.1160)  labels_decoder: 0.1032 (0.1129)  labels_encoder_unscaled: 0.1054 (0.1160)  labels_decoder_unscaled: 0.2064 (0.2258)  time: 0.1465  data: 0.0002  max mem: 3463
Epoch: [4]  [ 550/1406]  eta: 0:02:06  lr: 0.000000  loss: 0.2071 (0.2286)  labels_encoder: 0.0994 (0.1156)  labels_decoder: 0.1076 (0.1130)  labels_encoder_unscaled: 0.0994 (0.1156)  labels_decoder_unscaled: 0.2152 (0.2260)  time: 0.1497  data: 0.0003  max mem: 3463
Epoch: [4]  [ 600/1406]  eta: 0:01:59  lr: 0.000000  loss: 0.2283 (0.2286)  labels_encoder: 0.1133 (0.1156)  labels_decoder: 0.1130 (0.1130)  labels_encoder_unscaled: 0.1133 (0.1156)  labels_decoder_unscaled: 0.2260 (0.2260)  time: 0.1450  data: 0.0003  max mem: 3463
Epoch: [4]  [ 650/1406]  eta: 0:01:51  lr: 0.000000  loss: 0.2241 (0.2287)  labels_encoder: 0.1070 (0.1155)  labels_decoder: 0.1137 (0.1132)  labels_encoder_unscaled: 0.1070 (0.1155)  labels_decoder_unscaled: 0.2274 (0.2263)  time: 0.1461  data: 0.0002  max mem: 3463
Epoch: [4]  [ 700/1406]  eta: 0:01:44  lr: 0.000000  loss: 0.2368 (0.2293)  labels_encoder: 0.1231 (0.1158)  labels_decoder: 0.1172 (0.1135)  labels_encoder_unscaled: 0.1231 (0.1158)  labels_decoder_unscaled: 0.2344 (0.2269)  time: 0.1446  data: 0.0003  max mem: 3463
Epoch: [4]  [ 750/1406]  eta: 0:01:36  lr: 0.000000  loss: 0.2136 (0.2290)  labels_encoder: 0.1052 (0.1154)  labels_decoder: 0.1120 (0.1136)  labels_encoder_unscaled: 0.1052 (0.1154)  labels_decoder_unscaled: 0.2240 (0.2271)  time: 0.1455  data: 0.0003  max mem: 3463
Epoch: [4]  [ 800/1406]  eta: 0:01:29  lr: 0.000000  loss: 0.2172 (0.2292)  labels_encoder: 0.1114 (0.1157)  labels_decoder: 0.1107 (0.1135)  labels_encoder_unscaled: 0.1114 (0.1157)  labels_decoder_unscaled: 0.2214 (0.2270)  time: 0.1442  data: 0.0003  max mem: 3463
Epoch: [4]  [ 850/1406]  eta: 0:01:21  lr: 0.000000  loss: 0.2345 (0.2296)  labels_encoder: 0.1304 (0.1162)  labels_decoder: 0.1064 (0.1134)  labels_encoder_unscaled: 0.1304 (0.1162)  labels_decoder_unscaled: 0.2128 (0.2268)  time: 0.1475  data: 0.0003  max mem: 3463
Epoch: [4]  [ 900/1406]  eta: 0:01:14  lr: 0.000000  loss: 0.2320 (0.2297)  labels_encoder: 0.1196 (0.1164)  labels_decoder: 0.1097 (0.1133)  labels_encoder_unscaled: 0.1196 (0.1164)  labels_decoder_unscaled: 0.2193 (0.2266)  time: 0.1483  data: 0.0003  max mem: 3463
Epoch: [4]  [ 950/1406]  eta: 0:01:07  lr: 0.000000  loss: 0.2315 (0.2295)  labels_encoder: 0.1059 (0.1163)  labels_decoder: 0.1090 (0.1133)  labels_encoder_unscaled: 0.1059 (0.1163)  labels_decoder_unscaled: 0.2181 (0.2266)  time: 0.1438  data: 0.0002  max mem: 3463
Epoch: [4]  [1000/1406]  eta: 0:00:59  lr: 0.000000  loss: 0.2170 (0.2299)  labels_encoder: 0.1115 (0.1167)  labels_decoder: 0.1078 (0.1132)  labels_encoder_unscaled: 0.1115 (0.1167)  labels_decoder_unscaled: 0.2155 (0.2265)  time: 0.1484  data: 0.0003  max mem: 3463
Epoch: [4]  [1050/1406]  eta: 0:00:52  lr: 0.000000  loss: 0.2308 (0.2302)  labels_encoder: 0.1203 (0.1169)  labels_decoder: 0.1066 (0.1133)  labels_encoder_unscaled: 0.1203 (0.1169)  labels_decoder_unscaled: 0.2131 (0.2266)  time: 0.1486  data: 0.0003  max mem: 3463
Epoch: [4]  [1100/1406]  eta: 0:00:45  lr: 0.000000  loss: 0.2211 (0.2304)  labels_encoder: 0.1229 (0.1171)  labels_decoder: 0.1061 (0.1133)  labels_encoder_unscaled: 0.1229 (0.1171)  labels_decoder_unscaled: 0.2121 (0.2266)  time: 0.1475  data: 0.0003  max mem: 3463
Epoch: [4]  [1150/1406]  eta: 0:00:37  lr: 0.000000  loss: 0.2306 (0.2304)  labels_encoder: 0.1121 (0.1171)  labels_decoder: 0.1176 (0.1133)  labels_encoder_unscaled: 0.1121 (0.1171)  labels_decoder_unscaled: 0.2352 (0.2267)  time: 0.1503  data: 0.0003  max mem: 3463
Epoch: [4]  [1200/1406]  eta: 0:00:30  lr: 0.000000  loss: 0.2270 (0.2303)  labels_encoder: 0.1140 (0.1170)  labels_decoder: 0.1203 (0.1134)  labels_encoder_unscaled: 0.1140 (0.1170)  labels_decoder_unscaled: 0.2407 (0.2268)  time: 0.1462  data: 0.0002  max mem: 3463
Epoch: [4]  [1250/1406]  eta: 0:00:22  lr: 0.000000  loss: 0.2082 (0.2305)  labels_encoder: 0.1040 (0.1170)  labels_decoder: 0.1144 (0.1135)  labels_encoder_unscaled: 0.1040 (0.1170)  labels_decoder_unscaled: 0.2287 (0.2270)  time: 0.1447  data: 0.0003  max mem: 3463
Epoch: [4]  [1300/1406]  eta: 0:00:15  lr: 0.000000  loss: 0.2302 (0.2305)  labels_encoder: 0.1122 (0.1169)  labels_decoder: 0.1169 (0.1136)  labels_encoder_unscaled: 0.1122 (0.1169)  labels_decoder_unscaled: 0.2339 (0.2273)  time: 0.1449  data: 0.0003  max mem: 3463
Epoch: [4]  [1350/1406]  eta: 0:00:08  lr: 0.000000  loss: 0.2200 (0.2305)  labels_encoder: 0.1162 (0.1169)  labels_decoder: 0.1061 (0.1136)  labels_encoder_unscaled: 0.1162 (0.1169)  labels_decoder_unscaled: 0.2122 (0.2271)  time: 0.1320  data: 0.0002  max mem: 3463
Epoch: [4]  [1400/1406]  eta: 0:00:00  lr: 0.000000  loss: 0.2024 (0.2303)  labels_encoder: 0.0912 (0.1167)  labels_decoder: 0.1076 (0.1136)  labels_encoder_unscaled: 0.0912 (0.1167)  labels_decoder_unscaled: 0.2152 (0.2272)  time: 0.1344  data: 0.0004  max mem: 3463
Epoch: [4]  [1405/1406]  eta: 0:00:00  lr: 0.000000  loss: 0.2024 (0.2304)  labels_encoder: 0.1007 (0.1168)  labels_decoder: 0.1092 (0.1136)  labels_encoder_unscaled: 0.1007 (0.1168)  labels_decoder_unscaled: 0.2184 (0.2272)  time: 0.1271  data: 0.0004  max mem: 3463
Epoch: [4] Total time: 0:03:26 (0.1469 s / it)
Averaged stats: lr: 0.000000  loss: 0.2024 (0.2304)  labels_encoder: 0.1007 (0.1168)  labels_decoder: 0.1092 (0.1136)  labels_encoder_unscaled: 0.1007 (0.1168)  labels_decoder_unscaled: 0.2184 (0.2272)
Test:  [   0/1613]  eta: 0:46:58  loss: 0.6683 (0.6683)  labels_encoder: 0.4217 (0.4217)  labels_decoder: 0.2466 (0.2466)  labels_encoder_unscaled: 0.4217 (0.4217)  labels_decoder_unscaled: 0.4932 (0.4932)  time: 1.7475  data: 1.6798  max mem: 3463
Test:  [  50/1613]  eta: 0:02:36  loss: 0.6102 (0.9408)  labels_encoder: 0.3698 (0.6000)  labels_decoder: 0.2445 (0.3408)  labels_encoder_unscaled: 0.3698 (0.6000)  labels_decoder_unscaled: 0.4889 (0.6817)  time: 0.0671  data: 0.0002  max mem: 3463
Test:  [ 100/1613]  eta: 0:02:08  loss: 0.4257 (0.8151)  labels_encoder: 0.2651 (0.5338)  labels_decoder: 0.1061 (0.2813)  labels_encoder_unscaled: 0.2651 (0.5338)  labels_decoder_unscaled: 0.2122 (0.5626)  time: 0.0710  data: 0.0002  max mem: 3463
Test:  [ 150/1613]  eta: 0:01:56  loss: 0.7474 (0.7780)  labels_encoder: 0.5176 (0.5021)  labels_decoder: 0.2298 (0.2759)  labels_encoder_unscaled: 0.5176 (0.5021)  labels_decoder_unscaled: 0.4596 (0.5519)  time: 0.0654  data: 0.0002  max mem: 3463
Test:  [ 200/1613]  eta: 0:01:47  loss: 0.8710 (0.8875)  labels_encoder: 0.5052 (0.5712)  labels_decoder: 0.3761 (0.3162)  labels_encoder_unscaled: 0.5052 (0.5712)  labels_decoder_unscaled: 0.7521 (0.6324)  time: 0.0645  data: 0.0002  max mem: 3463
Test:  [ 250/1613]  eta: 0:01:41  loss: 0.6917 (0.9312)  labels_encoder: 0.4026 (0.5952)  labels_decoder: 0.3338 (0.3360)  labels_encoder_unscaled: 0.4026 (0.5952)  labels_decoder_unscaled: 0.6676 (0.6720)  time: 0.0658  data: 0.0002  max mem: 3463
Test:  [ 300/1613]  eta: 0:01:36  loss: 0.7676 (0.9470)  labels_encoder: 0.5139 (0.6086)  labels_decoder: 0.2762 (0.3384)  labels_encoder_unscaled: 0.5139 (0.6086)  labels_decoder_unscaled: 0.5525 (0.6767)  time: 0.0708  data: 0.0002  max mem: 3463
Test:  [ 350/1613]  eta: 0:01:32  loss: 1.2577 (0.9640)  labels_encoder: 0.6756 (0.6189)  labels_decoder: 0.4847 (0.3451)  labels_encoder_unscaled: 0.6756 (0.6189)  labels_decoder_unscaled: 0.9695 (0.6902)  time: 0.0741  data: 0.0002  max mem: 3463
Test:  [ 400/1613]  eta: 0:01:27  loss: 0.6530 (1.0220)  labels_encoder: 0.3327 (0.6569)  labels_decoder: 0.3172 (0.3651)  labels_encoder_unscaled: 0.3327 (0.6569)  labels_decoder_unscaled: 0.6343 (0.7302)  time: 0.0687  data: 0.0002  max mem: 3463
Test:  [ 450/1613]  eta: 0:01:23  loss: 1.0866 (1.1123)  labels_encoder: 0.8170 (0.7215)  labels_decoder: 0.3198 (0.3908)  labels_encoder_unscaled: 0.8170 (0.7215)  labels_decoder_unscaled: 0.6396 (0.7816)  time: 0.0598  data: 0.0002  max mem: 3463
Test:  [ 500/1613]  eta: 0:01:18  loss: 0.3153 (1.0650)  labels_encoder: 0.1725 (0.6879)  labels_decoder: 0.1681 (0.3771)  labels_encoder_unscaled: 0.1725 (0.6879)  labels_decoder_unscaled: 0.3362 (0.7541)  time: 0.0586  data: 0.0002  max mem: 3463
Test:  [ 550/1613]  eta: 0:01:14  loss: 0.7114 (1.0509)  labels_encoder: 0.4702 (0.6789)  labels_decoder: 0.2394 (0.3721)  labels_encoder_unscaled: 0.4702 (0.6789)  labels_decoder_unscaled: 0.4787 (0.7441)  time: 0.0662  data: 0.0002  max mem: 3463
Test:  [ 600/1613]  eta: 0:01:10  loss: 0.7027 (1.1188)  labels_encoder: 0.3839 (0.7336)  labels_decoder: 0.3063 (0.3853)  labels_encoder_unscaled: 0.3839 (0.7336)  labels_decoder_unscaled: 0.6126 (0.7705)  time: 0.0672  data: 0.0002  max mem: 3463
Test:  [ 650/1613]  eta: 0:01:07  loss: 1.1611 (1.1238)  labels_encoder: 0.6314 (0.7341)  labels_decoder: 0.4821 (0.3897)  labels_encoder_unscaled: 0.6314 (0.7341)  labels_decoder_unscaled: 0.9643 (0.7794)  time: 0.0748  data: 0.0002  max mem: 3463
Test:  [ 700/1613]  eta: 0:01:03  loss: 0.5336 (1.0967)  labels_encoder: 0.3101 (0.7152)  labels_decoder: 0.1877 (0.3815)  labels_encoder_unscaled: 0.3101 (0.7152)  labels_decoder_unscaled: 0.3755 (0.7629)  time: 0.0637  data: 0.0002  max mem: 3463
Test:  [ 750/1613]  eta: 0:00:59  loss: 0.6484 (1.0676)  labels_encoder: 0.4455 (0.6946)  labels_decoder: 0.2038 (0.3730)  labels_encoder_unscaled: 0.4455 (0.6946)  labels_decoder_unscaled: 0.4075 (0.7459)  time: 0.0699  data: 0.0002  max mem: 3463
Test:  [ 800/1613]  eta: 0:00:56  loss: 0.5680 (1.0558)  labels_encoder: 0.3535 (0.6859)  labels_decoder: 0.2182 (0.3698)  labels_encoder_unscaled: 0.3535 (0.6859)  labels_decoder_unscaled: 0.4364 (0.7396)  time: 0.0675  data: 0.0002  max mem: 3463
Test:  [ 850/1613]  eta: 0:00:52  loss: 0.8418 (1.0588)  labels_encoder: 0.4868 (0.6849)  labels_decoder: 0.3551 (0.3739)  labels_encoder_unscaled: 0.4868 (0.6849)  labels_decoder_unscaled: 0.7101 (0.7478)  time: 0.0648  data: 0.0002  max mem: 3463
Test:  [ 900/1613]  eta: 0:00:49  loss: 0.6575 (1.0399)  labels_encoder: 0.3806 (0.6705)  labels_decoder: 0.2685 (0.3694)  labels_encoder_unscaled: 0.3806 (0.6705)  labels_decoder_unscaled: 0.5371 (0.7388)  time: 0.0688  data: 0.0002  max mem: 3463
Test:  [ 950/1613]  eta: 0:00:45  loss: 0.8949 (1.0320)  labels_encoder: 0.5625 (0.6649)  labels_decoder: 0.3445 (0.3671)  labels_encoder_unscaled: 0.5625 (0.6649)  labels_decoder_unscaled: 0.6891 (0.7343)  time: 0.0646  data: 0.0002  max mem: 3463
Test:  [1000/1613]  eta: 0:00:42  loss: 0.5559 (1.0159)  labels_encoder: 0.2863 (0.6531)  labels_decoder: 0.2696 (0.3628)  labels_encoder_unscaled: 0.2863 (0.6531)  labels_decoder_unscaled: 0.5392 (0.7256)  time: 0.0728  data: 0.0002  max mem: 3463
Test:  [1050/1613]  eta: 0:00:39  loss: 0.9989 (1.0174)  labels_encoder: 0.6444 (0.6552)  labels_decoder: 0.3502 (0.3622)  labels_encoder_unscaled: 0.6444 (0.6552)  labels_decoder_unscaled: 0.7003 (0.7245)  time: 0.0709  data: 0.0002  max mem: 3463
Test:  [1100/1613]  eta: 0:00:35  loss: 0.3353 (1.0118)  labels_encoder: 0.2211 (0.6520)  labels_decoder: 0.1462 (0.3598)  labels_encoder_unscaled: 0.2211 (0.6520)  labels_decoder_unscaled: 0.2923 (0.7195)  time: 0.0682  data: 0.0002  max mem: 3463
Test:  [1150/1613]  eta: 0:00:32  loss: 0.8162 (1.0051)  labels_encoder: 0.4958 (0.6473)  labels_decoder: 0.2400 (0.3578)  labels_encoder_unscaled: 0.4958 (0.6473)  labels_decoder_unscaled: 0.4800 (0.7157)  time: 0.0708  data: 0.0002  max mem: 3463
Test:  [1200/1613]  eta: 0:00:28  loss: 0.6000 (1.0148)  labels_encoder: 0.2854 (0.6535)  labels_decoder: 0.2477 (0.3614)  labels_encoder_unscaled: 0.2854 (0.6535)  labels_decoder_unscaled: 0.4954 (0.7227)  time: 0.0656  data: 0.0002  max mem: 3463
Test:  [1250/1613]  eta: 0:00:25  loss: 0.5140 (1.0143)  labels_encoder: 0.2652 (0.6532)  labels_decoder: 0.2251 (0.3612)  labels_encoder_unscaled: 0.2652 (0.6532)  labels_decoder_unscaled: 0.4502 (0.7224)  time: 0.0649  data: 0.0002  max mem: 3463
Test:  [1300/1613]  eta: 0:00:21  loss: 0.5933 (1.0047)  labels_encoder: 0.3672 (0.6458)  labels_decoder: 0.2606 (0.3588)  labels_encoder_unscaled: 0.3672 (0.6458)  labels_decoder_unscaled: 0.5211 (0.7177)  time: 0.0665  data: 0.0002  max mem: 3463
Test:  [1350/1613]  eta: 0:00:18  loss: 1.0048 (1.0070)  labels_encoder: 0.6346 (0.6479)  labels_decoder: 0.3702 (0.3591)  labels_encoder_unscaled: 0.6346 (0.6479)  labels_decoder_unscaled: 0.7404 (0.7183)  time: 0.0658  data: 0.0002  max mem: 3463
Test:  [1400/1613]  eta: 0:00:14  loss: 0.9049 (1.0150)  labels_encoder: 0.6028 (0.6534)  labels_decoder: 0.3326 (0.3617)  labels_encoder_unscaled: 0.6028 (0.6534)  labels_decoder_unscaled: 0.6651 (0.7234)  time: 0.0714  data: 0.0002  max mem: 3463
Test:  [1450/1613]  eta: 0:00:11  loss: 0.5020 (1.0171)  labels_encoder: 0.2157 (0.6548)  labels_decoder: 0.1916 (0.3624)  labels_encoder_unscaled: 0.2157 (0.6548)  labels_decoder_unscaled: 0.3831 (0.7248)  time: 0.0656  data: 0.0002  max mem: 3463
Test:  [1500/1613]  eta: 0:00:07  loss: 0.5281 (1.0139)  labels_encoder: 0.3255 (0.6526)  labels_decoder: 0.1859 (0.3612)  labels_encoder_unscaled: 0.3255 (0.6526)  labels_decoder_unscaled: 0.3719 (0.7225)  time: 0.0642  data: 0.0010  max mem: 3463
Test:  [1550/1613]  eta: 0:00:04  loss: 0.8823 (1.0114)  labels_encoder: 0.5585 (0.6517)  labels_decoder: 0.3050 (0.3597)  labels_encoder_unscaled: 0.5585 (0.6517)  labels_decoder_unscaled: 0.6099 (0.7194)  time: 0.0710  data: 0.0002  max mem: 3463
Test:  [1600/1613]  eta: 0:00:00  loss: 0.8363 (1.0070)  labels_encoder: 0.5208 (0.6479)  labels_decoder: 0.3739 (0.3591)  labels_encoder_unscaled: 0.5208 (0.6479)  labels_decoder_unscaled: 0.7479 (0.7181)  time: 0.0617  data: 0.0002  max mem: 3463
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6191 (1.0053)  labels_encoder: 0.2901 (0.6470)  labels_decoder: 0.2882 (0.3583)  labels_encoder_unscaled: 0.2901 (0.6470)  labels_decoder_unscaled: 0.5764 (0.7166)  time: 0.0494  data: 0.0001  max mem: 3463
Test: Total time: 0:01:51 (0.0689 s / it)
Averaged stats: loss: 0.6191 (1.0053)  labels_encoder: 0.2901 (0.6470)  labels_decoder: 0.2882 (0.3583)  labels_encoder_unscaled: 0.2901 (0.6470)  labels_decoder_unscaled: 0.5764 (0.7166)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-kin] mAP: 0.6415

dec_mAP all together: | 0.5115131807969171 |.
dec_mAP_pred | 0 : 0.5596247295935983 |.
dec_mAP_pred | 1 : 0.5515416003965231 |.
dec_mAP_pred | 2 : 0.5387763838453851 |.
dec_mAP_pred | 3 : 0.5234383317984942 |.
dec_mAP_pred | 4 : 0.5067129552727756 |.
dec_mAP_pred | 5 : 0.4900379357641288 |.
dec_mAP_pred | 6 : 0.47348725171276973 |.
dec_mAP_pred | 7 : 0.4576261897010093 |.
all decoder map: | 0.5127 |.
BaseballPitch: 0.4067
BasketballDunk: 0.8116
Billiards: 0.2917
CleanAndJerk: 0.7346
CliffDiving: 0.8526
CricketBowling: 0.4639
CricketShot: 0.2393
Diving: 0.8561
FrisbeeCatch: 0.4742
GolfSwing: 0.7834
HammerThrow: 0.8611
HighJump: 0.7663
JavelinThrow: 0.7727
LongJump: 0.7828
PoleVault: 0.8813
Shotput: 0.7325
SoccerPenalty: 0.4272
TennisSwing: 0.5749
ThrowDiscus: 0.6920
VolleyballSpiking: 0.4260
Training time 0:23:05
