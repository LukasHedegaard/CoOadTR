Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:1
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  78.772 M, 99.834% Params, 2.714 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 9.304% Params, 0.47 GMac, 17.307% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 23.933% Params, 1.227 GMac, 45.207% MACs, 
    (net): Sequential(
      18.884 M, 23.933% Params, 1.227 GMac, 45.207% MACs, 
      (0): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.057% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 66.512% Params, 1.017 GMac, 37.478% MACs, 
    (layers): ModuleList(
      52.48 M, 66.512% Params, 1.017 GMac, 37.478% MACs, 
      (0): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.029% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2714272812.0
Model params: 78903340
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1415]  eta: 1:26:47  lr: 0.000100  loss: 4.8669 (4.8669)  labels_encoder: 3.1856 (3.1856)  labels_decoder: 1.6813 (1.6813)  labels_encoder_unscaled: 3.1856 (3.1856)  labels_decoder_unscaled: 3.3627 (3.3627)  time: 3.6799  data: 2.9085  max mem: 2800
Epoch: [1]  [  50/1415]  eta: 0:06:28  lr: 0.000100  loss: 1.0981 (1.7126)  labels_encoder: 0.7237 (1.1060)  labels_decoder: 0.4168 (0.6065)  labels_encoder_unscaled: 0.7237 (1.1060)  labels_decoder_unscaled: 0.8335 (1.2130)  time: 0.1802  data: 0.0003  max mem: 3702
Epoch: [1]  [ 100/1415]  eta: 0:05:08  lr: 0.000100  loss: 0.7196 (1.2692)  labels_encoder: 0.4412 (0.8117)  labels_decoder: 0.2684 (0.4575)  labels_encoder_unscaled: 0.4412 (0.8117)  labels_decoder_unscaled: 0.5368 (0.9149)  time: 0.1735  data: 0.0003  max mem: 3702
Epoch: [1]  [ 150/1415]  eta: 0:04:32  lr: 0.000100  loss: 0.6772 (1.0927)  labels_encoder: 0.4249 (0.6940)  labels_decoder: 0.2595 (0.3987)  labels_encoder_unscaled: 0.4249 (0.6940)  labels_decoder_unscaled: 0.5191 (0.7974)  time: 0.1819  data: 0.0003  max mem: 3702
Epoch: [1]  [ 200/1415]  eta: 0:04:10  lr: 0.000100  loss: 0.6788 (0.9979)  labels_encoder: 0.4143 (0.6312)  labels_decoder: 0.2763 (0.3667)  labels_encoder_unscaled: 0.4143 (0.6312)  labels_decoder_unscaled: 0.5526 (0.7334)  time: 0.1762  data: 0.0004  max mem: 3702
Epoch: [1]  [ 250/1415]  eta: 0:03:54  lr: 0.000100  loss: 0.6217 (0.9241)  labels_encoder: 0.3757 (0.5806)  labels_decoder: 0.2459 (0.3435)  labels_encoder_unscaled: 0.3757 (0.5806)  labels_decoder_unscaled: 0.4919 (0.6870)  time: 0.1793  data: 0.0017  max mem: 3702
Epoch: [1]  [ 300/1415]  eta: 0:03:41  lr: 0.000100  loss: 0.5736 (0.8722)  labels_encoder: 0.3587 (0.5471)  labels_decoder: 0.2376 (0.3251)  labels_encoder_unscaled: 0.3587 (0.5471)  labels_decoder_unscaled: 0.4752 (0.6502)  time: 0.1875  data: 0.0004  max mem: 3702
Epoch: [1]  [ 350/1415]  eta: 0:03:28  lr: 0.000100  loss: 0.5305 (0.8331)  labels_encoder: 0.3307 (0.5212)  labels_decoder: 0.2179 (0.3119)  labels_encoder_unscaled: 0.3307 (0.5212)  labels_decoder_unscaled: 0.4358 (0.6238)  time: 0.1750  data: 0.0003  max mem: 3702
Epoch: [1]  [ 400/1415]  eta: 0:03:16  lr: 0.000100  loss: 0.5532 (0.7992)  labels_encoder: 0.3353 (0.4984)  labels_decoder: 0.2225 (0.3008)  labels_encoder_unscaled: 0.3353 (0.4984)  labels_decoder_unscaled: 0.4450 (0.6015)  time: 0.1807  data: 0.0003  max mem: 3702
Epoch: [1]  [ 450/1415]  eta: 0:03:04  lr: 0.000100  loss: 0.5174 (0.7709)  labels_encoder: 0.3141 (0.4799)  labels_decoder: 0.2041 (0.2910)  labels_encoder_unscaled: 0.3141 (0.4799)  labels_decoder_unscaled: 0.4081 (0.5820)  time: 0.1843  data: 0.0003  max mem: 3702
Epoch: [1]  [ 500/1415]  eta: 0:02:54  lr: 0.000100  loss: 0.5095 (0.7459)  labels_encoder: 0.3053 (0.4632)  labels_decoder: 0.2085 (0.2827)  labels_encoder_unscaled: 0.3053 (0.4632)  labels_decoder_unscaled: 0.4169 (0.5654)  time: 0.1915  data: 0.0003  max mem: 3702
Epoch: [1]  [ 550/1415]  eta: 0:02:44  lr: 0.000100  loss: 0.4661 (0.7223)  labels_encoder: 0.2778 (0.4471)  labels_decoder: 0.1934 (0.2752)  labels_encoder_unscaled: 0.2778 (0.4471)  labels_decoder_unscaled: 0.3869 (0.5505)  time: 0.1938  data: 0.0003  max mem: 3702
Epoch: [1]  [ 600/1415]  eta: 0:02:34  lr: 0.000100  loss: 0.4842 (0.7038)  labels_encoder: 0.2764 (0.4347)  labels_decoder: 0.1964 (0.2690)  labels_encoder_unscaled: 0.2764 (0.4347)  labels_decoder_unscaled: 0.3927 (0.5380)  time: 0.1750  data: 0.0003  max mem: 3702
Epoch: [1]  [ 650/1415]  eta: 0:02:24  lr: 0.000100  loss: 0.4580 (0.6863)  labels_encoder: 0.2766 (0.4231)  labels_decoder: 0.1815 (0.2632)  labels_encoder_unscaled: 0.2766 (0.4231)  labels_decoder_unscaled: 0.3630 (0.5264)  time: 0.1769  data: 0.0003  max mem: 3702
Epoch: [1]  [ 700/1415]  eta: 0:02:14  lr: 0.000100  loss: 0.4818 (0.6713)  labels_encoder: 0.2890 (0.4131)  labels_decoder: 0.1841 (0.2581)  labels_encoder_unscaled: 0.2890 (0.4131)  labels_decoder_unscaled: 0.3682 (0.5163)  time: 0.1792  data: 0.0003  max mem: 3702
Epoch: [1]  [ 750/1415]  eta: 0:02:04  lr: 0.000100  loss: 0.4517 (0.6573)  labels_encoder: 0.2649 (0.4037)  labels_decoder: 0.1830 (0.2536)  labels_encoder_unscaled: 0.2649 (0.4037)  labels_decoder_unscaled: 0.3661 (0.5071)  time: 0.1753  data: 0.0005  max mem: 3702
Epoch: [1]  [ 800/1415]  eta: 0:01:55  lr: 0.000100  loss: 0.4617 (0.6440)  labels_encoder: 0.2659 (0.3943)  labels_decoder: 0.1954 (0.2496)  labels_encoder_unscaled: 0.2659 (0.3943)  labels_decoder_unscaled: 0.3907 (0.4993)  time: 0.1766  data: 0.0004  max mem: 3702
Epoch: [1]  [ 850/1415]  eta: 0:01:45  lr: 0.000100  loss: 0.4499 (0.6324)  labels_encoder: 0.2499 (0.3866)  labels_decoder: 0.1814 (0.2459)  labels_encoder_unscaled: 0.2499 (0.3866)  labels_decoder_unscaled: 0.3628 (0.4917)  time: 0.1908  data: 0.0003  max mem: 3702
Epoch: [1]  [ 900/1415]  eta: 0:01:36  lr: 0.000100  loss: 0.4754 (0.6221)  labels_encoder: 0.2728 (0.3795)  labels_decoder: 0.1876 (0.2426)  labels_encoder_unscaled: 0.2728 (0.3795)  labels_decoder_unscaled: 0.3751 (0.4851)  time: 0.1960  data: 0.0004  max mem: 3702
Epoch: [1]  [ 950/1415]  eta: 0:01:27  lr: 0.000100  loss: 0.4608 (0.6134)  labels_encoder: 0.2828 (0.3740)  labels_decoder: 0.1801 (0.2394)  labels_encoder_unscaled: 0.2828 (0.3740)  labels_decoder_unscaled: 0.3601 (0.4787)  time: 0.1778  data: 0.0003  max mem: 3702
Epoch: [1]  [1000/1415]  eta: 0:01:17  lr: 0.000100  loss: 0.3991 (0.6041)  labels_encoder: 0.2238 (0.3678)  labels_decoder: 0.1833 (0.2363)  labels_encoder_unscaled: 0.2238 (0.3678)  labels_decoder_unscaled: 0.3666 (0.4727)  time: 0.1761  data: 0.0003  max mem: 3702
Epoch: [1]  [1050/1415]  eta: 0:01:07  lr: 0.000100  loss: 0.4362 (0.5960)  labels_encoder: 0.2324 (0.3622)  labels_decoder: 0.1811 (0.2338)  labels_encoder_unscaled: 0.2324 (0.3622)  labels_decoder_unscaled: 0.3623 (0.4677)  time: 0.1659  data: 0.0003  max mem: 3702
Epoch: [1]  [1100/1415]  eta: 0:00:58  lr: 0.000100  loss: 0.3963 (0.5880)  labels_encoder: 0.2213 (0.3565)  labels_decoder: 0.1777 (0.2315)  labels_encoder_unscaled: 0.2213 (0.3565)  labels_decoder_unscaled: 0.3554 (0.4630)  time: 0.1802  data: 0.0004  max mem: 3702
Epoch: [1]  [1150/1415]  eta: 0:00:49  lr: 0.000100  loss: 0.3728 (0.5796)  labels_encoder: 0.2052 (0.3509)  labels_decoder: 0.1516 (0.2286)  labels_encoder_unscaled: 0.2052 (0.3509)  labels_decoder_unscaled: 0.3033 (0.4572)  time: 0.1795  data: 0.0003  max mem: 3702
Epoch: [1]  [1200/1415]  eta: 0:00:39  lr: 0.000100  loss: 0.4165 (0.5728)  labels_encoder: 0.2373 (0.3464)  labels_decoder: 0.1768 (0.2265)  labels_encoder_unscaled: 0.2373 (0.3464)  labels_decoder_unscaled: 0.3536 (0.4529)  time: 0.1850  data: 0.0004  max mem: 3702
Epoch: [1]  [1250/1415]  eta: 0:00:30  lr: 0.000100  loss: 0.3733 (0.5654)  labels_encoder: 0.2021 (0.3415)  labels_decoder: 0.1590 (0.2239)  labels_encoder_unscaled: 0.2021 (0.3415)  labels_decoder_unscaled: 0.3180 (0.4479)  time: 0.1729  data: 0.0003  max mem: 3702
Epoch: [1]  [1300/1415]  eta: 0:00:21  lr: 0.000100  loss: 0.3901 (0.5585)  labels_encoder: 0.2287 (0.3369)  labels_decoder: 0.1641 (0.2216)  labels_encoder_unscaled: 0.2287 (0.3369)  labels_decoder_unscaled: 0.3282 (0.4432)  time: 0.1799  data: 0.0003  max mem: 3702
Epoch: [1]  [1350/1415]  eta: 0:00:11  lr: 0.000100  loss: 0.3809 (0.5522)  labels_encoder: 0.2069 (0.3324)  labels_decoder: 0.1622 (0.2198)  labels_encoder_unscaled: 0.2069 (0.3324)  labels_decoder_unscaled: 0.3244 (0.4395)  time: 0.1833  data: 0.0004  max mem: 3702
Epoch: [1]  [1400/1415]  eta: 0:00:02  lr: 0.000100  loss: 0.3707 (0.5463)  labels_encoder: 0.2144 (0.3284)  labels_decoder: 0.1726 (0.2178)  labels_encoder_unscaled: 0.2144 (0.3284)  labels_decoder_unscaled: 0.3451 (0.4357)  time: 0.1645  data: 0.0005  max mem: 3702
Epoch: [1]  [1414/1415]  eta: 0:00:00  lr: 0.000100  loss: 0.3895 (0.5446)  labels_encoder: 0.2069 (0.3273)  labels_decoder: 0.1720 (0.2173)  labels_encoder_unscaled: 0.2069 (0.3273)  labels_decoder_unscaled: 0.3439 (0.4346)  time: 0.1431  data: 0.0004  max mem: 3702
Epoch: [1] Total time: 0:04:20 (0.1842 s / it)
Averaged stats: lr: 0.000100  loss: 0.3895 (0.5446)  labels_encoder: 0.2069 (0.3273)  labels_decoder: 0.1720 (0.2173)  labels_encoder_unscaled: 0.2069 (0.3273)  labels_decoder_unscaled: 0.3439 (0.4346)
Test:  [   0/1613]  eta: 1:00:02  loss: 1.8927 (1.8927)  labels_encoder: 1.1307 (1.1307)  labels_decoder: 0.7620 (0.7620)  labels_encoder_unscaled: 1.1307 (1.1307)  labels_decoder_unscaled: 1.5241 (1.5241)  time: 2.2337  data: 2.1680  max mem: 3702
Test:  [  50/1613]  eta: 0:04:09  loss: 0.4643 (0.8784)  labels_encoder: 0.2206 (0.5139)  labels_decoder: 0.2532 (0.3645)  labels_encoder_unscaled: 0.2206 (0.5139)  labels_decoder_unscaled: 0.5064 (0.7289)  time: 0.1149  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:25  loss: 0.3216 (0.7869)  labels_encoder: 0.2502 (0.4796)  labels_decoder: 0.1012 (0.3073)  labels_encoder_unscaled: 0.2502 (0.4796)  labels_decoder_unscaled: 0.2024 (0.6146)  time: 0.1093  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:04  loss: 1.0623 (0.7814)  labels_encoder: 0.7599 (0.4929)  labels_decoder: 0.2984 (0.2885)  labels_encoder_unscaled: 0.7599 (0.4929)  labels_decoder_unscaled: 0.5967 (0.5770)  time: 0.1013  data: 0.0002  max mem: 3702
Test:  [ 200/1613]  eta: 0:02:51  loss: 0.9792 (0.8775)  labels_encoder: 0.6096 (0.5630)  labels_decoder: 0.3696 (0.3145)  labels_encoder_unscaled: 0.6096 (0.5630)  labels_decoder_unscaled: 0.7391 (0.6289)  time: 0.1048  data: 0.0002  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:41  loss: 0.5416 (0.9437)  labels_encoder: 0.4379 (0.6062)  labels_decoder: 0.1601 (0.3376)  labels_encoder_unscaled: 0.4379 (0.6062)  labels_decoder_unscaled: 0.3202 (0.6751)  time: 0.1022  data: 0.0002  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:32  loss: 0.5206 (0.9643)  labels_encoder: 0.3004 (0.6230)  labels_decoder: 0.2202 (0.3413)  labels_encoder_unscaled: 0.3004 (0.6230)  labels_decoder_unscaled: 0.4403 (0.6826)  time: 0.1039  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:24  loss: 1.0887 (0.9602)  labels_encoder: 0.6123 (0.6156)  labels_decoder: 0.3948 (0.3446)  labels_encoder_unscaled: 0.6123 (0.6156)  labels_decoder_unscaled: 0.7896 (0.6892)  time: 0.1052  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:17  loss: 0.7524 (1.0227)  labels_encoder: 0.4125 (0.6556)  labels_decoder: 0.3499 (0.3671)  labels_encoder_unscaled: 0.4125 (0.6556)  labels_decoder_unscaled: 0.6998 (0.7341)  time: 0.1029  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:10  loss: 0.9290 (1.0960)  labels_encoder: 0.5747 (0.7043)  labels_decoder: 0.3076 (0.3917)  labels_encoder_unscaled: 0.5747 (0.7043)  labels_decoder_unscaled: 0.6151 (0.7834)  time: 0.1026  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:05  loss: 0.3847 (1.0547)  labels_encoder: 0.1990 (0.6755)  labels_decoder: 0.2026 (0.3792)  labels_encoder_unscaled: 0.1990 (0.6755)  labels_decoder_unscaled: 0.4053 (0.7583)  time: 0.1216  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:01:59  loss: 0.6744 (1.0675)  labels_encoder: 0.4286 (0.6872)  labels_decoder: 0.3247 (0.3803)  labels_encoder_unscaled: 0.4286 (0.6872)  labels_decoder_unscaled: 0.6495 (0.7606)  time: 0.1095  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:01:54  loss: 1.4304 (1.0871)  labels_encoder: 0.9129 (0.7054)  labels_decoder: 0.4636 (0.3817)  labels_encoder_unscaled: 0.9129 (0.7054)  labels_decoder_unscaled: 0.9271 (0.7634)  time: 0.1089  data: 0.0005  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:48  loss: 0.8219 (1.0676)  labels_encoder: 0.4862 (0.6880)  labels_decoder: 0.3946 (0.3796)  labels_encoder_unscaled: 0.4862 (0.6880)  labels_decoder_unscaled: 0.7893 (0.7591)  time: 0.1082  data: 0.0007  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:42  loss: 0.8846 (1.0405)  labels_encoder: 0.5317 (0.6695)  labels_decoder: 0.3008 (0.3710)  labels_encoder_unscaled: 0.5317 (0.6695)  labels_decoder_unscaled: 0.6015 (0.7420)  time: 0.1037  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:36  loss: 0.8201 (1.0323)  labels_encoder: 0.4834 (0.6617)  labels_decoder: 0.3390 (0.3706)  labels_encoder_unscaled: 0.4834 (0.6617)  labels_decoder_unscaled: 0.6781 (0.7412)  time: 0.1045  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:30  loss: 0.6286 (1.0227)  labels_encoder: 0.3820 (0.6569)  labels_decoder: 0.2385 (0.3659)  labels_encoder_unscaled: 0.3820 (0.6569)  labels_decoder_unscaled: 0.4769 (0.7318)  time: 0.1110  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:24  loss: 1.7269 (1.0435)  labels_encoder: 1.0535 (0.6673)  labels_decoder: 0.7285 (0.3762)  labels_encoder_unscaled: 1.0535 (0.6673)  labels_decoder_unscaled: 1.4570 (0.7524)  time: 0.1113  data: 0.0002  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:18  loss: 0.7255 (1.0655)  labels_encoder: 0.3565 (0.6804)  labels_decoder: 0.3455 (0.3851)  labels_encoder_unscaled: 0.3565 (0.6804)  labels_decoder_unscaled: 0.6910 (0.7703)  time: 0.1072  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:13  loss: 1.2284 (1.0555)  labels_encoder: 0.7980 (0.6735)  labels_decoder: 0.3628 (0.3820)  labels_encoder_unscaled: 0.7980 (0.6735)  labels_decoder_unscaled: 0.7256 (0.7640)  time: 0.1106  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:07  loss: 0.5013 (1.0396)  labels_encoder: 0.2746 (0.6619)  labels_decoder: 0.2429 (0.3778)  labels_encoder_unscaled: 0.2746 (0.6619)  labels_decoder_unscaled: 0.4858 (0.7556)  time: 0.1126  data: 0.0002  max mem: 3702
Test:  [1050/1613]  eta: 0:01:02  loss: 0.9153 (1.0406)  labels_encoder: 0.5676 (0.6623)  labels_decoder: 0.3823 (0.3783)  labels_encoder_unscaled: 0.5676 (0.6623)  labels_decoder_unscaled: 0.7647 (0.7566)  time: 0.1073  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:00:56  loss: 0.5963 (1.0399)  labels_encoder: 0.3352 (0.6634)  labels_decoder: 0.2611 (0.3765)  labels_encoder_unscaled: 0.3352 (0.6634)  labels_decoder_unscaled: 0.5222 (0.7530)  time: 0.1110  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:51  loss: 0.5710 (1.0295)  labels_encoder: 0.2773 (0.6554)  labels_decoder: 0.2553 (0.3740)  labels_encoder_unscaled: 0.2773 (0.6554)  labels_decoder_unscaled: 0.5105 (0.7481)  time: 0.1080  data: 0.0003  max mem: 3702
Test:  [1200/1613]  eta: 0:00:45  loss: 0.6066 (1.0277)  labels_encoder: 0.3628 (0.6533)  labels_decoder: 0.2395 (0.3744)  labels_encoder_unscaled: 0.3628 (0.6533)  labels_decoder_unscaled: 0.4790 (0.7488)  time: 0.1048  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:39  loss: 0.3759 (1.0259)  labels_encoder: 0.1819 (0.6519)  labels_decoder: 0.1940 (0.3741)  labels_encoder_unscaled: 0.1819 (0.6519)  labels_decoder_unscaled: 0.3880 (0.7481)  time: 0.1019  data: 0.0003  max mem: 3702
Test:  [1300/1613]  eta: 0:00:34  loss: 0.6240 (1.0142)  labels_encoder: 0.4176 (0.6434)  labels_decoder: 0.2906 (0.3708)  labels_encoder_unscaled: 0.4176 (0.6434)  labels_decoder_unscaled: 0.5812 (0.7416)  time: 0.1043  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:29  loss: 0.8625 (1.0317)  labels_encoder: 0.4671 (0.6555)  labels_decoder: 0.3513 (0.3762)  labels_encoder_unscaled: 0.4671 (0.6555)  labels_decoder_unscaled: 0.7027 (0.7524)  time: 0.1117  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:23  loss: 1.2196 (1.0300)  labels_encoder: 0.7964 (0.6549)  labels_decoder: 0.4232 (0.3751)  labels_encoder_unscaled: 0.7964 (0.6549)  labels_decoder_unscaled: 0.8464 (0.7502)  time: 0.1171  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:18  loss: 0.5656 (1.0427)  labels_encoder: 0.3000 (0.6640)  labels_decoder: 0.2204 (0.3787)  labels_encoder_unscaled: 0.3000 (0.6640)  labels_decoder_unscaled: 0.4408 (0.7574)  time: 0.1170  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:12  loss: 0.7837 (1.0412)  labels_encoder: 0.4334 (0.6626)  labels_decoder: 0.3285 (0.3787)  labels_encoder_unscaled: 0.4334 (0.6626)  labels_decoder_unscaled: 0.6570 (0.7574)  time: 0.1052  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6120 (1.0407)  labels_encoder: 0.3767 (0.6620)  labels_decoder: 0.2638 (0.3787)  labels_encoder_unscaled: 0.3767 (0.6620)  labels_decoder_unscaled: 0.5277 (0.7574)  time: 0.1044  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9141 (1.0390)  labels_encoder: 0.5345 (0.6599)  labels_decoder: 0.3796 (0.3790)  labels_encoder_unscaled: 0.5345 (0.6599)  labels_decoder_unscaled: 0.7591 (0.7580)  time: 0.1142  data: 0.0002  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7015 (1.0386)  labels_encoder: 0.3596 (0.6600)  labels_decoder: 0.3419 (0.3786)  labels_encoder_unscaled: 0.3596 (0.6600)  labels_decoder_unscaled: 0.6838 (0.7572)  time: 0.0959  data: 0.0001  max mem: 3702
Test: Total time: 0:02:58 (0.1109 s / it)
Averaged stats: loss: 0.7015 (1.0386)  labels_encoder: 0.3596 (0.6600)  labels_decoder: 0.3419 (0.3786)  labels_encoder_unscaled: 0.3596 (0.6600)  labels_decoder_unscaled: 0.6838 (0.7572)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.5776

dec_mAP all together: | 0.46693617080131977 |.
dec_mAP_pred | 0 : 0.5209099791303144 |.
dec_mAP_pred | 1 : 0.5089400553733331 |.
dec_mAP_pred | 2 : 0.49315291586574606 |.
dec_mAP_pred | 3 : 0.4762990706474174 |.
dec_mAP_pred | 4 : 0.45995786656916804 |.
dec_mAP_pred | 5 : 0.44417538854432453 |.
dec_mAP_pred | 6 : 0.42916039375037685 |.
dec_mAP_pred | 7 : 0.4154230375364154 |.
all decoder map: | 0.4685 |.
BaseballPitch: 0.0963
BasketballDunk: 0.7867
Billiards: 0.4468
CleanAndJerk: 0.7910
CliffDiving: 0.8338
CricketBowling: 0.4536
CricketShot: 0.2370
Diving: 0.6840
FrisbeeCatch: 0.3557
GolfSwing: 0.6096
HammerThrow: 0.8562
HighJump: 0.6533
JavelinThrow: 0.6774
LongJump: 0.7797
PoleVault: 0.9003
Shotput: 0.6871
SoccerPenalty: 0.2556
TennisSwing: 0.5013
ThrowDiscus: 0.6119
VolleyballSpiking: 0.3344
Epoch: [2]  [   0/1415]  eta: 1:07:48  lr: 0.000010  loss: 0.3413 (0.3413)  labels_encoder: 0.1848 (0.1848)  labels_decoder: 0.1565 (0.1565)  labels_encoder_unscaled: 0.1848 (0.1848)  labels_decoder_unscaled: 0.3131 (0.3131)  time: 2.8755  data: 2.6812  max mem: 3702
Epoch: [2]  [  50/1415]  eta: 0:05:09  lr: 0.000010  loss: 0.3015 (0.3303)  labels_encoder: 0.1624 (0.1800)  labels_decoder: 0.1391 (0.1503)  labels_encoder_unscaled: 0.1624 (0.1800)  labels_decoder_unscaled: 0.2782 (0.3006)  time: 0.1683  data: 0.0003  max mem: 3702
Epoch: [2]  [ 100/1415]  eta: 0:04:20  lr: 0.000010  loss: 0.3012 (0.3264)  labels_encoder: 0.1581 (0.1784)  labels_decoder: 0.1385 (0.1480)  labels_encoder_unscaled: 0.1581 (0.1784)  labels_decoder_unscaled: 0.2770 (0.2960)  time: 0.1722  data: 0.0003  max mem: 3702
Epoch: [2]  [ 150/1415]  eta: 0:03:59  lr: 0.000010  loss: 0.3153 (0.3210)  labels_encoder: 0.1676 (0.1750)  labels_decoder: 0.1451 (0.1460)  labels_encoder_unscaled: 0.1676 (0.1750)  labels_decoder_unscaled: 0.2903 (0.2921)  time: 0.1762  data: 0.0003  max mem: 3702
Epoch: [2]  [ 200/1415]  eta: 0:03:51  lr: 0.000010  loss: 0.2671 (0.3117)  labels_encoder: 0.1415 (0.1686)  labels_decoder: 0.1341 (0.1431)  labels_encoder_unscaled: 0.1415 (0.1686)  labels_decoder_unscaled: 0.2681 (0.2863)  time: 0.1852  data: 0.0003  max mem: 3702
Epoch: [2]  [ 250/1415]  eta: 0:03:41  lr: 0.000010  loss: 0.2684 (0.3086)  labels_encoder: 0.1482 (0.1667)  labels_decoder: 0.1339 (0.1420)  labels_encoder_unscaled: 0.1482 (0.1667)  labels_decoder_unscaled: 0.2677 (0.2840)  time: 0.1942  data: 0.0004  max mem: 3702
Epoch: [2]  [ 300/1415]  eta: 0:03:31  lr: 0.000010  loss: 0.2903 (0.3058)  labels_encoder: 0.1552 (0.1651)  labels_decoder: 0.1323 (0.1408)  labels_encoder_unscaled: 0.1552 (0.1651)  labels_decoder_unscaled: 0.2646 (0.2815)  time: 0.1855  data: 0.0003  max mem: 3702
Epoch: [2]  [ 350/1415]  eta: 0:03:21  lr: 0.000010  loss: 0.2479 (0.3013)  labels_encoder: 0.1319 (0.1624)  labels_decoder: 0.1113 (0.1389)  labels_encoder_unscaled: 0.1319 (0.1624)  labels_decoder_unscaled: 0.2226 (0.2778)  time: 0.1816  data: 0.0003  max mem: 3702
Epoch: [2]  [ 400/1415]  eta: 0:03:12  lr: 0.000010  loss: 0.2877 (0.2998)  labels_encoder: 0.1585 (0.1619)  labels_decoder: 0.1287 (0.1379)  labels_encoder_unscaled: 0.1585 (0.1619)  labels_decoder_unscaled: 0.2574 (0.2759)  time: 0.1848  data: 0.0003  max mem: 3702
Epoch: [2]  [ 450/1415]  eta: 0:03:02  lr: 0.000010  loss: 0.2867 (0.2988)  labels_encoder: 0.1589 (0.1617)  labels_decoder: 0.1230 (0.1371)  labels_encoder_unscaled: 0.1589 (0.1617)  labels_decoder_unscaled: 0.2461 (0.2742)  time: 0.1915  data: 0.0003  max mem: 3702
Epoch: [2]  [ 500/1415]  eta: 0:02:52  lr: 0.000010  loss: 0.2627 (0.2965)  labels_encoder: 0.1431 (0.1601)  labels_decoder: 0.1315 (0.1364)  labels_encoder_unscaled: 0.1431 (0.1601)  labels_decoder_unscaled: 0.2630 (0.2729)  time: 0.1919  data: 0.0003  max mem: 3702
Epoch: [2]  [ 550/1415]  eta: 0:02:43  lr: 0.000010  loss: 0.2767 (0.2954)  labels_encoder: 0.1462 (0.1595)  labels_decoder: 0.1335 (0.1359)  labels_encoder_unscaled: 0.1462 (0.1595)  labels_decoder_unscaled: 0.2671 (0.2718)  time: 0.1810  data: 0.0003  max mem: 3702
Epoch: [2]  [ 600/1415]  eta: 0:02:33  lr: 0.000010  loss: 0.2667 (0.2948)  labels_encoder: 0.1322 (0.1593)  labels_decoder: 0.1274 (0.1355)  labels_encoder_unscaled: 0.1322 (0.1593)  labels_decoder_unscaled: 0.2548 (0.2710)  time: 0.1918  data: 0.0003  max mem: 3702
Epoch: [2]  [ 650/1415]  eta: 0:02:24  lr: 0.000010  loss: 0.2677 (0.2938)  labels_encoder: 0.1278 (0.1586)  labels_decoder: 0.1282 (0.1352)  labels_encoder_unscaled: 0.1278 (0.1586)  labels_decoder_unscaled: 0.2563 (0.2704)  time: 0.1886  data: 0.0003  max mem: 3702
Epoch: [2]  [ 700/1415]  eta: 0:02:14  lr: 0.000010  loss: 0.2719 (0.2931)  labels_encoder: 0.1324 (0.1585)  labels_decoder: 0.1224 (0.1346)  labels_encoder_unscaled: 0.1324 (0.1585)  labels_decoder_unscaled: 0.2447 (0.2692)  time: 0.1903  data: 0.0003  max mem: 3702
Epoch: [2]  [ 750/1415]  eta: 0:02:05  lr: 0.000010  loss: 0.2851 (0.2922)  labels_encoder: 0.1346 (0.1581)  labels_decoder: 0.1346 (0.1342)  labels_encoder_unscaled: 0.1346 (0.1581)  labels_decoder_unscaled: 0.2692 (0.2684)  time: 0.1891  data: 0.0003  max mem: 3702
Epoch: [2]  [ 800/1415]  eta: 0:01:56  lr: 0.000010  loss: 0.2591 (0.2909)  labels_encoder: 0.1294 (0.1572)  labels_decoder: 0.1256 (0.1337)  labels_encoder_unscaled: 0.1294 (0.1572)  labels_decoder_unscaled: 0.2512 (0.2674)  time: 0.1953  data: 0.0003  max mem: 3702
Epoch: [2]  [ 850/1415]  eta: 0:01:46  lr: 0.000010  loss: 0.2475 (0.2901)  labels_encoder: 0.1289 (0.1567)  labels_decoder: 0.1249 (0.1334)  labels_encoder_unscaled: 0.1289 (0.1567)  labels_decoder_unscaled: 0.2499 (0.2668)  time: 0.1922  data: 0.0003  max mem: 3702
Epoch: [2]  [ 900/1415]  eta: 0:01:37  lr: 0.000010  loss: 0.2714 (0.2891)  labels_encoder: 0.1399 (0.1559)  labels_decoder: 0.1209 (0.1331)  labels_encoder_unscaled: 0.1399 (0.1559)  labels_decoder_unscaled: 0.2417 (0.2663)  time: 0.1922  data: 0.0004  max mem: 3702
Epoch: [2]  [ 950/1415]  eta: 0:01:27  lr: 0.000010  loss: 0.2792 (0.2879)  labels_encoder: 0.1471 (0.1552)  labels_decoder: 0.1243 (0.1327)  labels_encoder_unscaled: 0.1471 (0.1552)  labels_decoder_unscaled: 0.2486 (0.2654)  time: 0.1991  data: 0.0003  max mem: 3702
Epoch: [2]  [1000/1415]  eta: 0:01:18  lr: 0.000010  loss: 0.2630 (0.2870)  labels_encoder: 0.1296 (0.1546)  labels_decoder: 0.1170 (0.1324)  labels_encoder_unscaled: 0.1296 (0.1546)  labels_decoder_unscaled: 0.2340 (0.2647)  time: 0.1878  data: 0.0003  max mem: 3702
Epoch: [2]  [1050/1415]  eta: 0:01:08  lr: 0.000010  loss: 0.2567 (0.2858)  labels_encoder: 0.1382 (0.1539)  labels_decoder: 0.1228 (0.1319)  labels_encoder_unscaled: 0.1382 (0.1539)  labels_decoder_unscaled: 0.2456 (0.2639)  time: 0.1747  data: 0.0003  max mem: 3702
Epoch: [2]  [1100/1415]  eta: 0:00:59  lr: 0.000010  loss: 0.2677 (0.2850)  labels_encoder: 0.1340 (0.1533)  labels_decoder: 0.1281 (0.1317)  labels_encoder_unscaled: 0.1340 (0.1533)  labels_decoder_unscaled: 0.2563 (0.2635)  time: 0.1928  data: 0.0003  max mem: 3702
Epoch: [2]  [1150/1415]  eta: 0:00:49  lr: 0.000010  loss: 0.2463 (0.2841)  labels_encoder: 0.1276 (0.1527)  labels_decoder: 0.1202 (0.1313)  labels_encoder_unscaled: 0.1276 (0.1527)  labels_decoder_unscaled: 0.2404 (0.2626)  time: 0.1783  data: 0.0003  max mem: 3702
Epoch: [2]  [1200/1415]  eta: 0:00:40  lr: 0.000010  loss: 0.2616 (0.2838)  labels_encoder: 0.1307 (0.1525)  labels_decoder: 0.1259 (0.1313)  labels_encoder_unscaled: 0.1307 (0.1525)  labels_decoder_unscaled: 0.2519 (0.2625)  time: 0.1942  data: 0.0003  max mem: 3702
Epoch: [2]  [1250/1415]  eta: 0:00:31  lr: 0.000010  loss: 0.2727 (0.2833)  labels_encoder: 0.1484 (0.1522)  labels_decoder: 0.1266 (0.1311)  labels_encoder_unscaled: 0.1484 (0.1522)  labels_decoder_unscaled: 0.2533 (0.2621)  time: 0.1908  data: 0.0003  max mem: 3702
Epoch: [2]  [1300/1415]  eta: 0:00:21  lr: 0.000010  loss: 0.2597 (0.2823)  labels_encoder: 0.1311 (0.1515)  labels_decoder: 0.1233 (0.1307)  labels_encoder_unscaled: 0.1311 (0.1515)  labels_decoder_unscaled: 0.2466 (0.2614)  time: 0.1883  data: 0.0003  max mem: 3702
Epoch: [2]  [1350/1415]  eta: 0:00:12  lr: 0.000010  loss: 0.2353 (0.2814)  labels_encoder: 0.1155 (0.1510)  labels_decoder: 0.1163 (0.1304)  labels_encoder_unscaled: 0.1155 (0.1510)  labels_decoder_unscaled: 0.2325 (0.2607)  time: 0.1903  data: 0.0003  max mem: 3702
Epoch: [2]  [1400/1415]  eta: 0:00:02  lr: 0.000010  loss: 0.2668 (0.2803)  labels_encoder: 0.1389 (0.1503)  labels_decoder: 0.1279 (0.1301)  labels_encoder_unscaled: 0.1389 (0.1503)  labels_decoder_unscaled: 0.2558 (0.2602)  time: 0.1834  data: 0.0004  max mem: 3702
Epoch: [2]  [1414/1415]  eta: 0:00:00  lr: 0.000010  loss: 0.2668 (0.2801)  labels_encoder: 0.1364 (0.1501)  labels_decoder: 0.1235 (0.1300)  labels_encoder_unscaled: 0.1364 (0.1501)  labels_decoder_unscaled: 0.2470 (0.2600)  time: 0.1539  data: 0.0003  max mem: 3702
Epoch: [2] Total time: 0:04:26 (0.1884 s / it)
Averaged stats: lr: 0.000010  loss: 0.2668 (0.2801)  labels_encoder: 0.1364 (0.1501)  labels_decoder: 0.1235 (0.1300)  labels_encoder_unscaled: 0.1364 (0.1501)  labels_decoder_unscaled: 0.2470 (0.2600)
Test:  [   0/1613]  eta: 1:24:26  loss: 2.3158 (2.3158)  labels_encoder: 1.5499 (1.5499)  labels_decoder: 0.7659 (0.7659)  labels_encoder_unscaled: 1.5499 (1.5499)  labels_decoder_unscaled: 1.5317 (1.5317)  time: 3.1413  data: 3.0244  max mem: 3702
Test:  [  50/1613]  eta: 0:04:36  loss: 0.4067 (0.8887)  labels_encoder: 0.2682 (0.5676)  labels_decoder: 0.1980 (0.3211)  labels_encoder_unscaled: 0.2682 (0.5676)  labels_decoder_unscaled: 0.3960 (0.6421)  time: 0.1105  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:38  loss: 0.3226 (0.7469)  labels_encoder: 0.2117 (0.4839)  labels_decoder: 0.0836 (0.2630)  labels_encoder_unscaled: 0.2117 (0.4839)  labels_decoder_unscaled: 0.1673 (0.5259)  time: 0.1148  data: 0.0148  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:17  loss: 1.0214 (0.7561)  labels_encoder: 0.7027 (0.4960)  labels_decoder: 0.3186 (0.2601)  labels_encoder_unscaled: 0.7027 (0.4960)  labels_decoder_unscaled: 0.6372 (0.5202)  time: 0.1141  data: 0.0002  max mem: 3702
Test:  [ 200/1613]  eta: 0:03:05  loss: 0.9970 (0.8912)  labels_encoder: 0.6209 (0.5892)  labels_decoder: 0.3836 (0.3020)  labels_encoder_unscaled: 0.6209 (0.5892)  labels_decoder_unscaled: 0.7672 (0.6039)  time: 0.1139  data: 0.0002  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:54  loss: 0.4785 (0.9532)  labels_encoder: 0.4075 (0.6255)  labels_decoder: 0.1904 (0.3277)  labels_encoder_unscaled: 0.4075 (0.6255)  labels_decoder_unscaled: 0.3807 (0.6555)  time: 0.1182  data: 0.0151  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:45  loss: 0.6243 (0.9846)  labels_encoder: 0.4005 (0.6441)  labels_decoder: 0.2323 (0.3405)  labels_encoder_unscaled: 0.4005 (0.6441)  labels_decoder_unscaled: 0.4646 (0.6810)  time: 0.1079  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:36  loss: 1.2385 (0.9874)  labels_encoder: 0.7692 (0.6382)  labels_decoder: 0.5084 (0.3492)  labels_encoder_unscaled: 0.7692 (0.6382)  labels_decoder_unscaled: 1.0169 (0.6985)  time: 0.1043  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:28  loss: 0.7632 (1.0827)  labels_encoder: 0.4871 (0.7022)  labels_decoder: 0.3753 (0.3805)  labels_encoder_unscaled: 0.4871 (0.7022)  labels_decoder_unscaled: 0.7506 (0.7610)  time: 0.1048  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:21  loss: 1.0024 (1.1709)  labels_encoder: 0.6555 (0.7615)  labels_decoder: 0.3469 (0.4093)  labels_encoder_unscaled: 0.6555 (0.7615)  labels_decoder_unscaled: 0.6938 (0.8187)  time: 0.1311  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:15  loss: 0.4893 (1.1275)  labels_encoder: 0.2638 (0.7321)  labels_decoder: 0.1771 (0.3954)  labels_encoder_unscaled: 0.2638 (0.7321)  labels_decoder_unscaled: 0.3541 (0.7908)  time: 0.1194  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:02:09  loss: 0.5208 (1.1239)  labels_encoder: 0.3302 (0.7292)  labels_decoder: 0.2297 (0.3947)  labels_encoder_unscaled: 0.3302 (0.7292)  labels_decoder_unscaled: 0.4594 (0.7893)  time: 0.1191  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:02:03  loss: 1.0807 (1.1584)  labels_encoder: 0.6715 (0.7606)  labels_decoder: 0.4240 (0.3978)  labels_encoder_unscaled: 0.6715 (0.7606)  labels_decoder_unscaled: 0.8479 (0.7955)  time: 0.1192  data: 0.0002  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:56  loss: 0.8999 (1.1380)  labels_encoder: 0.4827 (0.7426)  labels_decoder: 0.4603 (0.3953)  labels_encoder_unscaled: 0.4827 (0.7426)  labels_decoder_unscaled: 0.9205 (0.7906)  time: 0.1180  data: 0.0002  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:50  loss: 0.6121 (1.1065)  labels_encoder: 0.3729 (0.7201)  labels_decoder: 0.2900 (0.3864)  labels_encoder_unscaled: 0.3729 (0.7201)  labels_decoder_unscaled: 0.5801 (0.7727)  time: 0.1271  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:44  loss: 0.8979 (1.0925)  labels_encoder: 0.5530 (0.7087)  labels_decoder: 0.3449 (0.3839)  labels_encoder_unscaled: 0.5530 (0.7087)  labels_decoder_unscaled: 0.6898 (0.7678)  time: 0.1235  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:38  loss: 0.9281 (1.0877)  labels_encoder: 0.5177 (0.7055)  labels_decoder: 0.3672 (0.3822)  labels_encoder_unscaled: 0.5177 (0.7055)  labels_decoder_unscaled: 0.7344 (0.7644)  time: 0.1208  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:31  loss: 1.3734 (1.0919)  labels_encoder: 0.8854 (0.7060)  labels_decoder: 0.5315 (0.3859)  labels_encoder_unscaled: 0.8854 (0.7060)  labels_decoder_unscaled: 1.0630 (0.7718)  time: 0.1151  data: 0.0002  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:25  loss: 0.7382 (1.1155)  labels_encoder: 0.4266 (0.7215)  labels_decoder: 0.3119 (0.3940)  labels_encoder_unscaled: 0.4266 (0.7215)  labels_decoder_unscaled: 0.6238 (0.7880)  time: 0.1221  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:19  loss: 1.1593 (1.1105)  labels_encoder: 0.7378 (0.7182)  labels_decoder: 0.3755 (0.3923)  labels_encoder_unscaled: 0.7378 (0.7182)  labels_decoder_unscaled: 0.7510 (0.7847)  time: 0.0956  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:13  loss: 0.4430 (1.0965)  labels_encoder: 0.2698 (0.7085)  labels_decoder: 0.1837 (0.3880)  labels_encoder_unscaled: 0.2698 (0.7085)  labels_decoder_unscaled: 0.3674 (0.7759)  time: 0.1080  data: 0.0002  max mem: 3702
Test:  [1050/1613]  eta: 0:01:07  loss: 0.8534 (1.0949)  labels_encoder: 0.4861 (0.7071)  labels_decoder: 0.3236 (0.3878)  labels_encoder_unscaled: 0.4861 (0.7071)  labels_decoder_unscaled: 0.6472 (0.7756)  time: 0.1320  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:01:01  loss: 0.6615 (1.0986)  labels_encoder: 0.4049 (0.7109)  labels_decoder: 0.2340 (0.3877)  labels_encoder_unscaled: 0.4049 (0.7109)  labels_decoder_unscaled: 0.4680 (0.7755)  time: 0.1105  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:55  loss: 0.5427 (1.0848)  labels_encoder: 0.3219 (0.7012)  labels_decoder: 0.2098 (0.3836)  labels_encoder_unscaled: 0.3219 (0.7012)  labels_decoder_unscaled: 0.4196 (0.7673)  time: 0.1192  data: 0.0159  max mem: 3702
Test:  [1200/1613]  eta: 0:00:49  loss: 0.5589 (1.0885)  labels_encoder: 0.3540 (0.7027)  labels_decoder: 0.2100 (0.3858)  labels_encoder_unscaled: 0.3540 (0.7027)  labels_decoder_unscaled: 0.4199 (0.7717)  time: 0.1521  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:43  loss: 0.4301 (1.0888)  labels_encoder: 0.2245 (0.7024)  labels_decoder: 0.1457 (0.3864)  labels_encoder_unscaled: 0.2245 (0.7024)  labels_decoder_unscaled: 0.2915 (0.7727)  time: 0.1290  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:37  loss: 0.9485 (1.0828)  labels_encoder: 0.6865 (0.6982)  labels_decoder: 0.3398 (0.3846)  labels_encoder_unscaled: 0.6865 (0.6982)  labels_decoder_unscaled: 0.6797 (0.7692)  time: 0.1179  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:31  loss: 0.8816 (1.1004)  labels_encoder: 0.5388 (0.7107)  labels_decoder: 0.3381 (0.3897)  labels_encoder_unscaled: 0.5388 (0.7107)  labels_decoder_unscaled: 0.6761 (0.7794)  time: 0.1217  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:25  loss: 1.0829 (1.0935)  labels_encoder: 0.6546 (0.7060)  labels_decoder: 0.3761 (0.3875)  labels_encoder_unscaled: 0.6546 (0.7060)  labels_decoder_unscaled: 0.7521 (0.7750)  time: 0.1162  data: 0.0024  max mem: 3702
Test:  [1450/1613]  eta: 0:00:19  loss: 0.7446 (1.1055)  labels_encoder: 0.3644 (0.7127)  labels_decoder: 0.3833 (0.3928)  labels_encoder_unscaled: 0.3644 (0.7127)  labels_decoder_unscaled: 0.7666 (0.7857)  time: 0.1379  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:13  loss: 0.6159 (1.1167)  labels_encoder: 0.3633 (0.7203)  labels_decoder: 0.2206 (0.3964)  labels_encoder_unscaled: 0.3633 (0.7203)  labels_decoder_unscaled: 0.4413 (0.7929)  time: 0.1194  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:07  loss: 0.6814 (1.1130)  labels_encoder: 0.4181 (0.7182)  labels_decoder: 0.2771 (0.3948)  labels_encoder_unscaled: 0.4181 (0.7182)  labels_decoder_unscaled: 0.5542 (0.7896)  time: 0.1117  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 1.0299 (1.1100)  labels_encoder: 0.5813 (0.7156)  labels_decoder: 0.4573 (0.3944)  labels_encoder_unscaled: 0.5813 (0.7156)  labels_decoder_unscaled: 0.9146 (0.7889)  time: 0.1169  data: 0.0002  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 1.0241 (1.1106)  labels_encoder: 0.6094 (0.7162)  labels_decoder: 0.4428 (0.3944)  labels_encoder_unscaled: 0.6094 (0.7162)  labels_decoder_unscaled: 0.8857 (0.7888)  time: 0.0928  data: 0.0001  max mem: 3702
Test: Total time: 0:03:12 (0.1196 s / it)
Averaged stats: loss: 1.0241 (1.1106)  labels_encoder: 0.6094 (0.7162)  labels_decoder: 0.4428 (0.3944)  labels_encoder_unscaled: 0.6094 (0.7162)  labels_decoder_unscaled: 0.8857 (0.7888)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5790

dec_mAP all together: | 0.46394864874822234 |.
dec_mAP_pred | 0 : 0.5112926597438113 |.
dec_mAP_pred | 1 : 0.5019823294622061 |.
dec_mAP_pred | 2 : 0.488526372289199 |.
dec_mAP_pred | 3 : 0.473854557305957 |.
dec_mAP_pred | 4 : 0.4586177230948224 |.
dec_mAP_pred | 5 : 0.4434911870181574 |.
dec_mAP_pred | 6 : 0.42871654485702776 |.
dec_mAP_pred | 7 : 0.41530138595183014 |.
all decoder map: | 0.4652 |.
BaseballPitch: 0.1441
BasketballDunk: 0.7797
Billiards: 0.4363
CleanAndJerk: 0.7805
CliffDiving: 0.8075
CricketBowling: 0.4576
CricketShot: 0.2309
Diving: 0.6860
FrisbeeCatch: 0.3359
GolfSwing: 0.6145
HammerThrow: 0.8523
HighJump: 0.6478
JavelinThrow: 0.6846
LongJump: 0.7719
PoleVault: 0.8840
Shotput: 0.6721
SoccerPenalty: 0.2595
TennisSwing: 0.5780
ThrowDiscus: 0.6090
VolleyballSpiking: 0.3480
Epoch: [3]  [   0/1415]  eta: 1:27:46  lr: 0.000001  loss: 0.2006 (0.2006)  labels_encoder: 0.0888 (0.0888)  labels_decoder: 0.1118 (0.1118)  labels_encoder_unscaled: 0.0888 (0.0888)  labels_decoder_unscaled: 0.2237 (0.2237)  time: 3.7216  data: 3.4859  max mem: 3702
Epoch: [3]  [  50/1415]  eta: 0:06:02  lr: 0.000001  loss: 0.2418 (0.2471)  labels_encoder: 0.1256 (0.1239)  labels_decoder: 0.1161 (0.1232)  labels_encoder_unscaled: 0.1256 (0.1239)  labels_decoder_unscaled: 0.2323 (0.2463)  time: 0.1898  data: 0.0004  max mem: 3702
Epoch: [3]  [ 100/1415]  eta: 0:04:57  lr: 0.000001  loss: 0.2394 (0.2545)  labels_encoder: 0.1166 (0.1324)  labels_decoder: 0.1152 (0.1221)  labels_encoder_unscaled: 0.1166 (0.1324)  labels_decoder_unscaled: 0.2304 (0.2442)  time: 0.1918  data: 0.0003  max mem: 3702
Epoch: [3]  [ 150/1415]  eta: 0:04:30  lr: 0.000001  loss: 0.2413 (0.2525)  labels_encoder: 0.1225 (0.1323)  labels_decoder: 0.1103 (0.1202)  labels_encoder_unscaled: 0.1225 (0.1323)  labels_decoder_unscaled: 0.2206 (0.2404)  time: 0.1892  data: 0.0004  max mem: 3702
Epoch: [3]  [ 200/1415]  eta: 0:04:06  lr: 0.000001  loss: 0.2290 (0.2513)  labels_encoder: 0.1243 (0.1318)  labels_decoder: 0.1075 (0.1195)  labels_encoder_unscaled: 0.1243 (0.1318)  labels_decoder_unscaled: 0.2149 (0.2391)  time: 0.1680  data: 0.0003  max mem: 3702
Epoch: [3]  [ 250/1415]  eta: 0:03:49  lr: 0.000001  loss: 0.2636 (0.2521)  labels_encoder: 0.1318 (0.1321)  labels_decoder: 0.1218 (0.1201)  labels_encoder_unscaled: 0.1318 (0.1321)  labels_decoder_unscaled: 0.2437 (0.2401)  time: 0.1693  data: 0.0003  max mem: 3702
Epoch: [3]  [ 300/1415]  eta: 0:03:34  lr: 0.000001  loss: 0.2388 (0.2523)  labels_encoder: 0.1251 (0.1322)  labels_decoder: 0.1149 (0.1201)  labels_encoder_unscaled: 0.1251 (0.1322)  labels_decoder_unscaled: 0.2298 (0.2402)  time: 0.1626  data: 0.0003  max mem: 3702
Epoch: [3]  [ 350/1415]  eta: 0:03:22  lr: 0.000001  loss: 0.2415 (0.2510)  labels_encoder: 0.1259 (0.1311)  labels_decoder: 0.1119 (0.1199)  labels_encoder_unscaled: 0.1259 (0.1311)  labels_decoder_unscaled: 0.2238 (0.2397)  time: 0.1812  data: 0.0003  max mem: 3702
Epoch: [3]  [ 400/1415]  eta: 0:03:10  lr: 0.000001  loss: 0.2284 (0.2502)  labels_encoder: 0.1056 (0.1306)  labels_decoder: 0.1187 (0.1196)  labels_encoder_unscaled: 0.1056 (0.1306)  labels_decoder_unscaled: 0.2375 (0.2392)  time: 0.1803  data: 0.0003  max mem: 3702
Epoch: [3]  [ 450/1415]  eta: 0:03:01  lr: 0.000001  loss: 0.2415 (0.2484)  labels_encoder: 0.1164 (0.1293)  labels_decoder: 0.1087 (0.1191)  labels_encoder_unscaled: 0.1164 (0.1293)  labels_decoder_unscaled: 0.2175 (0.2382)  time: 0.1869  data: 0.0003  max mem: 3702
Epoch: [3]  [ 500/1415]  eta: 0:02:52  lr: 0.000001  loss: 0.2246 (0.2478)  labels_encoder: 0.1127 (0.1289)  labels_decoder: 0.1144 (0.1189)  labels_encoder_unscaled: 0.1127 (0.1289)  labels_decoder_unscaled: 0.2288 (0.2377)  time: 0.1878  data: 0.0003  max mem: 3702
Epoch: [3]  [ 550/1415]  eta: 0:02:42  lr: 0.000001  loss: 0.2406 (0.2474)  labels_encoder: 0.1243 (0.1287)  labels_decoder: 0.1258 (0.1187)  labels_encoder_unscaled: 0.1243 (0.1287)  labels_decoder_unscaled: 0.2517 (0.2374)  time: 0.1897  data: 0.0003  max mem: 3702
Epoch: [3]  [ 600/1415]  eta: 0:02:33  lr: 0.000001  loss: 0.2210 (0.2473)  labels_encoder: 0.1050 (0.1285)  labels_decoder: 0.1157 (0.1188)  labels_encoder_unscaled: 0.1050 (0.1285)  labels_decoder_unscaled: 0.2314 (0.2377)  time: 0.1969  data: 0.0003  max mem: 3702
Epoch: [3]  [ 650/1415]  eta: 0:02:24  lr: 0.000001  loss: 0.2263 (0.2468)  labels_encoder: 0.1187 (0.1280)  labels_decoder: 0.1197 (0.1188)  labels_encoder_unscaled: 0.1187 (0.1280)  labels_decoder_unscaled: 0.2394 (0.2376)  time: 0.1833  data: 0.0003  max mem: 3702
Epoch: [3]  [ 700/1415]  eta: 0:02:14  lr: 0.000001  loss: 0.2588 (0.2474)  labels_encoder: 0.1181 (0.1281)  labels_decoder: 0.1239 (0.1192)  labels_encoder_unscaled: 0.1181 (0.1281)  labels_decoder_unscaled: 0.2478 (0.2385)  time: 0.1888  data: 0.0003  max mem: 3702
Epoch: [3]  [ 750/1415]  eta: 0:02:05  lr: 0.000001  loss: 0.2470 (0.2472)  labels_encoder: 0.1283 (0.1281)  labels_decoder: 0.1210 (0.1190)  labels_encoder_unscaled: 0.1283 (0.1281)  labels_decoder_unscaled: 0.2420 (0.2381)  time: 0.1932  data: 0.0003  max mem: 3702
Epoch: [3]  [ 800/1415]  eta: 0:01:55  lr: 0.000001  loss: 0.2387 (0.2469)  labels_encoder: 0.1208 (0.1281)  labels_decoder: 0.1177 (0.1188)  labels_encoder_unscaled: 0.1208 (0.1281)  labels_decoder_unscaled: 0.2354 (0.2376)  time: 0.1835  data: 0.0003  max mem: 3702
Epoch: [3]  [ 850/1415]  eta: 0:01:46  lr: 0.000001  loss: 0.2256 (0.2467)  labels_encoder: 0.1115 (0.1278)  labels_decoder: 0.1180 (0.1188)  labels_encoder_unscaled: 0.1115 (0.1278)  labels_decoder_unscaled: 0.2361 (0.2377)  time: 0.1987  data: 0.0003  max mem: 3702
Epoch: [3]  [ 900/1415]  eta: 0:01:37  lr: 0.000001  loss: 0.2568 (0.2462)  labels_encoder: 0.1293 (0.1275)  labels_decoder: 0.1156 (0.1187)  labels_encoder_unscaled: 0.1293 (0.1275)  labels_decoder_unscaled: 0.2313 (0.2374)  time: 0.1903  data: 0.0003  max mem: 3702
Epoch: [3]  [ 950/1415]  eta: 0:01:27  lr: 0.000001  loss: 0.2285 (0.2461)  labels_encoder: 0.1132 (0.1272)  labels_decoder: 0.1172 (0.1188)  labels_encoder_unscaled: 0.1132 (0.1272)  labels_decoder_unscaled: 0.2345 (0.2377)  time: 0.1936  data: 0.0004  max mem: 3702
Epoch: [3]  [1000/1415]  eta: 0:01:18  lr: 0.000001  loss: 0.2282 (0.2458)  labels_encoder: 0.1115 (0.1270)  labels_decoder: 0.1165 (0.1188)  labels_encoder_unscaled: 0.1115 (0.1270)  labels_decoder_unscaled: 0.2329 (0.2376)  time: 0.1908  data: 0.0003  max mem: 3702
Epoch: [3]  [1050/1415]  eta: 0:01:08  lr: 0.000001  loss: 0.2500 (0.2459)  labels_encoder: 0.1162 (0.1271)  labels_decoder: 0.1166 (0.1188)  labels_encoder_unscaled: 0.1162 (0.1271)  labels_decoder_unscaled: 0.2331 (0.2376)  time: 0.1845  data: 0.0003  max mem: 3702
Epoch: [3]  [1100/1415]  eta: 0:00:59  lr: 0.000001  loss: 0.2513 (0.2455)  labels_encoder: 0.1267 (0.1269)  labels_decoder: 0.1174 (0.1186)  labels_encoder_unscaled: 0.1267 (0.1269)  labels_decoder_unscaled: 0.2349 (0.2373)  time: 0.1869  data: 0.0003  max mem: 3702
Epoch: [3]  [1150/1415]  eta: 0:00:50  lr: 0.000001  loss: 0.2492 (0.2462)  labels_encoder: 0.1284 (0.1273)  labels_decoder: 0.1209 (0.1188)  labels_encoder_unscaled: 0.1284 (0.1273)  labels_decoder_unscaled: 0.2418 (0.2377)  time: 0.1839  data: 0.0003  max mem: 3702
Epoch: [3]  [1200/1415]  eta: 0:00:40  lr: 0.000001  loss: 0.2499 (0.2460)  labels_encoder: 0.1334 (0.1272)  labels_decoder: 0.1098 (0.1188)  labels_encoder_unscaled: 0.1334 (0.1272)  labels_decoder_unscaled: 0.2197 (0.2376)  time: 0.1899  data: 0.0003  max mem: 3702
Epoch: [3]  [1250/1415]  eta: 0:00:31  lr: 0.000001  loss: 0.2220 (0.2455)  labels_encoder: 0.1139 (0.1269)  labels_decoder: 0.1082 (0.1185)  labels_encoder_unscaled: 0.1139 (0.1269)  labels_decoder_unscaled: 0.2164 (0.2371)  time: 0.1915  data: 0.0003  max mem: 3702
Epoch: [3]  [1300/1415]  eta: 0:00:21  lr: 0.000001  loss: 0.2226 (0.2451)  labels_encoder: 0.1075 (0.1268)  labels_decoder: 0.1099 (0.1183)  labels_encoder_unscaled: 0.1075 (0.1268)  labels_decoder_unscaled: 0.2199 (0.2366)  time: 0.1798  data: 0.0003  max mem: 3702
Epoch: [3]  [1350/1415]  eta: 0:00:12  lr: 0.000001  loss: 0.2280 (0.2455)  labels_encoder: 0.1165 (0.1269)  labels_decoder: 0.1182 (0.1185)  labels_encoder_unscaled: 0.1165 (0.1269)  labels_decoder_unscaled: 0.2363 (0.2370)  time: 0.1805  data: 0.0003  max mem: 3702
Epoch: [3]  [1400/1415]  eta: 0:00:02  lr: 0.000001  loss: 0.2397 (0.2457)  labels_encoder: 0.1144 (0.1271)  labels_decoder: 0.1146 (0.1186)  labels_encoder_unscaled: 0.1144 (0.1271)  labels_decoder_unscaled: 0.2292 (0.2373)  time: 0.1833  data: 0.0005  max mem: 3702
Epoch: [3]  [1414/1415]  eta: 0:00:00  lr: 0.000001  loss: 0.2458 (0.2457)  labels_encoder: 0.1224 (0.1271)  labels_decoder: 0.1150 (0.1186)  labels_encoder_unscaled: 0.1224 (0.1271)  labels_decoder_unscaled: 0.2301 (0.2373)  time: 0.1578  data: 0.0004  max mem: 3702
Epoch: [3] Total time: 0:04:27 (0.1888 s / it)
Averaged stats: lr: 0.000001  loss: 0.2458 (0.2457)  labels_encoder: 0.1224 (0.1271)  labels_decoder: 0.1150 (0.1186)  labels_encoder_unscaled: 0.1224 (0.1271)  labels_decoder_unscaled: 0.2301 (0.2373)
Test:  [   0/1613]  eta: 1:15:09  loss: 2.3039 (2.3039)  labels_encoder: 1.6487 (1.6487)  labels_decoder: 0.6553 (0.6553)  labels_encoder_unscaled: 1.6487 (1.6487)  labels_decoder_unscaled: 1.3106 (1.3106)  time: 2.7958  data: 2.7299  max mem: 3702
Test:  [  50/1613]  eta: 0:04:40  loss: 0.4519 (0.9047)  labels_encoder: 0.2674 (0.5799)  labels_decoder: 0.1955 (0.3248)  labels_encoder_unscaled: 0.2674 (0.5799)  labels_decoder_unscaled: 0.3909 (0.6496)  time: 0.1189  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:40  loss: 0.3161 (0.7514)  labels_encoder: 0.2215 (0.4881)  labels_decoder: 0.0891 (0.2633)  labels_encoder_unscaled: 0.2215 (0.4881)  labels_decoder_unscaled: 0.1783 (0.5265)  time: 0.1039  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:14  loss: 0.9689 (0.7620)  labels_encoder: 0.6019 (0.4989)  labels_decoder: 0.2753 (0.2631)  labels_encoder_unscaled: 0.6019 (0.4989)  labels_decoder_unscaled: 0.5507 (0.5261)  time: 0.1115  data: 0.0121  max mem: 3702
Test:  [ 200/1613]  eta: 0:03:03  loss: 1.0110 (0.9124)  labels_encoder: 0.6403 (0.6028)  labels_decoder: 0.3852 (0.3095)  labels_encoder_unscaled: 0.6403 (0.6028)  labels_decoder_unscaled: 0.7703 (0.6190)  time: 0.1174  data: 0.0138  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:52  loss: 0.5905 (0.9747)  labels_encoder: 0.3548 (0.6389)  labels_decoder: 0.2334 (0.3359)  labels_encoder_unscaled: 0.3548 (0.6389)  labels_decoder_unscaled: 0.4669 (0.6717)  time: 0.1204  data: 0.0049  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:44  loss: 0.7098 (1.0113)  labels_encoder: 0.4179 (0.6608)  labels_decoder: 0.2578 (0.3505)  labels_encoder_unscaled: 0.4179 (0.6608)  labels_decoder_unscaled: 0.5156 (0.7009)  time: 0.1142  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:37  loss: 1.2870 (1.0085)  labels_encoder: 0.7373 (0.6514)  labels_decoder: 0.5017 (0.3571)  labels_encoder_unscaled: 0.7373 (0.6514)  labels_decoder_unscaled: 1.0034 (0.7141)  time: 0.1147  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:28  loss: 0.8265 (1.1091)  labels_encoder: 0.4765 (0.7197)  labels_decoder: 0.3386 (0.3894)  labels_encoder_unscaled: 0.4765 (0.7197)  labels_decoder_unscaled: 0.6773 (0.7788)  time: 0.1104  data: 0.0192  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:21  loss: 1.1471 (1.2104)  labels_encoder: 0.6922 (0.7883)  labels_decoder: 0.3868 (0.4221)  labels_encoder_unscaled: 0.6922 (0.7883)  labels_decoder_unscaled: 0.7737 (0.8442)  time: 0.1084  data: 0.0261  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:14  loss: 0.4255 (1.1621)  labels_encoder: 0.2517 (0.7554)  labels_decoder: 0.1929 (0.4067)  labels_encoder_unscaled: 0.2517 (0.7554)  labels_decoder_unscaled: 0.3858 (0.8134)  time: 0.1122  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:02:09  loss: 0.5492 (1.1535)  labels_encoder: 0.3449 (0.7485)  labels_decoder: 0.2352 (0.4051)  labels_encoder_unscaled: 0.3449 (0.7485)  labels_decoder_unscaled: 0.4705 (0.8102)  time: 0.1298  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:02:02  loss: 1.0219 (1.1812)  labels_encoder: 0.5724 (0.7762)  labels_decoder: 0.4126 (0.4050)  labels_encoder_unscaled: 0.5724 (0.7762)  labels_decoder_unscaled: 0.8253 (0.8101)  time: 0.1216  data: 0.0131  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:56  loss: 0.9116 (1.1610)  labels_encoder: 0.4999 (0.7581)  labels_decoder: 0.4798 (0.4028)  labels_encoder_unscaled: 0.4999 (0.7581)  labels_decoder_unscaled: 0.9595 (0.8057)  time: 0.1220  data: 0.0204  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:50  loss: 0.5675 (1.1287)  labels_encoder: 0.3479 (0.7351)  labels_decoder: 0.2324 (0.3936)  labels_encoder_unscaled: 0.3479 (0.7351)  labels_decoder_unscaled: 0.4647 (0.7871)  time: 0.0983  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:44  loss: 0.8344 (1.1108)  labels_encoder: 0.5173 (0.7216)  labels_decoder: 0.3172 (0.3892)  labels_encoder_unscaled: 0.5173 (0.7216)  labels_decoder_unscaled: 0.6343 (0.7784)  time: 0.1246  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:37  loss: 0.8682 (1.1050)  labels_encoder: 0.5587 (0.7184)  labels_decoder: 0.3095 (0.3867)  labels_encoder_unscaled: 0.5587 (0.7184)  labels_decoder_unscaled: 0.6190 (0.7734)  time: 0.1048  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:31  loss: 1.3771 (1.1044)  labels_encoder: 0.8565 (0.7154)  labels_decoder: 0.5207 (0.3890)  labels_encoder_unscaled: 0.8565 (0.7154)  labels_decoder_unscaled: 1.0414 (0.7780)  time: 0.1268  data: 0.0002  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:25  loss: 0.7359 (1.1239)  labels_encoder: 0.4403 (0.7283)  labels_decoder: 0.3046 (0.3956)  labels_encoder_unscaled: 0.4403 (0.7283)  labels_decoder_unscaled: 0.6091 (0.7911)  time: 0.1198  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:19  loss: 1.1085 (1.1163)  labels_encoder: 0.7254 (0.7234)  labels_decoder: 0.3685 (0.3929)  labels_encoder_unscaled: 0.7254 (0.7234)  labels_decoder_unscaled: 0.7369 (0.7858)  time: 0.1335  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:13  loss: 0.4771 (1.1045)  labels_encoder: 0.2911 (0.7152)  labels_decoder: 0.2261 (0.3893)  labels_encoder_unscaled: 0.2911 (0.7152)  labels_decoder_unscaled: 0.4523 (0.7785)  time: 0.1359  data: 0.0002  max mem: 3702
Test:  [1050/1613]  eta: 0:01:07  loss: 0.8651 (1.1016)  labels_encoder: 0.5054 (0.7130)  labels_decoder: 0.3283 (0.3885)  labels_encoder_unscaled: 0.5054 (0.7130)  labels_decoder_unscaled: 0.6567 (0.7771)  time: 0.1330  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:01:01  loss: 0.7375 (1.1096)  labels_encoder: 0.4595 (0.7198)  labels_decoder: 0.2484 (0.3898)  labels_encoder_unscaled: 0.4595 (0.7198)  labels_decoder_unscaled: 0.4968 (0.7797)  time: 0.1087  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:55  loss: 0.6277 (1.0957)  labels_encoder: 0.3234 (0.7101)  labels_decoder: 0.2151 (0.3856)  labels_encoder_unscaled: 0.3234 (0.7101)  labels_decoder_unscaled: 0.4301 (0.7712)  time: 0.1147  data: 0.0002  max mem: 3702
Test:  [1200/1613]  eta: 0:00:49  loss: 0.6149 (1.1004)  labels_encoder: 0.3931 (0.7125)  labels_decoder: 0.2217 (0.3878)  labels_encoder_unscaled: 0.3931 (0.7125)  labels_decoder_unscaled: 0.4435 (0.7757)  time: 0.1219  data: 0.0005  max mem: 3702
Test:  [1250/1613]  eta: 0:00:43  loss: 0.4250 (1.1010)  labels_encoder: 0.2475 (0.7127)  labels_decoder: 0.2160 (0.3883)  labels_encoder_unscaled: 0.2475 (0.7127)  labels_decoder_unscaled: 0.4321 (0.7766)  time: 0.1258  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:37  loss: 1.1697 (1.0954)  labels_encoder: 0.8057 (0.7086)  labels_decoder: 0.3581 (0.3868)  labels_encoder_unscaled: 0.8057 (0.7086)  labels_decoder_unscaled: 0.7163 (0.7736)  time: 0.1204  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:31  loss: 0.8699 (1.1147)  labels_encoder: 0.5395 (0.7222)  labels_decoder: 0.3304 (0.3925)  labels_encoder_unscaled: 0.5395 (0.7222)  labels_decoder_unscaled: 0.6608 (0.7850)  time: 0.1157  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:25  loss: 1.1448 (1.1075)  labels_encoder: 0.7197 (0.7173)  labels_decoder: 0.3977 (0.3902)  labels_encoder_unscaled: 0.7197 (0.7173)  labels_decoder_unscaled: 0.7955 (0.7804)  time: 0.1168  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:19  loss: 0.7039 (1.1175)  labels_encoder: 0.3359 (0.7225)  labels_decoder: 0.3597 (0.3950)  labels_encoder_unscaled: 0.3359 (0.7225)  labels_decoder_unscaled: 0.7193 (0.7900)  time: 0.1094  data: 0.0028  max mem: 3702
Test:  [1500/1613]  eta: 0:00:13  loss: 0.7216 (1.1307)  labels_encoder: 0.4122 (0.7315)  labels_decoder: 0.2214 (0.3992)  labels_encoder_unscaled: 0.4122 (0.7315)  labels_decoder_unscaled: 0.4428 (0.7983)  time: 0.1360  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:07  loss: 0.6767 (1.1258)  labels_encoder: 0.4217 (0.7287)  labels_decoder: 0.2695 (0.3971)  labels_encoder_unscaled: 0.4217 (0.7287)  labels_decoder_unscaled: 0.5390 (0.7942)  time: 0.1150  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8704 (1.1209)  labels_encoder: 0.5086 (0.7249)  labels_decoder: 0.3458 (0.3960)  labels_encoder_unscaled: 0.5086 (0.7249)  labels_decoder_unscaled: 0.6916 (0.7921)  time: 0.1165  data: 0.0005  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8024 (1.1202)  labels_encoder: 0.4706 (0.7246)  labels_decoder: 0.3318 (0.3956)  labels_encoder_unscaled: 0.4706 (0.7246)  labels_decoder_unscaled: 0.6636 (0.7912)  time: 0.0865  data: 0.0001  max mem: 3702
Test: Total time: 0:03:15 (0.1213 s / it)
Averaged stats: loss: 0.8024 (1.1202)  labels_encoder: 0.4706 (0.7246)  labels_decoder: 0.3318 (0.3956)  labels_encoder_unscaled: 0.4706 (0.7246)  labels_decoder_unscaled: 0.6636 (0.7912)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5777

dec_mAP all together: | 0.46131929468030125 |.
dec_mAP_pred | 0 : 0.507976719785844 |.
dec_mAP_pred | 1 : 0.49880320061627215 |.
dec_mAP_pred | 2 : 0.48545198492166575 |.
dec_mAP_pred | 3 : 0.4710466411429565 |.
dec_mAP_pred | 4 : 0.45603228847175625 |.
dec_mAP_pred | 5 : 0.441168334557266 |.
dec_mAP_pred | 6 : 0.42665517808537895 |.
dec_mAP_pred | 7 : 0.4134736974519889 |.
all decoder map: | 0.4626 |.
BaseballPitch: 0.1348
BasketballDunk: 0.7840
Billiards: 0.4469
CleanAndJerk: 0.7802
CliffDiving: 0.8075
CricketBowling: 0.4578
CricketShot: 0.2316
Diving: 0.6861
FrisbeeCatch: 0.3403
GolfSwing: 0.5849
HammerThrow: 0.8513
HighJump: 0.6451
JavelinThrow: 0.6849
LongJump: 0.7654
PoleVault: 0.8790
Shotput: 0.6710
SoccerPenalty: 0.2606
TennisSwing: 0.5789
ThrowDiscus: 0.6120
VolleyballSpiking: 0.3514
Epoch: [4]  [   0/1415]  eta: 1:19:10  lr: 0.000000  loss: 0.2393 (0.2393)  labels_encoder: 0.1344 (0.1344)  labels_decoder: 0.1049 (0.1049)  labels_encoder_unscaled: 0.1344 (0.1344)  labels_decoder_unscaled: 0.2099 (0.2099)  time: 3.3576  data: 3.0523  max mem: 3702
Epoch: [4]  [  50/1415]  eta: 0:06:06  lr: 0.000000  loss: 0.2325 (0.2466)  labels_encoder: 0.1127 (0.1287)  labels_decoder: 0.1170 (0.1178)  labels_encoder_unscaled: 0.1127 (0.1287)  labels_decoder_unscaled: 0.2340 (0.2357)  time: 0.1934  data: 0.0003  max mem: 3702
Epoch: [4]  [ 100/1415]  eta: 0:05:00  lr: 0.000000  loss: 0.2140 (0.2439)  labels_encoder: 0.1051 (0.1262)  labels_decoder: 0.1151 (0.1177)  labels_encoder_unscaled: 0.1051 (0.1262)  labels_decoder_unscaled: 0.2301 (0.2354)  time: 0.1952  data: 0.0003  max mem: 3702
Epoch: [4]  [ 150/1415]  eta: 0:04:35  lr: 0.000000  loss: 0.2317 (0.2441)  labels_encoder: 0.1090 (0.1263)  labels_decoder: 0.1103 (0.1178)  labels_encoder_unscaled: 0.1090 (0.1263)  labels_decoder_unscaled: 0.2206 (0.2356)  time: 0.1956  data: 0.0004  max mem: 3702
Epoch: [4]  [ 200/1415]  eta: 0:04:16  lr: 0.000000  loss: 0.2439 (0.2444)  labels_encoder: 0.1223 (0.1272)  labels_decoder: 0.1078 (0.1173)  labels_encoder_unscaled: 0.1223 (0.1272)  labels_decoder_unscaled: 0.2156 (0.2346)  time: 0.1915  data: 0.0003  max mem: 3702
Epoch: [4]  [ 250/1415]  eta: 0:04:03  lr: 0.000000  loss: 0.2546 (0.2463)  labels_encoder: 0.1359 (0.1287)  labels_decoder: 0.1284 (0.1175)  labels_encoder_unscaled: 0.1359 (0.1287)  labels_decoder_unscaled: 0.2567 (0.2351)  time: 0.2008  data: 0.0004  max mem: 3702
Epoch: [4]  [ 300/1415]  eta: 0:03:49  lr: 0.000000  loss: 0.2429 (0.2455)  labels_encoder: 0.1261 (0.1275)  labels_decoder: 0.1281 (0.1180)  labels_encoder_unscaled: 0.1261 (0.1275)  labels_decoder_unscaled: 0.2562 (0.2360)  time: 0.1897  data: 0.0003  max mem: 3702
Epoch: [4]  [ 350/1415]  eta: 0:03:35  lr: 0.000000  loss: 0.2211 (0.2451)  labels_encoder: 0.1075 (0.1274)  labels_decoder: 0.1127 (0.1177)  labels_encoder_unscaled: 0.1075 (0.1274)  labels_decoder_unscaled: 0.2254 (0.2354)  time: 0.1745  data: 0.0003  max mem: 3702
Epoch: [4]  [ 400/1415]  eta: 0:03:22  lr: 0.000000  loss: 0.2321 (0.2448)  labels_encoder: 0.1169 (0.1268)  labels_decoder: 0.1197 (0.1180)  labels_encoder_unscaled: 0.1169 (0.1268)  labels_decoder_unscaled: 0.2394 (0.2360)  time: 0.1666  data: 0.0003  max mem: 3702
Epoch: [4]  [ 450/1415]  eta: 0:03:10  lr: 0.000000  loss: 0.2359 (0.2450)  labels_encoder: 0.1099 (0.1268)  labels_decoder: 0.1209 (0.1183)  labels_encoder_unscaled: 0.1099 (0.1268)  labels_decoder_unscaled: 0.2419 (0.2365)  time: 0.1708  data: 0.0004  max mem: 3702
Epoch: [4]  [ 500/1415]  eta: 0:02:57  lr: 0.000000  loss: 0.2375 (0.2438)  labels_encoder: 0.1193 (0.1259)  labels_decoder: 0.1063 (0.1178)  labels_encoder_unscaled: 0.1193 (0.1259)  labels_decoder_unscaled: 0.2126 (0.2357)  time: 0.1745  data: 0.0003  max mem: 3702
Epoch: [4]  [ 550/1415]  eta: 0:02:46  lr: 0.000000  loss: 0.2426 (0.2437)  labels_encoder: 0.1201 (0.1259)  labels_decoder: 0.1094 (0.1177)  labels_encoder_unscaled: 0.1201 (0.1259)  labels_decoder_unscaled: 0.2189 (0.2354)  time: 0.1744  data: 0.0004  max mem: 3702
Epoch: [4]  [ 600/1415]  eta: 0:02:36  lr: 0.000000  loss: 0.2595 (0.2434)  labels_encoder: 0.1312 (0.1257)  labels_decoder: 0.1145 (0.1177)  labels_encoder_unscaled: 0.1312 (0.1257)  labels_decoder_unscaled: 0.2290 (0.2354)  time: 0.1837  data: 0.0004  max mem: 3702
Epoch: [4]  [ 650/1415]  eta: 0:02:26  lr: 0.000000  loss: 0.2267 (0.2435)  labels_encoder: 0.1139 (0.1256)  labels_decoder: 0.1178 (0.1179)  labels_encoder_unscaled: 0.1139 (0.1256)  labels_decoder_unscaled: 0.2356 (0.2357)  time: 0.1859  data: 0.0003  max mem: 3702
Epoch: [4]  [ 700/1415]  eta: 0:02:16  lr: 0.000000  loss: 0.2332 (0.2428)  labels_encoder: 0.1223 (0.1252)  labels_decoder: 0.1109 (0.1175)  labels_encoder_unscaled: 0.1223 (0.1252)  labels_decoder_unscaled: 0.2218 (0.2351)  time: 0.1862  data: 0.0003  max mem: 3702
Epoch: [4]  [ 750/1415]  eta: 0:02:07  lr: 0.000000  loss: 0.2312 (0.2430)  labels_encoder: 0.1093 (0.1255)  labels_decoder: 0.1184 (0.1176)  labels_encoder_unscaled: 0.1093 (0.1255)  labels_decoder_unscaled: 0.2368 (0.2351)  time: 0.1884  data: 0.0004  max mem: 3702
Epoch: [4]  [ 800/1415]  eta: 0:01:57  lr: 0.000000  loss: 0.2414 (0.2426)  labels_encoder: 0.1123 (0.1252)  labels_decoder: 0.1176 (0.1174)  labels_encoder_unscaled: 0.1123 (0.1252)  labels_decoder_unscaled: 0.2351 (0.2348)  time: 0.1863  data: 0.0003  max mem: 3702
Epoch: [4]  [ 850/1415]  eta: 0:01:47  lr: 0.000000  loss: 0.2417 (0.2426)  labels_encoder: 0.1110 (0.1251)  labels_decoder: 0.1201 (0.1176)  labels_encoder_unscaled: 0.1110 (0.1251)  labels_decoder_unscaled: 0.2402 (0.2351)  time: 0.1891  data: 0.0003  max mem: 3702
Epoch: [4]  [ 900/1415]  eta: 0:01:38  lr: 0.000000  loss: 0.2187 (0.2420)  labels_encoder: 0.1064 (0.1247)  labels_decoder: 0.1079 (0.1173)  labels_encoder_unscaled: 0.1064 (0.1247)  labels_decoder_unscaled: 0.2158 (0.2347)  time: 0.1823  data: 0.0004  max mem: 3702
Epoch: [4]  [ 950/1415]  eta: 0:01:28  lr: 0.000000  loss: 0.2673 (0.2433)  labels_encoder: 0.1414 (0.1255)  labels_decoder: 0.1246 (0.1178)  labels_encoder_unscaled: 0.1414 (0.1255)  labels_decoder_unscaled: 0.2492 (0.2355)  time: 0.1842  data: 0.0003  max mem: 3702
Epoch: [4]  [1000/1415]  eta: 0:01:19  lr: 0.000000  loss: 0.2451 (0.2432)  labels_encoder: 0.1319 (0.1256)  labels_decoder: 0.1077 (0.1176)  labels_encoder_unscaled: 0.1319 (0.1256)  labels_decoder_unscaled: 0.2153 (0.2352)  time: 0.1872  data: 0.0003  max mem: 3702
Epoch: [4]  [1050/1415]  eta: 0:01:09  lr: 0.000000  loss: 0.2260 (0.2432)  labels_encoder: 0.1087 (0.1254)  labels_decoder: 0.1201 (0.1178)  labels_encoder_unscaled: 0.1087 (0.1254)  labels_decoder_unscaled: 0.2402 (0.2355)  time: 0.1972  data: 0.0003  max mem: 3702
Epoch: [4]  [1100/1415]  eta: 0:01:00  lr: 0.000000  loss: 0.2159 (0.2425)  labels_encoder: 0.1005 (0.1249)  labels_decoder: 0.1102 (0.1176)  labels_encoder_unscaled: 0.1005 (0.1249)  labels_decoder_unscaled: 0.2203 (0.2351)  time: 0.1921  data: 0.0004  max mem: 3702
Epoch: [4]  [1150/1415]  eta: 0:00:50  lr: 0.000000  loss: 0.2399 (0.2424)  labels_encoder: 0.1231 (0.1249)  labels_decoder: 0.1160 (0.1175)  labels_encoder_unscaled: 0.1231 (0.1249)  labels_decoder_unscaled: 0.2320 (0.2350)  time: 0.1826  data: 0.0003  max mem: 3702
Epoch: [4]  [1200/1415]  eta: 0:00:41  lr: 0.000000  loss: 0.2167 (0.2423)  labels_encoder: 0.1149 (0.1249)  labels_decoder: 0.1004 (0.1174)  labels_encoder_unscaled: 0.1149 (0.1249)  labels_decoder_unscaled: 0.2009 (0.2348)  time: 0.2082  data: 0.0003  max mem: 3702
Epoch: [4]  [1250/1415]  eta: 0:00:31  lr: 0.000000  loss: 0.2058 (0.2420)  labels_encoder: 0.1067 (0.1247)  labels_decoder: 0.1105 (0.1173)  labels_encoder_unscaled: 0.1067 (0.1247)  labels_decoder_unscaled: 0.2211 (0.2346)  time: 0.1965  data: 0.0003  max mem: 3702
Epoch: [4]  [1300/1415]  eta: 0:00:21  lr: 0.000000  loss: 0.2374 (0.2421)  labels_encoder: 0.1154 (0.1247)  labels_decoder: 0.1210 (0.1174)  labels_encoder_unscaled: 0.1154 (0.1247)  labels_decoder_unscaled: 0.2419 (0.2349)  time: 0.1857  data: 0.0003  max mem: 3702
Epoch: [4]  [1350/1415]  eta: 0:00:12  lr: 0.000000  loss: 0.2176 (0.2417)  labels_encoder: 0.1041 (0.1244)  labels_decoder: 0.1050 (0.1173)  labels_encoder_unscaled: 0.1041 (0.1244)  labels_decoder_unscaled: 0.2101 (0.2346)  time: 0.1848  data: 0.0003  max mem: 3702
Epoch: [4]  [1400/1415]  eta: 0:00:02  lr: 0.000000  loss: 0.2390 (0.2417)  labels_encoder: 0.1179 (0.1244)  labels_decoder: 0.1245 (0.1173)  labels_encoder_unscaled: 0.1179 (0.1244)  labels_decoder_unscaled: 0.2491 (0.2347)  time: 0.1911  data: 0.0006  max mem: 3702
Epoch: [4]  [1414/1415]  eta: 0:00:00  lr: 0.000000  loss: 0.2263 (0.2417)  labels_encoder: 0.1087 (0.1243)  labels_decoder: 0.1219 (0.1174)  labels_encoder_unscaled: 0.1087 (0.1243)  labels_decoder_unscaled: 0.2439 (0.2348)  time: 0.1593  data: 0.0005  max mem: 3702
Epoch: [4] Total time: 0:04:29 (0.1907 s / it)
Averaged stats: lr: 0.000000  loss: 0.2263 (0.2417)  labels_encoder: 0.1087 (0.1243)  labels_decoder: 0.1219 (0.1174)  labels_encoder_unscaled: 0.1087 (0.1243)  labels_decoder_unscaled: 0.2439 (0.2348)
Test:  [   0/1613]  eta: 1:23:12  loss: 2.1540 (2.1540)  labels_encoder: 1.5442 (1.5442)  labels_decoder: 0.6098 (0.6098)  labels_encoder_unscaled: 1.5442 (1.5442)  labels_decoder_unscaled: 1.2196 (1.2196)  time: 3.0951  data: 3.0338  max mem: 3702
Test:  [  50/1613]  eta: 0:04:34  loss: 0.4479 (0.9002)  labels_encoder: 0.2690 (0.5769)  labels_decoder: 0.1950 (0.3233)  labels_encoder_unscaled: 0.2690 (0.5769)  labels_decoder_unscaled: 0.3901 (0.6466)  time: 0.1130  data: 0.0033  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:42  loss: 0.3270 (0.7482)  labels_encoder: 0.2123 (0.4855)  labels_decoder: 0.0897 (0.2628)  labels_encoder_unscaled: 0.2123 (0.4855)  labels_decoder_unscaled: 0.1795 (0.5255)  time: 0.1160  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:20  loss: 0.9701 (0.7608)  labels_encoder: 0.6107 (0.4975)  labels_decoder: 0.2964 (0.2633)  labels_encoder_unscaled: 0.6107 (0.4975)  labels_decoder_unscaled: 0.5929 (0.5266)  time: 0.1223  data: 0.0003  max mem: 3702
Test:  [ 200/1613]  eta: 0:03:04  loss: 1.0178 (0.9122)  labels_encoder: 0.6423 (0.6023)  labels_decoder: 0.3851 (0.3099)  labels_encoder_unscaled: 0.6423 (0.6023)  labels_decoder_unscaled: 0.7702 (0.6197)  time: 0.0974  data: 0.0125  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:56  loss: 0.5926 (0.9738)  labels_encoder: 0.3581 (0.6380)  labels_decoder: 0.2287 (0.3358)  labels_encoder_unscaled: 0.3581 (0.6380)  labels_decoder_unscaled: 0.4574 (0.6715)  time: 0.1256  data: 0.0188  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:47  loss: 0.6877 (1.0084)  labels_encoder: 0.4168 (0.6591)  labels_decoder: 0.2564 (0.3493)  labels_encoder_unscaled: 0.4168 (0.6591)  labels_decoder_unscaled: 0.5127 (0.6987)  time: 0.1159  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:39  loss: 1.3038 (1.0064)  labels_encoder: 0.7429 (0.6502)  labels_decoder: 0.5073 (0.3561)  labels_encoder_unscaled: 0.7429 (0.6502)  labels_decoder_unscaled: 1.0146 (0.7123)  time: 0.1152  data: 0.0052  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:32  loss: 0.8140 (1.1081)  labels_encoder: 0.4771 (0.7195)  labels_decoder: 0.3308 (0.3887)  labels_encoder_unscaled: 0.4771 (0.7195)  labels_decoder_unscaled: 0.6615 (0.7773)  time: 0.1222  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:24  loss: 1.1242 (1.2091)  labels_encoder: 0.6955 (0.7880)  labels_decoder: 0.3850 (0.4211)  labels_encoder_unscaled: 0.6955 (0.7880)  labels_decoder_unscaled: 0.7699 (0.8422)  time: 0.0993  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:17  loss: 0.4341 (1.1608)  labels_encoder: 0.2468 (0.7551)  labels_decoder: 0.1953 (0.4057)  labels_encoder_unscaled: 0.2468 (0.7551)  labels_decoder_unscaled: 0.3906 (0.8114)  time: 0.1085  data: 0.0129  max mem: 3702
Test:  [ 550/1613]  eta: 0:02:10  loss: 0.5800 (1.1528)  labels_encoder: 0.3603 (0.7484)  labels_decoder: 0.2471 (0.4045)  labels_encoder_unscaled: 0.3603 (0.7484)  labels_decoder_unscaled: 0.4941 (0.8089)  time: 0.1186  data: 0.0098  max mem: 3702
Test:  [ 600/1613]  eta: 0:02:04  loss: 1.0628 (1.1756)  labels_encoder: 0.5632 (0.7717)  labels_decoder: 0.3887 (0.4039)  labels_encoder_unscaled: 0.5632 (0.7717)  labels_decoder_unscaled: 0.7774 (0.8078)  time: 0.1199  data: 0.0116  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:58  loss: 0.9298 (1.1554)  labels_encoder: 0.5103 (0.7537)  labels_decoder: 0.4817 (0.4016)  labels_encoder_unscaled: 0.5103 (0.7537)  labels_decoder_unscaled: 0.9635 (0.8033)  time: 0.1193  data: 0.0282  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:51  loss: 0.5698 (1.1234)  labels_encoder: 0.3483 (0.7310)  labels_decoder: 0.2374 (0.3924)  labels_encoder_unscaled: 0.3483 (0.7310)  labels_decoder_unscaled: 0.4748 (0.7848)  time: 0.1150  data: 0.0082  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:44  loss: 0.8481 (1.1065)  labels_encoder: 0.5283 (0.7181)  labels_decoder: 0.3198 (0.3883)  labels_encoder_unscaled: 0.5283 (0.7181)  labels_decoder_unscaled: 0.6396 (0.7767)  time: 0.1011  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:38  loss: 0.8530 (1.1006)  labels_encoder: 0.5492 (0.7150)  labels_decoder: 0.3038 (0.3856)  labels_encoder_unscaled: 0.5492 (0.7150)  labels_decoder_unscaled: 0.6076 (0.7713)  time: 0.1303  data: 0.0315  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:32  loss: 1.4184 (1.1006)  labels_encoder: 0.8842 (0.7124)  labels_decoder: 0.5342 (0.3881)  labels_encoder_unscaled: 0.8842 (0.7124)  labels_decoder_unscaled: 1.0685 (0.7763)  time: 0.1257  data: 0.0025  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:26  loss: 0.7192 (1.1206)  labels_encoder: 0.4200 (0.7258)  labels_decoder: 0.2992 (0.3947)  labels_encoder_unscaled: 0.4200 (0.7258)  labels_decoder_unscaled: 0.5984 (0.7895)  time: 0.1121  data: 0.0063  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:20  loss: 1.1149 (1.1136)  labels_encoder: 0.7202 (0.7213)  labels_decoder: 0.3667 (0.3922)  labels_encoder_unscaled: 0.7202 (0.7213)  labels_decoder_unscaled: 0.7333 (0.7844)  time: 0.1091  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:14  loss: 0.4668 (1.1020)  labels_encoder: 0.2903 (0.7134)  labels_decoder: 0.2236 (0.3886)  labels_encoder_unscaled: 0.2903 (0.7134)  labels_decoder_unscaled: 0.4473 (0.7772)  time: 0.1099  data: 0.0092  max mem: 3702
Test:  [1050/1613]  eta: 0:01:07  loss: 0.8629 (1.0991)  labels_encoder: 0.5018 (0.7112)  labels_decoder: 0.3289 (0.3879)  labels_encoder_unscaled: 0.5018 (0.7112)  labels_decoder_unscaled: 0.6578 (0.7758)  time: 0.1195  data: 0.0414  max mem: 3702
Test:  [1100/1613]  eta: 0:01:01  loss: 0.7493 (1.1065)  labels_encoder: 0.4611 (0.7176)  labels_decoder: 0.2493 (0.3889)  labels_encoder_unscaled: 0.4611 (0.7176)  labels_decoder_unscaled: 0.4986 (0.7778)  time: 0.1170  data: 0.0101  max mem: 3702
Test:  [1150/1613]  eta: 0:00:55  loss: 0.5937 (1.0928)  labels_encoder: 0.3244 (0.7080)  labels_decoder: 0.2161 (0.3847)  labels_encoder_unscaled: 0.3244 (0.7080)  labels_decoder_unscaled: 0.4321 (0.7695)  time: 0.1071  data: 0.0175  max mem: 3702
Test:  [1200/1613]  eta: 0:00:49  loss: 0.6077 (1.0974)  labels_encoder: 0.3876 (0.7105)  labels_decoder: 0.2201 (0.3869)  labels_encoder_unscaled: 0.3876 (0.7105)  labels_decoder_unscaled: 0.4403 (0.7738)  time: 0.0895  data: 0.0050  max mem: 3702
Test:  [1250/1613]  eta: 0:00:43  loss: 0.4161 (1.0984)  labels_encoder: 0.2449 (0.7109)  labels_decoder: 0.2121 (0.3875)  labels_encoder_unscaled: 0.2449 (0.7109)  labels_decoder_unscaled: 0.4242 (0.7749)  time: 0.1348  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:37  loss: 1.1406 (1.0928)  labels_encoder: 0.7921 (0.7069)  labels_decoder: 0.3565 (0.3860)  labels_encoder_unscaled: 0.7921 (0.7069)  labels_decoder_unscaled: 0.7130 (0.7719)  time: 0.1272  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:31  loss: 0.8734 (1.1117)  labels_encoder: 0.5403 (0.7202)  labels_decoder: 0.3331 (0.3915)  labels_encoder_unscaled: 0.5403 (0.7202)  labels_decoder_unscaled: 0.6662 (0.7829)  time: 0.1075  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:25  loss: 1.1299 (1.1050)  labels_encoder: 0.7115 (0.7157)  labels_decoder: 0.3860 (0.3893)  labels_encoder_unscaled: 0.7115 (0.7157)  labels_decoder_unscaled: 0.7719 (0.7786)  time: 0.1127  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:19  loss: 0.7226 (1.1151)  labels_encoder: 0.3433 (0.7210)  labels_decoder: 0.3558 (0.3941)  labels_encoder_unscaled: 0.3433 (0.7210)  labels_decoder_unscaled: 0.7116 (0.7882)  time: 0.1213  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:13  loss: 0.7293 (1.1283)  labels_encoder: 0.4161 (0.7301)  labels_decoder: 0.2251 (0.3982)  labels_encoder_unscaled: 0.4161 (0.7301)  labels_decoder_unscaled: 0.4501 (0.7964)  time: 0.1072  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:07  loss: 0.6783 (1.1238)  labels_encoder: 0.4218 (0.7276)  labels_decoder: 0.2723 (0.3962)  labels_encoder_unscaled: 0.4218 (0.7276)  labels_decoder_unscaled: 0.5446 (0.7925)  time: 0.1165  data: 0.0257  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8983 (1.1192)  labels_encoder: 0.5264 (0.7239)  labels_decoder: 0.3513 (0.3952)  labels_encoder_unscaled: 0.5264 (0.7239)  labels_decoder_unscaled: 0.7027 (0.7905)  time: 0.1135  data: 0.0002  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8382 (1.1186)  labels_encoder: 0.4960 (0.7237)  labels_decoder: 0.3421 (0.3948)  labels_encoder_unscaled: 0.4960 (0.7237)  labels_decoder_unscaled: 0.6842 (0.7897)  time: 0.1024  data: 0.0002  max mem: 3702
Test: Total time: 0:03:13 (0.1201 s / it)
Averaged stats: loss: 0.8382 (1.1186)  labels_encoder: 0.4960 (0.7237)  labels_decoder: 0.3421 (0.3948)  labels_encoder_unscaled: 0.4960 (0.7237)  labels_decoder_unscaled: 0.6842 (0.7897)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5775

dec_mAP all together: | 0.461225083232788 |.
dec_mAP_pred | 0 : 0.5080136033836292 |.
dec_mAP_pred | 1 : 0.4987874393248203 |.
dec_mAP_pred | 2 : 0.48539514527877115 |.
dec_mAP_pred | 3 : 0.4709385830650514 |.
dec_mAP_pred | 4 : 0.4559025848632053 |.
dec_mAP_pred | 5 : 0.44101028176195667 |.
dec_mAP_pred | 6 : 0.4264928777135615 |.
dec_mAP_pred | 7 : 0.41328309306846495 |.
all decoder map: | 0.4625 |.
BaseballPitch: 0.1360
BasketballDunk: 0.7833
Billiards: 0.4466
CleanAndJerk: 0.7794
CliffDiving: 0.8069
CricketBowling: 0.4574
CricketShot: 0.2322
Diving: 0.6863
FrisbeeCatch: 0.3402
GolfSwing: 0.5859
HammerThrow: 0.8512
HighJump: 0.6456
JavelinThrow: 0.6852
LongJump: 0.7648
PoleVault: 0.8792
Shotput: 0.6699
SoccerPenalty: 0.2585
TennisSwing: 0.5789
ThrowDiscus: 0.6104
VolleyballSpiking: 0.3513
Training time 0:34:10
