Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:2
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:4
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  72.478 M, 99.825% Params, 2.305 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 10.111% Params, 0.47 GMac, 20.378% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    12.589 M, 17.339% Params, 0.818 GMac, 35.485% MACs, 
    (net): Sequential(
      12.589 M, 17.339% Params, 0.818 GMac, 35.485% MACs, 
      (0): Residual(
        4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
            (qkv): Linear(3.146 M, 4.333% Params, 0.204 GMac, 8.870% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
        (fn): PreNorm(
          2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
            (net): Sequential(
              2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
              (0): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
            (qkv): Linear(3.146 M, 4.333% Params, 0.204 GMac, 8.870% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
        (fn): PreNorm(
          2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
            (net): Sequential(
              2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
              (0): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.062% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 72.282% Params, 1.017 GMac, 44.127% MACs, 
    (layers): ModuleList(
      52.48 M, 72.282% Params, 1.017 GMac, 44.127% MACs, 
      (0): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.031% Params, 0.0 GMac, 0.008% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2305258540.0
Model params: 72604716
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1404]  eta: 1:44:58  lr: 0.000100  loss: 4.2511 (4.2511)  labels_encoder: 2.6699 (2.6699)  labels_decoder: 1.5812 (1.5812)  labels_encoder_unscaled: 2.6699 (2.6699)  labels_decoder_unscaled: 3.1625 (3.1625)  time: 4.4860  data: 3.7517  max mem: 2365
Epoch: [1]  [  50/1404]  eta: 0:05:49  lr: 0.000100  loss: 1.0576 (1.5666)  labels_encoder: 0.6660 (1.0028)  labels_decoder: 0.3849 (0.5638)  labels_encoder_unscaled: 0.6660 (1.0028)  labels_decoder_unscaled: 0.7698 (1.1276)  time: 0.1608  data: 0.0003  max mem: 3197
Epoch: [1]  [ 100/1404]  eta: 0:04:40  lr: 0.000100  loss: 0.7713 (1.1939)  labels_encoder: 0.4792 (0.7558)  labels_decoder: 0.2855 (0.4381)  labels_encoder_unscaled: 0.4792 (0.7558)  labels_decoder_unscaled: 0.5709 (0.8762)  time: 0.1798  data: 0.0003  max mem: 3197
Epoch: [1]  [ 150/1404]  eta: 0:04:11  lr: 0.000100  loss: 0.6696 (1.0352)  labels_encoder: 0.4160 (0.6513)  labels_decoder: 0.2645 (0.3840)  labels_encoder_unscaled: 0.4160 (0.6513)  labels_decoder_unscaled: 0.5289 (0.7679)  time: 0.1664  data: 0.0003  max mem: 3197
Epoch: [1]  [ 200/1404]  eta: 0:03:50  lr: 0.000100  loss: 0.5848 (0.9355)  labels_encoder: 0.3647 (0.5853)  labels_decoder: 0.2314 (0.3502)  labels_encoder_unscaled: 0.3647 (0.5853)  labels_decoder_unscaled: 0.4628 (0.7005)  time: 0.1698  data: 0.0003  max mem: 3197
Epoch: [1]  [ 250/1404]  eta: 0:03:36  lr: 0.000100  loss: 0.6145 (0.8724)  labels_encoder: 0.3794 (0.5441)  labels_decoder: 0.2424 (0.3283)  labels_encoder_unscaled: 0.3794 (0.5441)  labels_decoder_unscaled: 0.4848 (0.6566)  time: 0.1702  data: 0.0003  max mem: 3197
Epoch: [1]  [ 300/1404]  eta: 0:03:23  lr: 0.000100  loss: 0.5339 (0.8227)  labels_encoder: 0.3190 (0.5120)  labels_decoder: 0.2166 (0.3108)  labels_encoder_unscaled: 0.3190 (0.5120)  labels_decoder_unscaled: 0.4332 (0.6216)  time: 0.1733  data: 0.0003  max mem: 3197
Epoch: [1]  [ 350/1404]  eta: 0:03:11  lr: 0.000100  loss: 0.5185 (0.7857)  labels_encoder: 0.3190 (0.4873)  labels_decoder: 0.2059 (0.2983)  labels_encoder_unscaled: 0.3190 (0.4873)  labels_decoder_unscaled: 0.4119 (0.5967)  time: 0.1712  data: 0.0003  max mem: 3197
Epoch: [1]  [ 400/1404]  eta: 0:03:01  lr: 0.000100  loss: 0.5120 (0.7550)  labels_encoder: 0.3025 (0.4668)  labels_decoder: 0.2088 (0.2882)  labels_encoder_unscaled: 0.3025 (0.4668)  labels_decoder_unscaled: 0.4176 (0.5764)  time: 0.1674  data: 0.0003  max mem: 3197
Epoch: [1]  [ 450/1404]  eta: 0:02:51  lr: 0.000100  loss: 0.5167 (0.7280)  labels_encoder: 0.3099 (0.4486)  labels_decoder: 0.2031 (0.2795)  labels_encoder_unscaled: 0.3099 (0.4486)  labels_decoder_unscaled: 0.4062 (0.5589)  time: 0.1578  data: 0.0003  max mem: 3197
Epoch: [1]  [ 500/1404]  eta: 0:02:41  lr: 0.000100  loss: 0.5105 (0.7061)  labels_encoder: 0.2871 (0.4340)  labels_decoder: 0.1987 (0.2721)  labels_encoder_unscaled: 0.2871 (0.4340)  labels_decoder_unscaled: 0.3975 (0.5441)  time: 0.1704  data: 0.0003  max mem: 3197
Epoch: [1]  [ 550/1404]  eta: 0:02:31  lr: 0.000100  loss: 0.5046 (0.6882)  labels_encoder: 0.3002 (0.4223)  labels_decoder: 0.1996 (0.2660)  labels_encoder_unscaled: 0.3002 (0.4223)  labels_decoder_unscaled: 0.3991 (0.5319)  time: 0.1611  data: 0.0003  max mem: 3197
Epoch: [1]  [ 600/1404]  eta: 0:02:21  lr: 0.000100  loss: 0.4487 (0.6717)  labels_encoder: 0.2637 (0.4116)  labels_decoder: 0.1855 (0.2601)  labels_encoder_unscaled: 0.2637 (0.4116)  labels_decoder_unscaled: 0.3710 (0.5202)  time: 0.1633  data: 0.0003  max mem: 3197
Epoch: [1]  [ 650/1404]  eta: 0:02:12  lr: 0.000100  loss: 0.5024 (0.6577)  labels_encoder: 0.3101 (0.4029)  labels_decoder: 0.1944 (0.2548)  labels_encoder_unscaled: 0.3101 (0.4029)  labels_decoder_unscaled: 0.3888 (0.5096)  time: 0.1635  data: 0.0003  max mem: 3197
Epoch: [1]  [ 700/1404]  eta: 0:02:03  lr: 0.000100  loss: 0.4688 (0.6457)  labels_encoder: 0.2732 (0.3947)  labels_decoder: 0.1937 (0.2510)  labels_encoder_unscaled: 0.2732 (0.3947)  labels_decoder_unscaled: 0.3874 (0.5020)  time: 0.1686  data: 0.0003  max mem: 3197
Epoch: [1]  [ 750/1404]  eta: 0:01:54  lr: 0.000100  loss: 0.4330 (0.6335)  labels_encoder: 0.2673 (0.3863)  labels_decoder: 0.1866 (0.2472)  labels_encoder_unscaled: 0.2673 (0.3863)  labels_decoder_unscaled: 0.3731 (0.4943)  time: 0.1619  data: 0.0004  max mem: 3197
Epoch: [1]  [ 800/1404]  eta: 0:01:45  lr: 0.000100  loss: 0.4816 (0.6234)  labels_encoder: 0.2803 (0.3796)  labels_decoder: 0.1987 (0.2438)  labels_encoder_unscaled: 0.2803 (0.3796)  labels_decoder_unscaled: 0.3975 (0.4875)  time: 0.1676  data: 0.0003  max mem: 3197
Epoch: [1]  [ 850/1404]  eta: 0:01:36  lr: 0.000100  loss: 0.4175 (0.6135)  labels_encoder: 0.2272 (0.3731)  labels_decoder: 0.1786 (0.2405)  labels_encoder_unscaled: 0.2272 (0.3731)  labels_decoder_unscaled: 0.3571 (0.4809)  time: 0.1876  data: 0.0003  max mem: 3197
Epoch: [1]  [ 900/1404]  eta: 0:01:27  lr: 0.000100  loss: 0.4561 (0.6043)  labels_encoder: 0.2527 (0.3667)  labels_decoder: 0.1904 (0.2376)  labels_encoder_unscaled: 0.2527 (0.3667)  labels_decoder_unscaled: 0.3807 (0.4752)  time: 0.1527  data: 0.0003  max mem: 3197
Epoch: [1]  [ 950/1404]  eta: 0:01:18  lr: 0.000100  loss: 0.4337 (0.5955)  labels_encoder: 0.2519 (0.3610)  labels_decoder: 0.1735 (0.2345)  labels_encoder_unscaled: 0.2519 (0.3610)  labels_decoder_unscaled: 0.3469 (0.4691)  time: 0.1740  data: 0.0003  max mem: 3197
Epoch: [1]  [1000/1404]  eta: 0:01:10  lr: 0.000100  loss: 0.4353 (0.5878)  labels_encoder: 0.2373 (0.3556)  labels_decoder: 0.1891 (0.2322)  labels_encoder_unscaled: 0.2373 (0.3556)  labels_decoder_unscaled: 0.3783 (0.4645)  time: 0.1644  data: 0.0003  max mem: 3197
Epoch: [1]  [1050/1404]  eta: 0:01:01  lr: 0.000100  loss: 0.3884 (0.5800)  labels_encoder: 0.2291 (0.3505)  labels_decoder: 0.1624 (0.2295)  labels_encoder_unscaled: 0.2291 (0.3505)  labels_decoder_unscaled: 0.3248 (0.4591)  time: 0.1558  data: 0.0003  max mem: 3197
Epoch: [1]  [1100/1404]  eta: 0:00:52  lr: 0.000100  loss: 0.4235 (0.5727)  labels_encoder: 0.2486 (0.3455)  labels_decoder: 0.1771 (0.2272)  labels_encoder_unscaled: 0.2486 (0.3455)  labels_decoder_unscaled: 0.3542 (0.4544)  time: 0.1780  data: 0.0003  max mem: 3197
Epoch: [1]  [1150/1404]  eta: 0:00:43  lr: 0.000100  loss: 0.3901 (0.5649)  labels_encoder: 0.2192 (0.3402)  labels_decoder: 0.1619 (0.2247)  labels_encoder_unscaled: 0.2192 (0.3402)  labels_decoder_unscaled: 0.3238 (0.4494)  time: 0.1645  data: 0.0003  max mem: 3197
Epoch: [1]  [1200/1404]  eta: 0:00:35  lr: 0.000100  loss: 0.3668 (0.5577)  labels_encoder: 0.2125 (0.3353)  labels_decoder: 0.1596 (0.2224)  labels_encoder_unscaled: 0.2125 (0.3353)  labels_decoder_unscaled: 0.3192 (0.4448)  time: 0.1589  data: 0.0003  max mem: 3197
Epoch: [1]  [1250/1404]  eta: 0:00:26  lr: 0.000100  loss: 0.3992 (0.5512)  labels_encoder: 0.2115 (0.3309)  labels_decoder: 0.1747 (0.2204)  labels_encoder_unscaled: 0.2115 (0.3309)  labels_decoder_unscaled: 0.3494 (0.4407)  time: 0.1704  data: 0.0026  max mem: 3197
Epoch: [1]  [1300/1404]  eta: 0:00:17  lr: 0.000100  loss: 0.3714 (0.5455)  labels_encoder: 0.2185 (0.3273)  labels_decoder: 0.1528 (0.2182)  labels_encoder_unscaled: 0.2185 (0.3273)  labels_decoder_unscaled: 0.3057 (0.4365)  time: 0.1707  data: 0.0005  max mem: 3197
Epoch: [1]  [1350/1404]  eta: 0:00:09  lr: 0.000100  loss: 0.3598 (0.5399)  labels_encoder: 0.2048 (0.3236)  labels_decoder: 0.1569 (0.2163)  labels_encoder_unscaled: 0.2048 (0.3236)  labels_decoder_unscaled: 0.3139 (0.4326)  time: 0.1551  data: 0.0003  max mem: 3197
Epoch: [1]  [1400/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3542 (0.5344)  labels_encoder: 0.2113 (0.3200)  labels_decoder: 0.1537 (0.2144)  labels_encoder_unscaled: 0.2113 (0.3200)  labels_decoder_unscaled: 0.3074 (0.4289)  time: 0.1463  data: 0.0004  max mem: 3197
Epoch: [1]  [1403/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3543 (0.5341)  labels_encoder: 0.2105 (0.3198)  labels_decoder: 0.1556 (0.2144)  labels_encoder_unscaled: 0.2105 (0.3198)  labels_decoder_unscaled: 0.3112 (0.4287)  time: 0.1447  data: 0.0004  max mem: 3197
Epoch: [1] Total time: 0:04:01 (0.1722 s / it)
Averaged stats: lr: 0.000100  loss: 0.3543 (0.5341)  labels_encoder: 0.2105 (0.3198)  labels_decoder: 0.1556 (0.2144)  labels_encoder_unscaled: 0.2105 (0.3198)  labels_decoder_unscaled: 0.3112 (0.4287)
Test:  [   0/1613]  eta: 1:33:10  loss: 0.3075 (0.3075)  labels_encoder: 0.1400 (0.1400)  labels_decoder: 0.1676 (0.1676)  labels_encoder_unscaled: 0.1400 (0.1400)  labels_decoder_unscaled: 0.3351 (0.3351)  time: 3.4660  data: 3.3557  max mem: 3197
Test:  [  50/1613]  eta: 0:04:30  loss: 0.4941 (1.0353)  labels_encoder: 0.2721 (0.6550)  labels_decoder: 0.2108 (0.3804)  labels_encoder_unscaled: 0.2721 (0.6550)  labels_decoder_unscaled: 0.4217 (0.7607)  time: 0.1189  data: 0.0002  max mem: 3197
Test:  [ 100/1613]  eta: 0:03:26  loss: 0.1419 (0.7853)  labels_encoder: 0.0850 (0.4942)  labels_decoder: 0.0565 (0.2911)  labels_encoder_unscaled: 0.0850 (0.4942)  labels_decoder_unscaled: 0.1131 (0.5823)  time: 0.0973  data: 0.0002  max mem: 3197
Test:  [ 150/1613]  eta: 0:03:01  loss: 0.8832 (0.7920)  labels_encoder: 0.5601 (0.5003)  labels_decoder: 0.2992 (0.2917)  labels_encoder_unscaled: 0.5601 (0.5003)  labels_decoder_unscaled: 0.5985 (0.5834)  time: 0.0963  data: 0.0002  max mem: 3197
Test:  [ 200/1613]  eta: 0:02:48  loss: 1.1465 (0.9284)  labels_encoder: 0.7485 (0.6003)  labels_decoder: 0.4122 (0.3281)  labels_encoder_unscaled: 0.7485 (0.6003)  labels_decoder_unscaled: 0.8243 (0.6562)  time: 0.1103  data: 0.0002  max mem: 3197
Test:  [ 250/1613]  eta: 0:02:35  loss: 0.7560 (0.9816)  labels_encoder: 0.4180 (0.6351)  labels_decoder: 0.2917 (0.3465)  labels_encoder_unscaled: 0.4180 (0.6351)  labels_decoder_unscaled: 0.5834 (0.6930)  time: 0.0943  data: 0.0002  max mem: 3197
Test:  [ 300/1613]  eta: 0:02:26  loss: 0.5810 (0.9873)  labels_encoder: 0.3145 (0.6397)  labels_decoder: 0.2505 (0.3477)  labels_encoder_unscaled: 0.3145 (0.6397)  labels_decoder_unscaled: 0.5011 (0.6953)  time: 0.1142  data: 0.0003  max mem: 3197
Test:  [ 350/1613]  eta: 0:02:19  loss: 1.0407 (0.9706)  labels_encoder: 0.6465 (0.6240)  labels_decoder: 0.3942 (0.3466)  labels_encoder_unscaled: 0.6465 (0.6240)  labels_decoder_unscaled: 0.7884 (0.6932)  time: 0.1009  data: 0.0002  max mem: 3197
Test:  [ 400/1613]  eta: 0:02:13  loss: 1.0125 (1.0397)  labels_encoder: 0.6662 (0.6688)  labels_decoder: 0.3587 (0.3710)  labels_encoder_unscaled: 0.6662 (0.6688)  labels_decoder_unscaled: 0.7173 (0.7420)  time: 0.1104  data: 0.0002  max mem: 3197
Test:  [ 450/1613]  eta: 0:02:07  loss: 1.1465 (1.1146)  labels_encoder: 0.6935 (0.7187)  labels_decoder: 0.3921 (0.3959)  labels_encoder_unscaled: 0.6935 (0.7187)  labels_decoder_unscaled: 0.7841 (0.7918)  time: 0.1063  data: 0.0002  max mem: 3197
Test:  [ 500/1613]  eta: 0:02:01  loss: 0.4171 (1.0762)  labels_encoder: 0.2364 (0.6945)  labels_decoder: 0.1808 (0.3817)  labels_encoder_unscaled: 0.2364 (0.6945)  labels_decoder_unscaled: 0.3615 (0.7634)  time: 0.1068  data: 0.0004  max mem: 3197
Test:  [ 550/1613]  eta: 0:01:56  loss: 0.7718 (1.1032)  labels_encoder: 0.5098 (0.7184)  labels_decoder: 0.2114 (0.3849)  labels_encoder_unscaled: 0.5098 (0.7184)  labels_decoder_unscaled: 0.4229 (0.7697)  time: 0.1245  data: 0.0002  max mem: 3197
Test:  [ 600/1613]  eta: 0:01:49  loss: 1.0379 (1.1601)  labels_encoder: 0.6538 (0.7646)  labels_decoder: 0.4058 (0.3955)  labels_encoder_unscaled: 0.6538 (0.7646)  labels_decoder_unscaled: 0.8116 (0.7910)  time: 0.1028  data: 0.0002  max mem: 3197
Test:  [ 650/1613]  eta: 0:01:44  loss: 0.7689 (1.1396)  labels_encoder: 0.3830 (0.7460)  labels_decoder: 0.3384 (0.3937)  labels_encoder_unscaled: 0.3830 (0.7460)  labels_decoder_unscaled: 0.6768 (0.7873)  time: 0.1029  data: 0.0002  max mem: 3197
Test:  [ 700/1613]  eta: 0:01:38  loss: 0.7192 (1.1194)  labels_encoder: 0.3910 (0.7316)  labels_decoder: 0.2705 (0.3878)  labels_encoder_unscaled: 0.3910 (0.7316)  labels_decoder_unscaled: 0.5411 (0.7756)  time: 0.1052  data: 0.0002  max mem: 3197
Test:  [ 750/1613]  eta: 0:01:33  loss: 0.6126 (1.0923)  labels_encoder: 0.3485 (0.7120)  labels_decoder: 0.2641 (0.3803)  labels_encoder_unscaled: 0.3485 (0.7120)  labels_decoder_unscaled: 0.5282 (0.7605)  time: 0.1083  data: 0.0002  max mem: 3197
Test:  [ 800/1613]  eta: 0:01:27  loss: 0.4615 (1.0844)  labels_encoder: 0.3070 (0.7061)  labels_decoder: 0.1964 (0.3783)  labels_encoder_unscaled: 0.3070 (0.7061)  labels_decoder_unscaled: 0.3927 (0.7566)  time: 0.1204  data: 0.0002  max mem: 3197
Test:  [ 850/1613]  eta: 0:01:21  loss: 1.8161 (1.0955)  labels_encoder: 1.1421 (0.7138)  labels_decoder: 0.5391 (0.3816)  labels_encoder_unscaled: 1.1421 (0.7138)  labels_decoder_unscaled: 1.0782 (0.7633)  time: 0.1064  data: 0.0002  max mem: 3197
Test:  [ 900/1613]  eta: 0:01:16  loss: 0.7472 (1.1054)  labels_encoder: 0.3996 (0.7199)  labels_decoder: 0.3276 (0.3856)  labels_encoder_unscaled: 0.3996 (0.7199)  labels_decoder_unscaled: 0.6552 (0.7711)  time: 0.0969  data: 0.0003  max mem: 3197
Test:  [ 950/1613]  eta: 0:01:11  loss: 0.5889 (1.0922)  labels_encoder: 0.3519 (0.7110)  labels_decoder: 0.2370 (0.3812)  labels_encoder_unscaled: 0.3519 (0.7110)  labels_decoder_unscaled: 0.4741 (0.7624)  time: 0.1152  data: 0.0002  max mem: 3197
Test:  [1000/1613]  eta: 0:01:05  loss: 0.4878 (1.0774)  labels_encoder: 0.3007 (0.7000)  labels_decoder: 0.2084 (0.3774)  labels_encoder_unscaled: 0.3007 (0.7000)  labels_decoder_unscaled: 0.4168 (0.7548)  time: 0.1084  data: 0.0004  max mem: 3197
Test:  [1050/1613]  eta: 0:01:00  loss: 0.8207 (1.0697)  labels_encoder: 0.5146 (0.6946)  labels_decoder: 0.3133 (0.3751)  labels_encoder_unscaled: 0.5146 (0.6946)  labels_decoder_unscaled: 0.6265 (0.7501)  time: 0.1079  data: 0.0004  max mem: 3197
Test:  [1100/1613]  eta: 0:00:54  loss: 0.5681 (1.0748)  labels_encoder: 0.3341 (0.7003)  labels_decoder: 0.2822 (0.3745)  labels_encoder_unscaled: 0.3341 (0.7003)  labels_decoder_unscaled: 0.5643 (0.7490)  time: 0.1071  data: 0.0003  max mem: 3197
Test:  [1150/1613]  eta: 0:00:49  loss: 0.5894 (1.0689)  labels_encoder: 0.3747 (0.6953)  labels_decoder: 0.2255 (0.3736)  labels_encoder_unscaled: 0.3747 (0.6953)  labels_decoder_unscaled: 0.4511 (0.7471)  time: 0.0958  data: 0.0002  max mem: 3197
Test:  [1200/1613]  eta: 0:00:44  loss: 0.6735 (1.0751)  labels_encoder: 0.3807 (0.6974)  labels_decoder: 0.2471 (0.3776)  labels_encoder_unscaled: 0.3807 (0.6974)  labels_decoder_unscaled: 0.4943 (0.7553)  time: 0.1167  data: 0.0002  max mem: 3197
Test:  [1250/1613]  eta: 0:00:38  loss: 0.3883 (1.0754)  labels_encoder: 0.2056 (0.6973)  labels_decoder: 0.2008 (0.3781)  labels_encoder_unscaled: 0.2056 (0.6973)  labels_decoder_unscaled: 0.4016 (0.7562)  time: 0.0998  data: 0.0002  max mem: 3197
Test:  [1300/1613]  eta: 0:00:33  loss: 0.5523 (1.0676)  labels_encoder: 0.3364 (0.6921)  labels_decoder: 0.2620 (0.3756)  labels_encoder_unscaled: 0.3364 (0.6921)  labels_decoder_unscaled: 0.5239 (0.7511)  time: 0.1039  data: 0.0002  max mem: 3197
Test:  [1350/1613]  eta: 0:00:27  loss: 0.8509 (1.0870)  labels_encoder: 0.4736 (0.7060)  labels_decoder: 0.3680 (0.3810)  labels_encoder_unscaled: 0.4736 (0.7060)  labels_decoder_unscaled: 0.7359 (0.7620)  time: 0.1020  data: 0.0002  max mem: 3197
Test:  [1400/1613]  eta: 0:00:22  loss: 1.2820 (1.0837)  labels_encoder: 0.8470 (0.7040)  labels_decoder: 0.4009 (0.3797)  labels_encoder_unscaled: 0.8470 (0.7040)  labels_decoder_unscaled: 0.8018 (0.7594)  time: 0.1325  data: 0.0002  max mem: 3197
Test:  [1450/1613]  eta: 0:00:17  loss: 0.5509 (1.1274)  labels_encoder: 0.3333 (0.7353)  labels_decoder: 0.2581 (0.3921)  labels_encoder_unscaled: 0.3333 (0.7353)  labels_decoder_unscaled: 0.5162 (0.7842)  time: 0.1056  data: 0.0005  max mem: 3197
Test:  [1500/1613]  eta: 0:00:12  loss: 0.5915 (1.1360)  labels_encoder: 0.3985 (0.7408)  labels_decoder: 0.2066 (0.3952)  labels_encoder_unscaled: 0.3985 (0.7408)  labels_decoder_unscaled: 0.4133 (0.7903)  time: 0.0972  data: 0.0002  max mem: 3197
Test:  [1550/1613]  eta: 0:00:06  loss: 0.5984 (1.1255)  labels_encoder: 0.3367 (0.7333)  labels_decoder: 0.2461 (0.3922)  labels_encoder_unscaled: 0.3367 (0.7333)  labels_decoder_unscaled: 0.4923 (0.7845)  time: 0.1128  data: 0.0002  max mem: 3197
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8911 (1.1217)  labels_encoder: 0.5014 (0.7307)  labels_decoder: 0.3251 (0.3910)  labels_encoder_unscaled: 0.5014 (0.7307)  labels_decoder_unscaled: 0.6502 (0.7820)  time: 0.0914  data: 0.0002  max mem: 3197
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8395 (1.1195)  labels_encoder: 0.4456 (0.7296)  labels_decoder: 0.3117 (0.3898)  labels_encoder_unscaled: 0.4456 (0.7296)  labels_decoder_unscaled: 0.6233 (0.7797)  time: 0.0636  data: 0.0001  max mem: 3197
Test: Total time: 0:02:51 (0.1061 s / it)
Averaged stats: loss: 0.8395 (1.1195)  labels_encoder: 0.4456 (0.7296)  labels_decoder: 0.3117 (0.3898)  labels_encoder_unscaled: 0.4456 (0.7296)  labels_decoder_unscaled: 0.6233 (0.7797)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.5395

dec_mAP all together: | 0.4300118818966518 |.
dec_mAP_pred | 0 : 0.4754108597094781 |.
dec_mAP_pred | 1 : 0.46632662511594913 |.
dec_mAP_pred | 2 : 0.45376674384380833 |.
dec_mAP_pred | 3 : 0.439853024491957 |.
dec_mAP_pred | 4 : 0.42535108550926637 |.
dec_mAP_pred | 5 : 0.41090175904564674 |.
dec_mAP_pred | 6 : 0.39646032605353637 |.
dec_mAP_pred | 7 : 0.3830694552236318 |.
all decoder map: | 0.4314 |.
BaseballPitch: 0.1005
BasketballDunk: 0.7216
Billiards: 0.4265
CleanAndJerk: 0.7257
CliffDiving: 0.7909
CricketBowling: 0.3776
CricketShot: 0.2332
Diving: 0.6605
FrisbeeCatch: 0.1806
GolfSwing: 0.4653
HammerThrow: 0.8539
HighJump: 0.6267
JavelinThrow: 0.6902
LongJump: 0.7795
PoleVault: 0.8749
Shotput: 0.6575
SoccerPenalty: 0.1903
TennisSwing: 0.5422
ThrowDiscus: 0.5745
VolleyballSpiking: 0.3179
Epoch: [2]  [   0/1404]  eta: 1:21:15  lr: 0.000010  loss: 0.4515 (0.4515)  labels_encoder: 0.3077 (0.3077)  labels_decoder: 0.1438 (0.1438)  labels_encoder_unscaled: 0.3077 (0.3077)  labels_decoder_unscaled: 0.2875 (0.2875)  time: 3.4722  data: 3.2996  max mem: 3197
Epoch: [2]  [  50/1404]  eta: 0:05:30  lr: 0.000010  loss: 0.2933 (0.3255)  labels_encoder: 0.1518 (0.1802)  labels_decoder: 0.1458 (0.1453)  labels_encoder_unscaled: 0.1518 (0.1802)  labels_decoder_unscaled: 0.2915 (0.2907)  time: 0.1786  data: 0.0005  max mem: 3197
Epoch: [2]  [ 100/1404]  eta: 0:04:32  lr: 0.000010  loss: 0.3000 (0.3088)  labels_encoder: 0.1614 (0.1674)  labels_decoder: 0.1357 (0.1414)  labels_encoder_unscaled: 0.1614 (0.1674)  labels_decoder_unscaled: 0.2714 (0.2828)  time: 0.1793  data: 0.0004  max mem: 3197
Epoch: [2]  [ 150/1404]  eta: 0:04:06  lr: 0.000010  loss: 0.2739 (0.3027)  labels_encoder: 0.1429 (0.1653)  labels_decoder: 0.1244 (0.1374)  labels_encoder_unscaled: 0.1429 (0.1653)  labels_decoder_unscaled: 0.2488 (0.2747)  time: 0.1676  data: 0.0003  max mem: 3197
Epoch: [2]  [ 200/1404]  eta: 0:03:49  lr: 0.000010  loss: 0.2797 (0.2983)  labels_encoder: 0.1453 (0.1613)  labels_decoder: 0.1309 (0.1370)  labels_encoder_unscaled: 0.1453 (0.1613)  labels_decoder_unscaled: 0.2617 (0.2741)  time: 0.1758  data: 0.0003  max mem: 3197
Epoch: [2]  [ 250/1404]  eta: 0:03:34  lr: 0.000010  loss: 0.2691 (0.2957)  labels_encoder: 0.1458 (0.1602)  labels_decoder: 0.1249 (0.1355)  labels_encoder_unscaled: 0.1458 (0.1602)  labels_decoder_unscaled: 0.2498 (0.2710)  time: 0.1624  data: 0.0003  max mem: 3197
Epoch: [2]  [ 300/1404]  eta: 0:03:22  lr: 0.000010  loss: 0.3011 (0.2945)  labels_encoder: 0.1576 (0.1596)  labels_decoder: 0.1403 (0.1348)  labels_encoder_unscaled: 0.1576 (0.1596)  labels_decoder_unscaled: 0.2805 (0.2697)  time: 0.1733  data: 0.0003  max mem: 3197
Epoch: [2]  [ 350/1404]  eta: 0:03:11  lr: 0.000010  loss: 0.2830 (0.2953)  labels_encoder: 0.1584 (0.1604)  labels_decoder: 0.1245 (0.1349)  labels_encoder_unscaled: 0.1584 (0.1604)  labels_decoder_unscaled: 0.2489 (0.2698)  time: 0.1774  data: 0.0003  max mem: 3197
Epoch: [2]  [ 400/1404]  eta: 0:03:00  lr: 0.000010  loss: 0.2765 (0.2933)  labels_encoder: 0.1448 (0.1595)  labels_decoder: 0.1237 (0.1338)  labels_encoder_unscaled: 0.1448 (0.1595)  labels_decoder_unscaled: 0.2474 (0.2677)  time: 0.1716  data: 0.0003  max mem: 3197
Epoch: [2]  [ 450/1404]  eta: 0:02:49  lr: 0.000010  loss: 0.2580 (0.2920)  labels_encoder: 0.1380 (0.1585)  labels_decoder: 0.1300 (0.1335)  labels_encoder_unscaled: 0.1380 (0.1585)  labels_decoder_unscaled: 0.2599 (0.2671)  time: 0.1656  data: 0.0003  max mem: 3197
Epoch: [2]  [ 500/1404]  eta: 0:02:40  lr: 0.000010  loss: 0.2956 (0.2920)  labels_encoder: 0.1563 (0.1580)  labels_decoder: 0.1337 (0.1340)  labels_encoder_unscaled: 0.1563 (0.1580)  labels_decoder_unscaled: 0.2673 (0.2681)  time: 0.1754  data: 0.0003  max mem: 3197
Epoch: [2]  [ 550/1404]  eta: 0:02:31  lr: 0.000010  loss: 0.2717 (0.2896)  labels_encoder: 0.1438 (0.1566)  labels_decoder: 0.1227 (0.1330)  labels_encoder_unscaled: 0.1438 (0.1566)  labels_decoder_unscaled: 0.2454 (0.2660)  time: 0.1771  data: 0.0003  max mem: 3197
Epoch: [2]  [ 600/1404]  eta: 0:02:22  lr: 0.000010  loss: 0.2486 (0.2883)  labels_encoder: 0.1240 (0.1554)  labels_decoder: 0.1256 (0.1329)  labels_encoder_unscaled: 0.1240 (0.1554)  labels_decoder_unscaled: 0.2512 (0.2657)  time: 0.1850  data: 0.0003  max mem: 3197
Epoch: [2]  [ 650/1404]  eta: 0:02:13  lr: 0.000010  loss: 0.2765 (0.2869)  labels_encoder: 0.1492 (0.1547)  labels_decoder: 0.1228 (0.1322)  labels_encoder_unscaled: 0.1492 (0.1547)  labels_decoder_unscaled: 0.2457 (0.2645)  time: 0.1770  data: 0.0003  max mem: 3197
Epoch: [2]  [ 700/1404]  eta: 0:02:04  lr: 0.000010  loss: 0.2626 (0.2858)  labels_encoder: 0.1445 (0.1540)  labels_decoder: 0.1260 (0.1319)  labels_encoder_unscaled: 0.1445 (0.1540)  labels_decoder_unscaled: 0.2519 (0.2638)  time: 0.1782  data: 0.0003  max mem: 3197
Epoch: [2]  [ 750/1404]  eta: 0:01:54  lr: 0.000010  loss: 0.2695 (0.2855)  labels_encoder: 0.1374 (0.1540)  labels_decoder: 0.1315 (0.1316)  labels_encoder_unscaled: 0.1374 (0.1540)  labels_decoder_unscaled: 0.2630 (0.2631)  time: 0.1674  data: 0.0004  max mem: 3197
Epoch: [2]  [ 800/1404]  eta: 0:01:46  lr: 0.000010  loss: 0.2768 (0.2856)  labels_encoder: 0.1442 (0.1542)  labels_decoder: 0.1285 (0.1314)  labels_encoder_unscaled: 0.1442 (0.1542)  labels_decoder_unscaled: 0.2570 (0.2628)  time: 0.1857  data: 0.0003  max mem: 3197
Epoch: [2]  [ 850/1404]  eta: 0:01:37  lr: 0.000010  loss: 0.2382 (0.2838)  labels_encoder: 0.1301 (0.1529)  labels_decoder: 0.1200 (0.1309)  labels_encoder_unscaled: 0.1301 (0.1529)  labels_decoder_unscaled: 0.2400 (0.2618)  time: 0.1703  data: 0.0003  max mem: 3197
Epoch: [2]  [ 900/1404]  eta: 0:01:28  lr: 0.000010  loss: 0.2552 (0.2824)  labels_encoder: 0.1303 (0.1517)  labels_decoder: 0.1245 (0.1306)  labels_encoder_unscaled: 0.1303 (0.1517)  labels_decoder_unscaled: 0.2491 (0.2612)  time: 0.1627  data: 0.0003  max mem: 3197
Epoch: [2]  [ 950/1404]  eta: 0:01:19  lr: 0.000010  loss: 0.2452 (0.2814)  labels_encoder: 0.1276 (0.1512)  labels_decoder: 0.1203 (0.1302)  labels_encoder_unscaled: 0.1276 (0.1512)  labels_decoder_unscaled: 0.2405 (0.2603)  time: 0.1734  data: 0.0003  max mem: 3197
Epoch: [2]  [1000/1404]  eta: 0:01:10  lr: 0.000010  loss: 0.2554 (0.2809)  labels_encoder: 0.1287 (0.1510)  labels_decoder: 0.1236 (0.1298)  labels_encoder_unscaled: 0.1287 (0.1510)  labels_decoder_unscaled: 0.2471 (0.2597)  time: 0.1768  data: 0.0004  max mem: 3197
Epoch: [2]  [1050/1404]  eta: 0:01:01  lr: 0.000010  loss: 0.2681 (0.2800)  labels_encoder: 0.1531 (0.1504)  labels_decoder: 0.1245 (0.1296)  labels_encoder_unscaled: 0.1531 (0.1504)  labels_decoder_unscaled: 0.2490 (0.2592)  time: 0.1667  data: 0.0003  max mem: 3197
Epoch: [2]  [1100/1404]  eta: 0:00:53  lr: 0.000010  loss: 0.2597 (0.2793)  labels_encoder: 0.1305 (0.1500)  labels_decoder: 0.1215 (0.1293)  labels_encoder_unscaled: 0.1305 (0.1500)  labels_decoder_unscaled: 0.2429 (0.2585)  time: 0.1683  data: 0.0003  max mem: 3197
Epoch: [2]  [1150/1404]  eta: 0:00:44  lr: 0.000010  loss: 0.2392 (0.2782)  labels_encoder: 0.1310 (0.1494)  labels_decoder: 0.1094 (0.1289)  labels_encoder_unscaled: 0.1310 (0.1494)  labels_decoder_unscaled: 0.2188 (0.2577)  time: 0.1702  data: 0.0003  max mem: 3197
Epoch: [2]  [1200/1404]  eta: 0:00:35  lr: 0.000010  loss: 0.2414 (0.2778)  labels_encoder: 0.1341 (0.1491)  labels_decoder: 0.1242 (0.1287)  labels_encoder_unscaled: 0.1341 (0.1491)  labels_decoder_unscaled: 0.2484 (0.2575)  time: 0.1591  data: 0.0003  max mem: 3197
Epoch: [2]  [1250/1404]  eta: 0:00:26  lr: 0.000010  loss: 0.2585 (0.2771)  labels_encoder: 0.1397 (0.1487)  labels_decoder: 0.1148 (0.1284)  labels_encoder_unscaled: 0.1397 (0.1487)  labels_decoder_unscaled: 0.2295 (0.2568)  time: 0.1797  data: 0.0003  max mem: 3197
Epoch: [2]  [1300/1404]  eta: 0:00:18  lr: 0.000010  loss: 0.2581 (0.2763)  labels_encoder: 0.1287 (0.1481)  labels_decoder: 0.1283 (0.1281)  labels_encoder_unscaled: 0.1287 (0.1481)  labels_decoder_unscaled: 0.2565 (0.2563)  time: 0.1653  data: 0.0004  max mem: 3197
Epoch: [2]  [1350/1404]  eta: 0:00:09  lr: 0.000010  loss: 0.2613 (0.2755)  labels_encoder: 0.1345 (0.1477)  labels_decoder: 0.1190 (0.1279)  labels_encoder_unscaled: 0.1345 (0.1477)  labels_decoder_unscaled: 0.2380 (0.2558)  time: 0.1701  data: 0.0005  max mem: 3197
Epoch: [2]  [1400/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2503 (0.2750)  labels_encoder: 0.1333 (0.1472)  labels_decoder: 0.1181 (0.1278)  labels_encoder_unscaled: 0.1333 (0.1472)  labels_decoder_unscaled: 0.2363 (0.2556)  time: 0.1495  data: 0.0004  max mem: 3197
Epoch: [2]  [1403/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2587 (0.2750)  labels_encoder: 0.1333 (0.1472)  labels_decoder: 0.1198 (0.1278)  labels_encoder_unscaled: 0.1333 (0.1472)  labels_decoder_unscaled: 0.2395 (0.2556)  time: 0.1446  data: 0.0004  max mem: 3197
Epoch: [2] Total time: 0:04:03 (0.1737 s / it)
Averaged stats: lr: 0.000010  loss: 0.2587 (0.2750)  labels_encoder: 0.1333 (0.1472)  labels_decoder: 0.1198 (0.1278)  labels_encoder_unscaled: 0.1333 (0.1472)  labels_decoder_unscaled: 0.2395 (0.2556)
Test:  [   0/1613]  eta: 1:18:32  loss: 0.6895 (0.6895)  labels_encoder: 0.4024 (0.4024)  labels_decoder: 0.2871 (0.2871)  labels_encoder_unscaled: 0.4024 (0.4024)  labels_decoder_unscaled: 0.5742 (0.5742)  time: 2.9217  data: 2.8563  max mem: 3197
Test:  [  50/1613]  eta: 0:04:20  loss: 0.4251 (0.8620)  labels_encoder: 0.2224 (0.5469)  labels_decoder: 0.1946 (0.3151)  labels_encoder_unscaled: 0.2224 (0.5469)  labels_decoder_unscaled: 0.3892 (0.6302)  time: 0.0967  data: 0.0002  max mem: 3197
Test:  [ 100/1613]  eta: 0:03:30  loss: 0.1464 (0.7188)  labels_encoder: 0.0955 (0.4611)  labels_decoder: 0.0509 (0.2578)  labels_encoder_unscaled: 0.0955 (0.4611)  labels_decoder_unscaled: 0.1018 (0.5155)  time: 0.1109  data: 0.0002  max mem: 3197
Test:  [ 150/1613]  eta: 0:03:05  loss: 0.9514 (0.7816)  labels_encoder: 0.6460 (0.5035)  labels_decoder: 0.3249 (0.2781)  labels_encoder_unscaled: 0.6460 (0.5035)  labels_decoder_unscaled: 0.6498 (0.5562)  time: 0.1091  data: 0.0002  max mem: 3197
Test:  [ 200/1613]  eta: 0:02:50  loss: 1.0207 (0.9171)  labels_encoder: 0.6241 (0.6001)  labels_decoder: 0.3971 (0.3170)  labels_encoder_unscaled: 0.6241 (0.6001)  labels_decoder_unscaled: 0.7942 (0.6340)  time: 0.1023  data: 0.0005  max mem: 3197
Test:  [ 250/1613]  eta: 0:02:40  loss: 0.7612 (0.9759)  labels_encoder: 0.5145 (0.6364)  labels_decoder: 0.2468 (0.3395)  labels_encoder_unscaled: 0.5145 (0.6364)  labels_decoder_unscaled: 0.4935 (0.6789)  time: 0.1007  data: 0.0002  max mem: 3197
Test:  [ 300/1613]  eta: 0:02:30  loss: 0.6522 (0.9972)  labels_encoder: 0.3556 (0.6495)  labels_decoder: 0.2673 (0.3478)  labels_encoder_unscaled: 0.3556 (0.6495)  labels_decoder_unscaled: 0.5345 (0.6955)  time: 0.1015  data: 0.0002  max mem: 3197
Test:  [ 350/1613]  eta: 0:02:22  loss: 1.0331 (0.9825)  labels_encoder: 0.5894 (0.6334)  labels_decoder: 0.4437 (0.3491)  labels_encoder_unscaled: 0.5894 (0.6334)  labels_decoder_unscaled: 0.8873 (0.6982)  time: 0.0956  data: 0.0002  max mem: 3197
Test:  [ 400/1613]  eta: 0:02:15  loss: 0.8614 (1.0593)  labels_encoder: 0.4805 (0.6867)  labels_decoder: 0.3155 (0.3726)  labels_encoder_unscaled: 0.4805 (0.6867)  labels_decoder_unscaled: 0.6311 (0.7452)  time: 0.0991  data: 0.0002  max mem: 3197
Test:  [ 450/1613]  eta: 0:02:09  loss: 0.9661 (1.1585)  labels_encoder: 0.6391 (0.7547)  labels_decoder: 0.3270 (0.4038)  labels_encoder_unscaled: 0.6391 (0.7547)  labels_decoder_unscaled: 0.6539 (0.8075)  time: 0.1070  data: 0.0002  max mem: 3197
Test:  [ 500/1613]  eta: 0:02:02  loss: 0.4741 (1.1136)  labels_encoder: 0.2647 (0.7240)  labels_decoder: 0.1939 (0.3896)  labels_encoder_unscaled: 0.2647 (0.7240)  labels_decoder_unscaled: 0.3878 (0.7792)  time: 0.1167  data: 0.0002  max mem: 3197
Test:  [ 550/1613]  eta: 0:01:56  loss: 0.7320 (1.1134)  labels_encoder: 0.5081 (0.7230)  labels_decoder: 0.2369 (0.3903)  labels_encoder_unscaled: 0.5081 (0.7230)  labels_decoder_unscaled: 0.4739 (0.7807)  time: 0.1017  data: 0.0002  max mem: 3197
Test:  [ 600/1613]  eta: 0:01:50  loss: 1.5049 (1.1636)  labels_encoder: 0.8819 (0.7655)  labels_decoder: 0.4951 (0.3980)  labels_encoder_unscaled: 0.8819 (0.7655)  labels_decoder_unscaled: 0.9902 (0.7960)  time: 0.0965  data: 0.0002  max mem: 3197
Test:  [ 650/1613]  eta: 0:01:44  loss: 0.7254 (1.1383)  labels_encoder: 0.3232 (0.7434)  labels_decoder: 0.4055 (0.3949)  labels_encoder_unscaled: 0.3232 (0.7434)  labels_decoder_unscaled: 0.8110 (0.7898)  time: 0.1035  data: 0.0002  max mem: 3197
Test:  [ 700/1613]  eta: 0:01:38  loss: 0.5941 (1.1186)  labels_encoder: 0.3020 (0.7293)  labels_decoder: 0.2786 (0.3893)  labels_encoder_unscaled: 0.3020 (0.7293)  labels_decoder_unscaled: 0.5573 (0.7786)  time: 0.1033  data: 0.0002  max mem: 3197
Test:  [ 750/1613]  eta: 0:01:33  loss: 0.6204 (1.0949)  labels_encoder: 0.3770 (0.7124)  labels_decoder: 0.2443 (0.3824)  labels_encoder_unscaled: 0.3770 (0.7124)  labels_decoder_unscaled: 0.4886 (0.7649)  time: 0.1175  data: 0.0002  max mem: 3197
Test:  [ 800/1613]  eta: 0:01:27  loss: 0.7535 (1.0878)  labels_encoder: 0.4305 (0.7081)  labels_decoder: 0.2851 (0.3796)  labels_encoder_unscaled: 0.4305 (0.7081)  labels_decoder_unscaled: 0.5702 (0.7593)  time: 0.1074  data: 0.0002  max mem: 3197
Test:  [ 850/1613]  eta: 0:01:22  loss: 1.5710 (1.0942)  labels_encoder: 1.1150 (0.7101)  labels_decoder: 0.6612 (0.3841)  labels_encoder_unscaled: 1.1150 (0.7101)  labels_decoder_unscaled: 1.3223 (0.7682)  time: 0.1093  data: 0.0003  max mem: 3197
Test:  [ 900/1613]  eta: 0:01:16  loss: 0.7564 (1.1072)  labels_encoder: 0.4173 (0.7181)  labels_decoder: 0.3294 (0.3891)  labels_encoder_unscaled: 0.4173 (0.7181)  labels_decoder_unscaled: 0.6587 (0.7782)  time: 0.1048  data: 0.0002  max mem: 3197
Test:  [ 950/1613]  eta: 0:01:11  loss: 1.0939 (1.0994)  labels_encoder: 0.7577 (0.7130)  labels_decoder: 0.3628 (0.3864)  labels_encoder_unscaled: 0.7577 (0.7130)  labels_decoder_unscaled: 0.7255 (0.7727)  time: 0.1012  data: 0.0002  max mem: 3197
Test:  [1000/1613]  eta: 0:01:05  loss: 0.5340 (1.0849)  labels_encoder: 0.2870 (0.7023)  labels_decoder: 0.2470 (0.3826)  labels_encoder_unscaled: 0.2870 (0.7023)  labels_decoder_unscaled: 0.4939 (0.7653)  time: 0.1117  data: 0.0002  max mem: 3197
Test:  [1050/1613]  eta: 0:01:00  loss: 0.8168 (1.0812)  labels_encoder: 0.4816 (0.7000)  labels_decoder: 0.3039 (0.3812)  labels_encoder_unscaled: 0.4816 (0.7000)  labels_decoder_unscaled: 0.6078 (0.7625)  time: 0.1073  data: 0.0004  max mem: 3197
Test:  [1100/1613]  eta: 0:00:54  loss: 0.7495 (1.0914)  labels_encoder: 0.3956 (0.7088)  labels_decoder: 0.3744 (0.3826)  labels_encoder_unscaled: 0.3956 (0.7088)  labels_decoder_unscaled: 0.7487 (0.7652)  time: 0.1057  data: 0.0002  max mem: 3197
Test:  [1150/1613]  eta: 0:00:49  loss: 0.5924 (1.0778)  labels_encoder: 0.3253 (0.6988)  labels_decoder: 0.2671 (0.3790)  labels_encoder_unscaled: 0.3253 (0.6988)  labels_decoder_unscaled: 0.5343 (0.7581)  time: 0.1042  data: 0.0002  max mem: 3197
Test:  [1200/1613]  eta: 0:00:44  loss: 0.4676 (1.0844)  labels_encoder: 0.3193 (0.7024)  labels_decoder: 0.2103 (0.3820)  labels_encoder_unscaled: 0.3193 (0.7024)  labels_decoder_unscaled: 0.4206 (0.7640)  time: 0.0987  data: 0.0002  max mem: 3197
Test:  [1250/1613]  eta: 0:00:38  loss: 0.5201 (1.0863)  labels_encoder: 0.2748 (0.7033)  labels_decoder: 0.2217 (0.3830)  labels_encoder_unscaled: 0.2748 (0.7033)  labels_decoder_unscaled: 0.4434 (0.7660)  time: 0.1040  data: 0.0002  max mem: 3197
Test:  [1300/1613]  eta: 0:00:33  loss: 1.0590 (1.0823)  labels_encoder: 0.7161 (0.7006)  labels_decoder: 0.3429 (0.3817)  labels_encoder_unscaled: 0.7161 (0.7006)  labels_decoder_unscaled: 0.6857 (0.7635)  time: 0.1049  data: 0.0002  max mem: 3197
Test:  [1350/1613]  eta: 0:00:28  loss: 0.9190 (1.1001)  labels_encoder: 0.5367 (0.7137)  labels_decoder: 0.3951 (0.3865)  labels_encoder_unscaled: 0.5367 (0.7137)  labels_decoder_unscaled: 0.7903 (0.7730)  time: 0.0927  data: 0.0002  max mem: 3197
Test:  [1400/1613]  eta: 0:00:22  loss: 1.0468 (1.0913)  labels_encoder: 0.6749 (0.7078)  labels_decoder: 0.3466 (0.3835)  labels_encoder_unscaled: 0.6749 (0.7078)  labels_decoder_unscaled: 0.6932 (0.7670)  time: 0.1022  data: 0.0002  max mem: 3197
Test:  [1450/1613]  eta: 0:00:17  loss: 0.6980 (1.1051)  labels_encoder: 0.3374 (0.7172)  labels_decoder: 0.3074 (0.3879)  labels_encoder_unscaled: 0.3374 (0.7172)  labels_decoder_unscaled: 0.6149 (0.7758)  time: 0.0994  data: 0.0002  max mem: 3197
Test:  [1500/1613]  eta: 0:00:12  loss: 0.7193 (1.1176)  labels_encoder: 0.4493 (0.7259)  labels_decoder: 0.2600 (0.3917)  labels_encoder_unscaled: 0.4493 (0.7259)  labels_decoder_unscaled: 0.5199 (0.7835)  time: 0.1010  data: 0.0002  max mem: 3197
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6335 (1.1139)  labels_encoder: 0.3853 (0.7237)  labels_decoder: 0.2388 (0.3902)  labels_encoder_unscaled: 0.3853 (0.7237)  labels_decoder_unscaled: 0.4776 (0.7804)  time: 0.1035  data: 0.0002  max mem: 3197
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9115 (1.1095)  labels_encoder: 0.5598 (0.7204)  labels_decoder: 0.3862 (0.3891)  labels_encoder_unscaled: 0.5598 (0.7204)  labels_decoder_unscaled: 0.7724 (0.7782)  time: 0.0941  data: 0.0002  max mem: 3197
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6824 (1.1079)  labels_encoder: 0.4123 (0.7197)  labels_decoder: 0.2701 (0.3883)  labels_encoder_unscaled: 0.4123 (0.7197)  labels_decoder_unscaled: 0.5402 (0.7765)  time: 0.0726  data: 0.0001  max mem: 3197
Test: Total time: 0:02:51 (0.1060 s / it)
Averaged stats: loss: 0.6824 (1.1079)  labels_encoder: 0.4123 (0.7197)  labels_decoder: 0.2701 (0.3883)  labels_encoder_unscaled: 0.4123 (0.7197)  labels_decoder_unscaled: 0.5402 (0.7765)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5747

dec_mAP all together: | 0.4570763142083639 |.
dec_mAP_pred | 0 : 0.5027140059081265 |.
dec_mAP_pred | 1 : 0.4940796946265361 |.
dec_mAP_pred | 2 : 0.4812778858592158 |.
dec_mAP_pred | 3 : 0.4670426089904816 |.
dec_mAP_pred | 4 : 0.45212962298298776 |.
dec_mAP_pred | 5 : 0.43751931872447053 |.
dec_mAP_pred | 6 : 0.4230656796660777 |.
dec_mAP_pred | 7 : 0.41003087309494346 |.
all decoder map: | 0.4585 |.
BaseballPitch: 0.1626
BasketballDunk: 0.7701
Billiards: 0.4577
CleanAndJerk: 0.7442
CliffDiving: 0.8202
CricketBowling: 0.4541
CricketShot: 0.2326
Diving: 0.6782
FrisbeeCatch: 0.2250
GolfSwing: 0.6102
HammerThrow: 0.8542
HighJump: 0.6405
JavelinThrow: 0.7024
LongJump: 0.7867
PoleVault: 0.8734
Shotput: 0.6955
SoccerPenalty: 0.2613
TennisSwing: 0.5673
ThrowDiscus: 0.5903
VolleyballSpiking: 0.3677
Epoch: [3]  [   0/1404]  eta: 1:13:14  lr: 0.000001  loss: 0.2461 (0.2461)  labels_encoder: 0.1121 (0.1121)  labels_decoder: 0.1340 (0.1340)  labels_encoder_unscaled: 0.1121 (0.1121)  labels_decoder_unscaled: 0.2680 (0.2680)  time: 3.1299  data: 2.8897  max mem: 3197
Epoch: [3]  [  50/1404]  eta: 0:05:13  lr: 0.000001  loss: 0.2299 (0.2460)  labels_encoder: 0.1186 (0.1272)  labels_decoder: 0.1134 (0.1188)  labels_encoder_unscaled: 0.1186 (0.1272)  labels_decoder_unscaled: 0.2267 (0.2376)  time: 0.1738  data: 0.0003  max mem: 3197
Epoch: [3]  [ 100/1404]  eta: 0:04:21  lr: 0.000001  loss: 0.2271 (0.2435)  labels_encoder: 0.1258 (0.1262)  labels_decoder: 0.1126 (0.1172)  labels_encoder_unscaled: 0.1258 (0.1262)  labels_decoder_unscaled: 0.2252 (0.2345)  time: 0.1698  data: 0.0003  max mem: 3197
Epoch: [3]  [ 150/1404]  eta: 0:03:59  lr: 0.000001  loss: 0.2562 (0.2474)  labels_encoder: 0.1230 (0.1287)  labels_decoder: 0.1248 (0.1187)  labels_encoder_unscaled: 0.1230 (0.1287)  labels_decoder_unscaled: 0.2496 (0.2373)  time: 0.1589  data: 0.0003  max mem: 3197
Epoch: [3]  [ 200/1404]  eta: 0:03:43  lr: 0.000001  loss: 0.2430 (0.2468)  labels_encoder: 0.1245 (0.1284)  labels_decoder: 0.1175 (0.1184)  labels_encoder_unscaled: 0.1245 (0.1284)  labels_decoder_unscaled: 0.2349 (0.2368)  time: 0.1663  data: 0.0003  max mem: 3197
Epoch: [3]  [ 250/1404]  eta: 0:03:31  lr: 0.000001  loss: 0.2469 (0.2465)  labels_encoder: 0.1393 (0.1286)  labels_decoder: 0.1161 (0.1179)  labels_encoder_unscaled: 0.1393 (0.1286)  labels_decoder_unscaled: 0.2322 (0.2357)  time: 0.1767  data: 0.0003  max mem: 3197
Epoch: [3]  [ 300/1404]  eta: 0:03:19  lr: 0.000001  loss: 0.2535 (0.2486)  labels_encoder: 0.1367 (0.1304)  labels_decoder: 0.1201 (0.1181)  labels_encoder_unscaled: 0.1367 (0.1304)  labels_decoder_unscaled: 0.2402 (0.2363)  time: 0.1674  data: 0.0003  max mem: 3197
Epoch: [3]  [ 350/1404]  eta: 0:03:08  lr: 0.000001  loss: 0.2425 (0.2484)  labels_encoder: 0.1196 (0.1303)  labels_decoder: 0.1183 (0.1182)  labels_encoder_unscaled: 0.1196 (0.1303)  labels_decoder_unscaled: 0.2366 (0.2363)  time: 0.1637  data: 0.0003  max mem: 3197
Epoch: [3]  [ 400/1404]  eta: 0:02:58  lr: 0.000001  loss: 0.2536 (0.2485)  labels_encoder: 0.1250 (0.1307)  labels_decoder: 0.1155 (0.1178)  labels_encoder_unscaled: 0.1250 (0.1307)  labels_decoder_unscaled: 0.2309 (0.2356)  time: 0.1686  data: 0.0003  max mem: 3197
Epoch: [3]  [ 450/1404]  eta: 0:02:48  lr: 0.000001  loss: 0.2302 (0.2471)  labels_encoder: 0.1176 (0.1293)  labels_decoder: 0.1151 (0.1178)  labels_encoder_unscaled: 0.1176 (0.1293)  labels_decoder_unscaled: 0.2303 (0.2356)  time: 0.1613  data: 0.0003  max mem: 3197
Epoch: [3]  [ 500/1404]  eta: 0:02:38  lr: 0.000001  loss: 0.2404 (0.2467)  labels_encoder: 0.1119 (0.1288)  labels_decoder: 0.1129 (0.1179)  labels_encoder_unscaled: 0.1119 (0.1288)  labels_decoder_unscaled: 0.2258 (0.2357)  time: 0.1693  data: 0.0003  max mem: 3197
Epoch: [3]  [ 550/1404]  eta: 0:02:29  lr: 0.000001  loss: 0.2476 (0.2464)  labels_encoder: 0.1203 (0.1286)  labels_decoder: 0.1269 (0.1177)  labels_encoder_unscaled: 0.1203 (0.1286)  labels_decoder_unscaled: 0.2539 (0.2355)  time: 0.1740  data: 0.0003  max mem: 3197
Epoch: [3]  [ 600/1404]  eta: 0:02:20  lr: 0.000001  loss: 0.2446 (0.2457)  labels_encoder: 0.1140 (0.1279)  labels_decoder: 0.1209 (0.1178)  labels_encoder_unscaled: 0.1140 (0.1279)  labels_decoder_unscaled: 0.2417 (0.2356)  time: 0.1608  data: 0.0003  max mem: 3197
Epoch: [3]  [ 650/1404]  eta: 0:02:10  lr: 0.000001  loss: 0.2371 (0.2456)  labels_encoder: 0.1300 (0.1278)  labels_decoder: 0.1189 (0.1178)  labels_encoder_unscaled: 0.1300 (0.1278)  labels_decoder_unscaled: 0.2379 (0.2355)  time: 0.1678  data: 0.0003  max mem: 3197
Epoch: [3]  [ 700/1404]  eta: 0:02:01  lr: 0.000001  loss: 0.2450 (0.2447)  labels_encoder: 0.1308 (0.1271)  labels_decoder: 0.1192 (0.1176)  labels_encoder_unscaled: 0.1308 (0.1271)  labels_decoder_unscaled: 0.2384 (0.2353)  time: 0.1833  data: 0.0003  max mem: 3197
Epoch: [3]  [ 750/1404]  eta: 0:01:52  lr: 0.000001  loss: 0.2415 (0.2442)  labels_encoder: 0.1175 (0.1269)  labels_decoder: 0.1114 (0.1173)  labels_encoder_unscaled: 0.1175 (0.1269)  labels_decoder_unscaled: 0.2227 (0.2346)  time: 0.1613  data: 0.0005  max mem: 3197
Epoch: [3]  [ 800/1404]  eta: 0:01:43  lr: 0.000001  loss: 0.2371 (0.2441)  labels_encoder: 0.1166 (0.1268)  labels_decoder: 0.1148 (0.1173)  labels_encoder_unscaled: 0.1166 (0.1268)  labels_decoder_unscaled: 0.2296 (0.2347)  time: 0.1734  data: 0.0003  max mem: 3197
Epoch: [3]  [ 850/1404]  eta: 0:01:35  lr: 0.000001  loss: 0.2302 (0.2438)  labels_encoder: 0.1193 (0.1265)  labels_decoder: 0.1140 (0.1173)  labels_encoder_unscaled: 0.1193 (0.1265)  labels_decoder_unscaled: 0.2281 (0.2346)  time: 0.1704  data: 0.0003  max mem: 3197
Epoch: [3]  [ 900/1404]  eta: 0:01:26  lr: 0.000001  loss: 0.2333 (0.2435)  labels_encoder: 0.1100 (0.1262)  labels_decoder: 0.1165 (0.1173)  labels_encoder_unscaled: 0.1100 (0.1262)  labels_decoder_unscaled: 0.2329 (0.2347)  time: 0.1592  data: 0.0003  max mem: 3197
Epoch: [3]  [ 950/1404]  eta: 0:01:17  lr: 0.000001  loss: 0.2154 (0.2428)  labels_encoder: 0.1033 (0.1255)  labels_decoder: 0.1113 (0.1173)  labels_encoder_unscaled: 0.1033 (0.1255)  labels_decoder_unscaled: 0.2226 (0.2347)  time: 0.1714  data: 0.0005  max mem: 3197
Epoch: [3]  [1000/1404]  eta: 0:01:09  lr: 0.000001  loss: 0.2257 (0.2425)  labels_encoder: 0.1182 (0.1253)  labels_decoder: 0.1065 (0.1171)  labels_encoder_unscaled: 0.1182 (0.1253)  labels_decoder_unscaled: 0.2130 (0.2342)  time: 0.1757  data: 0.0003  max mem: 3197
Epoch: [3]  [1050/1404]  eta: 0:01:00  lr: 0.000001  loss: 0.2262 (0.2420)  labels_encoder: 0.1162 (0.1251)  labels_decoder: 0.1118 (0.1168)  labels_encoder_unscaled: 0.1162 (0.1251)  labels_decoder_unscaled: 0.2235 (0.2337)  time: 0.1539  data: 0.0003  max mem: 3197
Epoch: [3]  [1100/1404]  eta: 0:00:51  lr: 0.000001  loss: 0.2302 (0.2417)  labels_encoder: 0.1178 (0.1250)  labels_decoder: 0.1132 (0.1167)  labels_encoder_unscaled: 0.1178 (0.1250)  labels_decoder_unscaled: 0.2264 (0.2334)  time: 0.1615  data: 0.0003  max mem: 3197
Epoch: [3]  [1150/1404]  eta: 0:00:43  lr: 0.000001  loss: 0.2219 (0.2416)  labels_encoder: 0.1051 (0.1248)  labels_decoder: 0.1161 (0.1168)  labels_encoder_unscaled: 0.1051 (0.1248)  labels_decoder_unscaled: 0.2322 (0.2336)  time: 0.1732  data: 0.0003  max mem: 3197
Epoch: [3]  [1200/1404]  eta: 0:00:34  lr: 0.000001  loss: 0.2221 (0.2408)  labels_encoder: 0.1114 (0.1244)  labels_decoder: 0.1099 (0.1165)  labels_encoder_unscaled: 0.1114 (0.1244)  labels_decoder_unscaled: 0.2198 (0.2329)  time: 0.1554  data: 0.0003  max mem: 3197
Epoch: [3]  [1250/1404]  eta: 0:00:26  lr: 0.000001  loss: 0.2552 (0.2408)  labels_encoder: 0.1190 (0.1243)  labels_decoder: 0.1151 (0.1165)  labels_encoder_unscaled: 0.1190 (0.1243)  labels_decoder_unscaled: 0.2303 (0.2329)  time: 0.1735  data: 0.0005  max mem: 3197
Epoch: [3]  [1300/1404]  eta: 0:00:17  lr: 0.000001  loss: 0.2056 (0.2406)  labels_encoder: 0.0993 (0.1242)  labels_decoder: 0.1119 (0.1164)  labels_encoder_unscaled: 0.0993 (0.1242)  labels_decoder_unscaled: 0.2238 (0.2328)  time: 0.1722  data: 0.0003  max mem: 3197
Epoch: [3]  [1350/1404]  eta: 0:00:09  lr: 0.000001  loss: 0.2385 (0.2405)  labels_encoder: 0.1229 (0.1242)  labels_decoder: 0.1092 (0.1163)  labels_encoder_unscaled: 0.1229 (0.1242)  labels_decoder_unscaled: 0.2185 (0.2326)  time: 0.1812  data: 0.0003  max mem: 3197
Epoch: [3]  [1400/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2506 (0.2408)  labels_encoder: 0.1231 (0.1243)  labels_decoder: 0.1210 (0.1165)  labels_encoder_unscaled: 0.1231 (0.1243)  labels_decoder_unscaled: 0.2421 (0.2330)  time: 0.1386  data: 0.0004  max mem: 3197
Epoch: [3]  [1403/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2470 (0.2408)  labels_encoder: 0.1231 (0.1243)  labels_decoder: 0.1210 (0.1165)  labels_encoder_unscaled: 0.1231 (0.1243)  labels_decoder_unscaled: 0.2421 (0.2330)  time: 0.1297  data: 0.0004  max mem: 3197
Epoch: [3] Total time: 0:03:58 (0.1702 s / it)
Averaged stats: lr: 0.000001  loss: 0.2470 (0.2408)  labels_encoder: 0.1231 (0.1243)  labels_decoder: 0.1210 (0.1165)  labels_encoder_unscaled: 0.1231 (0.1243)  labels_decoder_unscaled: 0.2421 (0.2330)
Test:  [   0/1613]  eta: 1:23:16  loss: 0.7993 (0.7993)  labels_encoder: 0.4416 (0.4416)  labels_decoder: 0.3577 (0.3577)  labels_encoder_unscaled: 0.4416 (0.4416)  labels_decoder_unscaled: 0.7154 (0.7154)  time: 3.0978  data: 3.0369  max mem: 3197
Test:  [  50/1613]  eta: 0:04:26  loss: 0.4438 (0.8530)  labels_encoder: 0.2337 (0.5375)  labels_decoder: 0.1994 (0.3155)  labels_encoder_unscaled: 0.2337 (0.5375)  labels_decoder_unscaled: 0.3987 (0.6310)  time: 0.0909  data: 0.0002  max mem: 3197
Test:  [ 100/1613]  eta: 0:03:31  loss: 0.0925 (0.7201)  labels_encoder: 0.0561 (0.4591)  labels_decoder: 0.0364 (0.2610)  labels_encoder_unscaled: 0.0561 (0.4591)  labels_decoder_unscaled: 0.0728 (0.5220)  time: 0.1040  data: 0.0003  max mem: 3197
Test:  [ 150/1613]  eta: 0:03:07  loss: 1.0027 (0.7730)  labels_encoder: 0.6507 (0.4951)  labels_decoder: 0.3180 (0.2780)  labels_encoder_unscaled: 0.6507 (0.4951)  labels_decoder_unscaled: 0.6360 (0.5559)  time: 0.1039  data: 0.0002  max mem: 3197
Test:  [ 200/1613]  eta: 0:02:51  loss: 1.0524 (0.9107)  labels_encoder: 0.6522 (0.5919)  labels_decoder: 0.4093 (0.3187)  labels_encoder_unscaled: 0.6522 (0.5919)  labels_decoder_unscaled: 0.8185 (0.6374)  time: 0.1009  data: 0.0002  max mem: 3197
Test:  [ 250/1613]  eta: 0:02:41  loss: 0.4785 (0.9677)  labels_encoder: 0.3767 (0.6276)  labels_decoder: 0.2236 (0.3401)  labels_encoder_unscaled: 0.3767 (0.6276)  labels_decoder_unscaled: 0.4473 (0.6803)  time: 0.1016  data: 0.0002  max mem: 3197
Test:  [ 300/1613]  eta: 0:02:32  loss: 0.6226 (0.9843)  labels_encoder: 0.3392 (0.6396)  labels_decoder: 0.2713 (0.3447)  labels_encoder_unscaled: 0.3392 (0.6396)  labels_decoder_unscaled: 0.5426 (0.6895)  time: 0.1158  data: 0.0002  max mem: 3197
Test:  [ 350/1613]  eta: 0:02:24  loss: 1.0792 (0.9761)  labels_encoder: 0.6002 (0.6283)  labels_decoder: 0.4598 (0.3478)  labels_encoder_unscaled: 0.6002 (0.6283)  labels_decoder_unscaled: 0.9196 (0.6956)  time: 0.1038  data: 0.0002  max mem: 3197
Test:  [ 400/1613]  eta: 0:02:16  loss: 0.8053 (1.0639)  labels_encoder: 0.5048 (0.6911)  labels_decoder: 0.3194 (0.3727)  labels_encoder_unscaled: 0.5048 (0.6911)  labels_decoder_unscaled: 0.6387 (0.7455)  time: 0.1034  data: 0.0002  max mem: 3197
Test:  [ 450/1613]  eta: 0:02:09  loss: 1.0060 (1.1601)  labels_encoder: 0.6106 (0.7577)  labels_decoder: 0.3402 (0.4024)  labels_encoder_unscaled: 0.6106 (0.7577)  labels_decoder_unscaled: 0.6804 (0.8048)  time: 0.1024  data: 0.0002  max mem: 3197
Test:  [ 500/1613]  eta: 0:02:02  loss: 0.4080 (1.1150)  labels_encoder: 0.2148 (0.7266)  labels_decoder: 0.2028 (0.3884)  labels_encoder_unscaled: 0.2148 (0.7266)  labels_decoder_unscaled: 0.4055 (0.7768)  time: 0.1095  data: 0.0002  max mem: 3197
Test:  [ 550/1613]  eta: 0:01:56  loss: 0.6602 (1.1113)  labels_encoder: 0.4554 (0.7223)  labels_decoder: 0.2685 (0.3890)  labels_encoder_unscaled: 0.4554 (0.7223)  labels_decoder_unscaled: 0.5371 (0.7779)  time: 0.1078  data: 0.0002  max mem: 3197
Test:  [ 600/1613]  eta: 0:01:50  loss: 1.5876 (1.1553)  labels_encoder: 0.9677 (0.7599)  labels_decoder: 0.5147 (0.3954)  labels_encoder_unscaled: 0.9677 (0.7599)  labels_decoder_unscaled: 1.0295 (0.7908)  time: 0.1090  data: 0.0002  max mem: 3197
Test:  [ 650/1613]  eta: 0:01:44  loss: 0.8514 (1.1377)  labels_encoder: 0.4297 (0.7432)  labels_decoder: 0.4217 (0.3945)  labels_encoder_unscaled: 0.4297 (0.7432)  labels_decoder_unscaled: 0.8434 (0.7891)  time: 0.0937  data: 0.0002  max mem: 3197
Test:  [ 700/1613]  eta: 0:01:38  loss: 0.5766 (1.1171)  labels_encoder: 0.2967 (0.7285)  labels_decoder: 0.2712 (0.3886)  labels_encoder_unscaled: 0.2967 (0.7285)  labels_decoder_unscaled: 0.5425 (0.7773)  time: 0.1021  data: 0.0002  max mem: 3197
Test:  [ 750/1613]  eta: 0:01:33  loss: 0.8363 (1.0995)  labels_encoder: 0.5184 (0.7157)  labels_decoder: 0.3179 (0.3837)  labels_encoder_unscaled: 0.5184 (0.7157)  labels_decoder_unscaled: 0.6358 (0.7675)  time: 0.1065  data: 0.0002  max mem: 3197
Test:  [ 800/1613]  eta: 0:01:27  loss: 0.7405 (1.0928)  labels_encoder: 0.4458 (0.7116)  labels_decoder: 0.3158 (0.3813)  labels_encoder_unscaled: 0.4458 (0.7116)  labels_decoder_unscaled: 0.6316 (0.7625)  time: 0.1156  data: 0.0002  max mem: 3197
Test:  [ 850/1613]  eta: 0:01:22  loss: 1.6635 (1.1015)  labels_encoder: 1.1354 (0.7147)  labels_decoder: 0.6889 (0.3867)  labels_encoder_unscaled: 1.1354 (0.7147)  labels_decoder_unscaled: 1.3779 (0.7735)  time: 0.1097  data: 0.0002  max mem: 3197
Test:  [ 900/1613]  eta: 0:01:16  loss: 0.6604 (1.1193)  labels_encoder: 0.4171 (0.7269)  labels_decoder: 0.2771 (0.3924)  labels_encoder_unscaled: 0.4171 (0.7269)  labels_decoder_unscaled: 0.5543 (0.7849)  time: 0.0960  data: 0.0002  max mem: 3197
Test:  [ 950/1613]  eta: 0:01:11  loss: 1.2268 (1.1118)  labels_encoder: 0.8293 (0.7220)  labels_decoder: 0.3940 (0.3898)  labels_encoder_unscaled: 0.8293 (0.7220)  labels_decoder_unscaled: 0.7880 (0.7796)  time: 0.1088  data: 0.0002  max mem: 3197
Test:  [1000/1613]  eta: 0:01:05  loss: 0.5723 (1.0969)  labels_encoder: 0.3263 (0.7114)  labels_decoder: 0.2193 (0.3855)  labels_encoder_unscaled: 0.3263 (0.7114)  labels_decoder_unscaled: 0.4387 (0.7710)  time: 0.0972  data: 0.0002  max mem: 3197
Test:  [1050/1613]  eta: 0:01:00  loss: 0.8361 (1.0929)  labels_encoder: 0.5064 (0.7089)  labels_decoder: 0.3148 (0.3840)  labels_encoder_unscaled: 0.5064 (0.7089)  labels_decoder_unscaled: 0.6295 (0.7680)  time: 0.1219  data: 0.0002  max mem: 3197
Test:  [1100/1613]  eta: 0:00:54  loss: 0.7471 (1.1022)  labels_encoder: 0.5226 (0.7172)  labels_decoder: 0.3511 (0.3850)  labels_encoder_unscaled: 0.5226 (0.7172)  labels_decoder_unscaled: 0.7022 (0.7700)  time: 0.1077  data: 0.0002  max mem: 3197
Test:  [1150/1613]  eta: 0:00:49  loss: 0.5991 (1.0902)  labels_encoder: 0.3352 (0.7086)  labels_decoder: 0.2640 (0.3816)  labels_encoder_unscaled: 0.3352 (0.7086)  labels_decoder_unscaled: 0.5279 (0.7632)  time: 0.1024  data: 0.0002  max mem: 3197
Test:  [1200/1613]  eta: 0:00:44  loss: 0.4855 (1.0963)  labels_encoder: 0.2959 (0.7120)  labels_decoder: 0.1999 (0.3843)  labels_encoder_unscaled: 0.2959 (0.7120)  labels_decoder_unscaled: 0.3998 (0.7686)  time: 0.0995  data: 0.0002  max mem: 3197
Test:  [1250/1613]  eta: 0:00:38  loss: 0.4931 (1.0986)  labels_encoder: 0.2617 (0.7133)  labels_decoder: 0.2103 (0.3853)  labels_encoder_unscaled: 0.2617 (0.7133)  labels_decoder_unscaled: 0.4206 (0.7707)  time: 0.1018  data: 0.0002  max mem: 3197
Test:  [1300/1613]  eta: 0:00:33  loss: 0.9316 (1.0929)  labels_encoder: 0.6492 (0.7095)  labels_decoder: 0.3722 (0.3834)  labels_encoder_unscaled: 0.6492 (0.7095)  labels_decoder_unscaled: 0.7443 (0.7668)  time: 0.1160  data: 0.0002  max mem: 3197
Test:  [1350/1613]  eta: 0:00:27  loss: 0.9282 (1.1078)  labels_encoder: 0.5440 (0.7205)  labels_decoder: 0.3843 (0.3873)  labels_encoder_unscaled: 0.5440 (0.7205)  labels_decoder_unscaled: 0.7685 (0.7746)  time: 0.0988  data: 0.0002  max mem: 3197
Test:  [1400/1613]  eta: 0:00:22  loss: 1.0191 (1.0994)  labels_encoder: 0.6101 (0.7148)  labels_decoder: 0.4113 (0.3846)  labels_encoder_unscaled: 0.6101 (0.7148)  labels_decoder_unscaled: 0.8226 (0.7692)  time: 0.1011  data: 0.0002  max mem: 3197
Test:  [1450/1613]  eta: 0:00:17  loss: 0.7370 (1.1111)  labels_encoder: 0.3775 (0.7227)  labels_decoder: 0.3139 (0.3884)  labels_encoder_unscaled: 0.3775 (0.7227)  labels_decoder_unscaled: 0.6279 (0.7768)  time: 0.1027  data: 0.0003  max mem: 3197
Test:  [1500/1613]  eta: 0:00:11  loss: 0.8045 (1.1261)  labels_encoder: 0.5070 (0.7338)  labels_decoder: 0.2622 (0.3923)  labels_encoder_unscaled: 0.5070 (0.7338)  labels_decoder_unscaled: 0.5243 (0.7845)  time: 0.0927  data: 0.0002  max mem: 3197
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6142 (1.1225)  labels_encoder: 0.3772 (0.7317)  labels_decoder: 0.2370 (0.3908)  labels_encoder_unscaled: 0.3772 (0.7317)  labels_decoder_unscaled: 0.4740 (0.7816)  time: 0.1172  data: 0.0002  max mem: 3197
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8937 (1.1192)  labels_encoder: 0.5410 (0.7292)  labels_decoder: 0.3758 (0.3900)  labels_encoder_unscaled: 0.5410 (0.7292)  labels_decoder_unscaled: 0.7515 (0.7799)  time: 0.0932  data: 0.0002  max mem: 3197
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6478 (1.1175)  labels_encoder: 0.3989 (0.7284)  labels_decoder: 0.2700 (0.3891)  labels_encoder_unscaled: 0.3989 (0.7284)  labels_decoder_unscaled: 0.5401 (0.7782)  time: 0.0669  data: 0.0001  max mem: 3197
Test: Total time: 0:02:50 (0.1055 s / it)
Averaged stats: loss: 0.6478 (1.1175)  labels_encoder: 0.3989 (0.7284)  labels_decoder: 0.2700 (0.3891)  labels_encoder_unscaled: 0.3989 (0.7284)  labels_decoder_unscaled: 0.5401 (0.7782)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5730

dec_mAP all together: | 0.4560895121214249 |.
dec_mAP_pred | 0 : 0.5002278278023593 |.
dec_mAP_pred | 1 : 0.4922248753497911 |.
dec_mAP_pred | 2 : 0.47991610395361367 |.
dec_mAP_pred | 3 : 0.4660286972324899 |.
dec_mAP_pred | 4 : 0.4514054111164915 |.
dec_mAP_pred | 5 : 0.4369468463835524 |.
dec_mAP_pred | 6 : 0.42257213277980493 |.
dec_mAP_pred | 7 : 0.4095738732534496 |.
all decoder map: | 0.4574 |.
BaseballPitch: 0.1525
BasketballDunk: 0.7676
Billiards: 0.4632
CleanAndJerk: 0.7428
CliffDiving: 0.8106
CricketBowling: 0.4517
CricketShot: 0.2314
Diving: 0.6733
FrisbeeCatch: 0.2349
GolfSwing: 0.6085
HammerThrow: 0.8536
HighJump: 0.6400
JavelinThrow: 0.7019
LongJump: 0.7776
PoleVault: 0.8675
Shotput: 0.6875
SoccerPenalty: 0.2541
TennisSwing: 0.5676
ThrowDiscus: 0.5989
VolleyballSpiking: 0.3753
Epoch: [4]  [   0/1404]  eta: 1:24:42  lr: 0.000000  loss: 0.2013 (0.2013)  labels_encoder: 0.0753 (0.0753)  labels_decoder: 0.1260 (0.1260)  labels_encoder_unscaled: 0.0753 (0.0753)  labels_decoder_unscaled: 0.2520 (0.2520)  time: 3.6200  data: 3.4173  max mem: 3197
Epoch: [4]  [  50/1404]  eta: 0:05:25  lr: 0.000000  loss: 0.2223 (0.2394)  labels_encoder: 0.1229 (0.1261)  labels_decoder: 0.1034 (0.1133)  labels_encoder_unscaled: 0.1229 (0.1261)  labels_decoder_unscaled: 0.2068 (0.2266)  time: 0.1714  data: 0.0003  max mem: 3197
Epoch: [4]  [ 100/1404]  eta: 0:04:30  lr: 0.000000  loss: 0.2292 (0.2412)  labels_encoder: 0.1171 (0.1251)  labels_decoder: 0.1092 (0.1161)  labels_encoder_unscaled: 0.1171 (0.1251)  labels_decoder_unscaled: 0.2183 (0.2322)  time: 0.1814  data: 0.0003  max mem: 3197
Epoch: [4]  [ 150/1404]  eta: 0:04:04  lr: 0.000000  loss: 0.2273 (0.2396)  labels_encoder: 0.1060 (0.1231)  labels_decoder: 0.1024 (0.1165)  labels_encoder_unscaled: 0.1060 (0.1231)  labels_decoder_unscaled: 0.2048 (0.2330)  time: 0.1749  data: 0.0003  max mem: 3197
Epoch: [4]  [ 200/1404]  eta: 0:03:48  lr: 0.000000  loss: 0.2433 (0.2425)  labels_encoder: 0.1304 (0.1258)  labels_decoder: 0.1146 (0.1167)  labels_encoder_unscaled: 0.1304 (0.1258)  labels_decoder_unscaled: 0.2292 (0.2334)  time: 0.1629  data: 0.0003  max mem: 3197
Epoch: [4]  [ 250/1404]  eta: 0:03:39  lr: 0.000000  loss: 0.2331 (0.2411)  labels_encoder: 0.1235 (0.1244)  labels_decoder: 0.1102 (0.1167)  labels_encoder_unscaled: 0.1235 (0.1244)  labels_decoder_unscaled: 0.2203 (0.2335)  time: 0.1861  data: 0.0004  max mem: 3197
Epoch: [4]  [ 300/1404]  eta: 0:03:29  lr: 0.000000  loss: 0.2185 (0.2390)  labels_encoder: 0.1126 (0.1227)  labels_decoder: 0.1074 (0.1162)  labels_encoder_unscaled: 0.1126 (0.1227)  labels_decoder_unscaled: 0.2148 (0.2325)  time: 0.1858  data: 0.0004  max mem: 3197
Epoch: [4]  [ 350/1404]  eta: 0:03:19  lr: 0.000000  loss: 0.2350 (0.2413)  labels_encoder: 0.1127 (0.1249)  labels_decoder: 0.1111 (0.1164)  labels_encoder_unscaled: 0.1127 (0.1249)  labels_decoder_unscaled: 0.2223 (0.2328)  time: 0.1900  data: 0.0006  max mem: 3197
Epoch: [4]  [ 400/1404]  eta: 0:03:07  lr: 0.000000  loss: 0.2460 (0.2402)  labels_encoder: 0.1318 (0.1244)  labels_decoder: 0.1118 (0.1158)  labels_encoder_unscaled: 0.1318 (0.1244)  labels_decoder_unscaled: 0.2236 (0.2315)  time: 0.1640  data: 0.0003  max mem: 3197
Epoch: [4]  [ 450/1404]  eta: 0:02:56  lr: 0.000000  loss: 0.2303 (0.2406)  labels_encoder: 0.1173 (0.1248)  labels_decoder: 0.1103 (0.1158)  labels_encoder_unscaled: 0.1173 (0.1248)  labels_decoder_unscaled: 0.2206 (0.2316)  time: 0.1676  data: 0.0003  max mem: 3197
Epoch: [4]  [ 500/1404]  eta: 0:02:45  lr: 0.000000  loss: 0.2129 (0.2399)  labels_encoder: 0.1034 (0.1243)  labels_decoder: 0.1064 (0.1156)  labels_encoder_unscaled: 0.1034 (0.1243)  labels_decoder_unscaled: 0.2129 (0.2312)  time: 0.1707  data: 0.0003  max mem: 3197
Epoch: [4]  [ 550/1404]  eta: 0:02:35  lr: 0.000000  loss: 0.2399 (0.2402)  labels_encoder: 0.1273 (0.1245)  labels_decoder: 0.1156 (0.1158)  labels_encoder_unscaled: 0.1273 (0.1245)  labels_decoder_unscaled: 0.2313 (0.2316)  time: 0.1589  data: 0.0003  max mem: 3197
Epoch: [4]  [ 600/1404]  eta: 0:02:25  lr: 0.000000  loss: 0.2334 (0.2404)  labels_encoder: 0.1105 (0.1245)  labels_decoder: 0.1160 (0.1160)  labels_encoder_unscaled: 0.1105 (0.1245)  labels_decoder_unscaled: 0.2321 (0.2319)  time: 0.1791  data: 0.0003  max mem: 3197
Epoch: [4]  [ 650/1404]  eta: 0:02:16  lr: 0.000000  loss: 0.2432 (0.2400)  labels_encoder: 0.1252 (0.1242)  labels_decoder: 0.1174 (0.1158)  labels_encoder_unscaled: 0.1252 (0.1242)  labels_decoder_unscaled: 0.2347 (0.2315)  time: 0.1788  data: 0.0003  max mem: 3197
Epoch: [4]  [ 700/1404]  eta: 0:02:06  lr: 0.000000  loss: 0.2125 (0.2392)  labels_encoder: 0.0980 (0.1236)  labels_decoder: 0.1085 (0.1156)  labels_encoder_unscaled: 0.0980 (0.1236)  labels_decoder_unscaled: 0.2170 (0.2313)  time: 0.1738  data: 0.0003  max mem: 3197
Epoch: [4]  [ 750/1404]  eta: 0:01:57  lr: 0.000000  loss: 0.2540 (0.2389)  labels_encoder: 0.1168 (0.1232)  labels_decoder: 0.1169 (0.1157)  labels_encoder_unscaled: 0.1168 (0.1232)  labels_decoder_unscaled: 0.2338 (0.2314)  time: 0.1797  data: 0.0003  max mem: 3197
Epoch: [4]  [ 800/1404]  eta: 0:01:48  lr: 0.000000  loss: 0.2452 (0.2391)  labels_encoder: 0.1294 (0.1234)  labels_decoder: 0.1126 (0.1157)  labels_encoder_unscaled: 0.1294 (0.1234)  labels_decoder_unscaled: 0.2252 (0.2314)  time: 0.1735  data: 0.0003  max mem: 3197
Epoch: [4]  [ 850/1404]  eta: 0:01:38  lr: 0.000000  loss: 0.2281 (0.2390)  labels_encoder: 0.1244 (0.1234)  labels_decoder: 0.1146 (0.1156)  labels_encoder_unscaled: 0.1244 (0.1234)  labels_decoder_unscaled: 0.2291 (0.2312)  time: 0.1587  data: 0.0003  max mem: 3197
Epoch: [4]  [ 900/1404]  eta: 0:01:29  lr: 0.000000  loss: 0.2384 (0.2384)  labels_encoder: 0.1102 (0.1228)  labels_decoder: 0.1149 (0.1156)  labels_encoder_unscaled: 0.1102 (0.1228)  labels_decoder_unscaled: 0.2299 (0.2312)  time: 0.1745  data: 0.0003  max mem: 3197
Epoch: [4]  [ 950/1404]  eta: 0:01:20  lr: 0.000000  loss: 0.2346 (0.2385)  labels_encoder: 0.1184 (0.1229)  labels_decoder: 0.1127 (0.1156)  labels_encoder_unscaled: 0.1184 (0.1229)  labels_decoder_unscaled: 0.2253 (0.2313)  time: 0.1680  data: 0.0003  max mem: 3197
Epoch: [4]  [1000/1404]  eta: 0:01:11  lr: 0.000000  loss: 0.2167 (0.2384)  labels_encoder: 0.1086 (0.1228)  labels_decoder: 0.1077 (0.1157)  labels_encoder_unscaled: 0.1086 (0.1228)  labels_decoder_unscaled: 0.2153 (0.2313)  time: 0.1630  data: 0.0006  max mem: 3197
Epoch: [4]  [1050/1404]  eta: 0:01:02  lr: 0.000000  loss: 0.2364 (0.2381)  labels_encoder: 0.1228 (0.1226)  labels_decoder: 0.1129 (0.1156)  labels_encoder_unscaled: 0.1228 (0.1226)  labels_decoder_unscaled: 0.2258 (0.2311)  time: 0.1678  data: 0.0003  max mem: 3197
Epoch: [4]  [1100/1404]  eta: 0:00:53  lr: 0.000000  loss: 0.2384 (0.2382)  labels_encoder: 0.1301 (0.1226)  labels_decoder: 0.1136 (0.1156)  labels_encoder_unscaled: 0.1301 (0.1226)  labels_decoder_unscaled: 0.2272 (0.2311)  time: 0.1655  data: 0.0003  max mem: 3197
Epoch: [4]  [1150/1404]  eta: 0:00:44  lr: 0.000000  loss: 0.2205 (0.2378)  labels_encoder: 0.1054 (0.1222)  labels_decoder: 0.1113 (0.1155)  labels_encoder_unscaled: 0.1054 (0.1222)  labels_decoder_unscaled: 0.2226 (0.2311)  time: 0.1650  data: 0.0004  max mem: 3197
Epoch: [4]  [1200/1404]  eta: 0:00:35  lr: 0.000000  loss: 0.2159 (0.2372)  labels_encoder: 0.1183 (0.1220)  labels_decoder: 0.1042 (0.1152)  labels_encoder_unscaled: 0.1183 (0.1220)  labels_decoder_unscaled: 0.2083 (0.2305)  time: 0.1754  data: 0.0003  max mem: 3197
Epoch: [4]  [1250/1404]  eta: 0:00:26  lr: 0.000000  loss: 0.2335 (0.2373)  labels_encoder: 0.1155 (0.1219)  labels_decoder: 0.1113 (0.1154)  labels_encoder_unscaled: 0.1155 (0.1219)  labels_decoder_unscaled: 0.2226 (0.2307)  time: 0.1758  data: 0.0003  max mem: 3197
Epoch: [4]  [1300/1404]  eta: 0:00:18  lr: 0.000000  loss: 0.2475 (0.2369)  labels_encoder: 0.1337 (0.1217)  labels_decoder: 0.1095 (0.1151)  labels_encoder_unscaled: 0.1337 (0.1217)  labels_decoder_unscaled: 0.2190 (0.2303)  time: 0.1619  data: 0.0003  max mem: 3197
Epoch: [4]  [1350/1404]  eta: 0:00:09  lr: 0.000000  loss: 0.2446 (0.2371)  labels_encoder: 0.1227 (0.1219)  labels_decoder: 0.1234 (0.1152)  labels_encoder_unscaled: 0.1227 (0.1219)  labels_decoder_unscaled: 0.2468 (0.2304)  time: 0.1746  data: 0.0003  max mem: 3197
Epoch: [4]  [1400/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2259 (0.2371)  labels_encoder: 0.1196 (0.1218)  labels_decoder: 0.1121 (0.1153)  labels_encoder_unscaled: 0.1196 (0.1218)  labels_decoder_unscaled: 0.2243 (0.2306)  time: 0.1410  data: 0.0003  max mem: 3197
Epoch: [4]  [1403/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2259 (0.2370)  labels_encoder: 0.1196 (0.1218)  labels_decoder: 0.1061 (0.1153)  labels_encoder_unscaled: 0.1196 (0.1218)  labels_decoder_unscaled: 0.2121 (0.2305)  time: 0.1341  data: 0.0003  max mem: 3197
Epoch: [4] Total time: 0:04:04 (0.1741 s / it)
Averaged stats: lr: 0.000000  loss: 0.2259 (0.2370)  labels_encoder: 0.1196 (0.1218)  labels_decoder: 0.1061 (0.1153)  labels_encoder_unscaled: 0.1196 (0.1218)  labels_decoder_unscaled: 0.2121 (0.2305)
Test:  [   0/1613]  eta: 1:23:46  loss: 0.7628 (0.7628)  labels_encoder: 0.4260 (0.4260)  labels_decoder: 0.3369 (0.3369)  labels_encoder_unscaled: 0.4260 (0.4260)  labels_decoder_unscaled: 0.6738 (0.6738)  time: 3.1161  data: 3.0020  max mem: 3197
Test:  [  50/1613]  eta: 0:04:38  loss: 0.4381 (0.8565)  labels_encoder: 0.2364 (0.5415)  labels_decoder: 0.1894 (0.3150)  labels_encoder_unscaled: 0.2364 (0.5415)  labels_decoder_unscaled: 0.3787 (0.6300)  time: 0.1019  data: 0.0002  max mem: 3197
Test:  [ 100/1613]  eta: 0:03:31  loss: 0.0884 (0.7197)  labels_encoder: 0.0543 (0.4605)  labels_decoder: 0.0341 (0.2592)  labels_encoder_unscaled: 0.0543 (0.4605)  labels_decoder_unscaled: 0.0682 (0.5184)  time: 0.0972  data: 0.0002  max mem: 3197
Test:  [ 150/1613]  eta: 0:03:06  loss: 0.9913 (0.7705)  labels_encoder: 0.6520 (0.4946)  labels_decoder: 0.3186 (0.2759)  labels_encoder_unscaled: 0.6520 (0.4946)  labels_decoder_unscaled: 0.6371 (0.5519)  time: 0.1119  data: 0.0002  max mem: 3197
Test:  [ 200/1613]  eta: 0:02:51  loss: 1.0506 (0.9082)  labels_encoder: 0.6535 (0.5915)  labels_decoder: 0.4088 (0.3167)  labels_encoder_unscaled: 0.6535 (0.5915)  labels_decoder_unscaled: 0.8177 (0.6334)  time: 0.1085  data: 0.0002  max mem: 3197
Test:  [ 250/1613]  eta: 0:02:39  loss: 0.4469 (0.9667)  labels_encoder: 0.3857 (0.6279)  labels_decoder: 0.2164 (0.3389)  labels_encoder_unscaled: 0.3857 (0.6279)  labels_decoder_unscaled: 0.4328 (0.6777)  time: 0.0975  data: 0.0002  max mem: 3197
Test:  [ 300/1613]  eta: 0:02:30  loss: 0.6205 (0.9859)  labels_encoder: 0.3435 (0.6412)  labels_decoder: 0.2452 (0.3448)  labels_encoder_unscaled: 0.3435 (0.6412)  labels_decoder_unscaled: 0.4903 (0.6895)  time: 0.1007  data: 0.0003  max mem: 3197
Test:  [ 350/1613]  eta: 0:02:22  loss: 1.0805 (0.9770)  labels_encoder: 0.6035 (0.6294)  labels_decoder: 0.4657 (0.3476)  labels_encoder_unscaled: 0.6035 (0.6294)  labels_decoder_unscaled: 0.9315 (0.6952)  time: 0.1001  data: 0.0002  max mem: 3197
Test:  [ 400/1613]  eta: 0:02:15  loss: 0.8105 (1.0640)  labels_encoder: 0.5216 (0.6915)  labels_decoder: 0.3213 (0.3725)  labels_encoder_unscaled: 0.5216 (0.6915)  labels_decoder_unscaled: 0.6427 (0.7450)  time: 0.1055  data: 0.0002  max mem: 3197
Test:  [ 450/1613]  eta: 0:02:08  loss: 0.9567 (1.1597)  labels_encoder: 0.6029 (0.7576)  labels_decoder: 0.3423 (0.4021)  labels_encoder_unscaled: 0.6029 (0.7576)  labels_decoder_unscaled: 0.6846 (0.8042)  time: 0.1018  data: 0.0002  max mem: 3197
Test:  [ 500/1613]  eta: 0:02:02  loss: 0.4008 (1.1151)  labels_encoder: 0.2029 (0.7268)  labels_decoder: 0.1987 (0.3883)  labels_encoder_unscaled: 0.2029 (0.7268)  labels_decoder_unscaled: 0.3974 (0.7767)  time: 0.1087  data: 0.0002  max mem: 3197
Test:  [ 550/1613]  eta: 0:01:56  loss: 0.6829 (1.1125)  labels_encoder: 0.4753 (0.7235)  labels_decoder: 0.2593 (0.3890)  labels_encoder_unscaled: 0.4753 (0.7235)  labels_decoder_unscaled: 0.5187 (0.7779)  time: 0.1136  data: 0.0002  max mem: 3197
Test:  [ 600/1613]  eta: 0:01:50  loss: 1.5960 (1.1582)  labels_encoder: 0.9129 (0.7626)  labels_decoder: 0.5141 (0.3956)  labels_encoder_unscaled: 0.9129 (0.7626)  labels_decoder_unscaled: 1.0283 (0.7912)  time: 0.1006  data: 0.0004  max mem: 3197
Test:  [ 650/1613]  eta: 0:01:44  loss: 0.8551 (1.1401)  labels_encoder: 0.4313 (0.7456)  labels_decoder: 0.4257 (0.3945)  labels_encoder_unscaled: 0.4313 (0.7456)  labels_decoder_unscaled: 0.8513 (0.7890)  time: 0.1063  data: 0.0003  max mem: 3197
Test:  [ 700/1613]  eta: 0:01:39  loss: 0.5942 (1.1202)  labels_encoder: 0.3052 (0.7312)  labels_decoder: 0.2795 (0.3890)  labels_encoder_unscaled: 0.3052 (0.7312)  labels_decoder_unscaled: 0.5591 (0.7780)  time: 0.1071  data: 0.0002  max mem: 3197
Test:  [ 750/1613]  eta: 0:01:33  loss: 0.8232 (1.1028)  labels_encoder: 0.5076 (0.7186)  labels_decoder: 0.3174 (0.3843)  labels_encoder_unscaled: 0.5076 (0.7186)  labels_decoder_unscaled: 0.6349 (0.7686)  time: 0.1026  data: 0.0002  max mem: 3197
Test:  [ 800/1613]  eta: 0:01:27  loss: 0.7407 (1.0960)  labels_encoder: 0.4278 (0.7142)  labels_decoder: 0.2966 (0.3818)  labels_encoder_unscaled: 0.4278 (0.7142)  labels_decoder_unscaled: 0.5931 (0.7635)  time: 0.1088  data: 0.0002  max mem: 3197
Test:  [ 850/1613]  eta: 0:01:22  loss: 1.6004 (1.1053)  labels_encoder: 1.1590 (0.7179)  labels_decoder: 0.7056 (0.3874)  labels_encoder_unscaled: 1.1590 (0.7179)  labels_decoder_unscaled: 1.4112 (0.7749)  time: 0.0976  data: 0.0002  max mem: 3197
Test:  [ 900/1613]  eta: 0:01:16  loss: 0.6721 (1.1236)  labels_encoder: 0.4162 (0.7304)  labels_decoder: 0.2701 (0.3933)  labels_encoder_unscaled: 0.4162 (0.7304)  labels_decoder_unscaled: 0.5402 (0.7865)  time: 0.1013  data: 0.0002  max mem: 3197
Test:  [ 950/1613]  eta: 0:01:11  loss: 1.2835 (1.1165)  labels_encoder: 0.8349 (0.7257)  labels_decoder: 0.4187 (0.3908)  labels_encoder_unscaled: 0.8349 (0.7257)  labels_decoder_unscaled: 0.8375 (0.7816)  time: 0.1109  data: 0.0002  max mem: 3197
Test:  [1000/1613]  eta: 0:01:05  loss: 0.5506 (1.1017)  labels_encoder: 0.3296 (0.7150)  labels_decoder: 0.2264 (0.3866)  labels_encoder_unscaled: 0.3296 (0.7150)  labels_decoder_unscaled: 0.4528 (0.7733)  time: 0.1096  data: 0.0002  max mem: 3197
Test:  [1050/1613]  eta: 0:01:00  loss: 0.8339 (1.0974)  labels_encoder: 0.5106 (0.7124)  labels_decoder: 0.3148 (0.3850)  labels_encoder_unscaled: 0.5106 (0.7124)  labels_decoder_unscaled: 0.6296 (0.7700)  time: 0.1026  data: 0.0002  max mem: 3197
Test:  [1100/1613]  eta: 0:00:54  loss: 0.7452 (1.1073)  labels_encoder: 0.5179 (0.7210)  labels_decoder: 0.3673 (0.3863)  labels_encoder_unscaled: 0.5179 (0.7210)  labels_decoder_unscaled: 0.7346 (0.7726)  time: 0.0943  data: 0.0002  max mem: 3197
Test:  [1150/1613]  eta: 0:00:49  loss: 0.5779 (1.0949)  labels_encoder: 0.3316 (0.7121)  labels_decoder: 0.2463 (0.3828)  labels_encoder_unscaled: 0.3316 (0.7121)  labels_decoder_unscaled: 0.4926 (0.7656)  time: 0.0989  data: 0.0002  max mem: 3197
Test:  [1200/1613]  eta: 0:00:44  loss: 0.4857 (1.1012)  labels_encoder: 0.2957 (0.7156)  labels_decoder: 0.2028 (0.3856)  labels_encoder_unscaled: 0.2957 (0.7156)  labels_decoder_unscaled: 0.4056 (0.7712)  time: 0.1073  data: 0.0002  max mem: 3197
Test:  [1250/1613]  eta: 0:00:38  loss: 0.4918 (1.1038)  labels_encoder: 0.2569 (0.7170)  labels_decoder: 0.2089 (0.3868)  labels_encoder_unscaled: 0.2569 (0.7170)  labels_decoder_unscaled: 0.4178 (0.7735)  time: 0.1127  data: 0.0002  max mem: 3197
Test:  [1300/1613]  eta: 0:00:33  loss: 0.9089 (1.0982)  labels_encoder: 0.6308 (0.7132)  labels_decoder: 0.3629 (0.3849)  labels_encoder_unscaled: 0.6308 (0.7132)  labels_decoder_unscaled: 0.7258 (0.7698)  time: 0.1001  data: 0.0007  max mem: 3197
Test:  [1350/1613]  eta: 0:00:27  loss: 0.9226 (1.1135)  labels_encoder: 0.5417 (0.7244)  labels_decoder: 0.3840 (0.3891)  labels_encoder_unscaled: 0.5417 (0.7244)  labels_decoder_unscaled: 0.7680 (0.7782)  time: 0.1002  data: 0.0002  max mem: 3197
Test:  [1400/1613]  eta: 0:00:22  loss: 1.0549 (1.1054)  labels_encoder: 0.6578 (0.7189)  labels_decoder: 0.4088 (0.3865)  labels_encoder_unscaled: 0.6578 (0.7189)  labels_decoder_unscaled: 0.8176 (0.7729)  time: 0.1021  data: 0.0002  max mem: 3197
Test:  [1450/1613]  eta: 0:00:17  loss: 0.7348 (1.1187)  labels_encoder: 0.3848 (0.7279)  labels_decoder: 0.3284 (0.3908)  labels_encoder_unscaled: 0.3848 (0.7279)  labels_decoder_unscaled: 0.6567 (0.7816)  time: 0.0978  data: 0.0002  max mem: 3197
Test:  [1500/1613]  eta: 0:00:11  loss: 0.8038 (1.1334)  labels_encoder: 0.5081 (0.7388)  labels_decoder: 0.2652 (0.3946)  labels_encoder_unscaled: 0.5081 (0.7388)  labels_decoder_unscaled: 0.5305 (0.7893)  time: 0.1024  data: 0.0004  max mem: 3197
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6157 (1.1303)  labels_encoder: 0.3856 (0.7369)  labels_decoder: 0.2384 (0.3933)  labels_encoder_unscaled: 0.3856 (0.7369)  labels_decoder_unscaled: 0.4768 (0.7867)  time: 0.1006  data: 0.0003  max mem: 3197
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8964 (1.1271)  labels_encoder: 0.5882 (0.7346)  labels_decoder: 0.4014 (0.3926)  labels_encoder_unscaled: 0.5882 (0.7346)  labels_decoder_unscaled: 0.8029 (0.7851)  time: 0.1059  data: 0.0002  max mem: 3197
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7197 (1.1255)  labels_encoder: 0.4366 (0.7338)  labels_decoder: 0.2831 (0.3917)  labels_encoder_unscaled: 0.4366 (0.7338)  labels_decoder_unscaled: 0.5662 (0.7835)  time: 0.0700  data: 0.0001  max mem: 3197
Test: Total time: 0:02:51 (0.1060 s / it)
Averaged stats: loss: 0.7197 (1.1255)  labels_encoder: 0.4366 (0.7338)  labels_decoder: 0.2831 (0.3917)  labels_encoder_unscaled: 0.4366 (0.7338)  labels_decoder_unscaled: 0.5662 (0.7835)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5729

dec_mAP all together: | 0.4560680755584852 |.
dec_mAP_pred | 0 : 0.5007129978193401 |.
dec_mAP_pred | 1 : 0.4925265357421841 |.
dec_mAP_pred | 2 : 0.48006222457520115 |.
dec_mAP_pred | 3 : 0.4660279531666993 |.
dec_mAP_pred | 4 : 0.4513315498332796 |.
dec_mAP_pred | 5 : 0.4368021413120931 |.
dec_mAP_pred | 6 : 0.4223156280557359 |.
dec_mAP_pred | 7 : 0.40926492622787586 |.
all decoder map: | 0.4574 |.
BaseballPitch: 0.1528
BasketballDunk: 0.7674
Billiards: 0.4627
CleanAndJerk: 0.7426
CliffDiving: 0.8095
CricketBowling: 0.4513
CricketShot: 0.2311
Diving: 0.6747
FrisbeeCatch: 0.2341
GolfSwing: 0.6105
HammerThrow: 0.8539
HighJump: 0.6395
JavelinThrow: 0.7012
LongJump: 0.7779
PoleVault: 0.8678
Shotput: 0.6849
SoccerPenalty: 0.2551
TennisSwing: 0.5682
ThrowDiscus: 0.5977
VolleyballSpiking: 0.3745
Training time 0:33:12
