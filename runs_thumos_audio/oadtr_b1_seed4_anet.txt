Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:4
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  66.183 M, 99.815% Params, 1.896 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 11.071% Params, 0.47 GMac, 24.773% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    6.295 M, 9.493% Params, 0.409 GMac, 21.570% MACs, 
    (net): Sequential(
      6.295 M, 9.493% Params, 0.409 GMac, 21.570% MACs, 
      (0): Residual(
        4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
        (fn): PreNormDrop(
          4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
            (qkv): Linear(3.146 M, 4.744% Params, 0.204 GMac, 10.783% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
        (fn): PreNorm(
          2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
            (net): Sequential(
              2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
              (0): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.068% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 79.148% Params, 1.017 GMac, 53.645% MACs, 
    (layers): ModuleList(
      52.48 M, 79.148% Params, 1.017 GMac, 53.645% MACs, 
      (0): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.034% Params, 0.0 GMac, 0.010% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 1896244268.0
Model params: 66306092
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1404]  eta: 1:38:51  lr: 0.000100  loss: 4.8444 (4.8444)  labels_encoder: 3.2901 (3.2901)  labels_decoder: 1.5543 (1.5543)  labels_encoder_unscaled: 3.2901 (3.2901)  labels_decoder_unscaled: 3.1087 (3.1087)  time: 4.2249  data: 3.5100  max mem: 1929
Epoch: [1]  [  50/1404]  eta: 0:05:43  lr: 0.000100  loss: 1.1325 (1.6338)  labels_encoder: 0.6978 (1.0585)  labels_decoder: 0.4170 (0.5753)  labels_encoder_unscaled: 0.6978 (1.0585)  labels_decoder_unscaled: 0.8339 (1.1506)  time: 0.1604  data: 0.0003  max mem: 2688
Epoch: [1]  [ 100/1404]  eta: 0:04:33  lr: 0.000100  loss: 0.7267 (1.2596)  labels_encoder: 0.4340 (0.8061)  labels_decoder: 0.2785 (0.4534)  labels_encoder_unscaled: 0.4340 (0.8061)  labels_decoder_unscaled: 0.5570 (0.9068)  time: 0.1526  data: 0.0004  max mem: 2688
Epoch: [1]  [ 150/1404]  eta: 0:04:00  lr: 0.000100  loss: 0.6675 (1.0763)  labels_encoder: 0.4071 (0.6859)  labels_decoder: 0.2563 (0.3903)  labels_encoder_unscaled: 0.4071 (0.6859)  labels_decoder_unscaled: 0.5127 (0.7807)  time: 0.1476  data: 0.0003  max mem: 2688
Epoch: [1]  [ 200/1404]  eta: 0:03:38  lr: 0.000100  loss: 0.6130 (0.9787)  labels_encoder: 0.3594 (0.6201)  labels_decoder: 0.2451 (0.3587)  labels_encoder_unscaled: 0.3594 (0.6201)  labels_decoder_unscaled: 0.4901 (0.7173)  time: 0.1482  data: 0.0003  max mem: 2688
Epoch: [1]  [ 250/1404]  eta: 0:03:22  lr: 0.000100  loss: 0.6349 (0.9111)  labels_encoder: 0.3807 (0.5744)  labels_decoder: 0.2359 (0.3367)  labels_encoder_unscaled: 0.3807 (0.5744)  labels_decoder_unscaled: 0.4718 (0.6733)  time: 0.1572  data: 0.0003  max mem: 2688
Epoch: [1]  [ 300/1404]  eta: 0:03:09  lr: 0.000100  loss: 0.5976 (0.8589)  labels_encoder: 0.3572 (0.5394)  labels_decoder: 0.2364 (0.3195)  labels_encoder_unscaled: 0.3572 (0.5394)  labels_decoder_unscaled: 0.4729 (0.6391)  time: 0.1481  data: 0.0003  max mem: 2688
Epoch: [1]  [ 350/1404]  eta: 0:02:59  lr: 0.000100  loss: 0.5773 (0.8156)  labels_encoder: 0.3241 (0.5101)  labels_decoder: 0.2294 (0.3055)  labels_encoder_unscaled: 0.3241 (0.5101)  labels_decoder_unscaled: 0.4588 (0.6110)  time: 0.1583  data: 0.0003  max mem: 2688
Epoch: [1]  [ 400/1404]  eta: 0:02:49  lr: 0.000100  loss: 0.4961 (0.7787)  labels_encoder: 0.2847 (0.4851)  labels_decoder: 0.1993 (0.2936)  labels_encoder_unscaled: 0.2847 (0.4851)  labels_decoder_unscaled: 0.3987 (0.5871)  time: 0.1714  data: 0.0003  max mem: 2688
Epoch: [1]  [ 450/1404]  eta: 0:02:39  lr: 0.000100  loss: 0.5051 (0.7492)  labels_encoder: 0.3022 (0.4657)  labels_decoder: 0.2042 (0.2835)  labels_encoder_unscaled: 0.3022 (0.4657)  labels_decoder_unscaled: 0.4084 (0.5671)  time: 0.1501  data: 0.0003  max mem: 2688
Epoch: [1]  [ 500/1404]  eta: 0:02:29  lr: 0.000100  loss: 0.5486 (0.7271)  labels_encoder: 0.3244 (0.4506)  labels_decoder: 0.2062 (0.2765)  labels_encoder_unscaled: 0.3244 (0.4506)  labels_decoder_unscaled: 0.4124 (0.5530)  time: 0.1566  data: 0.0003  max mem: 2688
Epoch: [1]  [ 550/1404]  eta: 0:02:20  lr: 0.000100  loss: 0.4708 (0.7053)  labels_encoder: 0.2601 (0.4358)  labels_decoder: 0.2041 (0.2694)  labels_encoder_unscaled: 0.2601 (0.4358)  labels_decoder_unscaled: 0.4082 (0.5389)  time: 0.1647  data: 0.0003  max mem: 2688
Epoch: [1]  [ 600/1404]  eta: 0:02:12  lr: 0.000100  loss: 0.4523 (0.6857)  labels_encoder: 0.2632 (0.4228)  labels_decoder: 0.1860 (0.2630)  labels_encoder_unscaled: 0.2632 (0.4228)  labels_decoder_unscaled: 0.3720 (0.5259)  time: 0.1612  data: 0.0003  max mem: 2688
Epoch: [1]  [ 650/1404]  eta: 0:02:03  lr: 0.000100  loss: 0.4539 (0.6679)  labels_encoder: 0.2597 (0.4108)  labels_decoder: 0.1968 (0.2571)  labels_encoder_unscaled: 0.2597 (0.4108)  labels_decoder_unscaled: 0.3936 (0.5141)  time: 0.1600  data: 0.0003  max mem: 2688
Epoch: [1]  [ 700/1404]  eta: 0:01:54  lr: 0.000100  loss: 0.4496 (0.6525)  labels_encoder: 0.2558 (0.4007)  labels_decoder: 0.1787 (0.2518)  labels_encoder_unscaled: 0.2558 (0.4007)  labels_decoder_unscaled: 0.3574 (0.5036)  time: 0.1532  data: 0.0003  max mem: 2688
Epoch: [1]  [ 750/1404]  eta: 0:01:45  lr: 0.000100  loss: 0.4557 (0.6399)  labels_encoder: 0.2672 (0.3923)  labels_decoder: 0.1843 (0.2476)  labels_encoder_unscaled: 0.2672 (0.3923)  labels_decoder_unscaled: 0.3685 (0.4952)  time: 0.1565  data: 0.0003  max mem: 2688
Epoch: [1]  [ 800/1404]  eta: 0:01:37  lr: 0.000100  loss: 0.4534 (0.6279)  labels_encoder: 0.2540 (0.3842)  labels_decoder: 0.1847 (0.2437)  labels_encoder_unscaled: 0.2540 (0.3842)  labels_decoder_unscaled: 0.3693 (0.4873)  time: 0.1531  data: 0.0003  max mem: 2688
Epoch: [1]  [ 850/1404]  eta: 0:01:28  lr: 0.000100  loss: 0.4434 (0.6166)  labels_encoder: 0.2399 (0.3768)  labels_decoder: 0.1699 (0.2398)  labels_encoder_unscaled: 0.2399 (0.3768)  labels_decoder_unscaled: 0.3398 (0.4795)  time: 0.1419  data: 0.0003  max mem: 2688
Epoch: [1]  [ 900/1404]  eta: 0:01:20  lr: 0.000100  loss: 0.4145 (0.6062)  labels_encoder: 0.2373 (0.3697)  labels_decoder: 0.1831 (0.2365)  labels_encoder_unscaled: 0.2373 (0.3697)  labels_decoder_unscaled: 0.3661 (0.4729)  time: 0.1477  data: 0.0003  max mem: 2688
Epoch: [1]  [ 950/1404]  eta: 0:01:11  lr: 0.000100  loss: 0.4520 (0.5969)  labels_encoder: 0.2501 (0.3636)  labels_decoder: 0.1903 (0.2334)  labels_encoder_unscaled: 0.2501 (0.3636)  labels_decoder_unscaled: 0.3805 (0.4668)  time: 0.1458  data: 0.0003  max mem: 2688
Epoch: [1]  [1000/1404]  eta: 0:01:03  lr: 0.000100  loss: 0.3977 (0.5876)  labels_encoder: 0.2175 (0.3571)  labels_decoder: 0.1714 (0.2305)  labels_encoder_unscaled: 0.2175 (0.3571)  labels_decoder_unscaled: 0.3428 (0.4610)  time: 0.1436  data: 0.0003  max mem: 2688
Epoch: [1]  [1050/1404]  eta: 0:00:55  lr: 0.000100  loss: 0.3866 (0.5785)  labels_encoder: 0.2164 (0.3509)  labels_decoder: 0.1662 (0.2276)  labels_encoder_unscaled: 0.2164 (0.3509)  labels_decoder_unscaled: 0.3324 (0.4551)  time: 0.1491  data: 0.0003  max mem: 2688
Epoch: [1]  [1100/1404]  eta: 0:00:47  lr: 0.000100  loss: 0.3758 (0.5710)  labels_encoder: 0.2215 (0.3460)  labels_decoder: 0.1636 (0.2251)  labels_encoder_unscaled: 0.2215 (0.3460)  labels_decoder_unscaled: 0.3272 (0.4501)  time: 0.1353  data: 0.0003  max mem: 2688
Epoch: [1]  [1150/1404]  eta: 0:00:39  lr: 0.000100  loss: 0.3676 (0.5626)  labels_encoder: 0.1936 (0.3401)  labels_decoder: 0.1612 (0.2225)  labels_encoder_unscaled: 0.1936 (0.3401)  labels_decoder_unscaled: 0.3223 (0.4450)  time: 0.1457  data: 0.0004  max mem: 2688
Epoch: [1]  [1200/1404]  eta: 0:00:31  lr: 0.000100  loss: 0.4041 (0.5567)  labels_encoder: 0.2279 (0.3363)  labels_decoder: 0.1729 (0.2204)  labels_encoder_unscaled: 0.2279 (0.3363)  labels_decoder_unscaled: 0.3458 (0.4408)  time: 0.1516  data: 0.0003  max mem: 2688
Epoch: [1]  [1250/1404]  eta: 0:00:24  lr: 0.000100  loss: 0.3984 (0.5501)  labels_encoder: 0.2348 (0.3320)  labels_decoder: 0.1606 (0.2181)  labels_encoder_unscaled: 0.2348 (0.3320)  labels_decoder_unscaled: 0.3211 (0.4362)  time: 0.1494  data: 0.0003  max mem: 2688
Epoch: [1]  [1300/1404]  eta: 0:00:16  lr: 0.000100  loss: 0.3729 (0.5432)  labels_encoder: 0.1918 (0.3274)  labels_decoder: 0.1526 (0.2159)  labels_encoder_unscaled: 0.1918 (0.3274)  labels_decoder_unscaled: 0.3052 (0.4317)  time: 0.1539  data: 0.0003  max mem: 2688
Epoch: [1]  [1350/1404]  eta: 0:00:08  lr: 0.000100  loss: 0.3994 (0.5380)  labels_encoder: 0.2236 (0.3237)  labels_decoder: 0.1757 (0.2143)  labels_encoder_unscaled: 0.2236 (0.3237)  labels_decoder_unscaled: 0.3514 (0.4286)  time: 0.1518  data: 0.0003  max mem: 2688
Epoch: [1]  [1400/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3718 (0.5320)  labels_encoder: 0.2151 (0.3197)  labels_decoder: 0.1647 (0.2123)  labels_encoder_unscaled: 0.2151 (0.3197)  labels_decoder_unscaled: 0.3294 (0.4247)  time: 0.1319  data: 0.0004  max mem: 2688
Epoch: [1]  [1403/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3718 (0.5316)  labels_encoder: 0.2151 (0.3194)  labels_decoder: 0.1654 (0.2122)  labels_encoder_unscaled: 0.2151 (0.3194)  labels_decoder_unscaled: 0.3308 (0.4245)  time: 0.1223  data: 0.0004  max mem: 2688
Epoch: [1] Total time: 0:03:38 (0.1558 s / it)
Averaged stats: lr: 0.000100  loss: 0.3718 (0.5316)  labels_encoder: 0.2151 (0.3194)  labels_decoder: 0.1654 (0.2122)  labels_encoder_unscaled: 0.2151 (0.3194)  labels_decoder_unscaled: 0.3308 (0.4245)
Test:  [   0/1613]  eta: 1:16:33  loss: 0.1449 (0.1449)  labels_encoder: 0.0491 (0.0491)  labels_decoder: 0.0958 (0.0958)  labels_encoder_unscaled: 0.0491 (0.0491)  labels_decoder_unscaled: 0.1916 (0.1916)  time: 2.8478  data: 2.7896  max mem: 2688
Test:  [  50/1613]  eta: 0:04:20  loss: 0.5742 (0.8824)  labels_encoder: 0.2967 (0.5428)  labels_decoder: 0.2362 (0.3396)  labels_encoder_unscaled: 0.2967 (0.5428)  labels_decoder_unscaled: 0.4724 (0.6792)  time: 0.1023  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:22  loss: 0.2900 (0.7709)  labels_encoder: 0.1591 (0.4772)  labels_decoder: 0.1389 (0.2936)  labels_encoder_unscaled: 0.1591 (0.4772)  labels_decoder_unscaled: 0.2778 (0.5873)  time: 0.1009  data: 0.0002  max mem: 2688
Test:  [ 150/1613]  eta: 0:03:03  loss: 1.0188 (0.8055)  labels_encoder: 0.6789 (0.5103)  labels_decoder: 0.3546 (0.2952)  labels_encoder_unscaled: 0.6789 (0.5103)  labels_decoder_unscaled: 0.7093 (0.5904)  time: 0.1067  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:48  loss: 1.5203 (0.9528)  labels_encoder: 1.1551 (0.6293)  labels_decoder: 0.4006 (0.3235)  labels_encoder_unscaled: 1.1551 (0.6293)  labels_decoder_unscaled: 0.8013 (0.6470)  time: 0.1046  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:36  loss: 0.4065 (1.0004)  labels_encoder: 0.2209 (0.6609)  labels_decoder: 0.1962 (0.3395)  labels_encoder_unscaled: 0.2209 (0.6609)  labels_decoder_unscaled: 0.3924 (0.6790)  time: 0.0957  data: 0.0004  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:27  loss: 0.5229 (0.9903)  labels_encoder: 0.3159 (0.6533)  labels_decoder: 0.2089 (0.3370)  labels_encoder_unscaled: 0.3159 (0.6533)  labels_decoder_unscaled: 0.4177 (0.6740)  time: 0.1087  data: 0.0002  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:18  loss: 0.9825 (0.9887)  labels_encoder: 0.5575 (0.6433)  labels_decoder: 0.3861 (0.3453)  labels_encoder_unscaled: 0.5575 (0.6433)  labels_decoder_unscaled: 0.7722 (0.6906)  time: 0.0937  data: 0.0028  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:11  loss: 0.8211 (1.0721)  labels_encoder: 0.4468 (0.7001)  labels_decoder: 0.3505 (0.3720)  labels_encoder_unscaled: 0.4468 (0.7001)  labels_decoder_unscaled: 0.7010 (0.7439)  time: 0.0971  data: 0.0002  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:04  loss: 1.2879 (1.1524)  labels_encoder: 0.7440 (0.7539)  labels_decoder: 0.5224 (0.3985)  labels_encoder_unscaled: 0.7440 (0.7539)  labels_decoder_unscaled: 1.0448 (0.7971)  time: 0.0918  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:58  loss: 0.3654 (1.0948)  labels_encoder: 0.1443 (0.7141)  labels_decoder: 0.1618 (0.3807)  labels_encoder_unscaled: 0.1443 (0.7141)  labels_decoder_unscaled: 0.3235 (0.7614)  time: 0.0969  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:52  loss: 0.9252 (1.0906)  labels_encoder: 0.4741 (0.7093)  labels_decoder: 0.3637 (0.3813)  labels_encoder_unscaled: 0.4741 (0.7093)  labels_decoder_unscaled: 0.7273 (0.7626)  time: 0.0999  data: 0.0002  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:46  loss: 1.2916 (1.1266)  labels_encoder: 0.6528 (0.7390)  labels_decoder: 0.3940 (0.3876)  labels_encoder_unscaled: 0.6528 (0.7390)  labels_decoder_unscaled: 0.7879 (0.7752)  time: 0.0981  data: 0.0002  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:41  loss: 0.9552 (1.1122)  labels_encoder: 0.6420 (0.7255)  labels_decoder: 0.4087 (0.3867)  labels_encoder_unscaled: 0.6420 (0.7255)  labels_decoder_unscaled: 0.8174 (0.7734)  time: 0.1052  data: 0.0002  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:35  loss: 0.5316 (1.0903)  labels_encoder: 0.3415 (0.7097)  labels_decoder: 0.2438 (0.3806)  labels_encoder_unscaled: 0.3415 (0.7097)  labels_decoder_unscaled: 0.4877 (0.7611)  time: 0.0904  data: 0.0002  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:29  loss: 0.8181 (1.0802)  labels_encoder: 0.4876 (0.7027)  labels_decoder: 0.2708 (0.3776)  labels_encoder_unscaled: 0.4876 (0.7027)  labels_decoder_unscaled: 0.5417 (0.7551)  time: 0.0932  data: 0.0002  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:24  loss: 0.6062 (1.0790)  labels_encoder: 0.4217 (0.7032)  labels_decoder: 0.2066 (0.3758)  labels_encoder_unscaled: 0.4217 (0.7032)  labels_decoder_unscaled: 0.4131 (0.7517)  time: 0.1010  data: 0.0097  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:19  loss: 1.6455 (1.0928)  labels_encoder: 1.1288 (0.7121)  labels_decoder: 0.5939 (0.3807)  labels_encoder_unscaled: 1.1288 (0.7121)  labels_decoder_unscaled: 1.1879 (0.7614)  time: 0.1024  data: 0.0106  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:13  loss: 0.5729 (1.1048)  labels_encoder: 0.3265 (0.7208)  labels_decoder: 0.2775 (0.3840)  labels_encoder_unscaled: 0.3265 (0.7208)  labels_decoder_unscaled: 0.5550 (0.7680)  time: 0.1087  data: 0.0002  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:08  loss: 1.8615 (1.1151)  labels_encoder: 1.2304 (0.7295)  labels_decoder: 0.4900 (0.3857)  labels_encoder_unscaled: 1.2304 (0.7295)  labels_decoder_unscaled: 0.9800 (0.7713)  time: 0.0958  data: 0.0002  max mem: 2688
Test:  [1000/1613]  eta: 0:01:03  loss: 0.5311 (1.0973)  labels_encoder: 0.2793 (0.7160)  labels_decoder: 0.2336 (0.3813)  labels_encoder_unscaled: 0.2793 (0.7160)  labels_decoder_unscaled: 0.4672 (0.7626)  time: 0.1069  data: 0.0005  max mem: 2688
Test:  [1050/1613]  eta: 0:00:58  loss: 1.0372 (1.0952)  labels_encoder: 0.6697 (0.7150)  labels_decoder: 0.3614 (0.3802)  labels_encoder_unscaled: 0.6697 (0.7150)  labels_decoder_unscaled: 0.7228 (0.7605)  time: 0.1301  data: 0.0048  max mem: 2688
Test:  [1100/1613]  eta: 0:00:53  loss: 0.4218 (1.0787)  labels_encoder: 0.2830 (0.7042)  labels_decoder: 0.1642 (0.3744)  labels_encoder_unscaled: 0.2830 (0.7042)  labels_decoder_unscaled: 0.3284 (0.7489)  time: 0.0969  data: 0.0002  max mem: 2688
Test:  [1150/1613]  eta: 0:00:47  loss: 0.4924 (1.0647)  labels_encoder: 0.2872 (0.6943)  labels_decoder: 0.1809 (0.3703)  labels_encoder_unscaled: 0.2872 (0.6943)  labels_decoder_unscaled: 0.3618 (0.7406)  time: 0.1014  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:42  loss: 0.6425 (1.0707)  labels_encoder: 0.3637 (0.6982)  labels_decoder: 0.2883 (0.3725)  labels_encoder_unscaled: 0.3637 (0.6982)  labels_decoder_unscaled: 0.5767 (0.7451)  time: 0.1057  data: 0.0032  max mem: 2688
Test:  [1250/1613]  eta: 0:00:37  loss: 0.4173 (1.0712)  labels_encoder: 0.2599 (0.6978)  labels_decoder: 0.1759 (0.3735)  labels_encoder_unscaled: 0.2599 (0.6978)  labels_decoder_unscaled: 0.3517 (0.7469)  time: 0.1014  data: 0.0053  max mem: 2688
Test:  [1300/1613]  eta: 0:00:32  loss: 0.5242 (1.0615)  labels_encoder: 0.3411 (0.6908)  labels_decoder: 0.2153 (0.3707)  labels_encoder_unscaled: 0.3411 (0.6908)  labels_decoder_unscaled: 0.4306 (0.7414)  time: 0.1089  data: 0.0026  max mem: 2688
Test:  [1350/1613]  eta: 0:00:27  loss: 0.8745 (1.0659)  labels_encoder: 0.5775 (0.6939)  labels_decoder: 0.2923 (0.3720)  labels_encoder_unscaled: 0.5775 (0.6939)  labels_decoder_unscaled: 0.5846 (0.7439)  time: 0.1045  data: 0.0088  max mem: 2688
Test:  [1400/1613]  eta: 0:00:21  loss: 1.2150 (1.0631)  labels_encoder: 0.7407 (0.6913)  labels_decoder: 0.4169 (0.3718)  labels_encoder_unscaled: 0.7407 (0.6913)  labels_decoder_unscaled: 0.8337 (0.7435)  time: 0.1073  data: 0.0073  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.5434 (1.0707)  labels_encoder: 0.3225 (0.6963)  labels_decoder: 0.2862 (0.3745)  labels_encoder_unscaled: 0.3225 (0.6963)  labels_decoder_unscaled: 0.5724 (0.7489)  time: 0.0984  data: 0.0002  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.5762 (1.0728)  labels_encoder: 0.3420 (0.6983)  labels_decoder: 0.2271 (0.3744)  labels_encoder_unscaled: 0.3420 (0.6983)  labels_decoder_unscaled: 0.4542 (0.7489)  time: 0.1019  data: 0.0002  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.8187 (1.0686)  labels_encoder: 0.5347 (0.6961)  labels_decoder: 0.2678 (0.3724)  labels_encoder_unscaled: 0.5347 (0.6961)  labels_decoder_unscaled: 0.5355 (0.7448)  time: 0.0864  data: 0.0002  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9330 (1.0684)  labels_encoder: 0.6042 (0.6963)  labels_decoder: 0.3288 (0.3721)  labels_encoder_unscaled: 0.6042 (0.6963)  labels_decoder_unscaled: 0.6577 (0.7442)  time: 0.1004  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6910 (1.0674)  labels_encoder: 0.4070 (0.6961)  labels_decoder: 0.2412 (0.3712)  labels_encoder_unscaled: 0.4070 (0.6961)  labels_decoder_unscaled: 0.4823 (0.7425)  time: 0.0858  data: 0.0001  max mem: 2688
Test: Total time: 0:02:46 (0.1031 s / it)
Averaged stats: loss: 0.6910 (1.0674)  labels_encoder: 0.4070 (0.6961)  labels_decoder: 0.2412 (0.3712)  labels_encoder_unscaled: 0.4070 (0.6961)  labels_decoder_unscaled: 0.4823 (0.7425)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.5721

dec_mAP all together: | 0.45933187691784855 |.
dec_mAP_pred | 0 : 0.5153797010431351 |.
dec_mAP_pred | 1 : 0.503669586198028 |.
dec_mAP_pred | 2 : 0.4869268458421335 |.
dec_mAP_pred | 3 : 0.46980457239504886 |.
dec_mAP_pred | 4 : 0.4526262795155322 |.
dec_mAP_pred | 5 : 0.4364372228846645 |.
dec_mAP_pred | 6 : 0.42083854256595643 |.
dec_mAP_pred | 7 : 0.4064912238916879 |.
all decoder map: | 0.4615 |.
BaseballPitch: 0.1228
BasketballDunk: 0.7419
Billiards: 0.4423
CleanAndJerk: 0.7498
CliffDiving: 0.8364
CricketBowling: 0.4376
CricketShot: 0.2320
Diving: 0.6852
FrisbeeCatch: 0.2328
GolfSwing: 0.5656
HammerThrow: 0.8502
HighJump: 0.6686
JavelinThrow: 0.7373
LongJump: 0.8015
PoleVault: 0.8831
Shotput: 0.6842
SoccerPenalty: 0.2896
TennisSwing: 0.5852
ThrowDiscus: 0.5631
VolleyballSpiking: 0.3334
Epoch: [2]  [   0/1404]  eta: 1:21:32  lr: 0.000010  loss: 0.4314 (0.4314)  labels_encoder: 0.2651 (0.2651)  labels_decoder: 0.1663 (0.1663)  labels_encoder_unscaled: 0.2651 (0.2651)  labels_decoder_unscaled: 0.3326 (0.3326)  time: 3.4849  data: 3.2651  max mem: 2688
Epoch: [2]  [  50/1404]  eta: 0:05:10  lr: 0.000010  loss: 0.3215 (0.3292)  labels_encoder: 0.1768 (0.1851)  labels_decoder: 0.1578 (0.1441)  labels_encoder_unscaled: 0.1768 (0.1851)  labels_decoder_unscaled: 0.3156 (0.2882)  time: 0.1574  data: 0.0003  max mem: 2688
Epoch: [2]  [ 100/1404]  eta: 0:04:09  lr: 0.000010  loss: 0.2851 (0.3125)  labels_encoder: 0.1467 (0.1723)  labels_decoder: 0.1322 (0.1401)  labels_encoder_unscaled: 0.1467 (0.1723)  labels_decoder_unscaled: 0.2645 (0.2802)  time: 0.1604  data: 0.0003  max mem: 2688
Epoch: [2]  [ 150/1404]  eta: 0:03:43  lr: 0.000010  loss: 0.2650 (0.3041)  labels_encoder: 0.1486 (0.1666)  labels_decoder: 0.1202 (0.1374)  labels_encoder_unscaled: 0.1486 (0.1666)  labels_decoder_unscaled: 0.2403 (0.2748)  time: 0.1583  data: 0.0003  max mem: 2688
Epoch: [2]  [ 200/1404]  eta: 0:03:28  lr: 0.000010  loss: 0.3036 (0.3011)  labels_encoder: 0.1634 (0.1651)  labels_decoder: 0.1366 (0.1360)  labels_encoder_unscaled: 0.1634 (0.1651)  labels_decoder_unscaled: 0.2733 (0.2720)  time: 0.1426  data: 0.0003  max mem: 2688
Epoch: [2]  [ 250/1404]  eta: 0:03:14  lr: 0.000010  loss: 0.2433 (0.2947)  labels_encoder: 0.1184 (0.1607)  labels_decoder: 0.1159 (0.1340)  labels_encoder_unscaled: 0.1184 (0.1607)  labels_decoder_unscaled: 0.2318 (0.2680)  time: 0.1452  data: 0.0003  max mem: 2688
Epoch: [2]  [ 300/1404]  eta: 0:03:03  lr: 0.000010  loss: 0.2785 (0.2938)  labels_encoder: 0.1532 (0.1599)  labels_decoder: 0.1267 (0.1339)  labels_encoder_unscaled: 0.1532 (0.1599)  labels_decoder_unscaled: 0.2534 (0.2678)  time: 0.1513  data: 0.0003  max mem: 2688
Epoch: [2]  [ 350/1404]  eta: 0:02:53  lr: 0.000010  loss: 0.2690 (0.2901)  labels_encoder: 0.1433 (0.1572)  labels_decoder: 0.1319 (0.1329)  labels_encoder_unscaled: 0.1433 (0.1572)  labels_decoder_unscaled: 0.2639 (0.2657)  time: 0.1515  data: 0.0003  max mem: 2688
Epoch: [2]  [ 400/1404]  eta: 0:02:44  lr: 0.000010  loss: 0.2671 (0.2879)  labels_encoder: 0.1297 (0.1556)  labels_decoder: 0.1276 (0.1324)  labels_encoder_unscaled: 0.1297 (0.1556)  labels_decoder_unscaled: 0.2552 (0.2647)  time: 0.1558  data: 0.0003  max mem: 2688
Epoch: [2]  [ 450/1404]  eta: 0:02:34  lr: 0.000010  loss: 0.2557 (0.2858)  labels_encoder: 0.1422 (0.1544)  labels_decoder: 0.1194 (0.1314)  labels_encoder_unscaled: 0.1422 (0.1544)  labels_decoder_unscaled: 0.2388 (0.2628)  time: 0.1555  data: 0.0003  max mem: 2688
Epoch: [2]  [ 500/1404]  eta: 0:02:26  lr: 0.000010  loss: 0.2573 (0.2840)  labels_encoder: 0.1384 (0.1529)  labels_decoder: 0.1298 (0.1311)  labels_encoder_unscaled: 0.1384 (0.1529)  labels_decoder_unscaled: 0.2596 (0.2622)  time: 0.1527  data: 0.0003  max mem: 2688
Epoch: [2]  [ 550/1404]  eta: 0:02:17  lr: 0.000010  loss: 0.2795 (0.2829)  labels_encoder: 0.1473 (0.1524)  labels_decoder: 0.1186 (0.1305)  labels_encoder_unscaled: 0.1473 (0.1524)  labels_decoder_unscaled: 0.2372 (0.2610)  time: 0.1491  data: 0.0020  max mem: 2688
Epoch: [2]  [ 600/1404]  eta: 0:02:09  lr: 0.000010  loss: 0.2906 (0.2826)  labels_encoder: 0.1694 (0.1526)  labels_decoder: 0.1227 (0.1300)  labels_encoder_unscaled: 0.1694 (0.1526)  labels_decoder_unscaled: 0.2455 (0.2599)  time: 0.1632  data: 0.0003  max mem: 2688
Epoch: [2]  [ 650/1404]  eta: 0:02:00  lr: 0.000010  loss: 0.2682 (0.2817)  labels_encoder: 0.1420 (0.1522)  labels_decoder: 0.1223 (0.1295)  labels_encoder_unscaled: 0.1420 (0.1522)  labels_decoder_unscaled: 0.2447 (0.2590)  time: 0.1537  data: 0.0003  max mem: 2688
Epoch: [2]  [ 700/1404]  eta: 0:01:52  lr: 0.000010  loss: 0.2525 (0.2800)  labels_encoder: 0.1303 (0.1511)  labels_decoder: 0.1171 (0.1290)  labels_encoder_unscaled: 0.1303 (0.1511)  labels_decoder_unscaled: 0.2341 (0.2579)  time: 0.1660  data: 0.0003  max mem: 2688
Epoch: [2]  [ 750/1404]  eta: 0:01:44  lr: 0.000010  loss: 0.2638 (0.2789)  labels_encoder: 0.1442 (0.1506)  labels_decoder: 0.1172 (0.1284)  labels_encoder_unscaled: 0.1442 (0.1506)  labels_decoder_unscaled: 0.2344 (0.2567)  time: 0.1521  data: 0.0032  max mem: 2688
Epoch: [2]  [ 800/1404]  eta: 0:01:36  lr: 0.000010  loss: 0.2644 (0.2782)  labels_encoder: 0.1435 (0.1501)  labels_decoder: 0.1251 (0.1281)  labels_encoder_unscaled: 0.1435 (0.1501)  labels_decoder_unscaled: 0.2503 (0.2563)  time: 0.1581  data: 0.0003  max mem: 2688
Epoch: [2]  [ 850/1404]  eta: 0:01:28  lr: 0.000010  loss: 0.2560 (0.2776)  labels_encoder: 0.1333 (0.1495)  labels_decoder: 0.1289 (0.1281)  labels_encoder_unscaled: 0.1333 (0.1495)  labels_decoder_unscaled: 0.2579 (0.2561)  time: 0.1564  data: 0.0003  max mem: 2688
Epoch: [2]  [ 900/1404]  eta: 0:01:19  lr: 0.000010  loss: 0.2551 (0.2766)  labels_encoder: 0.1269 (0.1489)  labels_decoder: 0.1198 (0.1278)  labels_encoder_unscaled: 0.1269 (0.1489)  labels_decoder_unscaled: 0.2395 (0.2555)  time: 0.1467  data: 0.0003  max mem: 2688
Epoch: [2]  [ 950/1404]  eta: 0:01:12  lr: 0.000010  loss: 0.2577 (0.2754)  labels_encoder: 0.1363 (0.1480)  labels_decoder: 0.1159 (0.1273)  labels_encoder_unscaled: 0.1363 (0.1480)  labels_decoder_unscaled: 0.2318 (0.2546)  time: 0.1590  data: 0.0003  max mem: 2688
Epoch: [2]  [1000/1404]  eta: 0:01:04  lr: 0.000010  loss: 0.2418 (0.2750)  labels_encoder: 0.1296 (0.1479)  labels_decoder: 0.1163 (0.1271)  labels_encoder_unscaled: 0.1296 (0.1479)  labels_decoder_unscaled: 0.2326 (0.2542)  time: 0.1670  data: 0.0003  max mem: 2688
Epoch: [2]  [1050/1404]  eta: 0:00:56  lr: 0.000010  loss: 0.2470 (0.2743)  labels_encoder: 0.1313 (0.1475)  labels_decoder: 0.1208 (0.1268)  labels_encoder_unscaled: 0.1313 (0.1475)  labels_decoder_unscaled: 0.2416 (0.2537)  time: 0.1688  data: 0.0003  max mem: 2688
Epoch: [2]  [1100/1404]  eta: 0:00:48  lr: 0.000010  loss: 0.2338 (0.2733)  labels_encoder: 0.1246 (0.1467)  labels_decoder: 0.1103 (0.1265)  labels_encoder_unscaled: 0.1246 (0.1467)  labels_decoder_unscaled: 0.2207 (0.2531)  time: 0.1603  data: 0.0003  max mem: 2688
Epoch: [2]  [1150/1404]  eta: 0:00:40  lr: 0.000010  loss: 0.2177 (0.2724)  labels_encoder: 0.1096 (0.1462)  labels_decoder: 0.1147 (0.1262)  labels_encoder_unscaled: 0.1096 (0.1462)  labels_decoder_unscaled: 0.2294 (0.2524)  time: 0.1555  data: 0.0003  max mem: 2688
Epoch: [2]  [1200/1404]  eta: 0:00:32  lr: 0.000010  loss: 0.2542 (0.2721)  labels_encoder: 0.1357 (0.1461)  labels_decoder: 0.1202 (0.1260)  labels_encoder_unscaled: 0.1357 (0.1461)  labels_decoder_unscaled: 0.2403 (0.2521)  time: 0.1426  data: 0.0003  max mem: 2688
Epoch: [2]  [1250/1404]  eta: 0:00:24  lr: 0.000010  loss: 0.2397 (0.2716)  labels_encoder: 0.1365 (0.1458)  labels_decoder: 0.1078 (0.1258)  labels_encoder_unscaled: 0.1365 (0.1458)  labels_decoder_unscaled: 0.2155 (0.2516)  time: 0.1519  data: 0.0003  max mem: 2688
Epoch: [2]  [1300/1404]  eta: 0:00:16  lr: 0.000010  loss: 0.2364 (0.2708)  labels_encoder: 0.1169 (0.1452)  labels_decoder: 0.1119 (0.1255)  labels_encoder_unscaled: 0.1169 (0.1452)  labels_decoder_unscaled: 0.2238 (0.2511)  time: 0.1504  data: 0.0003  max mem: 2688
Epoch: [2]  [1350/1404]  eta: 0:00:08  lr: 0.000010  loss: 0.2742 (0.2701)  labels_encoder: 0.1411 (0.1448)  labels_decoder: 0.1241 (0.1253)  labels_encoder_unscaled: 0.1411 (0.1448)  labels_decoder_unscaled: 0.2482 (0.2506)  time: 0.1432  data: 0.0003  max mem: 2688
Epoch: [2]  [1400/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2403 (0.2691)  labels_encoder: 0.1125 (0.1441)  labels_decoder: 0.1121 (0.1250)  labels_encoder_unscaled: 0.1125 (0.1441)  labels_decoder_unscaled: 0.2241 (0.2501)  time: 0.1185  data: 0.0004  max mem: 2688
Epoch: [2]  [1403/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2392 (0.2691)  labels_encoder: 0.1125 (0.1441)  labels_decoder: 0.1066 (0.1250)  labels_encoder_unscaled: 0.1125 (0.1441)  labels_decoder_unscaled: 0.2132 (0.2500)  time: 0.1142  data: 0.0003  max mem: 2688
Epoch: [2] Total time: 0:03:40 (0.1570 s / it)
Averaged stats: lr: 0.000010  loss: 0.2392 (0.2691)  labels_encoder: 0.1125 (0.1441)  labels_decoder: 0.1066 (0.1250)  labels_encoder_unscaled: 0.1125 (0.1441)  labels_decoder_unscaled: 0.2132 (0.2500)
Test:  [   0/1613]  eta: 1:12:24  loss: 0.6513 (0.6513)  labels_encoder: 0.2779 (0.2779)  labels_decoder: 0.3734 (0.3734)  labels_encoder_unscaled: 0.2779 (0.2779)  labels_decoder_unscaled: 0.7468 (0.7468)  time: 2.6933  data: 2.5424  max mem: 2688
Test:  [  50/1613]  eta: 0:04:02  loss: 0.4710 (0.8721)  labels_encoder: 0.2436 (0.5448)  labels_decoder: 0.2077 (0.3273)  labels_encoder_unscaled: 0.2436 (0.5448)  labels_decoder_unscaled: 0.4153 (0.6545)  time: 0.0980  data: 0.0204  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:11  loss: 0.2574 (0.7355)  labels_encoder: 0.1553 (0.4684)  labels_decoder: 0.1021 (0.2672)  labels_encoder_unscaled: 0.1553 (0.4684)  labels_decoder_unscaled: 0.2042 (0.5343)  time: 0.1102  data: 0.0479  max mem: 2688
Test:  [ 150/1613]  eta: 0:02:45  loss: 1.0570 (0.7820)  labels_encoder: 0.6405 (0.5015)  labels_decoder: 0.3235 (0.2805)  labels_encoder_unscaled: 0.6405 (0.5015)  labels_decoder_unscaled: 0.6469 (0.5610)  time: 0.0865  data: 0.0177  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:33  loss: 1.1591 (0.9201)  labels_encoder: 0.7464 (0.5962)  labels_decoder: 0.4177 (0.3239)  labels_encoder_unscaled: 0.7464 (0.5962)  labels_decoder_unscaled: 0.8354 (0.6478)  time: 0.0907  data: 0.0224  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:23  loss: 0.4823 (0.9646)  labels_encoder: 0.3222 (0.6241)  labels_decoder: 0.1860 (0.3405)  labels_encoder_unscaled: 0.3222 (0.6241)  labels_decoder_unscaled: 0.3719 (0.6810)  time: 0.0972  data: 0.0317  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:16  loss: 0.6897 (0.9886)  labels_encoder: 0.4176 (0.6389)  labels_decoder: 0.2676 (0.3497)  labels_encoder_unscaled: 0.4176 (0.6389)  labels_decoder_unscaled: 0.5352 (0.6994)  time: 0.0911  data: 0.0089  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:10  loss: 1.0639 (0.9842)  labels_encoder: 0.6304 (0.6292)  labels_decoder: 0.4423 (0.3550)  labels_encoder_unscaled: 0.6304 (0.6292)  labels_decoder_unscaled: 0.8847 (0.7101)  time: 0.0892  data: 0.0179  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:04  loss: 0.7663 (1.0833)  labels_encoder: 0.4253 (0.6991)  labels_decoder: 0.3406 (0.3842)  labels_encoder_unscaled: 0.4253 (0.6991)  labels_decoder_unscaled: 0.6811 (0.7684)  time: 0.0974  data: 0.0097  max mem: 2688
Test:  [ 450/1613]  eta: 0:01:57  loss: 1.1303 (1.1653)  labels_encoder: 0.7168 (0.7533)  labels_decoder: 0.3340 (0.4120)  labels_encoder_unscaled: 0.7168 (0.7533)  labels_decoder_unscaled: 0.6679 (0.8240)  time: 0.0931  data: 0.0107  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:51  loss: 0.3484 (1.1132)  labels_encoder: 0.1877 (0.7181)  labels_decoder: 0.1898 (0.3952)  labels_encoder_unscaled: 0.1877 (0.7181)  labels_decoder_unscaled: 0.3795 (0.7903)  time: 0.0940  data: 0.0161  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:46  loss: 0.5286 (1.0993)  labels_encoder: 0.3346 (0.7081)  labels_decoder: 0.2582 (0.3912)  labels_encoder_unscaled: 0.3346 (0.7081)  labels_decoder_unscaled: 0.5164 (0.7824)  time: 0.0946  data: 0.0080  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:41  loss: 1.3003 (1.1527)  labels_encoder: 0.8420 (0.7492)  labels_decoder: 0.5570 (0.4034)  labels_encoder_unscaled: 0.8420 (0.7492)  labels_decoder_unscaled: 1.1139 (0.8069)  time: 0.0933  data: 0.0185  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:36  loss: 0.9624 (1.1344)  labels_encoder: 0.5483 (0.7323)  labels_decoder: 0.4117 (0.4021)  labels_encoder_unscaled: 0.5483 (0.7323)  labels_decoder_unscaled: 0.8235 (0.8042)  time: 0.0962  data: 0.0335  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:31  loss: 0.5496 (1.1085)  labels_encoder: 0.3110 (0.7145)  labels_decoder: 0.2386 (0.3940)  labels_encoder_unscaled: 0.3110 (0.7145)  labels_decoder_unscaled: 0.4773 (0.7880)  time: 0.0969  data: 0.0207  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:25  loss: 0.8984 (1.0933)  labels_encoder: 0.5473 (0.7049)  labels_decoder: 0.2872 (0.3884)  labels_encoder_unscaled: 0.5473 (0.7049)  labels_decoder_unscaled: 0.5744 (0.7769)  time: 0.0950  data: 0.0002  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:21  loss: 0.8561 (1.0929)  labels_encoder: 0.5221 (0.7051)  labels_decoder: 0.3399 (0.3878)  labels_encoder_unscaled: 0.5221 (0.7051)  labels_decoder_unscaled: 0.6798 (0.7755)  time: 0.0993  data: 0.0002  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:16  loss: 1.1474 (1.0946)  labels_encoder: 0.7113 (0.7039)  labels_decoder: 0.4638 (0.3907)  labels_encoder_unscaled: 0.7113 (0.7039)  labels_decoder_unscaled: 0.9277 (0.7813)  time: 0.1036  data: 0.0002  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:11  loss: 0.5707 (1.1154)  labels_encoder: 0.3205 (0.7193)  labels_decoder: 0.2714 (0.3961)  labels_encoder_unscaled: 0.3205 (0.7193)  labels_decoder_unscaled: 0.5429 (0.7923)  time: 0.0956  data: 0.0002  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:06  loss: 1.1449 (1.1094)  labels_encoder: 0.8288 (0.7166)  labels_decoder: 0.3766 (0.3928)  labels_encoder_unscaled: 0.8288 (0.7166)  labels_decoder_unscaled: 0.7531 (0.7857)  time: 0.1005  data: 0.0002  max mem: 2688
Test:  [1000/1613]  eta: 0:01:01  loss: 0.5541 (1.0943)  labels_encoder: 0.3071 (0.7057)  labels_decoder: 0.2375 (0.3886)  labels_encoder_unscaled: 0.3071 (0.7057)  labels_decoder_unscaled: 0.4750 (0.7772)  time: 0.1043  data: 0.0002  max mem: 2688
Test:  [1050/1613]  eta: 0:00:56  loss: 0.9265 (1.0857)  labels_encoder: 0.5695 (0.6999)  labels_decoder: 0.3287 (0.3858)  labels_encoder_unscaled: 0.5695 (0.6999)  labels_decoder_unscaled: 0.6575 (0.7716)  time: 0.1005  data: 0.0002  max mem: 2688
Test:  [1100/1613]  eta: 0:00:51  loss: 0.6012 (1.0850)  labels_encoder: 0.3513 (0.7008)  labels_decoder: 0.2915 (0.3842)  labels_encoder_unscaled: 0.3513 (0.7008)  labels_decoder_unscaled: 0.5831 (0.7684)  time: 0.1073  data: 0.0002  max mem: 2688
Test:  [1150/1613]  eta: 0:00:46  loss: 0.5321 (1.0719)  labels_encoder: 0.3264 (0.6917)  labels_decoder: 0.2324 (0.3802)  labels_encoder_unscaled: 0.3264 (0.6917)  labels_decoder_unscaled: 0.4648 (0.7605)  time: 0.0991  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:41  loss: 0.6088 (1.0766)  labels_encoder: 0.3686 (0.6944)  labels_decoder: 0.2616 (0.3822)  labels_encoder_unscaled: 0.3686 (0.6944)  labels_decoder_unscaled: 0.5232 (0.7644)  time: 0.1019  data: 0.0002  max mem: 2688
Test:  [1250/1613]  eta: 0:00:36  loss: 0.4480 (1.0788)  labels_encoder: 0.2426 (0.6953)  labels_decoder: 0.1648 (0.3835)  labels_encoder_unscaled: 0.2426 (0.6953)  labels_decoder_unscaled: 0.3296 (0.7670)  time: 0.0938  data: 0.0002  max mem: 2688
Test:  [1300/1613]  eta: 0:00:31  loss: 0.5639 (1.0735)  labels_encoder: 0.3288 (0.6914)  labels_decoder: 0.2758 (0.3821)  labels_encoder_unscaled: 0.3288 (0.6914)  labels_decoder_unscaled: 0.5517 (0.7641)  time: 0.1073  data: 0.0002  max mem: 2688
Test:  [1350/1613]  eta: 0:00:26  loss: 0.9104 (1.0915)  labels_encoder: 0.5133 (0.7046)  labels_decoder: 0.3786 (0.3869)  labels_encoder_unscaled: 0.5133 (0.7046)  labels_decoder_unscaled: 0.7571 (0.7737)  time: 0.0933  data: 0.0002  max mem: 2688
Test:  [1400/1613]  eta: 0:00:21  loss: 1.1287 (1.0872)  labels_encoder: 0.6726 (0.7014)  labels_decoder: 0.4048 (0.3858)  labels_encoder_unscaled: 0.6726 (0.7014)  labels_decoder_unscaled: 0.8095 (0.7716)  time: 0.0954  data: 0.0002  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.6217 (1.0989)  labels_encoder: 0.3798 (0.7090)  labels_decoder: 0.3097 (0.3899)  labels_encoder_unscaled: 0.3798 (0.7090)  labels_decoder_unscaled: 0.6194 (0.7798)  time: 0.1114  data: 0.0002  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.7927 (1.1108)  labels_encoder: 0.4864 (0.7181)  labels_decoder: 0.2757 (0.3927)  labels_encoder_unscaled: 0.4864 (0.7181)  labels_decoder_unscaled: 0.5515 (0.7855)  time: 0.0968  data: 0.0002  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6791 (1.1062)  labels_encoder: 0.4258 (0.7155)  labels_decoder: 0.2489 (0.3907)  labels_encoder_unscaled: 0.4258 (0.7155)  labels_decoder_unscaled: 0.4978 (0.7814)  time: 0.0975  data: 0.0002  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9739 (1.1073)  labels_encoder: 0.5990 (0.7160)  labels_decoder: 0.3749 (0.3913)  labels_encoder_unscaled: 0.5990 (0.7160)  labels_decoder_unscaled: 0.7497 (0.7826)  time: 0.0963  data: 0.0023  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7430 (1.1056)  labels_encoder: 0.4741 (0.7153)  labels_decoder: 0.3019 (0.3903)  labels_encoder_unscaled: 0.4741 (0.7153)  labels_decoder_unscaled: 0.6037 (0.7807)  time: 0.0659  data: 0.0022  max mem: 2688
Test: Total time: 0:02:42 (0.1005 s / it)
Averaged stats: loss: 0.7430 (1.1056)  labels_encoder: 0.4741 (0.7153)  labels_decoder: 0.3019 (0.3903)  labels_encoder_unscaled: 0.4741 (0.7153)  labels_decoder_unscaled: 0.6037 (0.7807)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5837

dec_mAP all together: | 0.4643996260211794 |.
dec_mAP_pred | 0 : 0.5137843000141202 |.
dec_mAP_pred | 1 : 0.5041975034938359 |.
dec_mAP_pred | 2 : 0.4896078055774996 |.
dec_mAP_pred | 3 : 0.4743392646456809 |.
dec_mAP_pred | 4 : 0.45872691630553264 |.
dec_mAP_pred | 5 : 0.4439056059495942 |.
dec_mAP_pred | 6 : 0.428919671969376 |.
dec_mAP_pred | 7 : 0.4151843577286206 |.
all decoder map: | 0.4661 |.
BaseballPitch: 0.1683
BasketballDunk: 0.7539
Billiards: 0.4510
CleanAndJerk: 0.7367
CliffDiving: 0.8102
CricketBowling: 0.4604
CricketShot: 0.2364
Diving: 0.6916
FrisbeeCatch: 0.2712
GolfSwing: 0.6543
HammerThrow: 0.8506
HighJump: 0.6404
JavelinThrow: 0.7260
LongJump: 0.7863
PoleVault: 0.8698
Shotput: 0.6874
SoccerPenalty: 0.2945
TennisSwing: 0.6182
ThrowDiscus: 0.6064
VolleyballSpiking: 0.3596
Epoch: [3]  [   0/1404]  eta: 1:19:39  lr: 0.000001  loss: 0.3649 (0.3649)  labels_encoder: 0.2263 (0.2263)  labels_decoder: 0.1386 (0.1386)  labels_encoder_unscaled: 0.2263 (0.2263)  labels_decoder_unscaled: 0.2772 (0.2772)  time: 3.4040  data: 3.2443  max mem: 2688
Epoch: [3]  [  50/1404]  eta: 0:05:11  lr: 0.000001  loss: 0.2347 (0.2434)  labels_encoder: 0.1074 (0.1262)  labels_decoder: 0.1100 (0.1172)  labels_encoder_unscaled: 0.1074 (0.1262)  labels_decoder_unscaled: 0.2201 (0.2344)  time: 0.1579  data: 0.0003  max mem: 2688
Epoch: [3]  [ 100/1404]  eta: 0:04:15  lr: 0.000001  loss: 0.2302 (0.2364)  labels_encoder: 0.1124 (0.1205)  labels_decoder: 0.1100 (0.1159)  labels_encoder_unscaled: 0.1124 (0.1205)  labels_decoder_unscaled: 0.2200 (0.2319)  time: 0.1564  data: 0.0003  max mem: 2688
Epoch: [3]  [ 150/1404]  eta: 0:03:47  lr: 0.000001  loss: 0.2514 (0.2425)  labels_encoder: 0.1302 (0.1249)  labels_decoder: 0.1187 (0.1176)  labels_encoder_unscaled: 0.1302 (0.1249)  labels_decoder_unscaled: 0.2374 (0.2352)  time: 0.1533  data: 0.0003  max mem: 2688
Epoch: [3]  [ 200/1404]  eta: 0:03:30  lr: 0.000001  loss: 0.2319 (0.2386)  labels_encoder: 0.1228 (0.1221)  labels_decoder: 0.1094 (0.1165)  labels_encoder_unscaled: 0.1228 (0.1221)  labels_decoder_unscaled: 0.2188 (0.2330)  time: 0.1619  data: 0.0003  max mem: 2688
Epoch: [3]  [ 250/1404]  eta: 0:03:17  lr: 0.000001  loss: 0.2296 (0.2377)  labels_encoder: 0.1120 (0.1215)  labels_decoder: 0.1134 (0.1162)  labels_encoder_unscaled: 0.1120 (0.1215)  labels_decoder_unscaled: 0.2267 (0.2323)  time: 0.1515  data: 0.0003  max mem: 2688
Epoch: [3]  [ 300/1404]  eta: 0:03:04  lr: 0.000001  loss: 0.2146 (0.2373)  labels_encoder: 0.1129 (0.1214)  labels_decoder: 0.1115 (0.1159)  labels_encoder_unscaled: 0.1129 (0.1214)  labels_decoder_unscaled: 0.2231 (0.2317)  time: 0.1479  data: 0.0003  max mem: 2688
Epoch: [3]  [ 350/1404]  eta: 0:02:53  lr: 0.000001  loss: 0.2133 (0.2366)  labels_encoder: 0.1053 (0.1207)  labels_decoder: 0.1132 (0.1159)  labels_encoder_unscaled: 0.1053 (0.1207)  labels_decoder_unscaled: 0.2265 (0.2317)  time: 0.1476  data: 0.0003  max mem: 2688
Epoch: [3]  [ 400/1404]  eta: 0:02:45  lr: 0.000001  loss: 0.2349 (0.2373)  labels_encoder: 0.1223 (0.1214)  labels_decoder: 0.1146 (0.1159)  labels_encoder_unscaled: 0.1223 (0.1214)  labels_decoder_unscaled: 0.2292 (0.2318)  time: 0.1529  data: 0.0003  max mem: 2688
Epoch: [3]  [ 450/1404]  eta: 0:02:35  lr: 0.000001  loss: 0.2366 (0.2382)  labels_encoder: 0.1279 (0.1223)  labels_decoder: 0.1154 (0.1159)  labels_encoder_unscaled: 0.1279 (0.1223)  labels_decoder_unscaled: 0.2307 (0.2317)  time: 0.1500  data: 0.0003  max mem: 2688
Epoch: [3]  [ 500/1404]  eta: 0:02:26  lr: 0.000001  loss: 0.2233 (0.2371)  labels_encoder: 0.1104 (0.1216)  labels_decoder: 0.1071 (0.1155)  labels_encoder_unscaled: 0.1104 (0.1216)  labels_decoder_unscaled: 0.2141 (0.2311)  time: 0.1470  data: 0.0003  max mem: 2688
Epoch: [3]  [ 550/1404]  eta: 0:02:17  lr: 0.000001  loss: 0.2358 (0.2375)  labels_encoder: 0.1124 (0.1220)  labels_decoder: 0.1110 (0.1155)  labels_encoder_unscaled: 0.1124 (0.1220)  labels_decoder_unscaled: 0.2220 (0.2311)  time: 0.1558  data: 0.0003  max mem: 2688
Epoch: [3]  [ 600/1404]  eta: 0:02:09  lr: 0.000001  loss: 0.2118 (0.2372)  labels_encoder: 0.1093 (0.1218)  labels_decoder: 0.1159 (0.1154)  labels_encoder_unscaled: 0.1093 (0.1218)  labels_decoder_unscaled: 0.2317 (0.2307)  time: 0.1507  data: 0.0002  max mem: 2688
Epoch: [3]  [ 650/1404]  eta: 0:02:00  lr: 0.000001  loss: 0.2269 (0.2369)  labels_encoder: 0.1175 (0.1217)  labels_decoder: 0.1154 (0.1152)  labels_encoder_unscaled: 0.1175 (0.1217)  labels_decoder_unscaled: 0.2308 (0.2304)  time: 0.1524  data: 0.0003  max mem: 2688
Epoch: [3]  [ 700/1404]  eta: 0:01:51  lr: 0.000001  loss: 0.2272 (0.2361)  labels_encoder: 0.1166 (0.1212)  labels_decoder: 0.1095 (0.1149)  labels_encoder_unscaled: 0.1166 (0.1212)  labels_decoder_unscaled: 0.2190 (0.2298)  time: 0.1498  data: 0.0003  max mem: 2688
Epoch: [3]  [ 750/1404]  eta: 0:01:44  lr: 0.000001  loss: 0.2155 (0.2351)  labels_encoder: 0.1054 (0.1206)  labels_decoder: 0.1086 (0.1145)  labels_encoder_unscaled: 0.1054 (0.1206)  labels_decoder_unscaled: 0.2172 (0.2289)  time: 0.1599  data: 0.0003  max mem: 2688
Epoch: [3]  [ 800/1404]  eta: 0:01:36  lr: 0.000001  loss: 0.2505 (0.2346)  labels_encoder: 0.1242 (0.1200)  labels_decoder: 0.1192 (0.1146)  labels_encoder_unscaled: 0.1242 (0.1200)  labels_decoder_unscaled: 0.2384 (0.2291)  time: 0.1607  data: 0.0003  max mem: 2688
Epoch: [3]  [ 850/1404]  eta: 0:01:28  lr: 0.000001  loss: 0.2143 (0.2343)  labels_encoder: 0.1084 (0.1199)  labels_decoder: 0.1060 (0.1143)  labels_encoder_unscaled: 0.1084 (0.1199)  labels_decoder_unscaled: 0.2119 (0.2287)  time: 0.1590  data: 0.0003  max mem: 2688
Epoch: [3]  [ 900/1404]  eta: 0:01:20  lr: 0.000001  loss: 0.2303 (0.2345)  labels_encoder: 0.1150 (0.1201)  labels_decoder: 0.1142 (0.1144)  labels_encoder_unscaled: 0.1150 (0.1201)  labels_decoder_unscaled: 0.2285 (0.2287)  time: 0.1506  data: 0.0003  max mem: 2688
Epoch: [3]  [ 950/1404]  eta: 0:01:12  lr: 0.000001  loss: 0.2445 (0.2349)  labels_encoder: 0.1293 (0.1204)  labels_decoder: 0.1168 (0.1146)  labels_encoder_unscaled: 0.1293 (0.1204)  labels_decoder_unscaled: 0.2336 (0.2291)  time: 0.1513  data: 0.0003  max mem: 2688
Epoch: [3]  [1000/1404]  eta: 0:01:04  lr: 0.000001  loss: 0.2401 (0.2350)  labels_encoder: 0.1131 (0.1206)  labels_decoder: 0.1059 (0.1145)  labels_encoder_unscaled: 0.1131 (0.1206)  labels_decoder_unscaled: 0.2117 (0.2290)  time: 0.1484  data: 0.0003  max mem: 2688
Epoch: [3]  [1050/1404]  eta: 0:00:56  lr: 0.000001  loss: 0.2423 (0.2355)  labels_encoder: 0.1204 (0.1208)  labels_decoder: 0.1134 (0.1146)  labels_encoder_unscaled: 0.1204 (0.1208)  labels_decoder_unscaled: 0.2267 (0.2293)  time: 0.1495  data: 0.0003  max mem: 2688
Epoch: [3]  [1100/1404]  eta: 0:00:48  lr: 0.000001  loss: 0.2383 (0.2357)  labels_encoder: 0.1239 (0.1212)  labels_decoder: 0.1082 (0.1145)  labels_encoder_unscaled: 0.1239 (0.1212)  labels_decoder_unscaled: 0.2163 (0.2290)  time: 0.1506  data: 0.0003  max mem: 2688
Epoch: [3]  [1150/1404]  eta: 0:00:40  lr: 0.000001  loss: 0.2348 (0.2358)  labels_encoder: 0.1047 (0.1213)  labels_decoder: 0.1103 (0.1144)  labels_encoder_unscaled: 0.1047 (0.1213)  labels_decoder_unscaled: 0.2207 (0.2289)  time: 0.1557  data: 0.0003  max mem: 2688
Epoch: [3]  [1200/1404]  eta: 0:00:32  lr: 0.000001  loss: 0.2319 (0.2356)  labels_encoder: 0.1114 (0.1212)  labels_decoder: 0.1112 (0.1144)  labels_encoder_unscaled: 0.1114 (0.1212)  labels_decoder_unscaled: 0.2224 (0.2288)  time: 0.1603  data: 0.0003  max mem: 2688
Epoch: [3]  [1250/1404]  eta: 0:00:24  lr: 0.000001  loss: 0.2399 (0.2359)  labels_encoder: 0.1172 (0.1214)  labels_decoder: 0.1182 (0.1145)  labels_encoder_unscaled: 0.1172 (0.1214)  labels_decoder_unscaled: 0.2363 (0.2290)  time: 0.1563  data: 0.0003  max mem: 2688
Epoch: [3]  [1300/1404]  eta: 0:00:16  lr: 0.000001  loss: 0.2158 (0.2358)  labels_encoder: 0.1045 (0.1213)  labels_decoder: 0.1182 (0.1145)  labels_encoder_unscaled: 0.1045 (0.1213)  labels_decoder_unscaled: 0.2364 (0.2290)  time: 0.1517  data: 0.0003  max mem: 2688
Epoch: [3]  [1350/1404]  eta: 0:00:08  lr: 0.000001  loss: 0.2288 (0.2355)  labels_encoder: 0.1057 (0.1211)  labels_decoder: 0.1105 (0.1144)  labels_encoder_unscaled: 0.1057 (0.1211)  labels_decoder_unscaled: 0.2210 (0.2288)  time: 0.1571  data: 0.0003  max mem: 2688
Epoch: [3]  [1400/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2297 (0.2355)  labels_encoder: 0.1207 (0.1211)  labels_decoder: 0.1132 (0.1143)  labels_encoder_unscaled: 0.1207 (0.1211)  labels_decoder_unscaled: 0.2263 (0.2286)  time: 0.1310  data: 0.0006  max mem: 2688
Epoch: [3]  [1403/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2289 (0.2354)  labels_encoder: 0.1207 (0.1211)  labels_decoder: 0.1132 (0.1143)  labels_encoder_unscaled: 0.1207 (0.1211)  labels_decoder_unscaled: 0.2263 (0.2286)  time: 0.1227  data: 0.0006  max mem: 2688
Epoch: [3] Total time: 0:03:41 (0.1579 s / it)
Averaged stats: lr: 0.000001  loss: 0.2289 (0.2354)  labels_encoder: 0.1207 (0.1211)  labels_decoder: 0.1132 (0.1143)  labels_encoder_unscaled: 0.1207 (0.1211)  labels_decoder_unscaled: 0.2263 (0.2286)
Test:  [   0/1613]  eta: 1:37:59  loss: 0.6890 (0.6890)  labels_encoder: 0.3410 (0.3410)  labels_decoder: 0.3480 (0.3480)  labels_encoder_unscaled: 0.3410 (0.3410)  labels_decoder_unscaled: 0.6960 (0.6960)  time: 3.6449  data: 3.5159  max mem: 2688
Test:  [  50/1613]  eta: 0:04:23  loss: 0.4652 (0.8539)  labels_encoder: 0.2413 (0.5238)  labels_decoder: 0.2199 (0.3301)  labels_encoder_unscaled: 0.2413 (0.5238)  labels_decoder_unscaled: 0.4398 (0.6602)  time: 0.1036  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:29  loss: 0.3418 (0.7307)  labels_encoder: 0.2396 (0.4632)  labels_decoder: 0.1001 (0.2675)  labels_encoder_unscaled: 0.2396 (0.4632)  labels_decoder_unscaled: 0.2001 (0.5350)  time: 0.1165  data: 0.0002  max mem: 2688
Test:  [ 150/1613]  eta: 0:03:06  loss: 0.9818 (0.7705)  labels_encoder: 0.6515 (0.4951)  labels_decoder: 0.3161 (0.2754)  labels_encoder_unscaled: 0.6515 (0.4951)  labels_decoder_unscaled: 0.6322 (0.5508)  time: 0.0946  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:53  loss: 1.1418 (0.9064)  labels_encoder: 0.6893 (0.5888)  labels_decoder: 0.4211 (0.3175)  labels_encoder_unscaled: 0.6893 (0.5888)  labels_decoder_unscaled: 0.8422 (0.6351)  time: 0.1110  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:42  loss: 0.4455 (0.9621)  labels_encoder: 0.3516 (0.6229)  labels_decoder: 0.1955 (0.3391)  labels_encoder_unscaled: 0.3516 (0.6229)  labels_decoder_unscaled: 0.3911 (0.6783)  time: 0.1081  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:33  loss: 0.6966 (0.9922)  labels_encoder: 0.4224 (0.6430)  labels_decoder: 0.2632 (0.3492)  labels_encoder_unscaled: 0.4224 (0.6430)  labels_decoder_unscaled: 0.5265 (0.6984)  time: 0.1065  data: 0.0003  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:24  loss: 1.0757 (0.9898)  labels_encoder: 0.6404 (0.6356)  labels_decoder: 0.4930 (0.3542)  labels_encoder_unscaled: 0.6404 (0.6356)  labels_decoder_unscaled: 0.9861 (0.7085)  time: 0.0951  data: 0.0002  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:16  loss: 0.7189 (1.0982)  labels_encoder: 0.4089 (0.7112)  labels_decoder: 0.3394 (0.3869)  labels_encoder_unscaled: 0.4089 (0.7112)  labels_decoder_unscaled: 0.6788 (0.7739)  time: 0.1028  data: 0.0002  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:10  loss: 1.0283 (1.1791)  labels_encoder: 0.6329 (0.7643)  labels_decoder: 0.3703 (0.4147)  labels_encoder_unscaled: 0.6329 (0.7643)  labels_decoder_unscaled: 0.7406 (0.8295)  time: 0.1090  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:02:02  loss: 0.3692 (1.1276)  labels_encoder: 0.2046 (0.7293)  labels_decoder: 0.1711 (0.3982)  labels_encoder_unscaled: 0.2046 (0.7293)  labels_decoder_unscaled: 0.3423 (0.7965)  time: 0.0871  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:54  loss: 0.6950 (1.1179)  labels_encoder: 0.4577 (0.7224)  labels_decoder: 0.2373 (0.3955)  labels_encoder_unscaled: 0.4577 (0.7224)  labels_decoder_unscaled: 0.4746 (0.7910)  time: 0.0853  data: 0.0002  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:48  loss: 1.2499 (1.1832)  labels_encoder: 0.8370 (0.7736)  labels_decoder: 0.4716 (0.4096)  labels_encoder_unscaled: 0.8370 (0.7736)  labels_decoder_unscaled: 0.9433 (0.8192)  time: 0.0934  data: 0.0068  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:42  loss: 0.8473 (1.1634)  labels_encoder: 0.4593 (0.7548)  labels_decoder: 0.4080 (0.4085)  labels_encoder_unscaled: 0.4593 (0.7548)  labels_decoder_unscaled: 0.8159 (0.8171)  time: 0.0846  data: 0.0002  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:36  loss: 0.5955 (1.1358)  labels_encoder: 0.3240 (0.7356)  labels_decoder: 0.2443 (0.4002)  labels_encoder_unscaled: 0.3240 (0.7356)  labels_decoder_unscaled: 0.4886 (0.8005)  time: 0.0944  data: 0.0386  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:30  loss: 0.7257 (1.1168)  labels_encoder: 0.4597 (0.7229)  labels_decoder: 0.2659 (0.3940)  labels_encoder_unscaled: 0.4597 (0.7229)  labels_decoder_unscaled: 0.5319 (0.7879)  time: 0.0869  data: 0.0326  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:24  loss: 0.8375 (1.1153)  labels_encoder: 0.5068 (0.7225)  labels_decoder: 0.3639 (0.3928)  labels_encoder_unscaled: 0.5068 (0.7225)  labels_decoder_unscaled: 0.7279 (0.7856)  time: 0.0911  data: 0.0364  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:18  loss: 1.3479 (1.1174)  labels_encoder: 0.8349 (0.7216)  labels_decoder: 0.5428 (0.3958)  labels_encoder_unscaled: 0.8349 (0.7216)  labels_decoder_unscaled: 1.0855 (0.7916)  time: 0.0954  data: 0.0482  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:13  loss: 0.6065 (1.1349)  labels_encoder: 0.3406 (0.7339)  labels_decoder: 0.2836 (0.4010)  labels_encoder_unscaled: 0.3406 (0.7339)  labels_decoder_unscaled: 0.5671 (0.8019)  time: 0.0971  data: 0.0225  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:07  loss: 1.0918 (1.1270)  labels_encoder: 0.7846 (0.7297)  labels_decoder: 0.3702 (0.3974)  labels_encoder_unscaled: 0.7846 (0.7297)  labels_decoder_unscaled: 0.7405 (0.7948)  time: 0.1011  data: 0.0293  max mem: 2688
Test:  [1000/1613]  eta: 0:01:02  loss: 0.5390 (1.1129)  labels_encoder: 0.3277 (0.7192)  labels_decoder: 0.2138 (0.3937)  labels_encoder_unscaled: 0.3277 (0.7192)  labels_decoder_unscaled: 0.4276 (0.7873)  time: 0.0929  data: 0.0289  max mem: 2688
Test:  [1050/1613]  eta: 0:00:57  loss: 0.9108 (1.1036)  labels_encoder: 0.5433 (0.7127)  labels_decoder: 0.3356 (0.3909)  labels_encoder_unscaled: 0.5433 (0.7127)  labels_decoder_unscaled: 0.6711 (0.7819)  time: 0.1002  data: 0.0226  max mem: 2688
Test:  [1100/1613]  eta: 0:00:52  loss: 0.6442 (1.1025)  labels_encoder: 0.3357 (0.7133)  labels_decoder: 0.3548 (0.3892)  labels_encoder_unscaled: 0.3357 (0.7133)  labels_decoder_unscaled: 0.7095 (0.7784)  time: 0.0887  data: 0.0273  max mem: 2688
Test:  [1150/1613]  eta: 0:00:47  loss: 0.5411 (1.0904)  labels_encoder: 0.3266 (0.7048)  labels_decoder: 0.2221 (0.3857)  labels_encoder_unscaled: 0.3266 (0.7048)  labels_decoder_unscaled: 0.4442 (0.7713)  time: 0.0975  data: 0.0182  max mem: 2688
Test:  [1200/1613]  eta: 0:00:42  loss: 0.5413 (1.0945)  labels_encoder: 0.3073 (0.7070)  labels_decoder: 0.2613 (0.3875)  labels_encoder_unscaled: 0.3073 (0.7070)  labels_decoder_unscaled: 0.5225 (0.7751)  time: 0.0995  data: 0.0185  max mem: 2688
Test:  [1250/1613]  eta: 0:00:36  loss: 0.4330 (1.0962)  labels_encoder: 0.2440 (0.7076)  labels_decoder: 0.1652 (0.3886)  labels_encoder_unscaled: 0.2440 (0.7076)  labels_decoder_unscaled: 0.3305 (0.7771)  time: 0.0963  data: 0.0372  max mem: 2688
Test:  [1300/1613]  eta: 0:00:31  loss: 0.5185 (1.0899)  labels_encoder: 0.3297 (0.7032)  labels_decoder: 0.2741 (0.3867)  labels_encoder_unscaled: 0.3297 (0.7032)  labels_decoder_unscaled: 0.5481 (0.7734)  time: 0.1048  data: 0.0274  max mem: 2688
Test:  [1350/1613]  eta: 0:00:26  loss: 0.8795 (1.1049)  labels_encoder: 0.4888 (0.7139)  labels_decoder: 0.3759 (0.3910)  labels_encoder_unscaled: 0.4888 (0.7139)  labels_decoder_unscaled: 0.7517 (0.7821)  time: 0.1076  data: 0.0390  max mem: 2688
Test:  [1400/1613]  eta: 0:00:21  loss: 1.2367 (1.1001)  labels_encoder: 0.7068 (0.7103)  labels_decoder: 0.4067 (0.3898)  labels_encoder_unscaled: 0.7068 (0.7103)  labels_decoder_unscaled: 0.8133 (0.7797)  time: 0.0981  data: 0.0407  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.6359 (1.1163)  labels_encoder: 0.3843 (0.7206)  labels_decoder: 0.3167 (0.3957)  labels_encoder_unscaled: 0.3843 (0.7206)  labels_decoder_unscaled: 0.6333 (0.7914)  time: 0.0991  data: 0.0281  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.9297 (1.1332)  labels_encoder: 0.6060 (0.7333)  labels_decoder: 0.3038 (0.3998)  labels_encoder_unscaled: 0.6060 (0.7333)  labels_decoder_unscaled: 0.6077 (0.7997)  time: 0.1076  data: 0.0059  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6996 (1.1288)  labels_encoder: 0.4467 (0.7309)  labels_decoder: 0.2469 (0.3978)  labels_encoder_unscaled: 0.4467 (0.7309)  labels_decoder_unscaled: 0.4939 (0.7957)  time: 0.0999  data: 0.0002  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9941 (1.1277)  labels_encoder: 0.6016 (0.7299)  labels_decoder: 0.3742 (0.3979)  labels_encoder_unscaled: 0.6016 (0.7299)  labels_decoder_unscaled: 0.7485 (0.7957)  time: 0.0970  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7693 (1.1261)  labels_encoder: 0.4951 (0.7293)  labels_decoder: 0.3039 (0.3969)  labels_encoder_unscaled: 0.4951 (0.7293)  labels_decoder_unscaled: 0.6078 (0.7937)  time: 0.0908  data: 0.0001  max mem: 2688
Test: Total time: 0:02:44 (0.1023 s / it)
Averaged stats: loss: 0.7693 (1.1261)  labels_encoder: 0.4951 (0.7293)  labels_decoder: 0.3039 (0.3969)  labels_encoder_unscaled: 0.4951 (0.7293)  labels_decoder_unscaled: 0.6078 (0.7937)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5810

dec_mAP all together: | 0.45933578596730396 |.
dec_mAP_pred | 0 : 0.5054029959715758 |.
dec_mAP_pred | 1 : 0.4968051300325273 |.
dec_mAP_pred | 2 : 0.4832389712505806 |.
dec_mAP_pred | 3 : 0.46886816106676016 |.
dec_mAP_pred | 4 : 0.45411276749648444 |.
dec_mAP_pred | 5 : 0.4400420193859788 |.
dec_mAP_pred | 6 : 0.42585293026396653 |.
dec_mAP_pred | 7 : 0.4127640345301269 |.
all decoder map: | 0.4609 |.
BaseballPitch: 0.1555
BasketballDunk: 0.7597
Billiards: 0.4544
CleanAndJerk: 0.7395
CliffDiving: 0.8076
CricketBowling: 0.4670
CricketShot: 0.2539
Diving: 0.6871
FrisbeeCatch: 0.2554
GolfSwing: 0.6432
HammerThrow: 0.8478
HighJump: 0.6285
JavelinThrow: 0.7170
LongJump: 0.7883
PoleVault: 0.8606
Shotput: 0.6841
SoccerPenalty: 0.3001
TennisSwing: 0.6148
ThrowDiscus: 0.5957
VolleyballSpiking: 0.3607
Epoch: [4]  [   0/1404]  eta: 1:26:51  lr: 0.000000  loss: 0.4149 (0.4149)  labels_encoder: 0.2603 (0.2603)  labels_decoder: 0.1546 (0.1546)  labels_encoder_unscaled: 0.2603 (0.2603)  labels_decoder_unscaled: 0.3093 (0.3093)  time: 3.7119  data: 3.4442  max mem: 2688
Epoch: [4]  [  50/1404]  eta: 0:05:18  lr: 0.000000  loss: 0.2341 (0.2324)  labels_encoder: 0.1115 (0.1203)  labels_decoder: 0.1131 (0.1120)  labels_encoder_unscaled: 0.1115 (0.1203)  labels_decoder_unscaled: 0.2263 (0.2240)  time: 0.1544  data: 0.0003  max mem: 2688
Epoch: [4]  [ 100/1404]  eta: 0:04:16  lr: 0.000000  loss: 0.2220 (0.2321)  labels_encoder: 0.1027 (0.1191)  labels_decoder: 0.1136 (0.1130)  labels_encoder_unscaled: 0.1027 (0.1191)  labels_decoder_unscaled: 0.2272 (0.2260)  time: 0.1614  data: 0.0003  max mem: 2688
Epoch: [4]  [ 150/1404]  eta: 0:03:51  lr: 0.000000  loss: 0.2530 (0.2312)  labels_encoder: 0.1209 (0.1178)  labels_decoder: 0.1274 (0.1134)  labels_encoder_unscaled: 0.1209 (0.1178)  labels_decoder_unscaled: 0.2549 (0.2268)  time: 0.1550  data: 0.0003  max mem: 2688
Epoch: [4]  [ 200/1404]  eta: 0:03:34  lr: 0.000000  loss: 0.2171 (0.2316)  labels_encoder: 0.1101 (0.1178)  labels_decoder: 0.1114 (0.1138)  labels_encoder_unscaled: 0.1101 (0.1178)  labels_decoder_unscaled: 0.2229 (0.2276)  time: 0.1528  data: 0.0003  max mem: 2688
Epoch: [4]  [ 250/1404]  eta: 0:03:19  lr: 0.000000  loss: 0.2311 (0.2328)  labels_encoder: 0.1256 (0.1184)  labels_decoder: 0.1117 (0.1143)  labels_encoder_unscaled: 0.1256 (0.1184)  labels_decoder_unscaled: 0.2235 (0.2286)  time: 0.1581  data: 0.0003  max mem: 2688
Epoch: [4]  [ 300/1404]  eta: 0:03:06  lr: 0.000000  loss: 0.2115 (0.2323)  labels_encoder: 0.1078 (0.1184)  labels_decoder: 0.1010 (0.1139)  labels_encoder_unscaled: 0.1078 (0.1184)  labels_decoder_unscaled: 0.2020 (0.2278)  time: 0.1523  data: 0.0003  max mem: 2688
Epoch: [4]  [ 350/1404]  eta: 0:02:56  lr: 0.000000  loss: 0.2277 (0.2339)  labels_encoder: 0.1147 (0.1195)  labels_decoder: 0.1112 (0.1145)  labels_encoder_unscaled: 0.1147 (0.1195)  labels_decoder_unscaled: 0.2225 (0.2289)  time: 0.1668  data: 0.0003  max mem: 2688
Epoch: [4]  [ 400/1404]  eta: 0:02:46  lr: 0.000000  loss: 0.2168 (0.2330)  labels_encoder: 0.0943 (0.1191)  labels_decoder: 0.1152 (0.1139)  labels_encoder_unscaled: 0.0943 (0.1191)  labels_decoder_unscaled: 0.2304 (0.2277)  time: 0.1537  data: 0.0003  max mem: 2688
Epoch: [4]  [ 450/1404]  eta: 0:02:36  lr: 0.000000  loss: 0.2245 (0.2327)  labels_encoder: 0.1110 (0.1185)  labels_decoder: 0.1098 (0.1142)  labels_encoder_unscaled: 0.1110 (0.1185)  labels_decoder_unscaled: 0.2196 (0.2284)  time: 0.1583  data: 0.0003  max mem: 2688
Epoch: [4]  [ 500/1404]  eta: 0:02:27  lr: 0.000000  loss: 0.2370 (0.2323)  labels_encoder: 0.1317 (0.1190)  labels_decoder: 0.1035 (0.1133)  labels_encoder_unscaled: 0.1317 (0.1190)  labels_decoder_unscaled: 0.2069 (0.2266)  time: 0.1499  data: 0.0003  max mem: 2688
Epoch: [4]  [ 550/1404]  eta: 0:02:19  lr: 0.000000  loss: 0.2212 (0.2318)  labels_encoder: 0.1041 (0.1186)  labels_decoder: 0.1089 (0.1132)  labels_encoder_unscaled: 0.1041 (0.1186)  labels_decoder_unscaled: 0.2178 (0.2264)  time: 0.1495  data: 0.0003  max mem: 2688
Epoch: [4]  [ 600/1404]  eta: 0:02:10  lr: 0.000000  loss: 0.2289 (0.2314)  labels_encoder: 0.1172 (0.1185)  labels_decoder: 0.1099 (0.1129)  labels_encoder_unscaled: 0.1172 (0.1185)  labels_decoder_unscaled: 0.2199 (0.2258)  time: 0.1523  data: 0.0003  max mem: 2688
Epoch: [4]  [ 650/1404]  eta: 0:02:02  lr: 0.000000  loss: 0.2237 (0.2310)  labels_encoder: 0.1137 (0.1183)  labels_decoder: 0.1041 (0.1126)  labels_encoder_unscaled: 0.1137 (0.1183)  labels_decoder_unscaled: 0.2082 (0.2253)  time: 0.1536  data: 0.0004  max mem: 2688
Epoch: [4]  [ 700/1404]  eta: 0:01:53  lr: 0.000000  loss: 0.2217 (0.2305)  labels_encoder: 0.1139 (0.1179)  labels_decoder: 0.1069 (0.1126)  labels_encoder_unscaled: 0.1139 (0.1179)  labels_decoder_unscaled: 0.2137 (0.2253)  time: 0.1517  data: 0.0003  max mem: 2688
Epoch: [4]  [ 750/1404]  eta: 0:01:45  lr: 0.000000  loss: 0.2356 (0.2307)  labels_encoder: 0.1172 (0.1180)  labels_decoder: 0.1099 (0.1127)  labels_encoder_unscaled: 0.1172 (0.1180)  labels_decoder_unscaled: 0.2198 (0.2254)  time: 0.1537  data: 0.0003  max mem: 2688
Epoch: [4]  [ 800/1404]  eta: 0:01:37  lr: 0.000000  loss: 0.2324 (0.2311)  labels_encoder: 0.1250 (0.1184)  labels_decoder: 0.1103 (0.1127)  labels_encoder_unscaled: 0.1250 (0.1184)  labels_decoder_unscaled: 0.2205 (0.2254)  time: 0.1519  data: 0.0003  max mem: 2688
Epoch: [4]  [ 850/1404]  eta: 0:01:29  lr: 0.000000  loss: 0.2141 (0.2311)  labels_encoder: 0.1126 (0.1185)  labels_decoder: 0.1056 (0.1127)  labels_encoder_unscaled: 0.1126 (0.1185)  labels_decoder_unscaled: 0.2112 (0.2254)  time: 0.1517  data: 0.0003  max mem: 2688
Epoch: [4]  [ 900/1404]  eta: 0:01:20  lr: 0.000000  loss: 0.2287 (0.2313)  labels_encoder: 0.1059 (0.1185)  labels_decoder: 0.1214 (0.1128)  labels_encoder_unscaled: 0.1059 (0.1185)  labels_decoder_unscaled: 0.2428 (0.2256)  time: 0.1599  data: 0.0003  max mem: 2688
Epoch: [4]  [ 950/1404]  eta: 0:01:12  lr: 0.000000  loss: 0.2186 (0.2314)  labels_encoder: 0.1052 (0.1186)  labels_decoder: 0.1096 (0.1129)  labels_encoder_unscaled: 0.1052 (0.1186)  labels_decoder_unscaled: 0.2191 (0.2257)  time: 0.1539  data: 0.0003  max mem: 2688
Epoch: [4]  [1000/1404]  eta: 0:01:04  lr: 0.000000  loss: 0.2238 (0.2314)  labels_encoder: 0.1205 (0.1185)  labels_decoder: 0.1108 (0.1129)  labels_encoder_unscaled: 0.1205 (0.1185)  labels_decoder_unscaled: 0.2216 (0.2257)  time: 0.1615  data: 0.0003  max mem: 2688
Epoch: [4]  [1050/1404]  eta: 0:00:56  lr: 0.000000  loss: 0.2122 (0.2312)  labels_encoder: 0.1066 (0.1185)  labels_decoder: 0.1065 (0.1127)  labels_encoder_unscaled: 0.1066 (0.1185)  labels_decoder_unscaled: 0.2130 (0.2254)  time: 0.1645  data: 0.0003  max mem: 2688
Epoch: [4]  [1100/1404]  eta: 0:00:48  lr: 0.000000  loss: 0.2417 (0.2311)  labels_encoder: 0.1112 (0.1184)  labels_decoder: 0.1157 (0.1128)  labels_encoder_unscaled: 0.1112 (0.1184)  labels_decoder_unscaled: 0.2314 (0.2255)  time: 0.1481  data: 0.0003  max mem: 2688
Epoch: [4]  [1150/1404]  eta: 0:00:40  lr: 0.000000  loss: 0.2292 (0.2310)  labels_encoder: 0.1164 (0.1184)  labels_decoder: 0.1041 (0.1126)  labels_encoder_unscaled: 0.1164 (0.1184)  labels_decoder_unscaled: 0.2081 (0.2252)  time: 0.1713  data: 0.0003  max mem: 2688
Epoch: [4]  [1200/1404]  eta: 0:00:32  lr: 0.000000  loss: 0.2294 (0.2312)  labels_encoder: 0.1171 (0.1185)  labels_decoder: 0.1033 (0.1127)  labels_encoder_unscaled: 0.1171 (0.1185)  labels_decoder_unscaled: 0.2066 (0.2253)  time: 0.1590  data: 0.0003  max mem: 2688
Epoch: [4]  [1250/1404]  eta: 0:00:24  lr: 0.000000  loss: 0.2320 (0.2310)  labels_encoder: 0.1132 (0.1184)  labels_decoder: 0.1181 (0.1126)  labels_encoder_unscaled: 0.1132 (0.1184)  labels_decoder_unscaled: 0.2362 (0.2252)  time: 0.1604  data: 0.0003  max mem: 2688
Epoch: [4]  [1300/1404]  eta: 0:00:16  lr: 0.000000  loss: 0.2342 (0.2315)  labels_encoder: 0.1205 (0.1186)  labels_decoder: 0.1093 (0.1129)  labels_encoder_unscaled: 0.1205 (0.1186)  labels_decoder_unscaled: 0.2186 (0.2257)  time: 0.1668  data: 0.0003  max mem: 2688
Epoch: [4]  [1350/1404]  eta: 0:00:08  lr: 0.000000  loss: 0.2317 (0.2318)  labels_encoder: 0.1142 (0.1188)  labels_decoder: 0.1238 (0.1130)  labels_encoder_unscaled: 0.1142 (0.1188)  labels_decoder_unscaled: 0.2477 (0.2261)  time: 0.1494  data: 0.0003  max mem: 2688
Epoch: [4]  [1400/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2188 (0.2315)  labels_encoder: 0.1101 (0.1185)  labels_decoder: 0.1097 (0.1130)  labels_encoder_unscaled: 0.1101 (0.1185)  labels_decoder_unscaled: 0.2193 (0.2260)  time: 0.1310  data: 0.0003  max mem: 2688
Epoch: [4]  [1403/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2279 (0.2315)  labels_encoder: 0.1113 (0.1185)  labels_decoder: 0.1151 (0.1130)  labels_encoder_unscaled: 0.1113 (0.1185)  labels_decoder_unscaled: 0.2301 (0.2260)  time: 0.1243  data: 0.0003  max mem: 2688
Epoch: [4] Total time: 0:03:43 (0.1594 s / it)
Averaged stats: lr: 0.000000  loss: 0.2279 (0.2315)  labels_encoder: 0.1113 (0.1185)  labels_decoder: 0.1151 (0.1130)  labels_encoder_unscaled: 0.1113 (0.1185)  labels_decoder_unscaled: 0.2301 (0.2260)
Test:  [   0/1613]  eta: 1:28:46  loss: 0.7236 (0.7236)  labels_encoder: 0.3582 (0.3582)  labels_decoder: 0.3653 (0.3653)  labels_encoder_unscaled: 0.3582 (0.3582)  labels_decoder_unscaled: 0.7307 (0.7307)  time: 3.3021  data: 3.1813  max mem: 2688
Test:  [  50/1613]  eta: 0:04:32  loss: 0.4589 (0.8557)  labels_encoder: 0.2495 (0.5281)  labels_decoder: 0.2156 (0.3276)  labels_encoder_unscaled: 0.2495 (0.5281)  labels_decoder_unscaled: 0.4313 (0.6551)  time: 0.1065  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:29  loss: 0.3032 (0.7296)  labels_encoder: 0.2149 (0.4639)  labels_decoder: 0.0882 (0.2656)  labels_encoder_unscaled: 0.2149 (0.4639)  labels_decoder_unscaled: 0.1765 (0.5313)  time: 0.1003  data: 0.0002  max mem: 2688
Test:  [ 150/1613]  eta: 0:03:10  loss: 0.9805 (0.7702)  labels_encoder: 0.6525 (0.4962)  labels_decoder: 0.3144 (0.2740)  labels_encoder_unscaled: 0.6525 (0.4962)  labels_decoder_unscaled: 0.6289 (0.5479)  time: 0.1068  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:53  loss: 1.1586 (0.9039)  labels_encoder: 0.7051 (0.5889)  labels_decoder: 0.4238 (0.3150)  labels_encoder_unscaled: 0.7051 (0.5889)  labels_decoder_unscaled: 0.8475 (0.6301)  time: 0.1059  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:40  loss: 0.4401 (0.9634)  labels_encoder: 0.3636 (0.6257)  labels_decoder: 0.1929 (0.3377)  labels_encoder_unscaled: 0.3636 (0.6257)  labels_decoder_unscaled: 0.3858 (0.6755)  time: 0.1021  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:32  loss: 0.7266 (0.9964)  labels_encoder: 0.4238 (0.6480)  labels_decoder: 0.2678 (0.3484)  labels_encoder_unscaled: 0.4238 (0.6480)  labels_decoder_unscaled: 0.5356 (0.6967)  time: 0.1002  data: 0.0003  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:24  loss: 1.1296 (0.9949)  labels_encoder: 0.6798 (0.6410)  labels_decoder: 0.4814 (0.3539)  labels_encoder_unscaled: 0.6798 (0.6410)  labels_decoder_unscaled: 0.9628 (0.7077)  time: 0.1032  data: 0.0002  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:17  loss: 0.7213 (1.1071)  labels_encoder: 0.4148 (0.7195)  labels_decoder: 0.3378 (0.3876)  labels_encoder_unscaled: 0.4148 (0.7195)  labels_decoder_unscaled: 0.6756 (0.7752)  time: 0.1048  data: 0.0002  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:10  loss: 0.9947 (1.1878)  labels_encoder: 0.6125 (0.7723)  labels_decoder: 0.3544 (0.4154)  labels_encoder_unscaled: 0.6125 (0.7723)  labels_decoder_unscaled: 0.7089 (0.8309)  time: 0.1034  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:02:03  loss: 0.3622 (1.1358)  labels_encoder: 0.1994 (0.7370)  labels_decoder: 0.1714 (0.3988)  labels_encoder_unscaled: 0.1994 (0.7370)  labels_decoder_unscaled: 0.3428 (0.7977)  time: 0.1051  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:57  loss: 0.6303 (1.1235)  labels_encoder: 0.4060 (0.7282)  labels_decoder: 0.2274 (0.3953)  labels_encoder_unscaled: 0.4060 (0.7282)  labels_decoder_unscaled: 0.4547 (0.7906)  time: 0.1031  data: 0.0002  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:51  loss: 1.2428 (1.1829)  labels_encoder: 0.8488 (0.7746)  labels_decoder: 0.4579 (0.4082)  labels_encoder_unscaled: 0.8488 (0.7746)  labels_decoder_unscaled: 0.9158 (0.8165)  time: 0.1082  data: 0.0002  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:45  loss: 0.8768 (1.1641)  labels_encoder: 0.4892 (0.7565)  labels_decoder: 0.4172 (0.4076)  labels_encoder_unscaled: 0.4892 (0.7565)  labels_decoder_unscaled: 0.8344 (0.8152)  time: 0.1133  data: 0.0002  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:40  loss: 0.6026 (1.1372)  labels_encoder: 0.3380 (0.7376)  labels_decoder: 0.2479 (0.3995)  labels_encoder_unscaled: 0.3380 (0.7376)  labels_decoder_unscaled: 0.4958 (0.7991)  time: 0.1108  data: 0.0002  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:34  loss: 0.7964 (1.1207)  labels_encoder: 0.4956 (0.7266)  labels_decoder: 0.2861 (0.3941)  labels_encoder_unscaled: 0.4956 (0.7266)  labels_decoder_unscaled: 0.5721 (0.7883)  time: 0.1081  data: 0.0002  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:28  loss: 0.8662 (1.1200)  labels_encoder: 0.5297 (0.7268)  labels_decoder: 0.3619 (0.3932)  labels_encoder_unscaled: 0.5297 (0.7268)  labels_decoder_unscaled: 0.7238 (0.7865)  time: 0.1030  data: 0.0002  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:23  loss: 1.2508 (1.1222)  labels_encoder: 0.7618 (0.7260)  labels_decoder: 0.4981 (0.3963)  labels_encoder_unscaled: 0.7618 (0.7260)  labels_decoder_unscaled: 0.9963 (0.7926)  time: 0.1155  data: 0.0002  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:17  loss: 0.5804 (1.1406)  labels_encoder: 0.3537 (0.7389)  labels_decoder: 0.2749 (0.4016)  labels_encoder_unscaled: 0.3537 (0.7389)  labels_decoder_unscaled: 0.5499 (0.8033)  time: 0.0990  data: 0.0002  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:12  loss: 1.1257 (1.1338)  labels_encoder: 0.7641 (0.7354)  labels_decoder: 0.3635 (0.3984)  labels_encoder_unscaled: 0.7641 (0.7354)  labels_decoder_unscaled: 0.7270 (0.7967)  time: 0.1000  data: 0.0002  max mem: 2688
Test:  [1000/1613]  eta: 0:01:06  loss: 0.5429 (1.1205)  labels_encoder: 0.3332 (0.7256)  labels_decoder: 0.2197 (0.3949)  labels_encoder_unscaled: 0.3332 (0.7256)  labels_decoder_unscaled: 0.4394 (0.7898)  time: 0.1028  data: 0.0002  max mem: 2688
Test:  [1050/1613]  eta: 0:01:00  loss: 0.9113 (1.1115)  labels_encoder: 0.5479 (0.7192)  labels_decoder: 0.3372 (0.3922)  labels_encoder_unscaled: 0.5479 (0.7192)  labels_decoder_unscaled: 0.6744 (0.7845)  time: 0.1020  data: 0.0002  max mem: 2688
Test:  [1100/1613]  eta: 0:00:55  loss: 0.6326 (1.1106)  labels_encoder: 0.3451 (0.7200)  labels_decoder: 0.3521 (0.3906)  labels_encoder_unscaled: 0.3451 (0.7200)  labels_decoder_unscaled: 0.7043 (0.7812)  time: 0.0887  data: 0.0002  max mem: 2688
Test:  [1150/1613]  eta: 0:00:49  loss: 0.5417 (1.0988)  labels_encoder: 0.3281 (0.7116)  labels_decoder: 0.2274 (0.3872)  labels_encoder_unscaled: 0.3281 (0.7116)  labels_decoder_unscaled: 0.4549 (0.7743)  time: 0.1145  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:44  loss: 0.5609 (1.1035)  labels_encoder: 0.3228 (0.7141)  labels_decoder: 0.2643 (0.3893)  labels_encoder_unscaled: 0.3228 (0.7141)  labels_decoder_unscaled: 0.5287 (0.7786)  time: 0.1073  data: 0.0002  max mem: 2688
Test:  [1250/1613]  eta: 0:00:38  loss: 0.4338 (1.1053)  labels_encoder: 0.2535 (0.7150)  labels_decoder: 0.1687 (0.3903)  labels_encoder_unscaled: 0.2535 (0.7150)  labels_decoder_unscaled: 0.3375 (0.7807)  time: 0.1028  data: 0.0002  max mem: 2688
Test:  [1300/1613]  eta: 0:00:33  loss: 0.5251 (1.0992)  labels_encoder: 0.3344 (0.7107)  labels_decoder: 0.2750 (0.3885)  labels_encoder_unscaled: 0.3344 (0.7107)  labels_decoder_unscaled: 0.5500 (0.7770)  time: 0.0898  data: 0.0002  max mem: 2688
Test:  [1350/1613]  eta: 0:00:27  loss: 0.8769 (1.1140)  labels_encoder: 0.4949 (0.7213)  labels_decoder: 0.3734 (0.3927)  labels_encoder_unscaled: 0.4949 (0.7213)  labels_decoder_unscaled: 0.7468 (0.7855)  time: 0.0736  data: 0.0003  max mem: 2688
Test:  [1400/1613]  eta: 0:00:22  loss: 1.2246 (1.1090)  labels_encoder: 0.6809 (0.7176)  labels_decoder: 0.4031 (0.3914)  labels_encoder_unscaled: 0.6809 (0.7176)  labels_decoder_unscaled: 0.8063 (0.7828)  time: 0.0919  data: 0.0166  max mem: 2688
Test:  [1450/1613]  eta: 0:00:17  loss: 0.6327 (1.1236)  labels_encoder: 0.3952 (0.7269)  labels_decoder: 0.3131 (0.3966)  labels_encoder_unscaled: 0.3952 (0.7269)  labels_decoder_unscaled: 0.6262 (0.7932)  time: 0.0920  data: 0.0178  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.9515 (1.1409)  labels_encoder: 0.6248 (0.7401)  labels_decoder: 0.3087 (0.4009)  labels_encoder_unscaled: 0.6248 (0.7401)  labels_decoder_unscaled: 0.6173 (0.8017)  time: 0.0950  data: 0.0331  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6982 (1.1370)  labels_encoder: 0.4446 (0.7380)  labels_decoder: 0.2534 (0.3989)  labels_encoder_unscaled: 0.4446 (0.7380)  labels_decoder_unscaled: 0.5067 (0.7979)  time: 0.0970  data: 0.0467  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 1.0222 (1.1365)  labels_encoder: 0.6384 (0.7373)  labels_decoder: 0.3838 (0.3992)  labels_encoder_unscaled: 0.6384 (0.7373)  labels_decoder_unscaled: 0.7676 (0.7983)  time: 0.1152  data: 0.0518  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8281 (1.1349)  labels_encoder: 0.5394 (0.7367)  labels_decoder: 0.3098 (0.3982)  labels_encoder_unscaled: 0.5394 (0.7367)  labels_decoder_unscaled: 0.6196 (0.7964)  time: 0.1135  data: 0.0534  max mem: 2688
Test: Total time: 0:02:49 (0.1051 s / it)
Averaged stats: loss: 0.8281 (1.1349)  labels_encoder: 0.5394 (0.7367)  labels_decoder: 0.3098 (0.3982)  labels_encoder_unscaled: 0.5394 (0.7367)  labels_decoder_unscaled: 0.6196 (0.7964)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5802

dec_mAP all together: | 0.4593224375490845 |.
dec_mAP_pred | 0 : 0.5059822615830818 |.
dec_mAP_pred | 1 : 0.49718836861690335 |.
dec_mAP_pred | 2 : 0.4833852529630862 |.
dec_mAP_pred | 3 : 0.46886879791228864 |.
dec_mAP_pred | 4 : 0.45402826657590756 |.
dec_mAP_pred | 5 : 0.43987814114936025 |.
dec_mAP_pred | 6 : 0.42557068569201756 |.
dec_mAP_pred | 7 : 0.41237025675627426 |.
all decoder map: | 0.4609 |.
BaseballPitch: 0.1539
BasketballDunk: 0.7574
Billiards: 0.4532
CleanAndJerk: 0.7382
CliffDiving: 0.8055
CricketBowling: 0.4660
CricketShot: 0.2540
Diving: 0.6857
FrisbeeCatch: 0.2559
GolfSwing: 0.6462
HammerThrow: 0.8476
HighJump: 0.6292
JavelinThrow: 0.7165
LongJump: 0.7858
PoleVault: 0.8609
Shotput: 0.6801
SoccerPenalty: 0.3014
TennisSwing: 0.6155
ThrowDiscus: 0.5916
VolleyballSpiking: 0.3604
Training time 0:29:06
