Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:2
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:2
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  72.478 M, 99.825% Params, 2.305 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 10.111% Params, 0.47 GMac, 20.378% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    12.589 M, 17.339% Params, 0.818 GMac, 35.485% MACs, 
    (net): Sequential(
      12.589 M, 17.339% Params, 0.818 GMac, 35.485% MACs, 
      (0): Residual(
        4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
            (qkv): Linear(3.146 M, 4.333% Params, 0.204 GMac, 8.870% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
        (fn): PreNorm(
          2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
            (net): Sequential(
              2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
              (0): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.778% Params, 0.273 GMac, 11.826% MACs, 
            (qkv): Linear(3.146 M, 4.333% Params, 0.204 GMac, 8.870% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
        (fn): PreNorm(
          2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
            (net): Sequential(
              2.099 M, 2.891% Params, 0.136 GMac, 5.916% MACs, 
              (0): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.062% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 72.282% Params, 1.017 GMac, 44.127% MACs, 
    (layers): ModuleList(
      52.48 M, 72.282% Params, 1.017 GMac, 44.127% MACs, 
      (0): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 14.456% Params, 0.203 GMac, 8.825% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.034 GMac, 1.456% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.783% Params, 0.153 GMac, 6.641% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.446% Params, 0.068 GMac, 2.957% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.446% Params, 0.008 GMac, 0.364% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.031% Params, 0.0 GMac, 0.008% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2305258540.0
Model params: 72604716
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1405]  eta: 1:30:19  lr: 0.000100  loss: 4.9462 (4.9462)  labels_encoder: 3.6570 (3.6570)  labels_decoder: 1.2891 (1.2891)  labels_encoder_unscaled: 3.6570 (3.6570)  labels_decoder_unscaled: 2.5783 (2.5783)  time: 3.8573  data: 3.0678  max mem: 2365
Epoch: [1]  [  50/1405]  eta: 0:06:14  lr: 0.000100  loss: 1.0381 (1.5818)  labels_encoder: 0.6724 (1.0285)  labels_decoder: 0.3946 (0.5533)  labels_encoder_unscaled: 0.6724 (1.0285)  labels_decoder_unscaled: 0.7893 (1.1066)  time: 0.1912  data: 0.0003  max mem: 3197
Epoch: [1]  [ 100/1405]  eta: 0:04:47  lr: 0.000100  loss: 0.7764 (1.2147)  labels_encoder: 0.4698 (0.7793)  labels_decoder: 0.2917 (0.4355)  labels_encoder_unscaled: 0.4698 (0.7793)  labels_decoder_unscaled: 0.5834 (0.8709)  time: 0.1623  data: 0.0003  max mem: 3197
Epoch: [1]  [ 150/1405]  eta: 0:04:13  lr: 0.000100  loss: 0.7046 (1.0610)  labels_encoder: 0.4350 (0.6756)  labels_decoder: 0.2760 (0.3855)  labels_encoder_unscaled: 0.4350 (0.6756)  labels_decoder_unscaled: 0.5520 (0.7709)  time: 0.1697  data: 0.0003  max mem: 3197
Epoch: [1]  [ 200/1405]  eta: 0:03:53  lr: 0.000100  loss: 0.6254 (0.9544)  labels_encoder: 0.3921 (0.6030)  labels_decoder: 0.2514 (0.3514)  labels_encoder_unscaled: 0.3921 (0.6030)  labels_decoder_unscaled: 0.5028 (0.7028)  time: 0.1694  data: 0.0003  max mem: 3197
Epoch: [1]  [ 250/1405]  eta: 0:03:37  lr: 0.000100  loss: 0.6100 (0.8857)  labels_encoder: 0.3605 (0.5569)  labels_decoder: 0.2249 (0.3288)  labels_encoder_unscaled: 0.3605 (0.5569)  labels_decoder_unscaled: 0.4498 (0.6576)  time: 0.1699  data: 0.0003  max mem: 3197
Epoch: [1]  [ 300/1405]  eta: 0:03:23  lr: 0.000100  loss: 0.5711 (0.8358)  labels_encoder: 0.3439 (0.5237)  labels_decoder: 0.2252 (0.3121)  labels_encoder_unscaled: 0.3439 (0.5237)  labels_decoder_unscaled: 0.4503 (0.6242)  time: 0.1651  data: 0.0003  max mem: 3197
Epoch: [1]  [ 350/1405]  eta: 0:03:11  lr: 0.000100  loss: 0.5779 (0.7978)  labels_encoder: 0.3624 (0.4982)  labels_decoder: 0.2223 (0.2997)  labels_encoder_unscaled: 0.3624 (0.4982)  labels_decoder_unscaled: 0.4446 (0.5993)  time: 0.1742  data: 0.0003  max mem: 3197
Epoch: [1]  [ 400/1405]  eta: 0:03:00  lr: 0.000100  loss: 0.5138 (0.7686)  labels_encoder: 0.3068 (0.4794)  labels_decoder: 0.2101 (0.2893)  labels_encoder_unscaled: 0.3068 (0.4794)  labels_decoder_unscaled: 0.4202 (0.5785)  time: 0.1601  data: 0.0003  max mem: 3197
Epoch: [1]  [ 450/1405]  eta: 0:02:49  lr: 0.000100  loss: 0.5029 (0.7386)  labels_encoder: 0.2991 (0.4589)  labels_decoder: 0.2009 (0.2798)  labels_encoder_unscaled: 0.2991 (0.4589)  labels_decoder_unscaled: 0.4018 (0.5595)  time: 0.1640  data: 0.0003  max mem: 3197
Epoch: [1]  [ 500/1405]  eta: 0:02:40  lr: 0.000100  loss: 0.4804 (0.7170)  labels_encoder: 0.3091 (0.4444)  labels_decoder: 0.2039 (0.2726)  labels_encoder_unscaled: 0.3091 (0.4444)  labels_decoder_unscaled: 0.4078 (0.5453)  time: 0.1677  data: 0.0003  max mem: 3197
Epoch: [1]  [ 550/1405]  eta: 0:02:30  lr: 0.000100  loss: 0.5221 (0.6994)  labels_encoder: 0.3149 (0.4326)  labels_decoder: 0.2029 (0.2667)  labels_encoder_unscaled: 0.3149 (0.4326)  labels_decoder_unscaled: 0.4058 (0.5335)  time: 0.1590  data: 0.0003  max mem: 3197
Epoch: [1]  [ 600/1405]  eta: 0:02:20  lr: 0.000100  loss: 0.4810 (0.6806)  labels_encoder: 0.2653 (0.4198)  labels_decoder: 0.1917 (0.2608)  labels_encoder_unscaled: 0.2653 (0.4198)  labels_decoder_unscaled: 0.3835 (0.5216)  time: 0.1701  data: 0.0003  max mem: 3197
Epoch: [1]  [ 650/1405]  eta: 0:02:11  lr: 0.000100  loss: 0.4421 (0.6639)  labels_encoder: 0.2643 (0.4084)  labels_decoder: 0.1836 (0.2555)  labels_encoder_unscaled: 0.2643 (0.4084)  labels_decoder_unscaled: 0.3672 (0.5109)  time: 0.1562  data: 0.0003  max mem: 3197
Epoch: [1]  [ 700/1405]  eta: 0:02:02  lr: 0.000100  loss: 0.4528 (0.6498)  labels_encoder: 0.2637 (0.3989)  labels_decoder: 0.1889 (0.2509)  labels_encoder_unscaled: 0.2637 (0.3989)  labels_decoder_unscaled: 0.3778 (0.5017)  time: 0.1779  data: 0.0003  max mem: 3197
Epoch: [1]  [ 750/1405]  eta: 0:01:53  lr: 0.000100  loss: 0.4516 (0.6375)  labels_encoder: 0.2780 (0.3907)  labels_decoder: 0.1755 (0.2468)  labels_encoder_unscaled: 0.2780 (0.3907)  labels_decoder_unscaled: 0.3509 (0.4936)  time: 0.1781  data: 0.0003  max mem: 3197
Epoch: [1]  [ 800/1405]  eta: 0:01:45  lr: 0.000100  loss: 0.4067 (0.6253)  labels_encoder: 0.2333 (0.3826)  labels_decoder: 0.1664 (0.2427)  labels_encoder_unscaled: 0.2333 (0.3826)  labels_decoder_unscaled: 0.3328 (0.4854)  time: 0.1723  data: 0.0003  max mem: 3197
Epoch: [1]  [ 850/1405]  eta: 0:01:36  lr: 0.000100  loss: 0.4360 (0.6146)  labels_encoder: 0.2373 (0.3752)  labels_decoder: 0.1863 (0.2393)  labels_encoder_unscaled: 0.2373 (0.3752)  labels_decoder_unscaled: 0.3725 (0.4787)  time: 0.1870  data: 0.0003  max mem: 3197
Epoch: [1]  [ 900/1405]  eta: 0:01:27  lr: 0.000100  loss: 0.4506 (0.6051)  labels_encoder: 0.2643 (0.3691)  labels_decoder: 0.1749 (0.2360)  labels_encoder_unscaled: 0.2643 (0.3691)  labels_decoder_unscaled: 0.3499 (0.4720)  time: 0.1711  data: 0.0003  max mem: 3197
Epoch: [1]  [ 950/1405]  eta: 0:01:18  lr: 0.000100  loss: 0.3794 (0.5958)  labels_encoder: 0.2182 (0.3629)  labels_decoder: 0.1641 (0.2329)  labels_encoder_unscaled: 0.2182 (0.3629)  labels_decoder_unscaled: 0.3283 (0.4658)  time: 0.1738  data: 0.0003  max mem: 3197
Epoch: [1]  [1000/1405]  eta: 0:01:10  lr: 0.000100  loss: 0.4370 (0.5872)  labels_encoder: 0.2502 (0.3570)  labels_decoder: 0.1808 (0.2301)  labels_encoder_unscaled: 0.2502 (0.3570)  labels_decoder_unscaled: 0.3616 (0.4603)  time: 0.1759  data: 0.0003  max mem: 3197
Epoch: [1]  [1050/1405]  eta: 0:01:01  lr: 0.000100  loss: 0.3910 (0.5786)  labels_encoder: 0.2179 (0.3511)  labels_decoder: 0.1746 (0.2275)  labels_encoder_unscaled: 0.2179 (0.3511)  labels_decoder_unscaled: 0.3491 (0.4550)  time: 0.1742  data: 0.0003  max mem: 3197
Epoch: [1]  [1100/1405]  eta: 0:00:52  lr: 0.000100  loss: 0.3843 (0.5713)  labels_encoder: 0.2129 (0.3463)  labels_decoder: 0.1649 (0.2250)  labels_encoder_unscaled: 0.2129 (0.3463)  labels_decoder_unscaled: 0.3298 (0.4501)  time: 0.1660  data: 0.0003  max mem: 3197
Epoch: [1]  [1150/1405]  eta: 0:00:44  lr: 0.000100  loss: 0.4223 (0.5638)  labels_encoder: 0.2358 (0.3413)  labels_decoder: 0.1758 (0.2225)  labels_encoder_unscaled: 0.2358 (0.3413)  labels_decoder_unscaled: 0.3515 (0.4450)  time: 0.1709  data: 0.0003  max mem: 3197
Epoch: [1]  [1200/1405]  eta: 0:00:35  lr: 0.000100  loss: 0.4019 (0.5567)  labels_encoder: 0.2152 (0.3365)  labels_decoder: 0.1702 (0.2202)  labels_encoder_unscaled: 0.2152 (0.3365)  labels_decoder_unscaled: 0.3405 (0.4405)  time: 0.1726  data: 0.0005  max mem: 3197
Epoch: [1]  [1250/1405]  eta: 0:00:26  lr: 0.000100  loss: 0.3848 (0.5505)  labels_encoder: 0.2172 (0.3322)  labels_decoder: 0.1679 (0.2184)  labels_encoder_unscaled: 0.2172 (0.3322)  labels_decoder_unscaled: 0.3359 (0.4368)  time: 0.1671  data: 0.0003  max mem: 3197
Epoch: [1]  [1300/1405]  eta: 0:00:18  lr: 0.000100  loss: 0.3644 (0.5437)  labels_encoder: 0.2084 (0.3276)  labels_decoder: 0.1592 (0.2162)  labels_encoder_unscaled: 0.2084 (0.3276)  labels_decoder_unscaled: 0.3183 (0.4323)  time: 0.1761  data: 0.0003  max mem: 3197
Epoch: [1]  [1350/1405]  eta: 0:00:09  lr: 0.000100  loss: 0.3833 (0.5374)  labels_encoder: 0.1996 (0.3231)  labels_decoder: 0.1507 (0.2143)  labels_encoder_unscaled: 0.1996 (0.3231)  labels_decoder_unscaled: 0.3015 (0.4286)  time: 0.1778  data: 0.0003  max mem: 3197
Epoch: [1]  [1400/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3593 (0.5319)  labels_encoder: 0.2062 (0.3194)  labels_decoder: 0.1496 (0.2124)  labels_encoder_unscaled: 0.2062 (0.3194)  labels_decoder_unscaled: 0.2992 (0.4249)  time: 0.1522  data: 0.0005  max mem: 3197
Epoch: [1]  [1404/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3593 (0.5312)  labels_encoder: 0.2024 (0.3190)  labels_decoder: 0.1490 (0.2123)  labels_encoder_unscaled: 0.2024 (0.3190)  labels_decoder_unscaled: 0.2980 (0.4245)  time: 0.1451  data: 0.0004  max mem: 3197
Epoch: [1] Total time: 0:04:04 (0.1739 s / it)
Averaged stats: lr: 0.000100  loss: 0.3593 (0.5312)  labels_encoder: 0.2024 (0.3190)  labels_decoder: 0.1490 (0.2123)  labels_encoder_unscaled: 0.2024 (0.3190)  labels_decoder_unscaled: 0.2980 (0.4245)
Test:  [   0/1613]  eta: 1:26:29  loss: 4.1202 (4.1202)  labels_encoder: 2.4820 (2.4820)  labels_decoder: 1.6382 (1.6382)  labels_encoder_unscaled: 2.4820 (2.4820)  labels_decoder_unscaled: 3.2764 (3.2764)  time: 3.2172  data: 3.1569  max mem: 3197
Test:  [  50/1613]  eta: 0:04:33  loss: 0.3934 (0.9517)  labels_encoder: 0.2297 (0.5999)  labels_decoder: 0.1557 (0.3518)  labels_encoder_unscaled: 0.2297 (0.5999)  labels_decoder_unscaled: 0.3114 (0.7037)  time: 0.1134  data: 0.0002  max mem: 3197
Test:  [ 100/1613]  eta: 0:03:34  loss: 0.2303 (0.7525)  labels_encoder: 0.1546 (0.4761)  labels_decoder: 0.0757 (0.2763)  labels_encoder_unscaled: 0.1546 (0.4761)  labels_decoder_unscaled: 0.1515 (0.5527)  time: 0.1159  data: 0.0002  max mem: 3197
Test:  [ 150/1613]  eta: 0:03:12  loss: 0.9353 (0.7583)  labels_encoder: 0.6384 (0.4859)  labels_decoder: 0.2969 (0.2724)  labels_encoder_unscaled: 0.6384 (0.4859)  labels_decoder_unscaled: 0.5938 (0.5447)  time: 0.1196  data: 0.0002  max mem: 3197
Test:  [ 200/1613]  eta: 0:02:58  loss: 1.1423 (0.9314)  labels_encoder: 0.7560 (0.6121)  labels_decoder: 0.3741 (0.3193)  labels_encoder_unscaled: 0.7560 (0.6121)  labels_decoder_unscaled: 0.7481 (0.6386)  time: 0.1074  data: 0.0002  max mem: 3197
Test:  [ 250/1613]  eta: 0:02:46  loss: 0.4816 (0.9510)  labels_encoder: 0.2713 (0.6194)  labels_decoder: 0.2894 (0.3317)  labels_encoder_unscaled: 0.2713 (0.6194)  labels_decoder_unscaled: 0.5789 (0.6633)  time: 0.1097  data: 0.0002  max mem: 3197
Test:  [ 300/1613]  eta: 0:02:38  loss: 0.6299 (1.0021)  labels_encoder: 0.3895 (0.6531)  labels_decoder: 0.2642 (0.3489)  labels_encoder_unscaled: 0.3895 (0.6531)  labels_decoder_unscaled: 0.5284 (0.6979)  time: 0.1054  data: 0.0002  max mem: 3197
Test:  [ 350/1613]  eta: 0:02:30  loss: 1.3708 (1.0089)  labels_encoder: 0.7968 (0.6499)  labels_decoder: 0.5108 (0.3590)  labels_encoder_unscaled: 0.7968 (0.6499)  labels_decoder_unscaled: 1.0215 (0.7181)  time: 0.1144  data: 0.0002  max mem: 3197
Test:  [ 400/1613]  eta: 0:02:21  loss: 0.8378 (1.1579)  labels_encoder: 0.5143 (0.7517)  labels_decoder: 0.3444 (0.4062)  labels_encoder_unscaled: 0.5143 (0.7517)  labels_decoder_unscaled: 0.6888 (0.8125)  time: 0.1079  data: 0.0002  max mem: 3197
Test:  [ 450/1613]  eta: 0:02:13  loss: 0.7123 (1.2220)  labels_encoder: 0.4354 (0.7934)  labels_decoder: 0.2769 (0.4285)  labels_encoder_unscaled: 0.4354 (0.7934)  labels_decoder_unscaled: 0.5539 (0.8570)  time: 0.1002  data: 0.0002  max mem: 3197
Test:  [ 500/1613]  eta: 0:02:06  loss: 0.3558 (1.1619)  labels_encoder: 0.1782 (0.7519)  labels_decoder: 0.1728 (0.4100)  labels_encoder_unscaled: 0.1782 (0.7519)  labels_decoder_unscaled: 0.3456 (0.8201)  time: 0.0984  data: 0.0002  max mem: 3197
Test:  [ 550/1613]  eta: 0:01:59  loss: 0.6028 (1.1619)  labels_encoder: 0.3364 (0.7504)  labels_decoder: 0.2430 (0.4115)  labels_encoder_unscaled: 0.3364 (0.7504)  labels_decoder_unscaled: 0.4861 (0.8230)  time: 0.0976  data: 0.0002  max mem: 3197
Test:  [ 600/1613]  eta: 0:01:52  loss: 0.7432 (1.1823)  labels_encoder: 0.4862 (0.7721)  labels_decoder: 0.2784 (0.4102)  labels_encoder_unscaled: 0.4862 (0.7721)  labels_decoder_unscaled: 0.5567 (0.8204)  time: 0.1097  data: 0.0002  max mem: 3197
Test:  [ 650/1613]  eta: 0:01:45  loss: 0.8196 (1.1568)  labels_encoder: 0.5360 (0.7533)  labels_decoder: 0.3384 (0.4034)  labels_encoder_unscaled: 0.5360 (0.7533)  labels_decoder_unscaled: 0.6767 (0.8069)  time: 0.1036  data: 0.0002  max mem: 3197
Test:  [ 700/1613]  eta: 0:01:39  loss: 0.5226 (1.1248)  labels_encoder: 0.2998 (0.7306)  labels_decoder: 0.2405 (0.3942)  labels_encoder_unscaled: 0.2998 (0.7306)  labels_decoder_unscaled: 0.4809 (0.7884)  time: 0.0957  data: 0.0002  max mem: 3197
Test:  [ 750/1613]  eta: 0:01:33  loss: 0.8894 (1.1024)  labels_encoder: 0.5511 (0.7152)  labels_decoder: 0.3120 (0.3872)  labels_encoder_unscaled: 0.5511 (0.7152)  labels_decoder_unscaled: 0.6240 (0.7745)  time: 0.0957  data: 0.0002  max mem: 3197
Test:  [ 800/1613]  eta: 0:01:27  loss: 0.6506 (1.0930)  labels_encoder: 0.3628 (0.7085)  labels_decoder: 0.2465 (0.3845)  labels_encoder_unscaled: 0.3628 (0.7085)  labels_decoder_unscaled: 0.4930 (0.7690)  time: 0.0962  data: 0.0002  max mem: 3197
Test:  [ 850/1613]  eta: 0:01:22  loss: 1.2907 (1.0986)  labels_encoder: 0.9326 (0.7109)  labels_decoder: 0.5155 (0.3877)  labels_encoder_unscaled: 0.9326 (0.7109)  labels_decoder_unscaled: 1.0309 (0.7755)  time: 0.0944  data: 0.0002  max mem: 3197
Test:  [ 900/1613]  eta: 0:01:16  loss: 0.9585 (1.1031)  labels_encoder: 0.4600 (0.7118)  labels_decoder: 0.3375 (0.3913)  labels_encoder_unscaled: 0.4600 (0.7118)  labels_decoder_unscaled: 0.6749 (0.7827)  time: 0.0909  data: 0.0002  max mem: 3197
Test:  [ 950/1613]  eta: 0:01:10  loss: 0.9529 (1.0880)  labels_encoder: 0.6012 (0.7009)  labels_decoder: 0.3517 (0.3872)  labels_encoder_unscaled: 0.6012 (0.7009)  labels_decoder_unscaled: 0.7034 (0.7743)  time: 0.0978  data: 0.0002  max mem: 3197
Test:  [1000/1613]  eta: 0:01:04  loss: 0.5441 (1.0803)  labels_encoder: 0.2958 (0.6951)  labels_decoder: 0.2483 (0.3853)  labels_encoder_unscaled: 0.2958 (0.6951)  labels_decoder_unscaled: 0.4966 (0.7705)  time: 0.0999  data: 0.0002  max mem: 3197
Test:  [1050/1613]  eta: 0:00:59  loss: 0.8295 (1.0670)  labels_encoder: 0.5001 (0.6869)  labels_decoder: 0.3027 (0.3801)  labels_encoder_unscaled: 0.5001 (0.6869)  labels_decoder_unscaled: 0.6055 (0.7602)  time: 0.1094  data: 0.0002  max mem: 3197
Test:  [1100/1613]  eta: 0:00:54  loss: 0.7188 (1.0695)  labels_encoder: 0.4533 (0.6880)  labels_decoder: 0.2550 (0.3815)  labels_encoder_unscaled: 0.4533 (0.6880)  labels_decoder_unscaled: 0.5099 (0.7630)  time: 0.1016  data: 0.0002  max mem: 3197
Test:  [1150/1613]  eta: 0:00:48  loss: 0.6409 (1.0525)  labels_encoder: 0.3901 (0.6767)  labels_decoder: 0.2508 (0.3758)  labels_encoder_unscaled: 0.3901 (0.6767)  labels_decoder_unscaled: 0.5015 (0.7517)  time: 0.0959  data: 0.0002  max mem: 3197
Test:  [1200/1613]  eta: 0:00:43  loss: 0.5892 (1.0573)  labels_encoder: 0.2985 (0.6788)  labels_decoder: 0.2517 (0.3785)  labels_encoder_unscaled: 0.2985 (0.6788)  labels_decoder_unscaled: 0.5035 (0.7570)  time: 0.0978  data: 0.0002  max mem: 3197
Test:  [1250/1613]  eta: 0:00:38  loss: 0.4631 (1.0634)  labels_encoder: 0.2995 (0.6824)  labels_decoder: 0.1615 (0.3809)  labels_encoder_unscaled: 0.2995 (0.6824)  labels_decoder_unscaled: 0.3230 (0.7619)  time: 0.1074  data: 0.0002  max mem: 3197
Test:  [1300/1613]  eta: 0:00:32  loss: 0.5594 (1.0583)  labels_encoder: 0.3132 (0.6787)  labels_decoder: 0.2737 (0.3797)  labels_encoder_unscaled: 0.3132 (0.6787)  labels_decoder_unscaled: 0.5474 (0.7593)  time: 0.1025  data: 0.0002  max mem: 3197
Test:  [1350/1613]  eta: 0:00:27  loss: 0.9511 (1.0739)  labels_encoder: 0.5929 (0.6896)  labels_decoder: 0.3629 (0.3843)  labels_encoder_unscaled: 0.5929 (0.6896)  labels_decoder_unscaled: 0.7258 (0.7685)  time: 0.1149  data: 0.0002  max mem: 3197
Test:  [1400/1613]  eta: 0:00:22  loss: 1.3161 (1.0725)  labels_encoder: 0.7878 (0.6876)  labels_decoder: 0.4344 (0.3849)  labels_encoder_unscaled: 0.7878 (0.6876)  labels_decoder_unscaled: 0.8688 (0.7698)  time: 0.1009  data: 0.0002  max mem: 3197
Test:  [1450/1613]  eta: 0:00:17  loss: 0.6464 (1.0836)  labels_encoder: 0.3634 (0.6937)  labels_decoder: 0.3379 (0.3898)  labels_encoder_unscaled: 0.3634 (0.6937)  labels_decoder_unscaled: 0.6758 (0.7796)  time: 0.1166  data: 0.0002  max mem: 3197
Test:  [1500/1613]  eta: 0:00:11  loss: 0.8386 (1.0993)  labels_encoder: 0.5450 (0.7051)  labels_decoder: 0.2844 (0.3942)  labels_encoder_unscaled: 0.5450 (0.7051)  labels_decoder_unscaled: 0.5689 (0.7885)  time: 0.1068  data: 0.0002  max mem: 3197
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6545 (1.0941)  labels_encoder: 0.4141 (0.7020)  labels_decoder: 0.2674 (0.3921)  labels_encoder_unscaled: 0.4141 (0.7020)  labels_decoder_unscaled: 0.5348 (0.7843)  time: 0.1057  data: 0.0002  max mem: 3197
Test:  [1600/1613]  eta: 0:00:01  loss: 1.1059 (1.0893)  labels_encoder: 0.6239 (0.6985)  labels_decoder: 0.4473 (0.3908)  labels_encoder_unscaled: 0.6239 (0.6985)  labels_decoder_unscaled: 0.8946 (0.7816)  time: 0.1061  data: 0.0023  max mem: 3197
Test:  [1612/1613]  eta: 0:00:00  loss: 0.9828 (1.0889)  labels_encoder: 0.5923 (0.6987)  labels_decoder: 0.3904 (0.3902)  labels_encoder_unscaled: 0.5923 (0.6987)  labels_decoder_unscaled: 0.7808 (0.7804)  time: 0.0691  data: 0.0001  max mem: 3197
Test: Total time: 0:02:50 (0.1057 s / it)
Averaged stats: loss: 0.9828 (1.0889)  labels_encoder: 0.5923 (0.6987)  labels_decoder: 0.3904 (0.3902)  labels_encoder_unscaled: 0.5923 (0.6987)  labels_decoder_unscaled: 0.7808 (0.7804)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.5731

dec_mAP all together: | 0.46288057166823754 |.
dec_mAP_pred | 0 : 0.5164193862454872 |.
dec_mAP_pred | 1 : 0.5056603825959731 |.
dec_mAP_pred | 2 : 0.4904717840652929 |.
dec_mAP_pred | 3 : 0.4738626150246937 |.
dec_mAP_pred | 4 : 0.4569615037562115 |.
dec_mAP_pred | 5 : 0.4401294560882955 |.
dec_mAP_pred | 6 : 0.42391244336184786 |.
dec_mAP_pred | 7 : 0.40874938604788946 |.
all decoder map: | 0.4645 |.
BaseballPitch: 0.1462
BasketballDunk: 0.7524
Billiards: 0.3913
CleanAndJerk: 0.7615
CliffDiving: 0.8275
CricketBowling: 0.4179
CricketShot: 0.2652
Diving: 0.7246
FrisbeeCatch: 0.2565
GolfSwing: 0.6291
HammerThrow: 0.8626
HighJump: 0.5693
JavelinThrow: 0.7018
LongJump: 0.7568
PoleVault: 0.8861
Shotput: 0.6881
SoccerPenalty: 0.3101
TennisSwing: 0.5952
ThrowDiscus: 0.6223
VolleyballSpiking: 0.2985
Epoch: [2]  [   0/1405]  eta: 1:24:10  lr: 0.000010  loss: 0.4239 (0.4239)  labels_encoder: 0.2241 (0.2241)  labels_decoder: 0.1999 (0.1999)  labels_encoder_unscaled: 0.2241 (0.2241)  labels_decoder_unscaled: 0.3997 (0.3997)  time: 3.5944  data: 3.3589  max mem: 3197
Epoch: [2]  [  50/1405]  eta: 0:05:30  lr: 0.000010  loss: 0.2689 (0.3087)  labels_encoder: 0.1449 (0.1678)  labels_decoder: 0.1237 (0.1409)  labels_encoder_unscaled: 0.1449 (0.1678)  labels_decoder_unscaled: 0.2473 (0.2818)  time: 0.1719  data: 0.0003  max mem: 3197
Epoch: [2]  [ 100/1405]  eta: 0:04:29  lr: 0.000010  loss: 0.2856 (0.3006)  labels_encoder: 0.1563 (0.1641)  labels_decoder: 0.1387 (0.1366)  labels_encoder_unscaled: 0.1563 (0.1641)  labels_decoder_unscaled: 0.2775 (0.2732)  time: 0.1689  data: 0.0003  max mem: 3197
Epoch: [2]  [ 150/1405]  eta: 0:04:02  lr: 0.000010  loss: 0.2840 (0.2989)  labels_encoder: 0.1419 (0.1643)  labels_decoder: 0.1319 (0.1346)  labels_encoder_unscaled: 0.1419 (0.1643)  labels_decoder_unscaled: 0.2637 (0.2692)  time: 0.1683  data: 0.0003  max mem: 3197
Epoch: [2]  [ 200/1405]  eta: 0:03:43  lr: 0.000010  loss: 0.3073 (0.2994)  labels_encoder: 0.1630 (0.1640)  labels_decoder: 0.1391 (0.1354)  labels_encoder_unscaled: 0.1630 (0.1640)  labels_decoder_unscaled: 0.2781 (0.2708)  time: 0.1590  data: 0.0003  max mem: 3197
Epoch: [2]  [ 250/1405]  eta: 0:03:29  lr: 0.000010  loss: 0.2768 (0.2970)  labels_encoder: 0.1449 (0.1623)  labels_decoder: 0.1278 (0.1347)  labels_encoder_unscaled: 0.1449 (0.1623)  labels_decoder_unscaled: 0.2556 (0.2695)  time: 0.1682  data: 0.0003  max mem: 3197
Epoch: [2]  [ 300/1405]  eta: 0:03:17  lr: 0.000010  loss: 0.2866 (0.2943)  labels_encoder: 0.1356 (0.1602)  labels_decoder: 0.1305 (0.1341)  labels_encoder_unscaled: 0.1356 (0.1602)  labels_decoder_unscaled: 0.2611 (0.2681)  time: 0.1609  data: 0.0003  max mem: 3197
Epoch: [2]  [ 350/1405]  eta: 0:03:05  lr: 0.000010  loss: 0.2767 (0.2929)  labels_encoder: 0.1384 (0.1591)  labels_decoder: 0.1366 (0.1338)  labels_encoder_unscaled: 0.1384 (0.1591)  labels_decoder_unscaled: 0.2732 (0.2676)  time: 0.1559  data: 0.0003  max mem: 3197
Epoch: [2]  [ 400/1405]  eta: 0:02:54  lr: 0.000010  loss: 0.2687 (0.2910)  labels_encoder: 0.1314 (0.1576)  labels_decoder: 0.1247 (0.1334)  labels_encoder_unscaled: 0.1314 (0.1576)  labels_decoder_unscaled: 0.2494 (0.2669)  time: 0.1598  data: 0.0003  max mem: 3197
Epoch: [2]  [ 450/1405]  eta: 0:02:44  lr: 0.000010  loss: 0.2794 (0.2897)  labels_encoder: 0.1571 (0.1570)  labels_decoder: 0.1267 (0.1328)  labels_encoder_unscaled: 0.1571 (0.1570)  labels_decoder_unscaled: 0.2534 (0.2655)  time: 0.1689  data: 0.0003  max mem: 3197
Epoch: [2]  [ 500/1405]  eta: 0:02:35  lr: 0.000010  loss: 0.2642 (0.2875)  labels_encoder: 0.1312 (0.1553)  labels_decoder: 0.1320 (0.1322)  labels_encoder_unscaled: 0.1312 (0.1553)  labels_decoder_unscaled: 0.2641 (0.2644)  time: 0.1571  data: 0.0003  max mem: 3197
Epoch: [2]  [ 550/1405]  eta: 0:02:26  lr: 0.000010  loss: 0.2490 (0.2863)  labels_encoder: 0.1304 (0.1542)  labels_decoder: 0.1242 (0.1321)  labels_encoder_unscaled: 0.1304 (0.1542)  labels_decoder_unscaled: 0.2485 (0.2642)  time: 0.1632  data: 0.0003  max mem: 3197
Epoch: [2]  [ 600/1405]  eta: 0:02:17  lr: 0.000010  loss: 0.2548 (0.2844)  labels_encoder: 0.1355 (0.1531)  labels_decoder: 0.1200 (0.1313)  labels_encoder_unscaled: 0.1355 (0.1531)  labels_decoder_unscaled: 0.2401 (0.2626)  time: 0.1699  data: 0.0003  max mem: 3197
Epoch: [2]  [ 650/1405]  eta: 0:02:08  lr: 0.000010  loss: 0.2558 (0.2828)  labels_encoder: 0.1381 (0.1519)  labels_decoder: 0.1171 (0.1308)  labels_encoder_unscaled: 0.1381 (0.1519)  labels_decoder_unscaled: 0.2341 (0.2617)  time: 0.1672  data: 0.0003  max mem: 3197
Epoch: [2]  [ 700/1405]  eta: 0:01:59  lr: 0.000010  loss: 0.2405 (0.2820)  labels_encoder: 0.1359 (0.1515)  labels_decoder: 0.1224 (0.1306)  labels_encoder_unscaled: 0.1359 (0.1515)  labels_decoder_unscaled: 0.2449 (0.2611)  time: 0.1590  data: 0.0003  max mem: 3197
Epoch: [2]  [ 750/1405]  eta: 0:01:51  lr: 0.000010  loss: 0.2414 (0.2804)  labels_encoder: 0.1207 (0.1505)  labels_decoder: 0.1226 (0.1299)  labels_encoder_unscaled: 0.1207 (0.1505)  labels_decoder_unscaled: 0.2451 (0.2598)  time: 0.1557  data: 0.0003  max mem: 3197
Epoch: [2]  [ 800/1405]  eta: 0:01:42  lr: 0.000010  loss: 0.2664 (0.2788)  labels_encoder: 0.1455 (0.1495)  labels_decoder: 0.1128 (0.1292)  labels_encoder_unscaled: 0.1455 (0.1495)  labels_decoder_unscaled: 0.2256 (0.2585)  time: 0.1630  data: 0.0003  max mem: 3197
Epoch: [2]  [ 850/1405]  eta: 0:01:33  lr: 0.000010  loss: 0.2499 (0.2778)  labels_encoder: 0.1268 (0.1488)  labels_decoder: 0.1251 (0.1290)  labels_encoder_unscaled: 0.1268 (0.1488)  labels_decoder_unscaled: 0.2502 (0.2579)  time: 0.1674  data: 0.0003  max mem: 3197
Epoch: [2]  [ 900/1405]  eta: 0:01:25  lr: 0.000010  loss: 0.2603 (0.2770)  labels_encoder: 0.1384 (0.1484)  labels_decoder: 0.1278 (0.1286)  labels_encoder_unscaled: 0.1384 (0.1484)  labels_decoder_unscaled: 0.2556 (0.2572)  time: 0.1682  data: 0.0003  max mem: 3197
Epoch: [2]  [ 950/1405]  eta: 0:01:16  lr: 0.000010  loss: 0.2685 (0.2766)  labels_encoder: 0.1584 (0.1484)  labels_decoder: 0.1243 (0.1283)  labels_encoder_unscaled: 0.1584 (0.1484)  labels_decoder_unscaled: 0.2485 (0.2566)  time: 0.1703  data: 0.0003  max mem: 3197
Epoch: [2]  [1000/1405]  eta: 0:01:08  lr: 0.000010  loss: 0.2736 (0.2761)  labels_encoder: 0.1380 (0.1481)  labels_decoder: 0.1282 (0.1280)  labels_encoder_unscaled: 0.1380 (0.1481)  labels_decoder_unscaled: 0.2563 (0.2560)  time: 0.1710  data: 0.0003  max mem: 3197
Epoch: [2]  [1050/1405]  eta: 0:01:00  lr: 0.000010  loss: 0.2631 (0.2756)  labels_encoder: 0.1330 (0.1476)  labels_decoder: 0.1275 (0.1280)  labels_encoder_unscaled: 0.1330 (0.1476)  labels_decoder_unscaled: 0.2550 (0.2560)  time: 0.1725  data: 0.0003  max mem: 3197
Epoch: [2]  [1100/1405]  eta: 0:00:51  lr: 0.000010  loss: 0.2488 (0.2743)  labels_encoder: 0.1327 (0.1468)  labels_decoder: 0.1149 (0.1275)  labels_encoder_unscaled: 0.1327 (0.1468)  labels_decoder_unscaled: 0.2297 (0.2551)  time: 0.1759  data: 0.0004  max mem: 3197
Epoch: [2]  [1150/1405]  eta: 0:00:43  lr: 0.000010  loss: 0.2493 (0.2737)  labels_encoder: 0.1253 (0.1464)  labels_decoder: 0.1229 (0.1273)  labels_encoder_unscaled: 0.1253 (0.1464)  labels_decoder_unscaled: 0.2457 (0.2545)  time: 0.1922  data: 0.0005  max mem: 3197
Epoch: [2]  [1200/1405]  eta: 0:00:35  lr: 0.000010  loss: 0.2560 (0.2728)  labels_encoder: 0.1309 (0.1459)  labels_decoder: 0.1143 (0.1270)  labels_encoder_unscaled: 0.1309 (0.1459)  labels_decoder_unscaled: 0.2287 (0.2540)  time: 0.2129  data: 0.0005  max mem: 3197
Epoch: [2]  [1250/1405]  eta: 0:00:26  lr: 0.000010  loss: 0.2432 (0.2721)  labels_encoder: 0.1291 (0.1453)  labels_decoder: 0.1217 (0.1267)  labels_encoder_unscaled: 0.1291 (0.1453)  labels_decoder_unscaled: 0.2435 (0.2534)  time: 0.1629  data: 0.0003  max mem: 3197
Epoch: [2]  [1300/1405]  eta: 0:00:18  lr: 0.000010  loss: 0.2437 (0.2718)  labels_encoder: 0.1399 (0.1452)  labels_decoder: 0.1164 (0.1265)  labels_encoder_unscaled: 0.1399 (0.1452)  labels_decoder_unscaled: 0.2328 (0.2531)  time: 0.1727  data: 0.0003  max mem: 3197
Epoch: [2]  [1350/1405]  eta: 0:00:09  lr: 0.000010  loss: 0.2427 (0.2711)  labels_encoder: 0.1292 (0.1448)  labels_decoder: 0.1135 (0.1263)  labels_encoder_unscaled: 0.1292 (0.1448)  labels_decoder_unscaled: 0.2271 (0.2526)  time: 0.1624  data: 0.0003  max mem: 3197
Epoch: [2]  [1400/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2429 (0.2707)  labels_encoder: 0.1229 (0.1445)  labels_decoder: 0.1220 (0.1262)  labels_encoder_unscaled: 0.1229 (0.1445)  labels_decoder_unscaled: 0.2441 (0.2524)  time: 0.1451  data: 0.0004  max mem: 3197
Epoch: [2]  [1404/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2519 (0.2706)  labels_encoder: 0.1241 (0.1444)  labels_decoder: 0.1185 (0.1262)  labels_encoder_unscaled: 0.1241 (0.1444)  labels_decoder_unscaled: 0.2370 (0.2524)  time: 0.1333  data: 0.0003  max mem: 3197
Epoch: [2] Total time: 0:04:03 (0.1732 s / it)
Averaged stats: lr: 0.000010  loss: 0.2519 (0.2706)  labels_encoder: 0.1241 (0.1444)  labels_decoder: 0.1185 (0.1262)  labels_encoder_unscaled: 0.1241 (0.1444)  labels_decoder_unscaled: 0.2370 (0.2524)
Test:  [   0/1613]  eta: 1:25:08  loss: 1.1129 (1.1129)  labels_encoder: 0.7183 (0.7183)  labels_decoder: 0.3946 (0.3946)  labels_encoder_unscaled: 0.7183 (0.7183)  labels_decoder_unscaled: 0.7893 (0.7893)  time: 3.1671  data: 3.0756  max mem: 3197
Test:  [  50/1613]  eta: 0:04:28  loss: 0.4130 (0.9342)  labels_encoder: 0.2120 (0.5923)  labels_decoder: 0.1855 (0.3419)  labels_encoder_unscaled: 0.2120 (0.5923)  labels_decoder_unscaled: 0.3709 (0.6838)  time: 0.1057  data: 0.0002  max mem: 3197
Test:  [ 100/1613]  eta: 0:03:32  loss: 0.1936 (0.7710)  labels_encoder: 0.1213 (0.4966)  labels_decoder: 0.0724 (0.2744)  labels_encoder_unscaled: 0.1213 (0.4966)  labels_decoder_unscaled: 0.1447 (0.5489)  time: 0.1087  data: 0.0002  max mem: 3197
Test:  [ 150/1613]  eta: 0:03:09  loss: 0.9724 (0.7871)  labels_encoder: 0.6738 (0.5072)  labels_decoder: 0.2986 (0.2799)  labels_encoder_unscaled: 0.6738 (0.5072)  labels_decoder_unscaled: 0.5972 (0.5598)  time: 0.1080  data: 0.0002  max mem: 3197
Test:  [ 200/1613]  eta: 0:02:53  loss: 1.0870 (0.9631)  labels_encoder: 0.6898 (0.6365)  labels_decoder: 0.4059 (0.3266)  labels_encoder_unscaled: 0.6898 (0.6365)  labels_decoder_unscaled: 0.8118 (0.6532)  time: 0.1138  data: 0.0002  max mem: 3197
Test:  [ 250/1613]  eta: 0:02:43  loss: 0.5020 (1.0028)  labels_encoder: 0.4173 (0.6570)  labels_decoder: 0.1869 (0.3458)  labels_encoder_unscaled: 0.4173 (0.6570)  labels_decoder_unscaled: 0.3738 (0.6916)  time: 0.1083  data: 0.0022  max mem: 3197
Test:  [ 300/1613]  eta: 0:02:34  loss: 0.6758 (1.0224)  labels_encoder: 0.4190 (0.6700)  labels_decoder: 0.2509 (0.3523)  labels_encoder_unscaled: 0.4190 (0.6700)  labels_decoder_unscaled: 0.5018 (0.7047)  time: 0.1112  data: 0.0002  max mem: 3197
Test:  [ 350/1613]  eta: 0:02:27  loss: 1.2564 (1.0228)  labels_encoder: 0.8634 (0.6642)  labels_decoder: 0.5315 (0.3587)  labels_encoder_unscaled: 0.8634 (0.6642)  labels_decoder_unscaled: 1.0631 (0.7173)  time: 0.1049  data: 0.0002  max mem: 3197
Test:  [ 400/1613]  eta: 0:02:20  loss: 0.7542 (1.1441)  labels_encoder: 0.4564 (0.7485)  labels_decoder: 0.3497 (0.3955)  labels_encoder_unscaled: 0.4564 (0.7485)  labels_decoder_unscaled: 0.6995 (0.7911)  time: 0.1256  data: 0.0002  max mem: 3197
Test:  [ 450/1613]  eta: 0:02:13  loss: 0.9022 (1.2300)  labels_encoder: 0.5618 (0.8062)  labels_decoder: 0.3403 (0.4238)  labels_encoder_unscaled: 0.5618 (0.8062)  labels_decoder_unscaled: 0.6807 (0.8476)  time: 0.1036  data: 0.0002  max mem: 3197
Test:  [ 500/1613]  eta: 0:02:07  loss: 0.3202 (1.1819)  labels_encoder: 0.1281 (0.7729)  labels_decoder: 0.1921 (0.4090)  labels_encoder_unscaled: 0.1281 (0.7729)  labels_decoder_unscaled: 0.3842 (0.8180)  time: 0.1044  data: 0.0002  max mem: 3197
Test:  [ 550/1613]  eta: 0:02:01  loss: 0.5883 (1.1820)  labels_encoder: 0.3783 (0.7724)  labels_decoder: 0.2380 (0.4096)  labels_encoder_unscaled: 0.3783 (0.7724)  labels_decoder_unscaled: 0.4761 (0.8193)  time: 0.1114  data: 0.0002  max mem: 3197
Test:  [ 600/1613]  eta: 0:01:55  loss: 1.2279 (1.2196)  labels_encoder: 0.6699 (0.8054)  labels_decoder: 0.4658 (0.4142)  labels_encoder_unscaled: 0.6699 (0.8054)  labels_decoder_unscaled: 0.9316 (0.8283)  time: 0.1145  data: 0.0002  max mem: 3197
Test:  [ 650/1613]  eta: 0:01:49  loss: 0.7669 (1.2007)  labels_encoder: 0.4333 (0.7883)  labels_decoder: 0.3845 (0.4124)  labels_encoder_unscaled: 0.4333 (0.7883)  labels_decoder_unscaled: 0.7689 (0.8249)  time: 0.1372  data: 0.0002  max mem: 3197
Test:  [ 700/1613]  eta: 0:01:42  loss: 0.5682 (1.1737)  labels_encoder: 0.2894 (0.7688)  labels_decoder: 0.2384 (0.4049)  labels_encoder_unscaled: 0.2894 (0.7688)  labels_decoder_unscaled: 0.4768 (0.8098)  time: 0.1126  data: 0.0002  max mem: 3197
Test:  [ 750/1613]  eta: 0:01:37  loss: 0.8522 (1.1552)  labels_encoder: 0.5162 (0.7545)  labels_decoder: 0.3360 (0.4007)  labels_encoder_unscaled: 0.5162 (0.7545)  labels_decoder_unscaled: 0.6720 (0.8014)  time: 0.1241  data: 0.0002  max mem: 3197
Test:  [ 800/1613]  eta: 0:01:31  loss: 0.8587 (1.1468)  labels_encoder: 0.5818 (0.7492)  labels_decoder: 0.2941 (0.3976)  labels_encoder_unscaled: 0.5818 (0.7492)  labels_decoder_unscaled: 0.5881 (0.7953)  time: 0.1055  data: 0.0002  max mem: 3197
Test:  [ 850/1613]  eta: 0:01:25  loss: 1.6553 (1.1508)  labels_encoder: 1.0896 (0.7493)  labels_decoder: 0.6079 (0.4015)  labels_encoder_unscaled: 1.0896 (0.7493)  labels_decoder_unscaled: 1.2157 (0.8030)  time: 0.0960  data: 0.0017  max mem: 3197
Test:  [ 900/1613]  eta: 0:01:19  loss: 0.7390 (1.1663)  labels_encoder: 0.4330 (0.7608)  labels_decoder: 0.3103 (0.4055)  labels_encoder_unscaled: 0.4330 (0.7608)  labels_decoder_unscaled: 0.6205 (0.8110)  time: 0.1115  data: 0.0002  max mem: 3197
Test:  [ 950/1613]  eta: 0:01:13  loss: 1.1123 (1.1548)  labels_encoder: 0.7543 (0.7524)  labels_decoder: 0.4085 (0.4024)  labels_encoder_unscaled: 0.7543 (0.7524)  labels_decoder_unscaled: 0.8169 (0.8047)  time: 0.1035  data: 0.0002  max mem: 3197
Test:  [1000/1613]  eta: 0:01:07  loss: 0.5987 (1.1386)  labels_encoder: 0.3454 (0.7406)  labels_decoder: 0.2712 (0.3980)  labels_encoder_unscaled: 0.3454 (0.7406)  labels_decoder_unscaled: 0.5424 (0.7961)  time: 0.1105  data: 0.0003  max mem: 3197
Test:  [1050/1613]  eta: 0:01:01  loss: 0.8298 (1.1260)  labels_encoder: 0.4933 (0.7321)  labels_decoder: 0.3232 (0.3938)  labels_encoder_unscaled: 0.4933 (0.7321)  labels_decoder_unscaled: 0.6464 (0.7876)  time: 0.1023  data: 0.0002  max mem: 3197
Test:  [1100/1613]  eta: 0:00:56  loss: 1.0452 (1.1408)  labels_encoder: 0.6752 (0.7438)  labels_decoder: 0.3407 (0.3971)  labels_encoder_unscaled: 0.6752 (0.7438)  labels_decoder_unscaled: 0.6814 (0.7942)  time: 0.0971  data: 0.0002  max mem: 3197
Test:  [1150/1613]  eta: 0:00:50  loss: 0.5929 (1.1260)  labels_encoder: 0.3166 (0.7334)  labels_decoder: 0.2517 (0.3927)  labels_encoder_unscaled: 0.3166 (0.7334)  labels_decoder_unscaled: 0.5035 (0.7853)  time: 0.0828  data: 0.0002  max mem: 3197
Test:  [1200/1613]  eta: 0:00:44  loss: 0.5691 (1.1308)  labels_encoder: 0.3633 (0.7356)  labels_decoder: 0.2474 (0.3952)  labels_encoder_unscaled: 0.3633 (0.7356)  labels_decoder_unscaled: 0.4947 (0.7904)  time: 0.0938  data: 0.0002  max mem: 3197
Test:  [1250/1613]  eta: 0:00:39  loss: 0.4348 (1.1336)  labels_encoder: 0.2812 (0.7372)  labels_decoder: 0.2298 (0.3964)  labels_encoder_unscaled: 0.2812 (0.7372)  labels_decoder_unscaled: 0.4596 (0.7929)  time: 0.1014  data: 0.0002  max mem: 3197
Test:  [1300/1613]  eta: 0:00:34  loss: 0.8800 (1.1295)  labels_encoder: 0.5902 (0.7342)  labels_decoder: 0.3007 (0.3953)  labels_encoder_unscaled: 0.5902 (0.7342)  labels_decoder_unscaled: 0.6014 (0.7906)  time: 0.1221  data: 0.0003  max mem: 3197
Test:  [1350/1613]  eta: 0:00:28  loss: 1.0205 (1.1485)  labels_encoder: 0.6367 (0.7478)  labels_decoder: 0.4043 (0.4007)  labels_encoder_unscaled: 0.6367 (0.7478)  labels_decoder_unscaled: 0.8087 (0.8014)  time: 0.1259  data: 0.0003  max mem: 3197
Test:  [1400/1613]  eta: 0:00:23  loss: 1.0921 (1.1416)  labels_encoder: 0.6610 (0.7429)  labels_decoder: 0.3914 (0.3986)  labels_encoder_unscaled: 0.6610 (0.7429)  labels_decoder_unscaled: 0.7828 (0.7972)  time: 0.0959  data: 0.0002  max mem: 3197
Test:  [1450/1613]  eta: 0:00:17  loss: 0.6595 (1.1540)  labels_encoder: 0.4371 (0.7504)  labels_decoder: 0.4048 (0.4037)  labels_encoder_unscaled: 0.4371 (0.7504)  labels_decoder_unscaled: 0.8096 (0.8073)  time: 0.1101  data: 0.0002  max mem: 3197
Test:  [1500/1613]  eta: 0:00:12  loss: 0.7845 (1.1629)  labels_encoder: 0.4957 (0.7577)  labels_decoder: 0.2365 (0.4052)  labels_encoder_unscaled: 0.4957 (0.7577)  labels_decoder_unscaled: 0.4730 (0.8103)  time: 0.1055  data: 0.0024  max mem: 3197
Test:  [1550/1613]  eta: 0:00:06  loss: 0.7236 (1.1572)  labels_encoder: 0.4712 (0.7542)  labels_decoder: 0.2655 (0.4029)  labels_encoder_unscaled: 0.4712 (0.7542)  labels_decoder_unscaled: 0.5310 (0.8059)  time: 0.0997  data: 0.0002  max mem: 3197
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8015 (1.1518)  labels_encoder: 0.4896 (0.7500)  labels_decoder: 0.3119 (0.4018)  labels_encoder_unscaled: 0.4896 (0.7500)  labels_decoder_unscaled: 0.6239 (0.8035)  time: 0.0952  data: 0.0002  max mem: 3197
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5882 (1.1489)  labels_encoder: 0.3629 (0.7484)  labels_decoder: 0.2368 (0.4005)  labels_encoder_unscaled: 0.3629 (0.7484)  labels_decoder_unscaled: 0.4737 (0.8011)  time: 0.0694  data: 0.0001  max mem: 3197
Test: Total time: 0:02:55 (0.1088 s / it)
Averaged stats: loss: 0.5882 (1.1489)  labels_encoder: 0.3629 (0.7484)  labels_decoder: 0.2368 (0.4005)  labels_encoder_unscaled: 0.3629 (0.7484)  labels_decoder_unscaled: 0.4737 (0.8011)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5776

dec_mAP all together: | 0.4586640074846698 |.
dec_mAP_pred | 0 : 0.5059552276982313 |.
dec_mAP_pred | 1 : 0.4967652403849933 |.
dec_mAP_pred | 2 : 0.4835650170516469 |.
dec_mAP_pred | 3 : 0.46901610064539784 |.
dec_mAP_pred | 4 : 0.4537032492934686 |.
dec_mAP_pred | 5 : 0.43850144138976416 |.
dec_mAP_pred | 6 : 0.42383992405158616 |.
dec_mAP_pred | 7 : 0.4100174673052651 |.
all decoder map: | 0.4602 |.
BaseballPitch: 0.1567
BasketballDunk: 0.7637
Billiards: 0.4189
CleanAndJerk: 0.7499
CliffDiving: 0.8032
CricketBowling: 0.4597
CricketShot: 0.2548
Diving: 0.7050
FrisbeeCatch: 0.2879
GolfSwing: 0.5685
HammerThrow: 0.8552
HighJump: 0.6333
JavelinThrow: 0.6771
LongJump: 0.7692
PoleVault: 0.8759
Shotput: 0.6795
SoccerPenalty: 0.3457
TennisSwing: 0.5944
ThrowDiscus: 0.6427
VolleyballSpiking: 0.3098
Epoch: [3]  [   0/1405]  eta: 1:14:39  lr: 0.000001  loss: 0.2280 (0.2280)  labels_encoder: 0.1182 (0.1182)  labels_decoder: 0.1098 (0.1098)  labels_encoder_unscaled: 0.1182 (0.1182)  labels_decoder_unscaled: 0.2195 (0.2195)  time: 3.1886  data: 2.9179  max mem: 3197
Epoch: [3]  [  50/1405]  eta: 0:05:24  lr: 0.000001  loss: 0.2431 (0.2311)  labels_encoder: 0.1322 (0.1212)  labels_decoder: 0.1146 (0.1099)  labels_encoder_unscaled: 0.1322 (0.1212)  labels_decoder_unscaled: 0.2291 (0.2198)  time: 0.1670  data: 0.0003  max mem: 3197
Epoch: [3]  [ 100/1405]  eta: 0:04:25  lr: 0.000001  loss: 0.2332 (0.2372)  labels_encoder: 0.1137 (0.1229)  labels_decoder: 0.1176 (0.1143)  labels_encoder_unscaled: 0.1137 (0.1229)  labels_decoder_unscaled: 0.2353 (0.2285)  time: 0.1630  data: 0.0003  max mem: 3197
Epoch: [3]  [ 150/1405]  eta: 0:03:59  lr: 0.000001  loss: 0.2440 (0.2360)  labels_encoder: 0.1363 (0.1219)  labels_decoder: 0.1153 (0.1141)  labels_encoder_unscaled: 0.1363 (0.1219)  labels_decoder_unscaled: 0.2307 (0.2283)  time: 0.1600  data: 0.0003  max mem: 3197
Epoch: [3]  [ 200/1405]  eta: 0:03:42  lr: 0.000001  loss: 0.2326 (0.2360)  labels_encoder: 0.1188 (0.1214)  labels_decoder: 0.1153 (0.1146)  labels_encoder_unscaled: 0.1188 (0.1214)  labels_decoder_unscaled: 0.2306 (0.2292)  time: 0.1662  data: 0.0003  max mem: 3197
Epoch: [3]  [ 250/1405]  eta: 0:03:28  lr: 0.000001  loss: 0.2410 (0.2373)  labels_encoder: 0.1232 (0.1219)  labels_decoder: 0.1209 (0.1154)  labels_encoder_unscaled: 0.1232 (0.1219)  labels_decoder_unscaled: 0.2419 (0.2307)  time: 0.1624  data: 0.0003  max mem: 3197
Epoch: [3]  [ 300/1405]  eta: 0:03:17  lr: 0.000001  loss: 0.2365 (0.2366)  labels_encoder: 0.1165 (0.1213)  labels_decoder: 0.1164 (0.1153)  labels_encoder_unscaled: 0.1165 (0.1213)  labels_decoder_unscaled: 0.2328 (0.2306)  time: 0.1682  data: 0.0003  max mem: 3197
Epoch: [3]  [ 350/1405]  eta: 0:03:06  lr: 0.000001  loss: 0.2348 (0.2360)  labels_encoder: 0.1163 (0.1207)  labels_decoder: 0.1142 (0.1153)  labels_encoder_unscaled: 0.1163 (0.1207)  labels_decoder_unscaled: 0.2284 (0.2306)  time: 0.1552  data: 0.0003  max mem: 3197
Epoch: [3]  [ 400/1405]  eta: 0:02:56  lr: 0.000001  loss: 0.2338 (0.2374)  labels_encoder: 0.1129 (0.1219)  labels_decoder: 0.1197 (0.1155)  labels_encoder_unscaled: 0.1129 (0.1219)  labels_decoder_unscaled: 0.2394 (0.2310)  time: 0.1707  data: 0.0003  max mem: 3197
Epoch: [3]  [ 450/1405]  eta: 0:02:46  lr: 0.000001  loss: 0.2308 (0.2383)  labels_encoder: 0.1320 (0.1227)  labels_decoder: 0.1165 (0.1157)  labels_encoder_unscaled: 0.1320 (0.1227)  labels_decoder_unscaled: 0.2329 (0.2313)  time: 0.1703  data: 0.0003  max mem: 3197
Epoch: [3]  [ 500/1405]  eta: 0:02:37  lr: 0.000001  loss: 0.2302 (0.2378)  labels_encoder: 0.1121 (0.1222)  labels_decoder: 0.1127 (0.1156)  labels_encoder_unscaled: 0.1121 (0.1222)  labels_decoder_unscaled: 0.2253 (0.2311)  time: 0.1603  data: 0.0003  max mem: 3197
Epoch: [3]  [ 550/1405]  eta: 0:02:28  lr: 0.000001  loss: 0.2403 (0.2386)  labels_encoder: 0.1236 (0.1229)  labels_decoder: 0.1129 (0.1157)  labels_encoder_unscaled: 0.1236 (0.1229)  labels_decoder_unscaled: 0.2258 (0.2314)  time: 0.1624  data: 0.0003  max mem: 3197
Epoch: [3]  [ 600/1405]  eta: 0:02:18  lr: 0.000001  loss: 0.2683 (0.2390)  labels_encoder: 0.1435 (0.1232)  labels_decoder: 0.1130 (0.1158)  labels_encoder_unscaled: 0.1435 (0.1232)  labels_decoder_unscaled: 0.2260 (0.2315)  time: 0.1655  data: 0.0003  max mem: 3197
Epoch: [3]  [ 650/1405]  eta: 0:02:09  lr: 0.000001  loss: 0.2160 (0.2386)  labels_encoder: 0.1015 (0.1227)  labels_decoder: 0.1109 (0.1159)  labels_encoder_unscaled: 0.1015 (0.1227)  labels_decoder_unscaled: 0.2219 (0.2318)  time: 0.1680  data: 0.0003  max mem: 3197
Epoch: [3]  [ 700/1405]  eta: 0:02:00  lr: 0.000001  loss: 0.2154 (0.2385)  labels_encoder: 0.1031 (0.1227)  labels_decoder: 0.1028 (0.1157)  labels_encoder_unscaled: 0.1031 (0.1227)  labels_decoder_unscaled: 0.2056 (0.2315)  time: 0.1606  data: 0.0003  max mem: 3197
Epoch: [3]  [ 750/1405]  eta: 0:01:52  lr: 0.000001  loss: 0.2312 (0.2385)  labels_encoder: 0.1201 (0.1228)  labels_decoder: 0.1063 (0.1156)  labels_encoder_unscaled: 0.1201 (0.1228)  labels_decoder_unscaled: 0.2127 (0.2312)  time: 0.1641  data: 0.0003  max mem: 3197
Epoch: [3]  [ 800/1405]  eta: 0:01:43  lr: 0.000001  loss: 0.2529 (0.2385)  labels_encoder: 0.1246 (0.1229)  labels_decoder: 0.1137 (0.1157)  labels_encoder_unscaled: 0.1246 (0.1229)  labels_decoder_unscaled: 0.2273 (0.2314)  time: 0.1582  data: 0.0003  max mem: 3197
Epoch: [3]  [ 850/1405]  eta: 0:01:34  lr: 0.000001  loss: 0.2233 (0.2383)  labels_encoder: 0.1177 (0.1227)  labels_decoder: 0.1142 (0.1156)  labels_encoder_unscaled: 0.1177 (0.1227)  labels_decoder_unscaled: 0.2283 (0.2311)  time: 0.1650  data: 0.0003  max mem: 3197
Epoch: [3]  [ 900/1405]  eta: 0:01:25  lr: 0.000001  loss: 0.2417 (0.2387)  labels_encoder: 0.1243 (0.1228)  labels_decoder: 0.1220 (0.1159)  labels_encoder_unscaled: 0.1243 (0.1228)  labels_decoder_unscaled: 0.2440 (0.2318)  time: 0.1762  data: 0.0003  max mem: 3197
Epoch: [3]  [ 950/1405]  eta: 0:01:17  lr: 0.000001  loss: 0.2290 (0.2382)  labels_encoder: 0.1077 (0.1224)  labels_decoder: 0.1105 (0.1158)  labels_encoder_unscaled: 0.1077 (0.1224)  labels_decoder_unscaled: 0.2210 (0.2317)  time: 0.1671  data: 0.0003  max mem: 3197
Epoch: [3]  [1000/1405]  eta: 0:01:08  lr: 0.000001  loss: 0.2419 (0.2382)  labels_encoder: 0.1193 (0.1223)  labels_decoder: 0.1098 (0.1159)  labels_encoder_unscaled: 0.1193 (0.1223)  labels_decoder_unscaled: 0.2197 (0.2317)  time: 0.1629  data: 0.0003  max mem: 3197
Epoch: [3]  [1050/1405]  eta: 0:01:00  lr: 0.000001  loss: 0.2287 (0.2377)  labels_encoder: 0.1132 (0.1220)  labels_decoder: 0.1148 (0.1157)  labels_encoder_unscaled: 0.1132 (0.1220)  labels_decoder_unscaled: 0.2295 (0.2313)  time: 0.1635  data: 0.0003  max mem: 3197
Epoch: [3]  [1100/1405]  eta: 0:00:51  lr: 0.000001  loss: 0.2334 (0.2377)  labels_encoder: 0.1229 (0.1222)  labels_decoder: 0.1106 (0.1155)  labels_encoder_unscaled: 0.1229 (0.1222)  labels_decoder_unscaled: 0.2212 (0.2311)  time: 0.1631  data: 0.0003  max mem: 3197
Epoch: [3]  [1150/1405]  eta: 0:00:42  lr: 0.000001  loss: 0.2319 (0.2374)  labels_encoder: 0.1118 (0.1220)  labels_decoder: 0.1156 (0.1154)  labels_encoder_unscaled: 0.1118 (0.1220)  labels_decoder_unscaled: 0.2311 (0.2309)  time: 0.1674  data: 0.0003  max mem: 3197
Epoch: [3]  [1200/1405]  eta: 0:00:34  lr: 0.000001  loss: 0.2385 (0.2376)  labels_encoder: 0.1024 (0.1220)  labels_decoder: 0.1177 (0.1156)  labels_encoder_unscaled: 0.1024 (0.1220)  labels_decoder_unscaled: 0.2355 (0.2312)  time: 0.1687  data: 0.0003  max mem: 3197
Epoch: [3]  [1250/1405]  eta: 0:00:26  lr: 0.000001  loss: 0.2211 (0.2376)  labels_encoder: 0.1138 (0.1222)  labels_decoder: 0.1054 (0.1154)  labels_encoder_unscaled: 0.1138 (0.1222)  labels_decoder_unscaled: 0.2107 (0.2308)  time: 0.1679  data: 0.0003  max mem: 3197
Epoch: [3]  [1300/1405]  eta: 0:00:17  lr: 0.000001  loss: 0.2349 (0.2373)  labels_encoder: 0.1164 (0.1219)  labels_decoder: 0.1150 (0.1153)  labels_encoder_unscaled: 0.1164 (0.1219)  labels_decoder_unscaled: 0.2300 (0.2307)  time: 0.1695  data: 0.0003  max mem: 3197
Epoch: [3]  [1350/1405]  eta: 0:00:09  lr: 0.000001  loss: 0.2123 (0.2371)  labels_encoder: 0.1052 (0.1218)  labels_decoder: 0.1150 (0.1153)  labels_encoder_unscaled: 0.1052 (0.1218)  labels_decoder_unscaled: 0.2300 (0.2305)  time: 0.1625  data: 0.0003  max mem: 3197
Epoch: [3]  [1400/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2380 (0.2376)  labels_encoder: 0.1290 (0.1221)  labels_decoder: 0.1147 (0.1154)  labels_encoder_unscaled: 0.1290 (0.1221)  labels_decoder_unscaled: 0.2294 (0.2309)  time: 0.1430  data: 0.0004  max mem: 3197
Epoch: [3]  [1404/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2380 (0.2377)  labels_encoder: 0.1281 (0.1222)  labels_decoder: 0.1154 (0.1155)  labels_encoder_unscaled: 0.1281 (0.1222)  labels_decoder_unscaled: 0.2309 (0.2309)  time: 0.1430  data: 0.0003  max mem: 3197
Epoch: [3] Total time: 0:03:56 (0.1681 s / it)
Averaged stats: lr: 0.000001  loss: 0.2380 (0.2377)  labels_encoder: 0.1281 (0.1222)  labels_decoder: 0.1154 (0.1155)  labels_encoder_unscaled: 0.1281 (0.1222)  labels_decoder_unscaled: 0.2309 (0.2309)
Test:  [   0/1613]  eta: 1:26:11  loss: 1.6966 (1.6966)  labels_encoder: 1.1220 (1.1220)  labels_decoder: 0.5746 (0.5746)  labels_encoder_unscaled: 1.1220 (1.1220)  labels_decoder_unscaled: 1.1491 (1.1491)  time: 3.2063  data: 3.1436  max mem: 3197
Test:  [  50/1613]  eta: 0:04:32  loss: 0.4580 (0.9124)  labels_encoder: 0.2288 (0.5822)  labels_decoder: 0.1887 (0.3301)  labels_encoder_unscaled: 0.2288 (0.5822)  labels_decoder_unscaled: 0.3775 (0.6603)  time: 0.1127  data: 0.0002  max mem: 3197
Test:  [ 100/1613]  eta: 0:03:36  loss: 0.2641 (0.7715)  labels_encoder: 0.1695 (0.4975)  labels_decoder: 0.0946 (0.2740)  labels_encoder_unscaled: 0.1695 (0.4975)  labels_decoder_unscaled: 0.1893 (0.5480)  time: 0.1074  data: 0.0002  max mem: 3197
Test:  [ 150/1613]  eta: 0:03:12  loss: 0.9654 (0.7887)  labels_encoder: 0.6225 (0.5104)  labels_decoder: 0.2998 (0.2783)  labels_encoder_unscaled: 0.6225 (0.5104)  labels_decoder_unscaled: 0.5995 (0.5567)  time: 0.1063  data: 0.0002  max mem: 3197
Test:  [ 200/1613]  eta: 0:02:57  loss: 1.0831 (0.9476)  labels_encoder: 0.6880 (0.6252)  labels_decoder: 0.3951 (0.3224)  labels_encoder_unscaled: 0.6880 (0.6252)  labels_decoder_unscaled: 0.7901 (0.6448)  time: 0.1065  data: 0.0002  max mem: 3197
Test:  [ 250/1613]  eta: 0:02:45  loss: 0.4957 (0.9982)  labels_encoder: 0.4080 (0.6543)  labels_decoder: 0.2391 (0.3439)  labels_encoder_unscaled: 0.4080 (0.6543)  labels_decoder_unscaled: 0.4783 (0.6878)  time: 0.1124  data: 0.0002  max mem: 3197
Test:  [ 300/1613]  eta: 0:02:36  loss: 0.6815 (1.0218)  labels_encoder: 0.4386 (0.6733)  labels_decoder: 0.2495 (0.3485)  labels_encoder_unscaled: 0.4386 (0.6733)  labels_decoder_unscaled: 0.4990 (0.6969)  time: 0.1109  data: 0.0002  max mem: 3197
Test:  [ 350/1613]  eta: 0:02:29  loss: 1.2470 (1.0232)  labels_encoder: 0.7987 (0.6669)  labels_decoder: 0.5267 (0.3563)  labels_encoder_unscaled: 0.7987 (0.6669)  labels_decoder_unscaled: 1.0533 (0.7127)  time: 0.1100  data: 0.0002  max mem: 3197
Test:  [ 400/1613]  eta: 0:02:21  loss: 0.8611 (1.1380)  labels_encoder: 0.4528 (0.7470)  labels_decoder: 0.3565 (0.3910)  labels_encoder_unscaled: 0.4528 (0.7470)  labels_decoder_unscaled: 0.7129 (0.7820)  time: 0.1062  data: 0.0002  max mem: 3197
Test:  [ 450/1613]  eta: 0:02:14  loss: 0.8982 (1.2181)  labels_encoder: 0.5701 (0.8009)  labels_decoder: 0.3281 (0.4172)  labels_encoder_unscaled: 0.5701 (0.8009)  labels_decoder_unscaled: 0.6563 (0.8343)  time: 0.1001  data: 0.0002  max mem: 3197
Test:  [ 500/1613]  eta: 0:02:07  loss: 0.3509 (1.1726)  labels_encoder: 0.1405 (0.7688)  labels_decoder: 0.2104 (0.4038)  labels_encoder_unscaled: 0.1405 (0.7688)  labels_decoder_unscaled: 0.4208 (0.8077)  time: 0.1134  data: 0.0003  max mem: 3197
Test:  [ 550/1613]  eta: 0:02:00  loss: 0.6006 (1.1687)  labels_encoder: 0.3526 (0.7649)  labels_decoder: 0.2480 (0.4038)  labels_encoder_unscaled: 0.3526 (0.7649)  labels_decoder_unscaled: 0.4961 (0.8076)  time: 0.1028  data: 0.0002  max mem: 3197
Test:  [ 600/1613]  eta: 0:01:54  loss: 1.3095 (1.2098)  labels_encoder: 0.7822 (0.8010)  labels_decoder: 0.4832 (0.4087)  labels_encoder_unscaled: 0.7822 (0.8010)  labels_decoder_unscaled: 0.9664 (0.8175)  time: 0.1039  data: 0.0002  max mem: 3197
Test:  [ 650/1613]  eta: 0:01:48  loss: 0.8372 (1.1913)  labels_encoder: 0.4914 (0.7840)  labels_decoder: 0.3915 (0.4072)  labels_encoder_unscaled: 0.4914 (0.7840)  labels_decoder_unscaled: 0.7831 (0.8145)  time: 0.1157  data: 0.0002  max mem: 3197
Test:  [ 700/1613]  eta: 0:01:42  loss: 0.5722 (1.1611)  labels_encoder: 0.3080 (0.7623)  labels_decoder: 0.2380 (0.3988)  labels_encoder_unscaled: 0.3080 (0.7623)  labels_decoder_unscaled: 0.4760 (0.7975)  time: 0.0906  data: 0.0002  max mem: 3197
Test:  [ 750/1613]  eta: 0:01:36  loss: 0.8413 (1.1450)  labels_encoder: 0.5252 (0.7499)  labels_decoder: 0.3160 (0.3950)  labels_encoder_unscaled: 0.5252 (0.7499)  labels_decoder_unscaled: 0.6321 (0.7900)  time: 0.1119  data: 0.0002  max mem: 3197
Test:  [ 800/1613]  eta: 0:01:30  loss: 0.9696 (1.1388)  labels_encoder: 0.6539 (0.7461)  labels_decoder: 0.3149 (0.3927)  labels_encoder_unscaled: 0.6539 (0.7461)  labels_decoder_unscaled: 0.6298 (0.7854)  time: 0.1121  data: 0.0002  max mem: 3197
Test:  [ 850/1613]  eta: 0:01:24  loss: 1.8379 (1.1470)  labels_encoder: 1.1620 (0.7486)  labels_decoder: 0.6867 (0.3984)  labels_encoder_unscaled: 1.1620 (0.7486)  labels_decoder_unscaled: 1.3733 (0.7968)  time: 0.1125  data: 0.0002  max mem: 3197
Test:  [ 900/1613]  eta: 0:01:19  loss: 0.8474 (1.1655)  labels_encoder: 0.5055 (0.7623)  labels_decoder: 0.3316 (0.4032)  labels_encoder_unscaled: 0.5055 (0.7623)  labels_decoder_unscaled: 0.6631 (0.8064)  time: 0.1116  data: 0.0002  max mem: 3197
Test:  [ 950/1613]  eta: 0:01:13  loss: 1.1517 (1.1547)  labels_encoder: 0.7568 (0.7548)  labels_decoder: 0.3777 (0.3998)  labels_encoder_unscaled: 0.7568 (0.7548)  labels_decoder_unscaled: 0.7555 (0.7997)  time: 0.1035  data: 0.0002  max mem: 3197
Test:  [1000/1613]  eta: 0:01:07  loss: 0.5702 (1.1387)  labels_encoder: 0.3254 (0.7433)  labels_decoder: 0.2448 (0.3954)  labels_encoder_unscaled: 0.3254 (0.7433)  labels_decoder_unscaled: 0.4896 (0.7909)  time: 0.1069  data: 0.0002  max mem: 3197
Test:  [1050/1613]  eta: 0:01:01  loss: 0.8632 (1.1267)  labels_encoder: 0.5300 (0.7354)  labels_decoder: 0.3184 (0.3913)  labels_encoder_unscaled: 0.5300 (0.7354)  labels_decoder_unscaled: 0.6368 (0.7826)  time: 0.1078  data: 0.0002  max mem: 3197
Test:  [1100/1613]  eta: 0:00:56  loss: 0.8880 (1.1429)  labels_encoder: 0.5718 (0.7479)  labels_decoder: 0.3210 (0.3950)  labels_encoder_unscaled: 0.5718 (0.7479)  labels_decoder_unscaled: 0.6420 (0.7899)  time: 0.1009  data: 0.0002  max mem: 3197
Test:  [1150/1613]  eta: 0:00:50  loss: 0.7355 (1.1281)  labels_encoder: 0.4443 (0.7375)  labels_decoder: 0.2648 (0.3907)  labels_encoder_unscaled: 0.4443 (0.7375)  labels_decoder_unscaled: 0.5295 (0.7813)  time: 0.0957  data: 0.0002  max mem: 3197
Test:  [1200/1613]  eta: 0:00:45  loss: 0.5600 (1.1321)  labels_encoder: 0.3259 (0.7394)  labels_decoder: 0.2344 (0.3927)  labels_encoder_unscaled: 0.3259 (0.7394)  labels_decoder_unscaled: 0.4687 (0.7854)  time: 0.1144  data: 0.0002  max mem: 3197
Test:  [1250/1613]  eta: 0:00:39  loss: 0.4193 (1.1344)  labels_encoder: 0.2594 (0.7407)  labels_decoder: 0.1980 (0.3938)  labels_encoder_unscaled: 0.2594 (0.7407)  labels_decoder_unscaled: 0.3960 (0.7875)  time: 0.1036  data: 0.0002  max mem: 3197
Test:  [1300/1613]  eta: 0:00:34  loss: 0.9494 (1.1294)  labels_encoder: 0.6337 (0.7374)  labels_decoder: 0.3431 (0.3920)  labels_encoder_unscaled: 0.6337 (0.7374)  labels_decoder_unscaled: 0.6862 (0.7840)  time: 0.1012  data: 0.0002  max mem: 3197
Test:  [1350/1613]  eta: 0:00:28  loss: 0.9948 (1.1474)  labels_encoder: 0.6215 (0.7507)  labels_decoder: 0.3789 (0.3967)  labels_encoder_unscaled: 0.6215 (0.7507)  labels_decoder_unscaled: 0.7579 (0.7935)  time: 0.1066  data: 0.0002  max mem: 3197
Test:  [1400/1613]  eta: 0:00:23  loss: 1.0100 (1.1393)  labels_encoder: 0.6293 (0.7449)  labels_decoder: 0.3879 (0.3944)  labels_encoder_unscaled: 0.6293 (0.7449)  labels_decoder_unscaled: 0.7759 (0.7888)  time: 0.1175  data: 0.0002  max mem: 3197
Test:  [1450/1613]  eta: 0:00:17  loss: 0.6458 (1.1476)  labels_encoder: 0.4328 (0.7496)  labels_decoder: 0.3835 (0.3980)  labels_encoder_unscaled: 0.4328 (0.7496)  labels_decoder_unscaled: 0.7670 (0.7961)  time: 0.1340  data: 0.0002  max mem: 3197
Test:  [1500/1613]  eta: 0:00:12  loss: 0.6914 (1.1545)  labels_encoder: 0.4543 (0.7553)  labels_decoder: 0.2105 (0.3992)  labels_encoder_unscaled: 0.4543 (0.7553)  labels_decoder_unscaled: 0.4210 (0.7984)  time: 0.1116  data: 0.0002  max mem: 3197
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6832 (1.1505)  labels_encoder: 0.4452 (0.7532)  labels_decoder: 0.2416 (0.3973)  labels_encoder_unscaled: 0.4452 (0.7532)  labels_decoder_unscaled: 0.4833 (0.7947)  time: 0.1007  data: 0.0002  max mem: 3197
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9588 (1.1457)  labels_encoder: 0.5656 (0.7494)  labels_decoder: 0.3914 (0.3963)  labels_encoder_unscaled: 0.5656 (0.7494)  labels_decoder_unscaled: 0.7828 (0.7925)  time: 0.0928  data: 0.0002  max mem: 3197
Test:  [1612/1613]  eta: 0:00:00  loss: 0.9001 (1.1439)  labels_encoder: 0.5656 (0.7485)  labels_decoder: 0.3346 (0.3954)  labels_encoder_unscaled: 0.5656 (0.7485)  labels_decoder_unscaled: 0.6691 (0.7908)  time: 0.0623  data: 0.0001  max mem: 3197
Test: Total time: 0:02:54 (0.1082 s / it)
Averaged stats: loss: 0.9001 (1.1439)  labels_encoder: 0.5656 (0.7485)  labels_decoder: 0.3346 (0.3954)  labels_encoder_unscaled: 0.5656 (0.7485)  labels_decoder_unscaled: 0.6691 (0.7908)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5733

dec_mAP all together: | 0.4552036297487511 |.
dec_mAP_pred | 0 : 0.5000822647854102 |.
dec_mAP_pred | 1 : 0.4917497955801565 |.
dec_mAP_pred | 2 : 0.479285283953591 |.
dec_mAP_pred | 3 : 0.46539816914920207 |.
dec_mAP_pred | 4 : 0.45064584703740207 |.
dec_mAP_pred | 5 : 0.4358924634251056 |.
dec_mAP_pred | 6 : 0.4215322019688865 |.
dec_mAP_pred | 7 : 0.40807627585883505 |.
all decoder map: | 0.4566 |.
BaseballPitch: 0.1407
BasketballDunk: 0.7688
Billiards: 0.4256
CleanAndJerk: 0.7503
CliffDiving: 0.8018
CricketBowling: 0.4520
CricketShot: 0.2556
Diving: 0.6971
FrisbeeCatch: 0.2898
GolfSwing: 0.5727
HammerThrow: 0.8517
HighJump: 0.6371
JavelinThrow: 0.6743
LongJump: 0.7680
PoleVault: 0.8746
Shotput: 0.6736
SoccerPenalty: 0.3182
TennisSwing: 0.5955
ThrowDiscus: 0.6129
VolleyballSpiking: 0.3059
Epoch: [4]  [   0/1405]  eta: 1:08:41  lr: 0.000000  loss: 0.2898 (0.2898)  labels_encoder: 0.1620 (0.1620)  labels_decoder: 0.1278 (0.1278)  labels_encoder_unscaled: 0.1620 (0.1620)  labels_decoder_unscaled: 0.2555 (0.2555)  time: 2.9337  data: 2.7120  max mem: 3197
Epoch: [4]  [  50/1405]  eta: 0:05:17  lr: 0.000000  loss: 0.2318 (0.2362)  labels_encoder: 0.1198 (0.1205)  labels_decoder: 0.1094 (0.1157)  labels_encoder_unscaled: 0.1198 (0.1205)  labels_decoder_unscaled: 0.2189 (0.2314)  time: 0.1633  data: 0.0003  max mem: 3197
Epoch: [4]  [ 100/1405]  eta: 0:04:23  lr: 0.000000  loss: 0.2323 (0.2322)  labels_encoder: 0.1036 (0.1173)  labels_decoder: 0.1147 (0.1150)  labels_encoder_unscaled: 0.1036 (0.1173)  labels_decoder_unscaled: 0.2293 (0.2299)  time: 0.1744  data: 0.0003  max mem: 3197
Epoch: [4]  [ 150/1405]  eta: 0:03:57  lr: 0.000000  loss: 0.2197 (0.2318)  labels_encoder: 0.1121 (0.1160)  labels_decoder: 0.1120 (0.1158)  labels_encoder_unscaled: 0.1121 (0.1160)  labels_decoder_unscaled: 0.2240 (0.2316)  time: 0.1684  data: 0.0003  max mem: 3197
Epoch: [4]  [ 200/1405]  eta: 0:03:41  lr: 0.000000  loss: 0.2114 (0.2338)  labels_encoder: 0.1045 (0.1179)  labels_decoder: 0.1052 (0.1158)  labels_encoder_unscaled: 0.1045 (0.1179)  labels_decoder_unscaled: 0.2103 (0.2316)  time: 0.1603  data: 0.0003  max mem: 3197
Epoch: [4]  [ 250/1405]  eta: 0:03:27  lr: 0.000000  loss: 0.2210 (0.2343)  labels_encoder: 0.1070 (0.1190)  labels_decoder: 0.1093 (0.1152)  labels_encoder_unscaled: 0.1070 (0.1190)  labels_decoder_unscaled: 0.2185 (0.2304)  time: 0.1553  data: 0.0003  max mem: 3197
Epoch: [4]  [ 300/1405]  eta: 0:03:14  lr: 0.000000  loss: 0.2425 (0.2355)  labels_encoder: 0.1192 (0.1196)  labels_decoder: 0.1126 (0.1158)  labels_encoder_unscaled: 0.1192 (0.1196)  labels_decoder_unscaled: 0.2251 (0.2317)  time: 0.1546  data: 0.0003  max mem: 3197
Epoch: [4]  [ 350/1405]  eta: 0:03:03  lr: 0.000000  loss: 0.2147 (0.2347)  labels_encoder: 0.0959 (0.1195)  labels_decoder: 0.1128 (0.1152)  labels_encoder_unscaled: 0.0959 (0.1195)  labels_decoder_unscaled: 0.2255 (0.2305)  time: 0.1593  data: 0.0003  max mem: 3197
Epoch: [4]  [ 400/1405]  eta: 0:02:54  lr: 0.000000  loss: 0.2216 (0.2346)  labels_encoder: 0.1088 (0.1194)  labels_decoder: 0.1167 (0.1152)  labels_encoder_unscaled: 0.1088 (0.1194)  labels_decoder_unscaled: 0.2334 (0.2303)  time: 0.1771  data: 0.0003  max mem: 3197
Epoch: [4]  [ 450/1405]  eta: 0:02:45  lr: 0.000000  loss: 0.2146 (0.2352)  labels_encoder: 0.1006 (0.1198)  labels_decoder: 0.1167 (0.1154)  labels_encoder_unscaled: 0.1006 (0.1198)  labels_decoder_unscaled: 0.2334 (0.2309)  time: 0.1855  data: 0.0003  max mem: 3197
Epoch: [4]  [ 500/1405]  eta: 0:02:37  lr: 0.000000  loss: 0.2368 (0.2346)  labels_encoder: 0.1189 (0.1192)  labels_decoder: 0.1102 (0.1154)  labels_encoder_unscaled: 0.1189 (0.1192)  labels_decoder_unscaled: 0.2205 (0.2308)  time: 0.1718  data: 0.0003  max mem: 3197
Epoch: [4]  [ 550/1405]  eta: 0:02:28  lr: 0.000000  loss: 0.2179 (0.2340)  labels_encoder: 0.1007 (0.1189)  labels_decoder: 0.1129 (0.1151)  labels_encoder_unscaled: 0.1007 (0.1189)  labels_decoder_unscaled: 0.2258 (0.2302)  time: 0.1826  data: 0.0003  max mem: 3197
Epoch: [4]  [ 600/1405]  eta: 0:02:20  lr: 0.000000  loss: 0.2325 (0.2345)  labels_encoder: 0.1241 (0.1195)  labels_decoder: 0.1109 (0.1150)  labels_encoder_unscaled: 0.1241 (0.1195)  labels_decoder_unscaled: 0.2219 (0.2300)  time: 0.1865  data: 0.0003  max mem: 3197
Epoch: [4]  [ 650/1405]  eta: 0:02:12  lr: 0.000000  loss: 0.2217 (0.2342)  labels_encoder: 0.1101 (0.1195)  labels_decoder: 0.1137 (0.1147)  labels_encoder_unscaled: 0.1101 (0.1195)  labels_decoder_unscaled: 0.2274 (0.2293)  time: 0.1882  data: 0.0003  max mem: 3197
Epoch: [4]  [ 700/1405]  eta: 0:02:03  lr: 0.000000  loss: 0.2320 (0.2342)  labels_encoder: 0.1222 (0.1197)  labels_decoder: 0.1052 (0.1145)  labels_encoder_unscaled: 0.1222 (0.1197)  labels_decoder_unscaled: 0.2104 (0.2290)  time: 0.1728  data: 0.0003  max mem: 3197
Epoch: [4]  [ 750/1405]  eta: 0:01:54  lr: 0.000000  loss: 0.2215 (0.2338)  labels_encoder: 0.1158 (0.1192)  labels_decoder: 0.1114 (0.1146)  labels_encoder_unscaled: 0.1158 (0.1192)  labels_decoder_unscaled: 0.2228 (0.2292)  time: 0.1747  data: 0.0003  max mem: 3197
Epoch: [4]  [ 800/1405]  eta: 0:01:46  lr: 0.000000  loss: 0.2341 (0.2337)  labels_encoder: 0.1058 (0.1191)  labels_decoder: 0.1163 (0.1146)  labels_encoder_unscaled: 0.1058 (0.1191)  labels_decoder_unscaled: 0.2326 (0.2292)  time: 0.1848  data: 0.0003  max mem: 3197
Epoch: [4]  [ 850/1405]  eta: 0:01:37  lr: 0.000000  loss: 0.2359 (0.2342)  labels_encoder: 0.1276 (0.1196)  labels_decoder: 0.1141 (0.1146)  labels_encoder_unscaled: 0.1276 (0.1196)  labels_decoder_unscaled: 0.2281 (0.2293)  time: 0.1808  data: 0.0003  max mem: 3197
Epoch: [4]  [ 900/1405]  eta: 0:01:28  lr: 0.000000  loss: 0.2231 (0.2344)  labels_encoder: 0.1010 (0.1198)  labels_decoder: 0.1121 (0.1147)  labels_encoder_unscaled: 0.1010 (0.1198)  labels_decoder_unscaled: 0.2243 (0.2293)  time: 0.1659  data: 0.0003  max mem: 3197
Epoch: [4]  [ 950/1405]  eta: 0:01:19  lr: 0.000000  loss: 0.2435 (0.2343)  labels_encoder: 0.1316 (0.1199)  labels_decoder: 0.1082 (0.1144)  labels_encoder_unscaled: 0.1316 (0.1199)  labels_decoder_unscaled: 0.2165 (0.2287)  time: 0.1722  data: 0.0003  max mem: 3197
Epoch: [4]  [1000/1405]  eta: 0:01:11  lr: 0.000000  loss: 0.2146 (0.2344)  labels_encoder: 0.1005 (0.1199)  labels_decoder: 0.1084 (0.1145)  labels_encoder_unscaled: 0.1005 (0.1199)  labels_decoder_unscaled: 0.2168 (0.2289)  time: 0.1804  data: 0.0004  max mem: 3197
Epoch: [4]  [1050/1405]  eta: 0:01:02  lr: 0.000000  loss: 0.2118 (0.2344)  labels_encoder: 0.1052 (0.1198)  labels_decoder: 0.1103 (0.1146)  labels_encoder_unscaled: 0.1052 (0.1198)  labels_decoder_unscaled: 0.2206 (0.2293)  time: 0.1655  data: 0.0003  max mem: 3197
Epoch: [4]  [1100/1405]  eta: 0:00:53  lr: 0.000000  loss: 0.2144 (0.2339)  labels_encoder: 0.1060 (0.1195)  labels_decoder: 0.1060 (0.1144)  labels_encoder_unscaled: 0.1060 (0.1195)  labels_decoder_unscaled: 0.2120 (0.2289)  time: 0.1722  data: 0.0003  max mem: 3197
Epoch: [4]  [1150/1405]  eta: 0:00:44  lr: 0.000000  loss: 0.2025 (0.2336)  labels_encoder: 0.1016 (0.1193)  labels_decoder: 0.1020 (0.1142)  labels_encoder_unscaled: 0.1016 (0.1193)  labels_decoder_unscaled: 0.2039 (0.2285)  time: 0.1716  data: 0.0003  max mem: 3197
Epoch: [4]  [1200/1405]  eta: 0:00:35  lr: 0.000000  loss: 0.2229 (0.2339)  labels_encoder: 0.1058 (0.1195)  labels_decoder: 0.1171 (0.1144)  labels_encoder_unscaled: 0.1058 (0.1195)  labels_decoder_unscaled: 0.2342 (0.2287)  time: 0.1754  data: 0.0003  max mem: 3197
Epoch: [4]  [1250/1405]  eta: 0:00:27  lr: 0.000000  loss: 0.2150 (0.2336)  labels_encoder: 0.1079 (0.1194)  labels_decoder: 0.1088 (0.1142)  labels_encoder_unscaled: 0.1079 (0.1194)  labels_decoder_unscaled: 0.2176 (0.2284)  time: 0.1688  data: 0.0003  max mem: 3197
Epoch: [4]  [1300/1405]  eta: 0:00:18  lr: 0.000000  loss: 0.2201 (0.2338)  labels_encoder: 0.1133 (0.1196)  labels_decoder: 0.1034 (0.1142)  labels_encoder_unscaled: 0.1133 (0.1196)  labels_decoder_unscaled: 0.2068 (0.2283)  time: 0.1864  data: 0.0003  max mem: 3197
Epoch: [4]  [1350/1405]  eta: 0:00:09  lr: 0.000000  loss: 0.2220 (0.2339)  labels_encoder: 0.1061 (0.1196)  labels_decoder: 0.1142 (0.1142)  labels_encoder_unscaled: 0.1061 (0.1196)  labels_decoder_unscaled: 0.2285 (0.2284)  time: 0.1757  data: 0.0003  max mem: 3197
Epoch: [4]  [1400/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2317 (0.2338)  labels_encoder: 0.1212 (0.1196)  labels_decoder: 0.1049 (0.1142)  labels_encoder_unscaled: 0.1212 (0.1196)  labels_decoder_unscaled: 0.2098 (0.2283)  time: 0.1598  data: 0.0003  max mem: 3197
Epoch: [4]  [1404/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2331 (0.2338)  labels_encoder: 0.1212 (0.1196)  labels_decoder: 0.1026 (0.1142)  labels_encoder_unscaled: 0.1212 (0.1196)  labels_decoder_unscaled: 0.2051 (0.2283)  time: 0.1462  data: 0.0003  max mem: 3197
Epoch: [4] Total time: 0:04:06 (0.1755 s / it)
Averaged stats: lr: 0.000000  loss: 0.2331 (0.2338)  labels_encoder: 0.1212 (0.1196)  labels_decoder: 0.1026 (0.1142)  labels_encoder_unscaled: 0.1212 (0.1196)  labels_decoder_unscaled: 0.2051 (0.2283)
Test:  [   0/1613]  eta: 1:25:12  loss: 1.6483 (1.6483)  labels_encoder: 1.0801 (1.0801)  labels_decoder: 0.5683 (0.5683)  labels_encoder_unscaled: 1.0801 (1.0801)  labels_decoder_unscaled: 1.1365 (1.1365)  time: 3.1698  data: 3.0038  max mem: 3197
Test:  [  50/1613]  eta: 0:04:41  loss: 0.4556 (0.9093)  labels_encoder: 0.2308 (0.5811)  labels_decoder: 0.1922 (0.3282)  labels_encoder_unscaled: 0.2308 (0.5811)  labels_decoder_unscaled: 0.3843 (0.6564)  time: 0.1156  data: 0.0125  max mem: 3197
Test:  [ 100/1613]  eta: 0:03:42  loss: 0.2839 (0.7704)  labels_encoder: 0.1826 (0.4973)  labels_decoder: 0.1013 (0.2731)  labels_encoder_unscaled: 0.1826 (0.4973)  labels_decoder_unscaled: 0.2027 (0.5462)  time: 0.1040  data: 0.0002  max mem: 3197
Test:  [ 150/1613]  eta: 0:03:19  loss: 0.9882 (0.7942)  labels_encoder: 0.6576 (0.5140)  labels_decoder: 0.3134 (0.2802)  labels_encoder_unscaled: 0.6576 (0.5140)  labels_decoder_unscaled: 0.6267 (0.5604)  time: 0.1120  data: 0.0028  max mem: 3197
Test:  [ 200/1613]  eta: 0:03:05  loss: 1.0740 (0.9505)  labels_encoder: 0.6840 (0.6268)  labels_decoder: 0.3900 (0.3237)  labels_encoder_unscaled: 0.6840 (0.6268)  labels_decoder_unscaled: 0.7800 (0.6474)  time: 0.1056  data: 0.0002  max mem: 3197
Test:  [ 250/1613]  eta: 0:02:56  loss: 0.5194 (1.0022)  labels_encoder: 0.3786 (0.6566)  labels_decoder: 0.2331 (0.3456)  labels_encoder_unscaled: 0.3786 (0.6566)  labels_decoder_unscaled: 0.4663 (0.6911)  time: 0.1298  data: 0.0026  max mem: 3197
Test:  [ 300/1613]  eta: 0:02:46  loss: 0.6978 (1.0247)  labels_encoder: 0.4452 (0.6749)  labels_decoder: 0.2526 (0.3497)  labels_encoder_unscaled: 0.4452 (0.6749)  labels_decoder_unscaled: 0.5052 (0.6995)  time: 0.1190  data: 0.0238  max mem: 3197
Test:  [ 350/1613]  eta: 0:02:38  loss: 1.2799 (1.0262)  labels_encoder: 0.7931 (0.6686)  labels_decoder: 0.5332 (0.3576)  labels_encoder_unscaled: 0.7931 (0.6686)  labels_decoder_unscaled: 1.0665 (0.7152)  time: 0.1102  data: 0.0342  max mem: 3197
Test:  [ 400/1613]  eta: 0:02:30  loss: 0.8651 (1.1388)  labels_encoder: 0.4605 (0.7473)  labels_decoder: 0.3609 (0.3915)  labels_encoder_unscaled: 0.4605 (0.7473)  labels_decoder_unscaled: 0.7218 (0.7830)  time: 0.1223  data: 0.0206  max mem: 3197
Test:  [ 450/1613]  eta: 0:02:23  loss: 0.8878 (1.2206)  labels_encoder: 0.5610 (0.8023)  labels_decoder: 0.3268 (0.4183)  labels_encoder_unscaled: 0.5610 (0.8023)  labels_decoder_unscaled: 0.6536 (0.8365)  time: 0.1306  data: 0.0491  max mem: 3197
Test:  [ 500/1613]  eta: 0:02:17  loss: 0.3520 (1.1747)  labels_encoder: 0.1412 (0.7698)  labels_decoder: 0.2098 (0.4049)  labels_encoder_unscaled: 0.1412 (0.7698)  labels_decoder_unscaled: 0.4196 (0.8098)  time: 0.1211  data: 0.0309  max mem: 3197
Test:  [ 550/1613]  eta: 0:02:10  loss: 0.5594 (1.1682)  labels_encoder: 0.3486 (0.7642)  labels_decoder: 0.2486 (0.4041)  labels_encoder_unscaled: 0.3486 (0.7642)  labels_decoder_unscaled: 0.4972 (0.8081)  time: 0.1161  data: 0.0487  max mem: 3197
Test:  [ 600/1613]  eta: 0:02:03  loss: 1.3255 (1.2097)  labels_encoder: 0.7915 (0.8005)  labels_decoder: 0.4840 (0.4092)  labels_encoder_unscaled: 0.7915 (0.8005)  labels_decoder_unscaled: 0.9680 (0.8184)  time: 0.1278  data: 0.0453  max mem: 3197
Test:  [ 650/1613]  eta: 0:01:57  loss: 0.8386 (1.1912)  labels_encoder: 0.4931 (0.7835)  labels_decoder: 0.3867 (0.4077)  labels_encoder_unscaled: 0.4931 (0.7835)  labels_decoder_unscaled: 0.7734 (0.8154)  time: 0.1168  data: 0.0172  max mem: 3197
Test:  [ 700/1613]  eta: 0:01:50  loss: 0.5696 (1.1613)  labels_encoder: 0.3090 (0.7621)  labels_decoder: 0.2369 (0.3993)  labels_encoder_unscaled: 0.3090 (0.7621)  labels_decoder_unscaled: 0.4739 (0.7986)  time: 0.1199  data: 0.0263  max mem: 3197
Test:  [ 750/1613]  eta: 0:01:44  loss: 0.8764 (1.1455)  labels_encoder: 0.5524 (0.7501)  labels_decoder: 0.3241 (0.3955)  labels_encoder_unscaled: 0.5524 (0.7501)  labels_decoder_unscaled: 0.6481 (0.7909)  time: 0.1178  data: 0.0188  max mem: 3197
Test:  [ 800/1613]  eta: 0:01:38  loss: 0.9662 (1.1397)  labels_encoder: 0.6519 (0.7465)  labels_decoder: 0.3144 (0.3932)  labels_encoder_unscaled: 0.6519 (0.7465)  labels_decoder_unscaled: 0.6287 (0.7863)  time: 0.1141  data: 0.0143  max mem: 3197
Test:  [ 850/1613]  eta: 0:01:32  loss: 1.8368 (1.1470)  labels_encoder: 1.1502 (0.7485)  labels_decoder: 0.6739 (0.3986)  labels_encoder_unscaled: 1.1502 (0.7485)  labels_decoder_unscaled: 1.3477 (0.7971)  time: 0.1135  data: 0.0306  max mem: 3197
Test:  [ 900/1613]  eta: 0:01:26  loss: 0.8631 (1.1644)  labels_encoder: 0.5159 (0.7613)  labels_decoder: 0.3304 (0.4031)  labels_encoder_unscaled: 0.5159 (0.7613)  labels_decoder_unscaled: 0.6608 (0.8061)  time: 0.1199  data: 0.0076  max mem: 3197
Test:  [ 950/1613]  eta: 0:01:20  loss: 1.1981 (1.1547)  labels_encoder: 0.7979 (0.7547)  labels_decoder: 0.3792 (0.3999)  labels_encoder_unscaled: 0.7979 (0.7547)  labels_decoder_unscaled: 0.7584 (0.7999)  time: 0.1132  data: 0.0234  max mem: 3197
Test:  [1000/1613]  eta: 0:01:13  loss: 0.5969 (1.1391)  labels_encoder: 0.3425 (0.7435)  labels_decoder: 0.2544 (0.3956)  labels_encoder_unscaled: 0.3425 (0.7435)  labels_decoder_unscaled: 0.5088 (0.7913)  time: 0.0987  data: 0.0023  max mem: 3197
Test:  [1050/1613]  eta: 0:01:07  loss: 0.8644 (1.1274)  labels_encoder: 0.5350 (0.7358)  labels_decoder: 0.3176 (0.3916)  labels_encoder_unscaled: 0.5350 (0.7358)  labels_decoder_unscaled: 0.6351 (0.7831)  time: 0.1216  data: 0.0002  max mem: 3197
Test:  [1100/1613]  eta: 0:01:01  loss: 0.8757 (1.1436)  labels_encoder: 0.5609 (0.7484)  labels_decoder: 0.3277 (0.3953)  labels_encoder_unscaled: 0.5609 (0.7484)  labels_decoder_unscaled: 0.6555 (0.7906)  time: 0.1234  data: 0.0002  max mem: 3197
Test:  [1150/1613]  eta: 0:00:55  loss: 0.7382 (1.1291)  labels_encoder: 0.4221 (0.7380)  labels_decoder: 0.2602 (0.3911)  labels_encoder_unscaled: 0.4221 (0.7380)  labels_decoder_unscaled: 0.5204 (0.7822)  time: 0.1054  data: 0.0002  max mem: 3197
Test:  [1200/1613]  eta: 0:00:49  loss: 0.5502 (1.1331)  labels_encoder: 0.3227 (0.7400)  labels_decoder: 0.2289 (0.3931)  labels_encoder_unscaled: 0.3227 (0.7400)  labels_decoder_unscaled: 0.4579 (0.7862)  time: 0.1020  data: 0.0002  max mem: 3197
Test:  [1250/1613]  eta: 0:00:43  loss: 0.4896 (1.1359)  labels_encoder: 0.2592 (0.7416)  labels_decoder: 0.2303 (0.3943)  labels_encoder_unscaled: 0.2592 (0.7416)  labels_decoder_unscaled: 0.4606 (0.7886)  time: 0.1349  data: 0.0249  max mem: 3197
Test:  [1300/1613]  eta: 0:00:37  loss: 0.9539 (1.1310)  labels_encoder: 0.6357 (0.7384)  labels_decoder: 0.3428 (0.3926)  labels_encoder_unscaled: 0.6357 (0.7384)  labels_decoder_unscaled: 0.6856 (0.7852)  time: 0.1279  data: 0.0091  max mem: 3197
Test:  [1350/1613]  eta: 0:00:31  loss: 1.0152 (1.1494)  labels_encoder: 0.6306 (0.7519)  labels_decoder: 0.3846 (0.3974)  labels_encoder_unscaled: 0.6306 (0.7519)  labels_decoder_unscaled: 0.7692 (0.7949)  time: 0.1278  data: 0.0058  max mem: 3197
Test:  [1400/1613]  eta: 0:00:25  loss: 0.9593 (1.1407)  labels_encoder: 0.5811 (0.7458)  labels_decoder: 0.3703 (0.3949)  labels_encoder_unscaled: 0.5811 (0.7458)  labels_decoder_unscaled: 0.7406 (0.7898)  time: 0.1187  data: 0.0152  max mem: 3197
Test:  [1450/1613]  eta: 0:00:19  loss: 0.6551 (1.1478)  labels_encoder: 0.4369 (0.7497)  labels_decoder: 0.3863 (0.3981)  labels_encoder_unscaled: 0.4369 (0.7497)  labels_decoder_unscaled: 0.7726 (0.7962)  time: 0.1246  data: 0.0087  max mem: 3197
Test:  [1500/1613]  eta: 0:00:13  loss: 0.6993 (1.1544)  labels_encoder: 0.4461 (0.7552)  labels_decoder: 0.2108 (0.3992)  labels_encoder_unscaled: 0.4461 (0.7552)  labels_decoder_unscaled: 0.4216 (0.7984)  time: 0.1250  data: 0.0060  max mem: 3197
Test:  [1550/1613]  eta: 0:00:07  loss: 0.6813 (1.1507)  labels_encoder: 0.4389 (0.7533)  labels_decoder: 0.2436 (0.3974)  labels_encoder_unscaled: 0.4389 (0.7533)  labels_decoder_unscaled: 0.4873 (0.7948)  time: 0.1270  data: 0.0132  max mem: 3197
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9528 (1.1455)  labels_encoder: 0.5423 (0.7493)  labels_decoder: 0.3898 (0.3962)  labels_encoder_unscaled: 0.5423 (0.7493)  labels_decoder_unscaled: 0.7797 (0.7924)  time: 0.1279  data: 0.0002  max mem: 3197
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8528 (1.1436)  labels_encoder: 0.5423 (0.7484)  labels_decoder: 0.3105 (0.3953)  labels_encoder_unscaled: 0.5423 (0.7484)  labels_decoder_unscaled: 0.6211 (0.7905)  time: 0.1085  data: 0.0001  max mem: 3197
Test: Total time: 0:03:12 (0.1194 s / it)
Averaged stats: loss: 0.8528 (1.1436)  labels_encoder: 0.5423 (0.7484)  labels_decoder: 0.3105 (0.3953)  labels_encoder_unscaled: 0.5423 (0.7484)  labels_decoder_unscaled: 0.6211 (0.7905)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5731

dec_mAP all together: | 0.45483931404424094 |.
dec_mAP_pred | 0 : 0.49971164032027654 |.
dec_mAP_pred | 1 : 0.49137223927081963 |.
dec_mAP_pred | 2 : 0.47893199963723615 |.
dec_mAP_pred | 3 : 0.4650240301294423 |.
dec_mAP_pred | 4 : 0.45029045147593205 |.
dec_mAP_pred | 5 : 0.43548584126617723 |.
dec_mAP_pred | 6 : 0.421171075528871 |.
dec_mAP_pred | 7 : 0.40766102201436427 |.
all decoder map: | 0.4562 |.
BaseballPitch: 0.1414
BasketballDunk: 0.7691
Billiards: 0.4258
CleanAndJerk: 0.7507
CliffDiving: 0.8031
CricketBowling: 0.4508
CricketShot: 0.2553
Diving: 0.6975
FrisbeeCatch: 0.2887
GolfSwing: 0.5716
HammerThrow: 0.8512
HighJump: 0.6377
JavelinThrow: 0.6754
LongJump: 0.7676
PoleVault: 0.8746
Shotput: 0.6733
SoccerPenalty: 0.3175
TennisSwing: 0.5955
ThrowDiscus: 0.6112
VolleyballSpiking: 0.3043
Training time 0:32:10
