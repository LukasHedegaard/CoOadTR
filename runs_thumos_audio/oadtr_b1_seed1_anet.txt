Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:1
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  66.183 M, 99.815% Params, 1.896 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 11.071% Params, 0.47 GMac, 24.773% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    6.295 M, 9.493% Params, 0.409 GMac, 21.570% MACs, 
    (net): Sequential(
      6.295 M, 9.493% Params, 0.409 GMac, 21.570% MACs, 
      (0): Residual(
        4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
        (fn): PreNormDrop(
          4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
            (qkv): Linear(3.146 M, 4.744% Params, 0.204 GMac, 10.783% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
        (fn): PreNorm(
          2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
            (net): Sequential(
              2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
              (0): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.068% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 79.148% Params, 1.017 GMac, 53.645% MACs, 
    (layers): ModuleList(
      52.48 M, 79.148% Params, 1.017 GMac, 53.645% MACs, 
      (0): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.034% Params, 0.0 GMac, 0.010% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 1896244268.0
Model params: 66306092
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1415]  eta: 1:16:37  lr: 0.000100  loss: 5.2808 (5.2808)  labels_encoder: 3.5407 (3.5407)  labels_decoder: 1.7401 (1.7401)  labels_encoder_unscaled: 3.5407 (3.5407)  labels_decoder_unscaled: 3.4802 (3.4802)  time: 3.2491  data: 2.4471  max mem: 1929
Epoch: [1]  [  50/1415]  eta: 0:05:40  lr: 0.000100  loss: 1.0501 (1.5659)  labels_encoder: 0.6590 (1.0076)  labels_decoder: 0.4013 (0.5582)  labels_encoder_unscaled: 0.6590 (1.0076)  labels_decoder_unscaled: 0.8025 (1.1164)  time: 0.1457  data: 0.0003  max mem: 2688
Epoch: [1]  [ 100/1415]  eta: 0:04:16  lr: 0.000100  loss: 0.7522 (1.2175)  labels_encoder: 0.4653 (0.7765)  labels_decoder: 0.2839 (0.4411)  labels_encoder_unscaled: 0.4653 (0.7765)  labels_decoder_unscaled: 0.5678 (0.8822)  time: 0.1409  data: 0.0003  max mem: 2688
Epoch: [1]  [ 150/1415]  eta: 0:03:44  lr: 0.000100  loss: 0.7217 (1.0600)  labels_encoder: 0.4450 (0.6721)  labels_decoder: 0.2715 (0.3878)  labels_encoder_unscaled: 0.4450 (0.6721)  labels_decoder_unscaled: 0.5430 (0.7757)  time: 0.1463  data: 0.0003  max mem: 2688
Epoch: [1]  [ 200/1415]  eta: 0:03:24  lr: 0.000100  loss: 0.6212 (0.9578)  labels_encoder: 0.3826 (0.6047)  labels_decoder: 0.2304 (0.3531)  labels_encoder_unscaled: 0.3826 (0.6047)  labels_decoder_unscaled: 0.4609 (0.7063)  time: 0.1440  data: 0.0003  max mem: 2688
Epoch: [1]  [ 250/1415]  eta: 0:03:11  lr: 0.000100  loss: 0.5541 (0.8866)  labels_encoder: 0.3425 (0.5573)  labels_decoder: 0.2182 (0.3293)  labels_encoder_unscaled: 0.3425 (0.5573)  labels_decoder_unscaled: 0.4363 (0.6587)  time: 0.1452  data: 0.0003  max mem: 2688
Epoch: [1]  [ 300/1415]  eta: 0:03:00  lr: 0.000100  loss: 0.5639 (0.8372)  labels_encoder: 0.3483 (0.5241)  labels_decoder: 0.2154 (0.3131)  labels_encoder_unscaled: 0.3483 (0.5241)  labels_decoder_unscaled: 0.4307 (0.6263)  time: 0.1590  data: 0.0003  max mem: 2688
Epoch: [1]  [ 350/1415]  eta: 0:02:50  lr: 0.000100  loss: 0.5174 (0.7945)  labels_encoder: 0.2942 (0.4951)  labels_decoder: 0.2044 (0.2993)  labels_encoder_unscaled: 0.2942 (0.4951)  labels_decoder_unscaled: 0.4088 (0.5987)  time: 0.1486  data: 0.0003  max mem: 2688
Epoch: [1]  [ 400/1415]  eta: 0:02:40  lr: 0.000100  loss: 0.5275 (0.7603)  labels_encoder: 0.3145 (0.4721)  labels_decoder: 0.2114 (0.2882)  labels_encoder_unscaled: 0.3145 (0.4721)  labels_decoder_unscaled: 0.4227 (0.5764)  time: 0.1505  data: 0.0003  max mem: 2688
Epoch: [1]  [ 450/1415]  eta: 0:02:30  lr: 0.000100  loss: 0.5014 (0.7357)  labels_encoder: 0.3000 (0.4557)  labels_decoder: 0.2010 (0.2800)  labels_encoder_unscaled: 0.3000 (0.4557)  labels_decoder_unscaled: 0.4020 (0.5600)  time: 0.1391  data: 0.0003  max mem: 2688
Epoch: [1]  [ 500/1415]  eta: 0:02:22  lr: 0.000100  loss: 0.4539 (0.7128)  labels_encoder: 0.2699 (0.4403)  labels_decoder: 0.1924 (0.2725)  labels_encoder_unscaled: 0.2699 (0.4403)  labels_decoder_unscaled: 0.3847 (0.5449)  time: 0.1462  data: 0.0003  max mem: 2688
Epoch: [1]  [ 550/1415]  eta: 0:02:13  lr: 0.000100  loss: 0.4777 (0.6923)  labels_encoder: 0.2859 (0.4267)  labels_decoder: 0.1950 (0.2655)  labels_encoder_unscaled: 0.2859 (0.4267)  labels_decoder_unscaled: 0.3901 (0.5311)  time: 0.1462  data: 0.0003  max mem: 2688
Epoch: [1]  [ 600/1415]  eta: 0:02:05  lr: 0.000100  loss: 0.5026 (0.6746)  labels_encoder: 0.2789 (0.4151)  labels_decoder: 0.1902 (0.2595)  labels_encoder_unscaled: 0.2789 (0.4151)  labels_decoder_unscaled: 0.3805 (0.5189)  time: 0.1524  data: 0.0003  max mem: 2688
Epoch: [1]  [ 650/1415]  eta: 0:01:57  lr: 0.000100  loss: 0.4562 (0.6588)  labels_encoder: 0.2660 (0.4043)  labels_decoder: 0.1902 (0.2545)  labels_encoder_unscaled: 0.2660 (0.4043)  labels_decoder_unscaled: 0.3803 (0.5090)  time: 0.1424  data: 0.0003  max mem: 2688
Epoch: [1]  [ 700/1415]  eta: 0:01:49  lr: 0.000100  loss: 0.4493 (0.6459)  labels_encoder: 0.2618 (0.3959)  labels_decoder: 0.1713 (0.2499)  labels_encoder_unscaled: 0.2618 (0.3959)  labels_decoder_unscaled: 0.3426 (0.4998)  time: 0.1496  data: 0.0003  max mem: 2688
Epoch: [1]  [ 750/1415]  eta: 0:01:41  lr: 0.000100  loss: 0.4246 (0.6338)  labels_encoder: 0.2369 (0.3876)  labels_decoder: 0.1863 (0.2462)  labels_encoder_unscaled: 0.2369 (0.3876)  labels_decoder_unscaled: 0.3726 (0.4924)  time: 0.1425  data: 0.0003  max mem: 2688
Epoch: [1]  [ 800/1415]  eta: 0:01:33  lr: 0.000100  loss: 0.4519 (0.6228)  labels_encoder: 0.2724 (0.3800)  labels_decoder: 0.1721 (0.2427)  labels_encoder_unscaled: 0.2724 (0.3800)  labels_decoder_unscaled: 0.3443 (0.4855)  time: 0.1449  data: 0.0003  max mem: 2688
Epoch: [1]  [ 850/1415]  eta: 0:01:25  lr: 0.000100  loss: 0.4257 (0.6125)  labels_encoder: 0.2607 (0.3731)  labels_decoder: 0.1754 (0.2394)  labels_encoder_unscaled: 0.2607 (0.3731)  labels_decoder_unscaled: 0.3507 (0.4788)  time: 0.1468  data: 0.0003  max mem: 2688
Epoch: [1]  [ 900/1415]  eta: 0:01:18  lr: 0.000100  loss: 0.4205 (0.6016)  labels_encoder: 0.2363 (0.3656)  labels_decoder: 0.1852 (0.2359)  labels_encoder_unscaled: 0.2363 (0.3656)  labels_decoder_unscaled: 0.3703 (0.4719)  time: 0.1486  data: 0.0003  max mem: 2688
Epoch: [1]  [ 950/1415]  eta: 0:01:10  lr: 0.000100  loss: 0.4027 (0.5925)  labels_encoder: 0.2385 (0.3598)  labels_decoder: 0.1678 (0.2327)  labels_encoder_unscaled: 0.2385 (0.3598)  labels_decoder_unscaled: 0.3357 (0.4654)  time: 0.1501  data: 0.0003  max mem: 2688
Epoch: [1]  [1000/1415]  eta: 0:01:02  lr: 0.000100  loss: 0.4549 (0.5847)  labels_encoder: 0.2647 (0.3546)  labels_decoder: 0.1864 (0.2302)  labels_encoder_unscaled: 0.2647 (0.3546)  labels_decoder_unscaled: 0.3729 (0.4603)  time: 0.1496  data: 0.0004  max mem: 2688
Epoch: [1]  [1050/1415]  eta: 0:00:55  lr: 0.000100  loss: 0.4338 (0.5769)  labels_encoder: 0.2521 (0.3495)  labels_decoder: 0.1708 (0.2274)  labels_encoder_unscaled: 0.2521 (0.3495)  labels_decoder_unscaled: 0.3415 (0.4548)  time: 0.1485  data: 0.0003  max mem: 2688
Epoch: [1]  [1100/1415]  eta: 0:00:47  lr: 0.000100  loss: 0.3939 (0.5690)  labels_encoder: 0.2134 (0.3441)  labels_decoder: 0.1792 (0.2249)  labels_encoder_unscaled: 0.2134 (0.3441)  labels_decoder_unscaled: 0.3584 (0.4498)  time: 0.1431  data: 0.0003  max mem: 2688
Epoch: [1]  [1150/1415]  eta: 0:00:39  lr: 0.000100  loss: 0.3629 (0.5614)  labels_encoder: 0.2173 (0.3391)  labels_decoder: 0.1619 (0.2224)  labels_encoder_unscaled: 0.2173 (0.3391)  labels_decoder_unscaled: 0.3237 (0.4447)  time: 0.1486  data: 0.0003  max mem: 2688
Epoch: [1]  [1200/1415]  eta: 0:00:32  lr: 0.000100  loss: 0.4181 (0.5550)  labels_encoder: 0.2492 (0.3346)  labels_decoder: 0.1621 (0.2204)  labels_encoder_unscaled: 0.2492 (0.3346)  labels_decoder_unscaled: 0.3241 (0.4407)  time: 0.1449  data: 0.0003  max mem: 2688
Epoch: [1]  [1250/1415]  eta: 0:00:24  lr: 0.000100  loss: 0.3753 (0.5481)  labels_encoder: 0.2121 (0.3300)  labels_decoder: 0.1607 (0.2182)  labels_encoder_unscaled: 0.2121 (0.3300)  labels_decoder_unscaled: 0.3214 (0.4363)  time: 0.1512  data: 0.0003  max mem: 2688
Epoch: [1]  [1300/1415]  eta: 0:00:17  lr: 0.000100  loss: 0.3929 (0.5428)  labels_encoder: 0.2378 (0.3265)  labels_decoder: 0.1567 (0.2163)  labels_encoder_unscaled: 0.2378 (0.3265)  labels_decoder_unscaled: 0.3134 (0.4325)  time: 0.1388  data: 0.0003  max mem: 2688
Epoch: [1]  [1350/1415]  eta: 0:00:09  lr: 0.000100  loss: 0.3801 (0.5373)  labels_encoder: 0.2020 (0.3229)  labels_decoder: 0.1591 (0.2144)  labels_encoder_unscaled: 0.2020 (0.3229)  labels_decoder_unscaled: 0.3181 (0.4288)  time: 0.1378  data: 0.0003  max mem: 2688
Epoch: [1]  [1400/1415]  eta: 0:00:02  lr: 0.000100  loss: 0.3724 (0.5314)  labels_encoder: 0.2021 (0.3190)  labels_decoder: 0.1661 (0.2124)  labels_encoder_unscaled: 0.2021 (0.3190)  labels_decoder_unscaled: 0.3322 (0.4248)  time: 0.1450  data: 0.0004  max mem: 2688
Epoch: [1]  [1414/1415]  eta: 0:00:00  lr: 0.000100  loss: 0.3901 (0.5300)  labels_encoder: 0.2133 (0.3180)  labels_decoder: 0.1689 (0.2120)  labels_encoder_unscaled: 0.2133 (0.3180)  labels_decoder_unscaled: 0.3379 (0.4240)  time: 0.1222  data: 0.0003  max mem: 2688
Epoch: [1] Total time: 0:03:31 (0.1494 s / it)
Averaged stats: lr: 0.000100  loss: 0.3901 (0.5300)  labels_encoder: 0.2133 (0.3180)  labels_decoder: 0.1689 (0.2120)  labels_encoder_unscaled: 0.2133 (0.3180)  labels_decoder_unscaled: 0.3379 (0.4240)
Test:  [   0/1613]  eta: 1:02:00  loss: 0.2786 (0.2786)  labels_encoder: 0.0755 (0.0755)  labels_decoder: 0.2031 (0.2031)  labels_encoder_unscaled: 0.0755 (0.0755)  labels_decoder_unscaled: 0.4062 (0.4062)  time: 2.3066  data: 2.2479  max mem: 2688
Test:  [  50/1613]  eta: 0:04:00  loss: 0.4464 (0.8449)  labels_encoder: 0.2653 (0.5386)  labels_decoder: 0.2060 (0.3063)  labels_encoder_unscaled: 0.2653 (0.5386)  labels_decoder_unscaled: 0.4120 (0.6126)  time: 0.1124  data: 0.0304  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:19  loss: 0.5171 (0.7517)  labels_encoder: 0.3574 (0.4792)  labels_decoder: 0.1597 (0.2725)  labels_encoder_unscaled: 0.3574 (0.4792)  labels_decoder_unscaled: 0.3193 (0.5451)  time: 0.1064  data: 0.0307  max mem: 2688
Test:  [ 150/1613]  eta: 0:03:04  loss: 0.9001 (0.7585)  labels_encoder: 0.6193 (0.4880)  labels_decoder: 0.2205 (0.2705)  labels_encoder_unscaled: 0.6193 (0.4880)  labels_decoder_unscaled: 0.4410 (0.5409)  time: 0.1122  data: 0.0228  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:54  loss: 1.1649 (0.9187)  labels_encoder: 0.7177 (0.5966)  labels_decoder: 0.4435 (0.3222)  labels_encoder_unscaled: 0.7177 (0.5966)  labels_decoder_unscaled: 0.8870 (0.6444)  time: 0.1231  data: 0.0179  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:45  loss: 0.5245 (0.9449)  labels_encoder: 0.2675 (0.6068)  labels_decoder: 0.2758 (0.3381)  labels_encoder_unscaled: 0.2675 (0.6068)  labels_decoder_unscaled: 0.5517 (0.6762)  time: 0.1137  data: 0.0288  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:37  loss: 0.6144 (0.9596)  labels_encoder: 0.4081 (0.6146)  labels_decoder: 0.2461 (0.3449)  labels_encoder_unscaled: 0.4081 (0.6146)  labels_decoder_unscaled: 0.4922 (0.6899)  time: 0.1063  data: 0.0124  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:30  loss: 1.3722 (0.9695)  labels_encoder: 0.8793 (0.6196)  labels_decoder: 0.5236 (0.3498)  labels_encoder_unscaled: 0.8793 (0.6196)  labels_decoder_unscaled: 1.0473 (0.6997)  time: 0.1070  data: 0.0325  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:24  loss: 0.8708 (1.1232)  labels_encoder: 0.5098 (0.7299)  labels_decoder: 0.3823 (0.3933)  labels_encoder_unscaled: 0.5098 (0.7299)  labels_decoder_unscaled: 0.7646 (0.7866)  time: 0.1158  data: 0.0400  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:17  loss: 0.7780 (1.1733)  labels_encoder: 0.5722 (0.7622)  labels_decoder: 0.2598 (0.4110)  labels_encoder_unscaled: 0.5722 (0.7622)  labels_decoder_unscaled: 0.5196 (0.8221)  time: 0.1144  data: 0.0351  max mem: 2688
Test:  [ 500/1613]  eta: 0:02:11  loss: 0.4270 (1.1228)  labels_encoder: 0.2329 (0.7276)  labels_decoder: 0.1941 (0.3952)  labels_encoder_unscaled: 0.2329 (0.7276)  labels_decoder_unscaled: 0.3883 (0.7904)  time: 0.1137  data: 0.0593  max mem: 2688
Test:  [ 550/1613]  eta: 0:02:05  loss: 0.7132 (1.1073)  labels_encoder: 0.5385 (0.7164)  labels_decoder: 0.2234 (0.3909)  labels_encoder_unscaled: 0.5385 (0.7164)  labels_decoder_unscaled: 0.4468 (0.7817)  time: 0.1207  data: 0.0396  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:59  loss: 0.6792 (1.1524)  labels_encoder: 0.3955 (0.7531)  labels_decoder: 0.2671 (0.3993)  labels_encoder_unscaled: 0.3955 (0.7531)  labels_decoder_unscaled: 0.5341 (0.7986)  time: 0.1174  data: 0.0371  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:53  loss: 0.7312 (1.1280)  labels_encoder: 0.3681 (0.7336)  labels_decoder: 0.2935 (0.3944)  labels_encoder_unscaled: 0.3681 (0.7336)  labels_decoder_unscaled: 0.5871 (0.7888)  time: 0.1174  data: 0.0337  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:47  loss: 0.5058 (1.1031)  labels_encoder: 0.3072 (0.7159)  labels_decoder: 0.1950 (0.3871)  labels_encoder_unscaled: 0.3072 (0.7159)  labels_decoder_unscaled: 0.3901 (0.7743)  time: 0.1199  data: 0.0394  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:41  loss: 0.8254 (1.0819)  labels_encoder: 0.4698 (0.6994)  labels_decoder: 0.3380 (0.3825)  labels_encoder_unscaled: 0.4698 (0.6994)  labels_decoder_unscaled: 0.6760 (0.7650)  time: 0.1177  data: 0.0380  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:36  loss: 0.6580 (1.0875)  labels_encoder: 0.3824 (0.7041)  labels_decoder: 0.2367 (0.3835)  labels_encoder_unscaled: 0.3824 (0.7041)  labels_decoder_unscaled: 0.4735 (0.7670)  time: 0.1187  data: 0.0313  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:30  loss: 1.2362 (1.0878)  labels_encoder: 0.8497 (0.7012)  labels_decoder: 0.5160 (0.3867)  labels_encoder_unscaled: 0.8497 (0.7012)  labels_decoder_unscaled: 1.0319 (0.7734)  time: 0.1256  data: 0.0595  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:24  loss: 0.7508 (1.0918)  labels_encoder: 0.4337 (0.7037)  labels_decoder: 0.3065 (0.3881)  labels_encoder_unscaled: 0.4337 (0.7037)  labels_decoder_unscaled: 0.6131 (0.7763)  time: 0.1279  data: 0.0604  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:18  loss: 1.1871 (1.0830)  labels_encoder: 0.7798 (0.6976)  labels_decoder: 0.3724 (0.3854)  labels_encoder_unscaled: 0.7798 (0.6976)  labels_decoder_unscaled: 0.7447 (0.7708)  time: 0.1186  data: 0.0500  max mem: 2688
Test:  [1000/1613]  eta: 0:01:12  loss: 0.5652 (1.0660)  labels_encoder: 0.3085 (0.6853)  labels_decoder: 0.2387 (0.3807)  labels_encoder_unscaled: 0.3085 (0.6853)  labels_decoder_unscaled: 0.4775 (0.7613)  time: 0.1256  data: 0.0559  max mem: 2688
Test:  [1050/1613]  eta: 0:01:06  loss: 0.8783 (1.0584)  labels_encoder: 0.5078 (0.6796)  labels_decoder: 0.3709 (0.3788)  labels_encoder_unscaled: 0.5078 (0.6796)  labels_decoder_unscaled: 0.7417 (0.7576)  time: 0.1216  data: 0.0452  max mem: 2688
Test:  [1100/1613]  eta: 0:01:00  loss: 0.6236 (1.0582)  labels_encoder: 0.3767 (0.6805)  labels_decoder: 0.2538 (0.3777)  labels_encoder_unscaled: 0.3767 (0.6805)  labels_decoder_unscaled: 0.5076 (0.7554)  time: 0.1242  data: 0.0573  max mem: 2688
Test:  [1150/1613]  eta: 0:00:54  loss: 0.6419 (1.0425)  labels_encoder: 0.3927 (0.6695)  labels_decoder: 0.2492 (0.3730)  labels_encoder_unscaled: 0.3927 (0.6695)  labels_decoder_unscaled: 0.4985 (0.7459)  time: 0.1207  data: 0.0303  max mem: 2688
Test:  [1200/1613]  eta: 0:00:49  loss: 0.5529 (1.0441)  labels_encoder: 0.3744 (0.6698)  labels_decoder: 0.2282 (0.3743)  labels_encoder_unscaled: 0.3744 (0.6698)  labels_decoder_unscaled: 0.4564 (0.7485)  time: 0.1103  data: 0.0379  max mem: 2688
Test:  [1250/1613]  eta: 0:00:43  loss: 0.4813 (1.0439)  labels_encoder: 0.2578 (0.6693)  labels_decoder: 0.1930 (0.3747)  labels_encoder_unscaled: 0.2578 (0.6693)  labels_decoder_unscaled: 0.3860 (0.7493)  time: 0.1140  data: 0.0170  max mem: 2688
Test:  [1300/1613]  eta: 0:00:37  loss: 0.6597 (1.0466)  labels_encoder: 0.4174 (0.6711)  labels_decoder: 0.2841 (0.3755)  labels_encoder_unscaled: 0.4174 (0.6711)  labels_decoder_unscaled: 0.5682 (0.7510)  time: 0.1297  data: 0.0432  max mem: 2688
Test:  [1350/1613]  eta: 0:00:31  loss: 0.8940 (1.0623)  labels_encoder: 0.5718 (0.6829)  labels_decoder: 0.3500 (0.3795)  labels_encoder_unscaled: 0.5718 (0.6829)  labels_decoder_unscaled: 0.6999 (0.7589)  time: 0.1208  data: 0.0355  max mem: 2688
Test:  [1400/1613]  eta: 0:00:25  loss: 0.8017 (1.0536)  labels_encoder: 0.4922 (0.6764)  labels_decoder: 0.3201 (0.3772)  labels_encoder_unscaled: 0.4922 (0.6764)  labels_decoder_unscaled: 0.6402 (0.7544)  time: 0.1185  data: 0.0430  max mem: 2688
Test:  [1450/1613]  eta: 0:00:19  loss: 0.4781 (1.0616)  labels_encoder: 0.2475 (0.6808)  labels_decoder: 0.1680 (0.3808)  labels_encoder_unscaled: 0.2475 (0.6808)  labels_decoder_unscaled: 0.3361 (0.7616)  time: 0.1347  data: 0.0393  max mem: 2688
Test:  [1500/1613]  eta: 0:00:13  loss: 0.8593 (1.0753)  labels_encoder: 0.5195 (0.6918)  labels_decoder: 0.3085 (0.3835)  labels_encoder_unscaled: 0.5195 (0.6918)  labels_decoder_unscaled: 0.6170 (0.7669)  time: 0.1280  data: 0.0458  max mem: 2688
Test:  [1550/1613]  eta: 0:00:07  loss: 0.7967 (1.0717)  labels_encoder: 0.4858 (0.6893)  labels_decoder: 0.3170 (0.3825)  labels_encoder_unscaled: 0.4858 (0.6893)  labels_decoder_unscaled: 0.6341 (0.7649)  time: 0.1115  data: 0.0297  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.5850 (1.0677)  labels_encoder: 0.3546 (0.6860)  labels_decoder: 0.2623 (0.3817)  labels_encoder_unscaled: 0.3546 (0.6860)  labels_decoder_unscaled: 0.5246 (0.7635)  time: 0.1138  data: 0.0185  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5558 (1.0656)  labels_encoder: 0.3227 (0.6849)  labels_decoder: 0.2092 (0.3807)  labels_encoder_unscaled: 0.3227 (0.6849)  labels_decoder_unscaled: 0.4185 (0.7615)  time: 0.1030  data: 0.0355  max mem: 2688
Test: Total time: 0:03:12 (0.1194 s / it)
Averaged stats: loss: 0.5558 (1.0656)  labels_encoder: 0.3227 (0.6849)  labels_decoder: 0.2092 (0.3807)  labels_encoder_unscaled: 0.3227 (0.6849)  labels_decoder_unscaled: 0.4185 (0.7615)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.6016

dec_mAP all together: | 0.47799112639501723 |.
dec_mAP_pred | 0 : 0.5347843787833011 |.
dec_mAP_pred | 1 : 0.5228004185461075 |.
dec_mAP_pred | 2 : 0.5067986389171486 |.
dec_mAP_pred | 3 : 0.4891093276640036 |.
dec_mAP_pred | 4 : 0.47129438018384323 |.
dec_mAP_pred | 5 : 0.454285795629764 |.
dec_mAP_pred | 6 : 0.43787843620797595 |.
dec_mAP_pred | 7 : 0.42318027475225256 |.
all decoder map: | 0.4800 |.
BaseballPitch: 0.3364
BasketballDunk: 0.7597
Billiards: 0.4314
CleanAndJerk: 0.7870
CliffDiving: 0.8250
CricketBowling: 0.4295
CricketShot: 0.2682
Diving: 0.6910
FrisbeeCatch: 0.3522
GolfSwing: 0.6975
HammerThrow: 0.8511
HighJump: 0.5395
JavelinThrow: 0.6981
LongJump: 0.7628
PoleVault: 0.8761
Shotput: 0.7027
SoccerPenalty: 0.3706
TennisSwing: 0.6070
ThrowDiscus: 0.6766
VolleyballSpiking: 0.3701
Epoch: [2]  [   0/1415]  eta: 1:07:24  lr: 0.000010  loss: 0.2545 (0.2545)  labels_encoder: 0.1335 (0.1335)  labels_decoder: 0.1210 (0.1210)  labels_encoder_unscaled: 0.1335 (0.1335)  labels_decoder_unscaled: 0.2421 (0.2421)  time: 2.8580  data: 2.7020  max mem: 2688
Epoch: [2]  [  50/1415]  eta: 0:04:55  lr: 0.000010  loss: 0.3063 (0.3146)  labels_encoder: 0.1569 (0.1723)  labels_decoder: 0.1374 (0.1423)  labels_encoder_unscaled: 0.1569 (0.1723)  labels_decoder_unscaled: 0.2748 (0.2846)  time: 0.1616  data: 0.0003  max mem: 2688
Epoch: [2]  [ 100/1415]  eta: 0:04:12  lr: 0.000010  loss: 0.2813 (0.3061)  labels_encoder: 0.1522 (0.1660)  labels_decoder: 0.1269 (0.1401)  labels_encoder_unscaled: 0.1522 (0.1660)  labels_decoder_unscaled: 0.2539 (0.2802)  time: 0.1616  data: 0.0003  max mem: 2688
Epoch: [2]  [ 150/1415]  eta: 0:03:50  lr: 0.000010  loss: 0.3182 (0.3097)  labels_encoder: 0.1762 (0.1690)  labels_decoder: 0.1351 (0.1407)  labels_encoder_unscaled: 0.1762 (0.1690)  labels_decoder_unscaled: 0.2702 (0.2814)  time: 0.1607  data: 0.0003  max mem: 2688
Epoch: [2]  [ 200/1415]  eta: 0:03:38  lr: 0.000010  loss: 0.2746 (0.3040)  labels_encoder: 0.1533 (0.1655)  labels_decoder: 0.1294 (0.1385)  labels_encoder_unscaled: 0.1533 (0.1655)  labels_decoder_unscaled: 0.2589 (0.2770)  time: 0.1801  data: 0.0003  max mem: 2688
Epoch: [2]  [ 250/1415]  eta: 0:03:27  lr: 0.000010  loss: 0.3030 (0.3016)  labels_encoder: 0.1584 (0.1643)  labels_decoder: 0.1320 (0.1373)  labels_encoder_unscaled: 0.1584 (0.1643)  labels_decoder_unscaled: 0.2641 (0.2746)  time: 0.1644  data: 0.0003  max mem: 2688
Epoch: [2]  [ 300/1415]  eta: 0:03:15  lr: 0.000010  loss: 0.2571 (0.2987)  labels_encoder: 0.1438 (0.1627)  labels_decoder: 0.1207 (0.1360)  labels_encoder_unscaled: 0.1438 (0.1627)  labels_decoder_unscaled: 0.2414 (0.2721)  time: 0.1635  data: 0.0003  max mem: 2688
Epoch: [2]  [ 350/1415]  eta: 0:03:06  lr: 0.000010  loss: 0.2389 (0.2951)  labels_encoder: 0.1200 (0.1607)  labels_decoder: 0.1125 (0.1345)  labels_encoder_unscaled: 0.1200 (0.1607)  labels_decoder_unscaled: 0.2250 (0.2689)  time: 0.1749  data: 0.0003  max mem: 2688
Epoch: [2]  [ 400/1415]  eta: 0:02:56  lr: 0.000010  loss: 0.2849 (0.2937)  labels_encoder: 0.1554 (0.1600)  labels_decoder: 0.1111 (0.1337)  labels_encoder_unscaled: 0.1554 (0.1600)  labels_decoder_unscaled: 0.2222 (0.2674)  time: 0.1732  data: 0.0004  max mem: 2688
Epoch: [2]  [ 450/1415]  eta: 0:02:46  lr: 0.000010  loss: 0.2817 (0.2925)  labels_encoder: 0.1575 (0.1594)  labels_decoder: 0.1263 (0.1331)  labels_encoder_unscaled: 0.1575 (0.1594)  labels_decoder_unscaled: 0.2527 (0.2663)  time: 0.1565  data: 0.0003  max mem: 2688
Epoch: [2]  [ 500/1415]  eta: 0:02:37  lr: 0.000010  loss: 0.2449 (0.2907)  labels_encoder: 0.1334 (0.1585)  labels_decoder: 0.1199 (0.1322)  labels_encoder_unscaled: 0.1334 (0.1585)  labels_decoder_unscaled: 0.2398 (0.2644)  time: 0.1572  data: 0.0003  max mem: 2688
Epoch: [2]  [ 550/1415]  eta: 0:02:27  lr: 0.000010  loss: 0.2837 (0.2895)  labels_encoder: 0.1504 (0.1580)  labels_decoder: 0.1219 (0.1316)  labels_encoder_unscaled: 0.1504 (0.1580)  labels_decoder_unscaled: 0.2437 (0.2631)  time: 0.1426  data: 0.0003  max mem: 2688
Epoch: [2]  [ 600/1415]  eta: 0:02:17  lr: 0.000010  loss: 0.2328 (0.2878)  labels_encoder: 0.1387 (0.1566)  labels_decoder: 0.1239 (0.1312)  labels_encoder_unscaled: 0.1387 (0.1566)  labels_decoder_unscaled: 0.2478 (0.2625)  time: 0.1529  data: 0.0003  max mem: 2688
Epoch: [2]  [ 650/1415]  eta: 0:02:08  lr: 0.000010  loss: 0.2820 (0.2862)  labels_encoder: 0.1497 (0.1555)  labels_decoder: 0.1267 (0.1308)  labels_encoder_unscaled: 0.1497 (0.1555)  labels_decoder_unscaled: 0.2534 (0.2615)  time: 0.1544  data: 0.0003  max mem: 2688
Epoch: [2]  [ 700/1415]  eta: 0:01:59  lr: 0.000010  loss: 0.2735 (0.2849)  labels_encoder: 0.1545 (0.1545)  labels_decoder: 0.1261 (0.1303)  labels_encoder_unscaled: 0.1545 (0.1545)  labels_decoder_unscaled: 0.2522 (0.2607)  time: 0.1585  data: 0.0003  max mem: 2688
Epoch: [2]  [ 750/1415]  eta: 0:01:50  lr: 0.000010  loss: 0.2340 (0.2831)  labels_encoder: 0.1249 (0.1530)  labels_decoder: 0.1244 (0.1301)  labels_encoder_unscaled: 0.1249 (0.1530)  labels_decoder_unscaled: 0.2489 (0.2602)  time: 0.1587  data: 0.0003  max mem: 2688
Epoch: [2]  [ 800/1415]  eta: 0:01:41  lr: 0.000010  loss: 0.2636 (0.2823)  labels_encoder: 0.1393 (0.1525)  labels_decoder: 0.1230 (0.1298)  labels_encoder_unscaled: 0.1393 (0.1525)  labels_decoder_unscaled: 0.2460 (0.2596)  time: 0.1496  data: 0.0003  max mem: 2688
Epoch: [2]  [ 850/1415]  eta: 0:01:32  lr: 0.000010  loss: 0.2639 (0.2815)  labels_encoder: 0.1323 (0.1518)  labels_decoder: 0.1291 (0.1297)  labels_encoder_unscaled: 0.1323 (0.1518)  labels_decoder_unscaled: 0.2582 (0.2593)  time: 0.1582  data: 0.0003  max mem: 2688
Epoch: [2]  [ 900/1415]  eta: 0:01:24  lr: 0.000010  loss: 0.2629 (0.2805)  labels_encoder: 0.1386 (0.1513)  labels_decoder: 0.1244 (0.1291)  labels_encoder_unscaled: 0.1386 (0.1513)  labels_decoder_unscaled: 0.2488 (0.2583)  time: 0.1559  data: 0.0003  max mem: 2688
Epoch: [2]  [ 950/1415]  eta: 0:01:16  lr: 0.000010  loss: 0.2543 (0.2794)  labels_encoder: 0.1341 (0.1505)  labels_decoder: 0.1186 (0.1289)  labels_encoder_unscaled: 0.1341 (0.1505)  labels_decoder_unscaled: 0.2373 (0.2578)  time: 0.1580  data: 0.0003  max mem: 2688
Epoch: [2]  [1000/1415]  eta: 0:01:07  lr: 0.000010  loss: 0.2349 (0.2786)  labels_encoder: 0.1212 (0.1499)  labels_decoder: 0.1254 (0.1286)  labels_encoder_unscaled: 0.1212 (0.1499)  labels_decoder_unscaled: 0.2507 (0.2572)  time: 0.1565  data: 0.0003  max mem: 2688
Epoch: [2]  [1050/1415]  eta: 0:00:59  lr: 0.000010  loss: 0.2514 (0.2780)  labels_encoder: 0.1228 (0.1496)  labels_decoder: 0.1192 (0.1284)  labels_encoder_unscaled: 0.1228 (0.1496)  labels_decoder_unscaled: 0.2384 (0.2568)  time: 0.1545  data: 0.0003  max mem: 2688
Epoch: [2]  [1100/1415]  eta: 0:00:51  lr: 0.000010  loss: 0.2344 (0.2776)  labels_encoder: 0.1224 (0.1493)  labels_decoder: 0.1219 (0.1283)  labels_encoder_unscaled: 0.1224 (0.1493)  labels_decoder_unscaled: 0.2437 (0.2566)  time: 0.1580  data: 0.0003  max mem: 2688
Epoch: [2]  [1150/1415]  eta: 0:00:43  lr: 0.000010  loss: 0.2594 (0.2771)  labels_encoder: 0.1344 (0.1490)  labels_decoder: 0.1225 (0.1281)  labels_encoder_unscaled: 0.1344 (0.1490)  labels_decoder_unscaled: 0.2451 (0.2562)  time: 0.1670  data: 0.0003  max mem: 2688
Epoch: [2]  [1200/1415]  eta: 0:00:34  lr: 0.000010  loss: 0.2458 (0.2765)  labels_encoder: 0.1264 (0.1487)  labels_decoder: 0.1182 (0.1278)  labels_encoder_unscaled: 0.1264 (0.1487)  labels_decoder_unscaled: 0.2363 (0.2556)  time: 0.1572  data: 0.0003  max mem: 2688
Epoch: [2]  [1250/1415]  eta: 0:00:26  lr: 0.000010  loss: 0.2629 (0.2762)  labels_encoder: 0.1396 (0.1485)  labels_decoder: 0.1231 (0.1277)  labels_encoder_unscaled: 0.1396 (0.1485)  labels_decoder_unscaled: 0.2462 (0.2555)  time: 0.1535  data: 0.0003  max mem: 2688
Epoch: [2]  [1300/1415]  eta: 0:00:18  lr: 0.000010  loss: 0.2586 (0.2753)  labels_encoder: 0.1436 (0.1479)  labels_decoder: 0.1155 (0.1274)  labels_encoder_unscaled: 0.1436 (0.1479)  labels_decoder_unscaled: 0.2310 (0.2549)  time: 0.1522  data: 0.0003  max mem: 2688
Epoch: [2]  [1350/1415]  eta: 0:00:10  lr: 0.000010  loss: 0.2613 (0.2747)  labels_encoder: 0.1348 (0.1476)  labels_decoder: 0.1223 (0.1271)  labels_encoder_unscaled: 0.1348 (0.1476)  labels_decoder_unscaled: 0.2447 (0.2542)  time: 0.1531  data: 0.0003  max mem: 2688
Epoch: [2]  [1400/1415]  eta: 0:00:02  lr: 0.000010  loss: 0.2446 (0.2741)  labels_encoder: 0.1225 (0.1472)  labels_decoder: 0.1170 (0.1269)  labels_encoder_unscaled: 0.1225 (0.1472)  labels_decoder_unscaled: 0.2340 (0.2537)  time: 0.1625  data: 0.0005  max mem: 2688
Epoch: [2]  [1414/1415]  eta: 0:00:00  lr: 0.000010  loss: 0.2451 (0.2739)  labels_encoder: 0.1201 (0.1471)  labels_decoder: 0.1188 (0.1269)  labels_encoder_unscaled: 0.1201 (0.1471)  labels_decoder_unscaled: 0.2376 (0.2537)  time: 0.1200  data: 0.0003  max mem: 2688
Epoch: [2] Total time: 0:03:47 (0.1611 s / it)
Averaged stats: lr: 0.000010  loss: 0.2451 (0.2739)  labels_encoder: 0.1201 (0.1471)  labels_decoder: 0.1188 (0.1269)  labels_encoder_unscaled: 0.1201 (0.1471)  labels_decoder_unscaled: 0.2376 (0.2537)
Test:  [   0/1613]  eta: 1:04:13  loss: 0.7538 (0.7538)  labels_encoder: 0.3293 (0.3293)  labels_decoder: 0.4245 (0.4245)  labels_encoder_unscaled: 0.3293 (0.3293)  labels_decoder_unscaled: 0.8490 (0.8490)  time: 2.3893  data: 2.3381  max mem: 2688
Test:  [  50/1613]  eta: 0:03:40  loss: 0.4632 (0.8964)  labels_encoder: 0.2625 (0.5699)  labels_decoder: 0.1936 (0.3265)  labels_encoder_unscaled: 0.2625 (0.5699)  labels_decoder_unscaled: 0.3873 (0.6530)  time: 0.0948  data: 0.0238  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:03  loss: 0.3067 (0.7062)  labels_encoder: 0.1817 (0.4493)  labels_decoder: 0.1250 (0.2570)  labels_encoder_unscaled: 0.1817 (0.4493)  labels_decoder_unscaled: 0.2500 (0.5139)  time: 0.1045  data: 0.0240  max mem: 2688
Test:  [ 150/1613]  eta: 0:02:44  loss: 1.0097 (0.7949)  labels_encoder: 0.6367 (0.5110)  labels_decoder: 0.3455 (0.2840)  labels_encoder_unscaled: 0.6367 (0.5110)  labels_decoder_unscaled: 0.6909 (0.5679)  time: 0.0916  data: 0.0175  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:34  loss: 1.3013 (0.9702)  labels_encoder: 0.7900 (0.6306)  labels_decoder: 0.4504 (0.3396)  labels_encoder_unscaled: 0.7900 (0.6306)  labels_decoder_unscaled: 0.9008 (0.6792)  time: 0.0912  data: 0.0210  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:25  loss: 0.6535 (1.0212)  labels_encoder: 0.4583 (0.6625)  labels_decoder: 0.2917 (0.3588)  labels_encoder_unscaled: 0.4583 (0.6625)  labels_decoder_unscaled: 0.5833 (0.7176)  time: 0.0990  data: 0.0105  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:18  loss: 0.6877 (1.0857)  labels_encoder: 0.4119 (0.7111)  labels_decoder: 0.2954 (0.3746)  labels_encoder_unscaled: 0.4119 (0.7111)  labels_decoder_unscaled: 0.5908 (0.7493)  time: 0.0931  data: 0.0306  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:12  loss: 1.3023 (1.0777)  labels_encoder: 0.8420 (0.6999)  labels_decoder: 0.5018 (0.3778)  labels_encoder_unscaled: 0.8420 (0.6999)  labels_decoder_unscaled: 1.0036 (0.7557)  time: 0.1045  data: 0.0231  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:05  loss: 0.8538 (1.1929)  labels_encoder: 0.4565 (0.7765)  labels_decoder: 0.3712 (0.4164)  labels_encoder_unscaled: 0.4565 (0.7765)  labels_decoder_unscaled: 0.7424 (0.8329)  time: 0.0921  data: 0.0277  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:00  loss: 0.8622 (1.2742)  labels_encoder: 0.5351 (0.8321)  labels_decoder: 0.3202 (0.4422)  labels_encoder_unscaled: 0.5351 (0.8321)  labels_decoder_unscaled: 0.6405 (0.8843)  time: 0.0979  data: 0.0234  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:54  loss: 0.4182 (1.2137)  labels_encoder: 0.1992 (0.7898)  labels_decoder: 0.2091 (0.4239)  labels_encoder_unscaled: 0.1992 (0.7898)  labels_decoder_unscaled: 0.4181 (0.8478)  time: 0.0946  data: 0.0201  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:49  loss: 0.7075 (1.1955)  labels_encoder: 0.4645 (0.7770)  labels_decoder: 0.2431 (0.4185)  labels_encoder_unscaled: 0.4645 (0.7770)  labels_decoder_unscaled: 0.4861 (0.8369)  time: 0.0919  data: 0.0295  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:43  loss: 1.0616 (1.2264)  labels_encoder: 0.6269 (0.8036)  labels_decoder: 0.4428 (0.4228)  labels_encoder_unscaled: 0.6269 (0.8036)  labels_decoder_unscaled: 0.8856 (0.8456)  time: 0.0905  data: 0.0162  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:38  loss: 0.7945 (1.2024)  labels_encoder: 0.4492 (0.7829)  labels_decoder: 0.3899 (0.4194)  labels_encoder_unscaled: 0.4492 (0.7829)  labels_decoder_unscaled: 0.7797 (0.8388)  time: 0.1011  data: 0.0332  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:32  loss: 0.5892 (1.1723)  labels_encoder: 0.3318 (0.7620)  labels_decoder: 0.2416 (0.4103)  labels_encoder_unscaled: 0.3318 (0.7620)  labels_decoder_unscaled: 0.4832 (0.8205)  time: 0.1000  data: 0.0182  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:27  loss: 0.8621 (1.1519)  labels_encoder: 0.5271 (0.7471)  labels_decoder: 0.3344 (0.4048)  labels_encoder_unscaled: 0.5271 (0.7471)  labels_decoder_unscaled: 0.6687 (0.8096)  time: 0.0984  data: 0.0050  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:22  loss: 1.1246 (1.1448)  labels_encoder: 0.6678 (0.7430)  labels_decoder: 0.4265 (0.4018)  labels_encoder_unscaled: 0.6678 (0.7430)  labels_decoder_unscaled: 0.8529 (0.8036)  time: 0.0927  data: 0.0110  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:16  loss: 1.5384 (1.1475)  labels_encoder: 0.8828 (0.7415)  labels_decoder: 0.6078 (0.4060)  labels_encoder_unscaled: 0.8828 (0.7415)  labels_decoder_unscaled: 1.2155 (0.8119)  time: 0.1021  data: 0.0174  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:11  loss: 0.7013 (1.1779)  labels_encoder: 0.4674 (0.7632)  labels_decoder: 0.2808 (0.4147)  labels_encoder_unscaled: 0.4674 (0.7632)  labels_decoder_unscaled: 0.5615 (0.8294)  time: 0.0996  data: 0.0260  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:06  loss: 1.0199 (1.1643)  labels_encoder: 0.7258 (0.7551)  labels_decoder: 0.3222 (0.4093)  labels_encoder_unscaled: 0.7258 (0.7551)  labels_decoder_unscaled: 0.6445 (0.8185)  time: 0.1043  data: 0.0218  max mem: 2688
Test:  [1000/1613]  eta: 0:01:01  loss: 0.7425 (1.1481)  labels_encoder: 0.4130 (0.7436)  labels_decoder: 0.2936 (0.4046)  labels_encoder_unscaled: 0.4130 (0.7436)  labels_decoder_unscaled: 0.5871 (0.8091)  time: 0.0988  data: 0.0271  max mem: 2688
Test:  [1050/1613]  eta: 0:00:56  loss: 0.9793 (1.1375)  labels_encoder: 0.5919 (0.7363)  labels_decoder: 0.3382 (0.4011)  labels_encoder_unscaled: 0.5919 (0.7363)  labels_decoder_unscaled: 0.6764 (0.8022)  time: 0.0966  data: 0.0145  max mem: 2688
Test:  [1100/1613]  eta: 0:00:51  loss: 0.5606 (1.1395)  labels_encoder: 0.3229 (0.7393)  labels_decoder: 0.2754 (0.4002)  labels_encoder_unscaled: 0.3229 (0.7393)  labels_decoder_unscaled: 0.5508 (0.8005)  time: 0.1125  data: 0.0467  max mem: 2688
Test:  [1150/1613]  eta: 0:00:46  loss: 0.4769 (1.1239)  labels_encoder: 0.3041 (0.7278)  labels_decoder: 0.2124 (0.3961)  labels_encoder_unscaled: 0.3041 (0.7278)  labels_decoder_unscaled: 0.4247 (0.7922)  time: 0.0964  data: 0.0165  max mem: 2688
Test:  [1200/1613]  eta: 0:00:41  loss: 0.5573 (1.1259)  labels_encoder: 0.3385 (0.7292)  labels_decoder: 0.2249 (0.3968)  labels_encoder_unscaled: 0.3385 (0.7292)  labels_decoder_unscaled: 0.4497 (0.7936)  time: 0.1013  data: 0.0150  max mem: 2688
Test:  [1250/1613]  eta: 0:00:36  loss: 0.5349 (1.1281)  labels_encoder: 0.3163 (0.7307)  labels_decoder: 0.1790 (0.3974)  labels_encoder_unscaled: 0.3163 (0.7307)  labels_decoder_unscaled: 0.3580 (0.7948)  time: 0.0994  data: 0.0365  max mem: 2688
Test:  [1300/1613]  eta: 0:00:31  loss: 0.5469 (1.1272)  labels_encoder: 0.3505 (0.7301)  labels_decoder: 0.3255 (0.3972)  labels_encoder_unscaled: 0.3505 (0.7301)  labels_decoder_unscaled: 0.6510 (0.7943)  time: 0.0917  data: 0.0248  max mem: 2688
Test:  [1350/1613]  eta: 0:00:26  loss: 0.9451 (1.1485)  labels_encoder: 0.5669 (0.7459)  labels_decoder: 0.3694 (0.4025)  labels_encoder_unscaled: 0.5669 (0.7459)  labels_decoder_unscaled: 0.7387 (0.8050)  time: 0.0964  data: 0.0462  max mem: 2688
Test:  [1400/1613]  eta: 0:00:21  loss: 0.9562 (1.1401)  labels_encoder: 0.6343 (0.7403)  labels_decoder: 0.3209 (0.3999)  labels_encoder_unscaled: 0.6343 (0.7403)  labels_decoder_unscaled: 0.6418 (0.7998)  time: 0.0930  data: 0.0413  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.6220 (1.1542)  labels_encoder: 0.3723 (0.7502)  labels_decoder: 0.2378 (0.4040)  labels_encoder_unscaled: 0.3723 (0.7502)  labels_decoder_unscaled: 0.4756 (0.8079)  time: 0.1044  data: 0.0002  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.8216 (1.1603)  labels_encoder: 0.4839 (0.7544)  labels_decoder: 0.3013 (0.4060)  labels_encoder_unscaled: 0.4839 (0.7544)  labels_decoder_unscaled: 0.6025 (0.8119)  time: 0.1044  data: 0.0238  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.7020 (1.1548)  labels_encoder: 0.4569 (0.7512)  labels_decoder: 0.2758 (0.4036)  labels_encoder_unscaled: 0.4569 (0.7512)  labels_decoder_unscaled: 0.5516 (0.8072)  time: 0.0900  data: 0.0031  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.7622 (1.1518)  labels_encoder: 0.4566 (0.7488)  labels_decoder: 0.3417 (0.4030)  labels_encoder_unscaled: 0.4566 (0.7488)  labels_decoder_unscaled: 0.6834 (0.8061)  time: 0.1022  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7622 (1.1498)  labels_encoder: 0.4566 (0.7477)  labels_decoder: 0.3349 (0.4020)  labels_encoder_unscaled: 0.4566 (0.7477)  labels_decoder_unscaled: 0.6697 (0.8040)  time: 0.0937  data: 0.0136  max mem: 2688
Test: Total time: 0:02:44 (0.1018 s / it)
Averaged stats: loss: 0.7622 (1.1498)  labels_encoder: 0.4566 (0.7477)  labels_decoder: 0.3349 (0.4020)  labels_encoder_unscaled: 0.4566 (0.7477)  labels_decoder_unscaled: 0.6697 (0.8040)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5809

dec_mAP all together: | 0.46036712412038094 |.
dec_mAP_pred | 0 : 0.5112201096369311 |.
dec_mAP_pred | 1 : 0.5010604915955204 |.
dec_mAP_pred | 2 : 0.4864329297222296 |.
dec_mAP_pred | 3 : 0.4703905185209611 |.
dec_mAP_pred | 4 : 0.4543362354166197 |.
dec_mAP_pred | 5 : 0.4387714405678689 |.
dec_mAP_pred | 6 : 0.42376032143041825 |.
dec_mAP_pred | 7 : 0.4102685695044415 |.
all decoder map: | 0.4620 |.
BaseballPitch: 0.1734
BasketballDunk: 0.7657
Billiards: 0.4497
CleanAndJerk: 0.7642
CliffDiving: 0.8099
CricketBowling: 0.4465
CricketShot: 0.2633
Diving: 0.6743
FrisbeeCatch: 0.3563
GolfSwing: 0.6770
HammerThrow: 0.8446
HighJump: 0.5676
JavelinThrow: 0.6872
LongJump: 0.7747
PoleVault: 0.8703
Shotput: 0.6853
SoccerPenalty: 0.2895
TennisSwing: 0.6054
ThrowDiscus: 0.5469
VolleyballSpiking: 0.3670
Epoch: [3]  [   0/1415]  eta: 1:00:06  lr: 0.000001  loss: 0.2797 (0.2797)  labels_encoder: 0.1677 (0.1677)  labels_decoder: 0.1120 (0.1120)  labels_encoder_unscaled: 0.1677 (0.1677)  labels_decoder_unscaled: 0.2240 (0.2240)  time: 2.5487  data: 2.4043  max mem: 2688
Epoch: [3]  [  50/1415]  eta: 0:04:41  lr: 0.000001  loss: 0.2456 (0.2441)  labels_encoder: 0.1226 (0.1285)  labels_decoder: 0.1166 (0.1156)  labels_encoder_unscaled: 0.1226 (0.1285)  labels_decoder_unscaled: 0.2333 (0.2311)  time: 0.1557  data: 0.0003  max mem: 2688
Epoch: [3]  [ 100/1415]  eta: 0:03:56  lr: 0.000001  loss: 0.2412 (0.2415)  labels_encoder: 0.1322 (0.1284)  labels_decoder: 0.1087 (0.1131)  labels_encoder_unscaled: 0.1322 (0.1284)  labels_decoder_unscaled: 0.2174 (0.2261)  time: 0.1499  data: 0.0003  max mem: 2688
Epoch: [3]  [ 150/1415]  eta: 0:03:38  lr: 0.000001  loss: 0.2472 (0.2433)  labels_encoder: 0.1175 (0.1286)  labels_decoder: 0.1208 (0.1147)  labels_encoder_unscaled: 0.1175 (0.1286)  labels_decoder_unscaled: 0.2417 (0.2293)  time: 0.1576  data: 0.0003  max mem: 2688
Epoch: [3]  [ 200/1415]  eta: 0:03:23  lr: 0.000001  loss: 0.2360 (0.2423)  labels_encoder: 0.1118 (0.1270)  labels_decoder: 0.1238 (0.1154)  labels_encoder_unscaled: 0.1118 (0.1270)  labels_decoder_unscaled: 0.2475 (0.2307)  time: 0.1569  data: 0.0004  max mem: 2688
Epoch: [3]  [ 250/1415]  eta: 0:03:12  lr: 0.000001  loss: 0.2536 (0.2427)  labels_encoder: 0.1314 (0.1272)  labels_decoder: 0.1233 (0.1155)  labels_encoder_unscaled: 0.1314 (0.1272)  labels_decoder_unscaled: 0.2465 (0.2310)  time: 0.1560  data: 0.0003  max mem: 2688
Epoch: [3]  [ 300/1415]  eta: 0:03:02  lr: 0.000001  loss: 0.2370 (0.2414)  labels_encoder: 0.1248 (0.1260)  labels_decoder: 0.1184 (0.1154)  labels_encoder_unscaled: 0.1248 (0.1260)  labels_decoder_unscaled: 0.2369 (0.2309)  time: 0.1476  data: 0.0003  max mem: 2688
Epoch: [3]  [ 350/1415]  eta: 0:02:52  lr: 0.000001  loss: 0.2388 (0.2410)  labels_encoder: 0.1181 (0.1257)  labels_decoder: 0.1116 (0.1152)  labels_encoder_unscaled: 0.1181 (0.1257)  labels_decoder_unscaled: 0.2232 (0.2305)  time: 0.1592  data: 0.0003  max mem: 2688
Epoch: [3]  [ 400/1415]  eta: 0:02:42  lr: 0.000001  loss: 0.2391 (0.2418)  labels_encoder: 0.1215 (0.1262)  labels_decoder: 0.1119 (0.1156)  labels_encoder_unscaled: 0.1215 (0.1262)  labels_decoder_unscaled: 0.2237 (0.2312)  time: 0.1471  data: 0.0003  max mem: 2688
Epoch: [3]  [ 450/1415]  eta: 0:02:33  lr: 0.000001  loss: 0.2223 (0.2405)  labels_encoder: 0.1092 (0.1250)  labels_decoder: 0.1126 (0.1155)  labels_encoder_unscaled: 0.1092 (0.1250)  labels_decoder_unscaled: 0.2252 (0.2309)  time: 0.1449  data: 0.0003  max mem: 2688
Epoch: [3]  [ 500/1415]  eta: 0:02:25  lr: 0.000001  loss: 0.2208 (0.2401)  labels_encoder: 0.1207 (0.1251)  labels_decoder: 0.1068 (0.1151)  labels_encoder_unscaled: 0.1207 (0.1251)  labels_decoder_unscaled: 0.2137 (0.2301)  time: 0.1553  data: 0.0003  max mem: 2688
Epoch: [3]  [ 550/1415]  eta: 0:02:17  lr: 0.000001  loss: 0.2402 (0.2401)  labels_encoder: 0.1331 (0.1253)  labels_decoder: 0.1060 (0.1148)  labels_encoder_unscaled: 0.1331 (0.1253)  labels_decoder_unscaled: 0.2121 (0.2296)  time: 0.1535  data: 0.0003  max mem: 2688
Epoch: [3]  [ 600/1415]  eta: 0:02:09  lr: 0.000001  loss: 0.2317 (0.2400)  labels_encoder: 0.1219 (0.1252)  labels_decoder: 0.1176 (0.1148)  labels_encoder_unscaled: 0.1219 (0.1252)  labels_decoder_unscaled: 0.2352 (0.2296)  time: 0.1597  data: 0.0003  max mem: 2688
Epoch: [3]  [ 650/1415]  eta: 0:02:01  lr: 0.000001  loss: 0.2386 (0.2400)  labels_encoder: 0.1194 (0.1250)  labels_decoder: 0.1097 (0.1150)  labels_encoder_unscaled: 0.1194 (0.1250)  labels_decoder_unscaled: 0.2194 (0.2301)  time: 0.1553  data: 0.0003  max mem: 2688
Epoch: [3]  [ 700/1415]  eta: 0:01:52  lr: 0.000001  loss: 0.2301 (0.2398)  labels_encoder: 0.1198 (0.1248)  labels_decoder: 0.1164 (0.1150)  labels_encoder_unscaled: 0.1198 (0.1248)  labels_decoder_unscaled: 0.2329 (0.2300)  time: 0.1441  data: 0.0003  max mem: 2688
Epoch: [3]  [ 750/1415]  eta: 0:01:44  lr: 0.000001  loss: 0.2380 (0.2396)  labels_encoder: 0.1127 (0.1247)  labels_decoder: 0.1113 (0.1149)  labels_encoder_unscaled: 0.1127 (0.1247)  labels_decoder_unscaled: 0.2225 (0.2298)  time: 0.1545  data: 0.0003  max mem: 2688
Epoch: [3]  [ 800/1415]  eta: 0:01:36  lr: 0.000001  loss: 0.2339 (0.2392)  labels_encoder: 0.1247 (0.1244)  labels_decoder: 0.1155 (0.1148)  labels_encoder_unscaled: 0.1247 (0.1244)  labels_decoder_unscaled: 0.2309 (0.2297)  time: 0.1640  data: 0.0003  max mem: 2688
Epoch: [3]  [ 850/1415]  eta: 0:01:28  lr: 0.000001  loss: 0.2363 (0.2396)  labels_encoder: 0.1262 (0.1246)  labels_decoder: 0.1139 (0.1150)  labels_encoder_unscaled: 0.1262 (0.1246)  labels_decoder_unscaled: 0.2279 (0.2299)  time: 0.1657  data: 0.0003  max mem: 2688
Epoch: [3]  [ 900/1415]  eta: 0:01:20  lr: 0.000001  loss: 0.2211 (0.2397)  labels_encoder: 0.1066 (0.1246)  labels_decoder: 0.1154 (0.1151)  labels_encoder_unscaled: 0.1066 (0.1246)  labels_decoder_unscaled: 0.2308 (0.2302)  time: 0.1457  data: 0.0003  max mem: 2688
Epoch: [3]  [ 950/1415]  eta: 0:01:12  lr: 0.000001  loss: 0.2480 (0.2398)  labels_encoder: 0.1234 (0.1246)  labels_decoder: 0.1193 (0.1152)  labels_encoder_unscaled: 0.1234 (0.1246)  labels_decoder_unscaled: 0.2387 (0.2303)  time: 0.1529  data: 0.0003  max mem: 2688
Epoch: [3]  [1000/1415]  eta: 0:01:04  lr: 0.000001  loss: 0.2551 (0.2404)  labels_encoder: 0.1277 (0.1248)  labels_decoder: 0.1186 (0.1156)  labels_encoder_unscaled: 0.1277 (0.1248)  labels_decoder_unscaled: 0.2371 (0.2311)  time: 0.1491  data: 0.0003  max mem: 2688
Epoch: [3]  [1050/1415]  eta: 0:00:56  lr: 0.000001  loss: 0.2125 (0.2398)  labels_encoder: 0.1053 (0.1244)  labels_decoder: 0.1051 (0.1155)  labels_encoder_unscaled: 0.1053 (0.1244)  labels_decoder_unscaled: 0.2102 (0.2309)  time: 0.1407  data: 0.0003  max mem: 2688
Epoch: [3]  [1100/1415]  eta: 0:00:48  lr: 0.000001  loss: 0.2501 (0.2403)  labels_encoder: 0.1246 (0.1247)  labels_decoder: 0.1125 (0.1156)  labels_encoder_unscaled: 0.1246 (0.1247)  labels_decoder_unscaled: 0.2250 (0.2312)  time: 0.1523  data: 0.0003  max mem: 2688
Epoch: [3]  [1150/1415]  eta: 0:00:40  lr: 0.000001  loss: 0.2518 (0.2402)  labels_encoder: 0.1392 (0.1247)  labels_decoder: 0.1076 (0.1155)  labels_encoder_unscaled: 0.1392 (0.1247)  labels_decoder_unscaled: 0.2152 (0.2311)  time: 0.1488  data: 0.0004  max mem: 2688
Epoch: [3]  [1200/1415]  eta: 0:00:33  lr: 0.000001  loss: 0.2474 (0.2401)  labels_encoder: 0.1361 (0.1246)  labels_decoder: 0.1152 (0.1155)  labels_encoder_unscaled: 0.1361 (0.1246)  labels_decoder_unscaled: 0.2305 (0.2310)  time: 0.1597  data: 0.0003  max mem: 2688
Epoch: [3]  [1250/1415]  eta: 0:00:25  lr: 0.000001  loss: 0.2211 (0.2401)  labels_encoder: 0.1068 (0.1244)  labels_decoder: 0.1145 (0.1156)  labels_encoder_unscaled: 0.1068 (0.1244)  labels_decoder_unscaled: 0.2291 (0.2312)  time: 0.1493  data: 0.0003  max mem: 2688
Epoch: [3]  [1300/1415]  eta: 0:00:17  lr: 0.000001  loss: 0.2527 (0.2406)  labels_encoder: 0.1298 (0.1249)  labels_decoder: 0.1200 (0.1157)  labels_encoder_unscaled: 0.1298 (0.1249)  labels_decoder_unscaled: 0.2400 (0.2314)  time: 0.1583  data: 0.0003  max mem: 2688
Epoch: [3]  [1350/1415]  eta: 0:00:10  lr: 0.000001  loss: 0.2417 (0.2411)  labels_encoder: 0.1366 (0.1252)  labels_decoder: 0.1118 (0.1159)  labels_encoder_unscaled: 0.1366 (0.1252)  labels_decoder_unscaled: 0.2236 (0.2317)  time: 0.1507  data: 0.0003  max mem: 2688
Epoch: [3]  [1400/1415]  eta: 0:00:02  lr: 0.000001  loss: 0.2190 (0.2405)  labels_encoder: 0.1151 (0.1248)  labels_decoder: 0.1091 (0.1156)  labels_encoder_unscaled: 0.1151 (0.1248)  labels_decoder_unscaled: 0.2183 (0.2313)  time: 0.1551  data: 0.0009  max mem: 2688
Epoch: [3]  [1414/1415]  eta: 0:00:00  lr: 0.000001  loss: 0.2221 (0.2405)  labels_encoder: 0.1178 (0.1249)  labels_decoder: 0.1090 (0.1156)  labels_encoder_unscaled: 0.1178 (0.1249)  labels_decoder_unscaled: 0.2180 (0.2312)  time: 0.1257  data: 0.0008  max mem: 2688
Epoch: [3] Total time: 0:03:38 (0.1541 s / it)
Averaged stats: lr: 0.000001  loss: 0.2221 (0.2405)  labels_encoder: 0.1178 (0.1249)  labels_decoder: 0.1090 (0.1156)  labels_encoder_unscaled: 0.1178 (0.1249)  labels_decoder_unscaled: 0.2180 (0.2312)
Test:  [   0/1613]  eta: 1:15:06  loss: 1.1325 (1.1325)  labels_encoder: 0.5989 (0.5989)  labels_decoder: 0.5336 (0.5336)  labels_encoder_unscaled: 0.5989 (0.5989)  labels_decoder_unscaled: 1.0672 (1.0672)  time: 2.7938  data: 2.6766  max mem: 2688
Test:  [  50/1613]  eta: 0:03:51  loss: 0.4382 (0.8781)  labels_encoder: 0.2362 (0.5465)  labels_decoder: 0.2145 (0.3316)  labels_encoder_unscaled: 0.2362 (0.5465)  labels_decoder_unscaled: 0.4290 (0.6631)  time: 0.0939  data: 0.0031  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:12  loss: 0.2282 (0.7031)  labels_encoder: 0.1406 (0.4406)  labels_decoder: 0.0876 (0.2624)  labels_encoder_unscaled: 0.1406 (0.4406)  labels_decoder_unscaled: 0.1751 (0.5249)  time: 0.1063  data: 0.0398  max mem: 2688
Test:  [ 150/1613]  eta: 0:02:53  loss: 0.9951 (0.7699)  labels_encoder: 0.6387 (0.4904)  labels_decoder: 0.3443 (0.2795)  labels_encoder_unscaled: 0.6387 (0.4904)  labels_decoder_unscaled: 0.6886 (0.5589)  time: 0.1033  data: 0.0365  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:42  loss: 1.0693 (0.9238)  labels_encoder: 0.6216 (0.5929)  labels_decoder: 0.4147 (0.3309)  labels_encoder_unscaled: 0.6216 (0.5929)  labels_decoder_unscaled: 0.8293 (0.6618)  time: 0.1091  data: 0.0379  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:32  loss: 0.6421 (0.9875)  labels_encoder: 0.3788 (0.6336)  labels_decoder: 0.2990 (0.3539)  labels_encoder_unscaled: 0.3788 (0.6336)  labels_decoder_unscaled: 0.5981 (0.7079)  time: 0.0990  data: 0.0244  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:25  loss: 0.6040 (1.0301)  labels_encoder: 0.3175 (0.6667)  labels_decoder: 0.2670 (0.3634)  labels_encoder_unscaled: 0.3175 (0.6667)  labels_decoder_unscaled: 0.5341 (0.7269)  time: 0.1007  data: 0.0190  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:19  loss: 1.3134 (1.0322)  labels_encoder: 0.8403 (0.6627)  labels_decoder: 0.5090 (0.3695)  labels_encoder_unscaled: 0.8403 (0.6627)  labels_decoder_unscaled: 1.0181 (0.7390)  time: 0.1067  data: 0.0304  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:11  loss: 0.8797 (1.1545)  labels_encoder: 0.5143 (0.7453)  labels_decoder: 0.3830 (0.4092)  labels_encoder_unscaled: 0.5143 (0.7453)  labels_decoder_unscaled: 0.7660 (0.8183)  time: 0.1042  data: 0.0259  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:05  loss: 0.8646 (1.2308)  labels_encoder: 0.5516 (0.7971)  labels_decoder: 0.3130 (0.4337)  labels_encoder_unscaled: 0.5516 (0.7971)  labels_decoder_unscaled: 0.6259 (0.8675)  time: 0.1000  data: 0.0353  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:59  loss: 0.4330 (1.1764)  labels_encoder: 0.2113 (0.7598)  labels_decoder: 0.2104 (0.4167)  labels_encoder_unscaled: 0.2113 (0.7598)  labels_decoder_unscaled: 0.4208 (0.8333)  time: 0.1046  data: 0.0256  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:53  loss: 0.7033 (1.1651)  labels_encoder: 0.4740 (0.7517)  labels_decoder: 0.2416 (0.4135)  labels_encoder_unscaled: 0.4740 (0.7517)  labels_decoder_unscaled: 0.4832 (0.8269)  time: 0.1021  data: 0.0308  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:48  loss: 1.3079 (1.1953)  labels_encoder: 0.7438 (0.7782)  labels_decoder: 0.4503 (0.4172)  labels_encoder_unscaled: 0.7438 (0.7782)  labels_decoder_unscaled: 0.9005 (0.8344)  time: 0.1126  data: 0.0059  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:42  loss: 0.8436 (1.1761)  labels_encoder: 0.4648 (0.7609)  labels_decoder: 0.4034 (0.4152)  labels_encoder_unscaled: 0.4648 (0.7609)  labels_decoder_unscaled: 0.8068 (0.8305)  time: 0.1045  data: 0.0225  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:36  loss: 0.5433 (1.1471)  labels_encoder: 0.3320 (0.7410)  labels_decoder: 0.2247 (0.4061)  labels_encoder_unscaled: 0.3320 (0.7410)  labels_decoder_unscaled: 0.4494 (0.8121)  time: 0.1105  data: 0.0315  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:31  loss: 0.8744 (1.1299)  labels_encoder: 0.5296 (0.7284)  labels_decoder: 0.3257 (0.4015)  labels_encoder_unscaled: 0.5296 (0.7284)  labels_decoder_unscaled: 0.6514 (0.8029)  time: 0.1083  data: 0.0345  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:25  loss: 0.9371 (1.1223)  labels_encoder: 0.5263 (0.7240)  labels_decoder: 0.4108 (0.3983)  labels_encoder_unscaled: 0.5263 (0.7240)  labels_decoder_unscaled: 0.8216 (0.7965)  time: 0.0971  data: 0.0238  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:20  loss: 1.4547 (1.1266)  labels_encoder: 0.8465 (0.7239)  labels_decoder: 0.6120 (0.4028)  labels_encoder_unscaled: 0.8465 (0.7239)  labels_decoder_unscaled: 1.2241 (0.8055)  time: 0.0978  data: 0.0182  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:14  loss: 0.6999 (1.1511)  labels_encoder: 0.3757 (0.7409)  labels_decoder: 0.3093 (0.4102)  labels_encoder_unscaled: 0.3757 (0.7409)  labels_decoder_unscaled: 0.6185 (0.8205)  time: 0.1018  data: 0.0140  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:09  loss: 0.9447 (1.1417)  labels_encoder: 0.6551 (0.7356)  labels_decoder: 0.3436 (0.4061)  labels_encoder_unscaled: 0.6551 (0.7356)  labels_decoder_unscaled: 0.6873 (0.8123)  time: 0.1088  data: 0.0411  max mem: 2688
Test:  [1000/1613]  eta: 0:01:04  loss: 0.5903 (1.1263)  labels_encoder: 0.3406 (0.7246)  labels_decoder: 0.2525 (0.4018)  labels_encoder_unscaled: 0.3406 (0.7246)  labels_decoder_unscaled: 0.5049 (0.8035)  time: 0.1064  data: 0.0210  max mem: 2688
Test:  [1050/1613]  eta: 0:00:59  loss: 0.8765 (1.1154)  labels_encoder: 0.5115 (0.7169)  labels_decoder: 0.3244 (0.3985)  labels_encoder_unscaled: 0.5115 (0.7169)  labels_decoder_unscaled: 0.6488 (0.7970)  time: 0.1006  data: 0.0150  max mem: 2688
Test:  [1100/1613]  eta: 0:00:53  loss: 0.6200 (1.1205)  labels_encoder: 0.3578 (0.7223)  labels_decoder: 0.2770 (0.3982)  labels_encoder_unscaled: 0.3578 (0.7223)  labels_decoder_unscaled: 0.5540 (0.7964)  time: 0.0970  data: 0.0276  max mem: 2688
Test:  [1150/1613]  eta: 0:00:48  loss: 0.5073 (1.1059)  labels_encoder: 0.3222 (0.7117)  labels_decoder: 0.2053 (0.3942)  labels_encoder_unscaled: 0.3222 (0.7117)  labels_decoder_unscaled: 0.4105 (0.7885)  time: 0.1135  data: 0.0247  max mem: 2688
Test:  [1200/1613]  eta: 0:00:43  loss: 0.5190 (1.1093)  labels_encoder: 0.3607 (0.7140)  labels_decoder: 0.2192 (0.3953)  labels_encoder_unscaled: 0.3607 (0.7140)  labels_decoder_unscaled: 0.4385 (0.7906)  time: 0.0959  data: 0.0229  max mem: 2688
Test:  [1250/1613]  eta: 0:00:38  loss: 0.4894 (1.1114)  labels_encoder: 0.2672 (0.7154)  labels_decoder: 0.1942 (0.3960)  labels_encoder_unscaled: 0.2672 (0.7154)  labels_decoder_unscaled: 0.3883 (0.7920)  time: 0.0999  data: 0.0153  max mem: 2688
Test:  [1300/1613]  eta: 0:00:32  loss: 0.6428 (1.1089)  labels_encoder: 0.4149 (0.7141)  labels_decoder: 0.2518 (0.3948)  labels_encoder_unscaled: 0.4149 (0.7141)  labels_decoder_unscaled: 0.5035 (0.7897)  time: 0.1186  data: 0.0481  max mem: 2688
Test:  [1350/1613]  eta: 0:00:27  loss: 0.9060 (1.1308)  labels_encoder: 0.5485 (0.7308)  labels_decoder: 0.3602 (0.4000)  labels_encoder_unscaled: 0.5485 (0.7308)  labels_decoder_unscaled: 0.7204 (0.8001)  time: 0.0976  data: 0.0134  max mem: 2688
Test:  [1400/1613]  eta: 0:00:22  loss: 0.9966 (1.1239)  labels_encoder: 0.6575 (0.7260)  labels_decoder: 0.3474 (0.3979)  labels_encoder_unscaled: 0.6575 (0.7260)  labels_decoder_unscaled: 0.6948 (0.7958)  time: 0.0983  data: 0.0327  max mem: 2688
Test:  [1450/1613]  eta: 0:00:17  loss: 0.6608 (1.1395)  labels_encoder: 0.3589 (0.7368)  labels_decoder: 0.2369 (0.4028)  labels_encoder_unscaled: 0.3589 (0.7368)  labels_decoder_unscaled: 0.4739 (0.8055)  time: 0.1127  data: 0.0502  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.8518 (1.1474)  labels_encoder: 0.5089 (0.7422)  labels_decoder: 0.3232 (0.4052)  labels_encoder_unscaled: 0.5089 (0.7422)  labels_decoder_unscaled: 0.6463 (0.8103)  time: 0.0908  data: 0.0106  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.7712 (1.1434)  labels_encoder: 0.4655 (0.7400)  labels_decoder: 0.2841 (0.4034)  labels_encoder_unscaled: 0.4655 (0.7400)  labels_decoder_unscaled: 0.5681 (0.8068)  time: 0.1051  data: 0.0196  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8028 (1.1390)  labels_encoder: 0.4542 (0.7366)  labels_decoder: 0.3371 (0.4024)  labels_encoder_unscaled: 0.4542 (0.7366)  labels_decoder_unscaled: 0.6742 (0.8048)  time: 0.0944  data: 0.0037  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7390 (1.1371)  labels_encoder: 0.4542 (0.7357)  labels_decoder: 0.2954 (0.4014)  labels_encoder_unscaled: 0.4542 (0.7357)  labels_decoder_unscaled: 0.5908 (0.8028)  time: 0.0834  data: 0.0176  max mem: 2688
Test: Total time: 0:02:48 (0.1048 s / it)
Averaged stats: loss: 0.7390 (1.1371)  labels_encoder: 0.4542 (0.7357)  labels_decoder: 0.2954 (0.4014)  labels_encoder_unscaled: 0.4542 (0.7357)  labels_decoder_unscaled: 0.5908 (0.8028)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5787

dec_mAP all together: | 0.4565110038210641 |.
dec_mAP_pred | 0 : 0.5045496168585293 |.
dec_mAP_pred | 1 : 0.4953527943434559 |.
dec_mAP_pred | 2 : 0.4816156566665219 |.
dec_mAP_pred | 3 : 0.4663799481806996 |.
dec_mAP_pred | 4 : 0.45097438316140454 |.
dec_mAP_pred | 5 : 0.4358592955981206 |.
dec_mAP_pred | 6 : 0.4212000002825131 |.
dec_mAP_pred | 7 : 0.4080820349705986 |.
all decoder map: | 0.4580 |.
BaseballPitch: 0.1596
BasketballDunk: 0.7698
Billiards: 0.4563
CleanAndJerk: 0.7583
CliffDiving: 0.8178
CricketBowling: 0.4508
CricketShot: 0.2656
Diving: 0.6760
FrisbeeCatch: 0.3423
GolfSwing: 0.6553
HammerThrow: 0.8422
HighJump: 0.5642
JavelinThrow: 0.6899
LongJump: 0.7773
PoleVault: 0.8700
Shotput: 0.6812
SoccerPenalty: 0.2739
TennisSwing: 0.5959
ThrowDiscus: 0.5600
VolleyballSpiking: 0.3682
Epoch: [4]  [   0/1415]  eta: 0:59:13  lr: 0.000000  loss: 0.1624 (0.1624)  labels_encoder: 0.0531 (0.0531)  labels_decoder: 0.1093 (0.1093)  labels_encoder_unscaled: 0.0531 (0.0531)  labels_decoder_unscaled: 0.2187 (0.2187)  time: 2.5112  data: 2.3691  max mem: 2688
Epoch: [4]  [  50/1415]  eta: 0:04:10  lr: 0.000000  loss: 0.2474 (0.2392)  labels_encoder: 0.1251 (0.1234)  labels_decoder: 0.1183 (0.1159)  labels_encoder_unscaled: 0.1251 (0.1234)  labels_decoder_unscaled: 0.2366 (0.2317)  time: 0.1334  data: 0.0003  max mem: 2688
Epoch: [4]  [ 100/1415]  eta: 0:03:34  lr: 0.000000  loss: 0.2316 (0.2386)  labels_encoder: 0.1252 (0.1247)  labels_decoder: 0.1077 (0.1138)  labels_encoder_unscaled: 0.1252 (0.1247)  labels_decoder_unscaled: 0.2153 (0.2277)  time: 0.1409  data: 0.0003  max mem: 2688
Epoch: [4]  [ 150/1415]  eta: 0:03:16  lr: 0.000000  loss: 0.2240 (0.2352)  labels_encoder: 0.1108 (0.1223)  labels_decoder: 0.1127 (0.1129)  labels_encoder_unscaled: 0.1108 (0.1223)  labels_decoder_unscaled: 0.2255 (0.2259)  time: 0.1401  data: 0.0003  max mem: 2688
Epoch: [4]  [ 200/1415]  eta: 0:03:07  lr: 0.000000  loss: 0.2282 (0.2367)  labels_encoder: 0.1179 (0.1233)  labels_decoder: 0.1076 (0.1134)  labels_encoder_unscaled: 0.1179 (0.1233)  labels_decoder_unscaled: 0.2151 (0.2269)  time: 0.1485  data: 0.0003  max mem: 2688
Epoch: [4]  [ 250/1415]  eta: 0:02:57  lr: 0.000000  loss: 0.2515 (0.2392)  labels_encoder: 0.1262 (0.1248)  labels_decoder: 0.1167 (0.1144)  labels_encoder_unscaled: 0.1262 (0.1248)  labels_decoder_unscaled: 0.2333 (0.2288)  time: 0.1478  data: 0.0003  max mem: 2688
Epoch: [4]  [ 300/1415]  eta: 0:02:48  lr: 0.000000  loss: 0.2393 (0.2401)  labels_encoder: 0.1208 (0.1250)  labels_decoder: 0.1244 (0.1151)  labels_encoder_unscaled: 0.1208 (0.1250)  labels_decoder_unscaled: 0.2488 (0.2302)  time: 0.1444  data: 0.0003  max mem: 2688
Epoch: [4]  [ 350/1415]  eta: 0:02:40  lr: 0.000000  loss: 0.2409 (0.2396)  labels_encoder: 0.1311 (0.1243)  labels_decoder: 0.1162 (0.1153)  labels_encoder_unscaled: 0.1311 (0.1243)  labels_decoder_unscaled: 0.2324 (0.2305)  time: 0.1439  data: 0.0003  max mem: 2688
Epoch: [4]  [ 400/1415]  eta: 0:02:31  lr: 0.000000  loss: 0.2314 (0.2393)  labels_encoder: 0.1288 (0.1241)  labels_decoder: 0.1126 (0.1152)  labels_encoder_unscaled: 0.1288 (0.1241)  labels_decoder_unscaled: 0.2252 (0.2305)  time: 0.1429  data: 0.0004  max mem: 2688
Epoch: [4]  [ 450/1415]  eta: 0:02:24  lr: 0.000000  loss: 0.2417 (0.2392)  labels_encoder: 0.1227 (0.1243)  labels_decoder: 0.1164 (0.1149)  labels_encoder_unscaled: 0.1227 (0.1243)  labels_decoder_unscaled: 0.2328 (0.2297)  time: 0.1427  data: 0.0003  max mem: 2688
Epoch: [4]  [ 500/1415]  eta: 0:02:16  lr: 0.000000  loss: 0.2286 (0.2384)  labels_encoder: 0.1170 (0.1242)  labels_decoder: 0.1103 (0.1142)  labels_encoder_unscaled: 0.1170 (0.1242)  labels_decoder_unscaled: 0.2207 (0.2284)  time: 0.1392  data: 0.0003  max mem: 2688
Epoch: [4]  [ 550/1415]  eta: 0:02:08  lr: 0.000000  loss: 0.2181 (0.2375)  labels_encoder: 0.1105 (0.1232)  labels_decoder: 0.1113 (0.1142)  labels_encoder_unscaled: 0.1105 (0.1232)  labels_decoder_unscaled: 0.2227 (0.2284)  time: 0.1452  data: 0.0003  max mem: 2688
Epoch: [4]  [ 600/1415]  eta: 0:02:00  lr: 0.000000  loss: 0.2278 (0.2375)  labels_encoder: 0.1174 (0.1231)  labels_decoder: 0.1149 (0.1144)  labels_encoder_unscaled: 0.1174 (0.1231)  labels_decoder_unscaled: 0.2297 (0.2288)  time: 0.1423  data: 0.0003  max mem: 2688
Epoch: [4]  [ 650/1415]  eta: 0:01:53  lr: 0.000000  loss: 0.2345 (0.2372)  labels_encoder: 0.1369 (0.1228)  labels_decoder: 0.1082 (0.1144)  labels_encoder_unscaled: 0.1369 (0.1228)  labels_decoder_unscaled: 0.2164 (0.2288)  time: 0.1482  data: 0.0003  max mem: 2688
Epoch: [4]  [ 700/1415]  eta: 0:01:45  lr: 0.000000  loss: 0.2353 (0.2374)  labels_encoder: 0.1197 (0.1232)  labels_decoder: 0.1089 (0.1142)  labels_encoder_unscaled: 0.1197 (0.1232)  labels_decoder_unscaled: 0.2179 (0.2284)  time: 0.1538  data: 0.0003  max mem: 2688
Epoch: [4]  [ 750/1415]  eta: 0:01:38  lr: 0.000000  loss: 0.2380 (0.2378)  labels_encoder: 0.1179 (0.1235)  labels_decoder: 0.1132 (0.1143)  labels_encoder_unscaled: 0.1179 (0.1235)  labels_decoder_unscaled: 0.2264 (0.2286)  time: 0.1440  data: 0.0003  max mem: 2688
Epoch: [4]  [ 800/1415]  eta: 0:01:31  lr: 0.000000  loss: 0.2242 (0.2372)  labels_encoder: 0.1192 (0.1232)  labels_decoder: 0.1019 (0.1140)  labels_encoder_unscaled: 0.1192 (0.1232)  labels_decoder_unscaled: 0.2038 (0.2280)  time: 0.1410  data: 0.0003  max mem: 2688
Epoch: [4]  [ 850/1415]  eta: 0:01:23  lr: 0.000000  loss: 0.2320 (0.2374)  labels_encoder: 0.1099 (0.1233)  labels_decoder: 0.1125 (0.1141)  labels_encoder_unscaled: 0.1099 (0.1233)  labels_decoder_unscaled: 0.2250 (0.2282)  time: 0.1408  data: 0.0002  max mem: 2688
Epoch: [4]  [ 900/1415]  eta: 0:01:16  lr: 0.000000  loss: 0.2276 (0.2375)  labels_encoder: 0.1047 (0.1231)  labels_decoder: 0.1192 (0.1144)  labels_encoder_unscaled: 0.1047 (0.1231)  labels_decoder_unscaled: 0.2385 (0.2289)  time: 0.1430  data: 0.0003  max mem: 2688
Epoch: [4]  [ 950/1415]  eta: 0:01:08  lr: 0.000000  loss: 0.2549 (0.2373)  labels_encoder: 0.1247 (0.1229)  labels_decoder: 0.1120 (0.1144)  labels_encoder_unscaled: 0.1247 (0.1229)  labels_decoder_unscaled: 0.2239 (0.2289)  time: 0.1493  data: 0.0002  max mem: 2688
Epoch: [4]  [1000/1415]  eta: 0:01:01  lr: 0.000000  loss: 0.2282 (0.2373)  labels_encoder: 0.1123 (0.1228)  labels_decoder: 0.1128 (0.1145)  labels_encoder_unscaled: 0.1123 (0.1228)  labels_decoder_unscaled: 0.2255 (0.2290)  time: 0.1408  data: 0.0003  max mem: 2688
Epoch: [4]  [1050/1415]  eta: 0:00:53  lr: 0.000000  loss: 0.2215 (0.2372)  labels_encoder: 0.1156 (0.1226)  labels_decoder: 0.1084 (0.1146)  labels_encoder_unscaled: 0.1156 (0.1226)  labels_decoder_unscaled: 0.2167 (0.2292)  time: 0.1431  data: 0.0002  max mem: 2688
Epoch: [4]  [1100/1415]  eta: 0:00:46  lr: 0.000000  loss: 0.2331 (0.2371)  labels_encoder: 0.1168 (0.1227)  labels_decoder: 0.1132 (0.1144)  labels_encoder_unscaled: 0.1168 (0.1227)  labels_decoder_unscaled: 0.2265 (0.2288)  time: 0.1495  data: 0.0003  max mem: 2688
Epoch: [4]  [1150/1415]  eta: 0:00:38  lr: 0.000000  loss: 0.2267 (0.2368)  labels_encoder: 0.1134 (0.1226)  labels_decoder: 0.1110 (0.1143)  labels_encoder_unscaled: 0.1134 (0.1226)  labels_decoder_unscaled: 0.2221 (0.2286)  time: 0.1431  data: 0.0003  max mem: 2688
Epoch: [4]  [1200/1415]  eta: 0:00:31  lr: 0.000000  loss: 0.2293 (0.2369)  labels_encoder: 0.1171 (0.1225)  labels_decoder: 0.1097 (0.1143)  labels_encoder_unscaled: 0.1171 (0.1225)  labels_decoder_unscaled: 0.2194 (0.2287)  time: 0.1466  data: 0.0003  max mem: 2688
Epoch: [4]  [1250/1415]  eta: 0:00:24  lr: 0.000000  loss: 0.2486 (0.2366)  labels_encoder: 0.1334 (0.1224)  labels_decoder: 0.1151 (0.1142)  labels_encoder_unscaled: 0.1334 (0.1224)  labels_decoder_unscaled: 0.2301 (0.2284)  time: 0.1583  data: 0.0003  max mem: 2688
Epoch: [4]  [1300/1415]  eta: 0:00:16  lr: 0.000000  loss: 0.2324 (0.2369)  labels_encoder: 0.1135 (0.1226)  labels_decoder: 0.1170 (0.1143)  labels_encoder_unscaled: 0.1135 (0.1226)  labels_decoder_unscaled: 0.2340 (0.2287)  time: 0.1366  data: 0.0003  max mem: 2688
Epoch: [4]  [1350/1415]  eta: 0:00:09  lr: 0.000000  loss: 0.2219 (0.2365)  labels_encoder: 0.1145 (0.1222)  labels_decoder: 0.1138 (0.1143)  labels_encoder_unscaled: 0.1145 (0.1222)  labels_decoder_unscaled: 0.2276 (0.2286)  time: 0.1315  data: 0.0002  max mem: 2688
Epoch: [4]  [1400/1415]  eta: 0:00:02  lr: 0.000000  loss: 0.2130 (0.2365)  labels_encoder: 0.0963 (0.1223)  labels_decoder: 0.1097 (0.1142)  labels_encoder_unscaled: 0.0963 (0.1223)  labels_decoder_unscaled: 0.2194 (0.2284)  time: 0.1275  data: 0.0005  max mem: 2688
Epoch: [4]  [1414/1415]  eta: 0:00:00  lr: 0.000000  loss: 0.2255 (0.2365)  labels_encoder: 0.1176 (0.1223)  labels_decoder: 0.1131 (0.1142)  labels_encoder_unscaled: 0.1176 (0.1223)  labels_decoder_unscaled: 0.2263 (0.2284)  time: 0.1055  data: 0.0004  max mem: 2688
Epoch: [4] Total time: 0:03:26 (0.1459 s / it)
Averaged stats: lr: 0.000000  loss: 0.2255 (0.2365)  labels_encoder: 0.1176 (0.1223)  labels_decoder: 0.1131 (0.1142)  labels_encoder_unscaled: 0.1176 (0.1223)  labels_decoder_unscaled: 0.2263 (0.2284)
Test:  [   0/1613]  eta: 1:02:12  loss: 1.0879 (1.0879)  labels_encoder: 0.5674 (0.5674)  labels_decoder: 0.5205 (0.5205)  labels_encoder_unscaled: 0.5674 (0.5674)  labels_decoder_unscaled: 1.0410 (1.0410)  time: 2.3142  data: 2.2587  max mem: 2688
Test:  [  50/1613]  eta: 0:03:41  loss: 0.4610 (0.8763)  labels_encoder: 0.2419 (0.5472)  labels_decoder: 0.2030 (0.3291)  labels_encoder_unscaled: 0.2419 (0.5472)  labels_decoder_unscaled: 0.4059 (0.6583)  time: 0.1017  data: 0.0502  max mem: 2688
Test:  [ 100/1613]  eta: 0:02:59  loss: 0.2214 (0.7031)  labels_encoder: 0.1471 (0.4417)  labels_decoder: 0.0858 (0.2615)  labels_encoder_unscaled: 0.1471 (0.4417)  labels_decoder_unscaled: 0.1717 (0.5229)  time: 0.0892  data: 0.0393  max mem: 2688
Test:  [ 150/1613]  eta: 0:02:44  loss: 0.9890 (0.7737)  labels_encoder: 0.6421 (0.4934)  labels_decoder: 0.3475 (0.2803)  labels_encoder_unscaled: 0.6421 (0.4934)  labels_decoder_unscaled: 0.6949 (0.5606)  time: 0.1047  data: 0.0598  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:31  loss: 1.0756 (0.9227)  labels_encoder: 0.6253 (0.5927)  labels_decoder: 0.4150 (0.3300)  labels_encoder_unscaled: 0.6253 (0.5927)  labels_decoder_unscaled: 0.8300 (0.6600)  time: 0.0916  data: 0.0350  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:22  loss: 0.6466 (0.9856)  labels_encoder: 0.4004 (0.6329)  labels_decoder: 0.2895 (0.3528)  labels_encoder_unscaled: 0.4004 (0.6329)  labels_decoder_unscaled: 0.5790 (0.7055)  time: 0.0935  data: 0.0331  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:17  loss: 0.6133 (1.0321)  labels_encoder: 0.3273 (0.6684)  labels_decoder: 0.2615 (0.3637)  labels_encoder_unscaled: 0.3273 (0.6684)  labels_decoder_unscaled: 0.5229 (0.7275)  time: 0.0924  data: 0.0390  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:09  loss: 1.3148 (1.0336)  labels_encoder: 0.8425 (0.6640)  labels_decoder: 0.5065 (0.3696)  labels_encoder_unscaled: 0.8425 (0.6640)  labels_decoder_unscaled: 1.0129 (0.7392)  time: 0.0906  data: 0.0194  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:03  loss: 0.8642 (1.1549)  labels_encoder: 0.4907 (0.7460)  labels_decoder: 0.3735 (0.4089)  labels_encoder_unscaled: 0.4907 (0.7460)  labels_decoder_unscaled: 0.7470 (0.8177)  time: 0.1044  data: 0.0303  max mem: 2688
Test:  [ 450/1613]  eta: 0:01:57  loss: 0.8511 (1.2317)  labels_encoder: 0.5553 (0.7981)  labels_decoder: 0.3078 (0.4336)  labels_encoder_unscaled: 0.5553 (0.7981)  labels_decoder_unscaled: 0.6157 (0.8673)  time: 0.0922  data: 0.0226  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:51  loss: 0.4140 (1.1768)  labels_encoder: 0.2021 (0.7604)  labels_decoder: 0.2105 (0.4164)  labels_encoder_unscaled: 0.2021 (0.7604)  labels_decoder_unscaled: 0.4210 (0.8328)  time: 0.0989  data: 0.0401  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:46  loss: 0.6734 (1.1643)  labels_encoder: 0.4530 (0.7514)  labels_decoder: 0.2428 (0.4128)  labels_encoder_unscaled: 0.4530 (0.7514)  labels_decoder_unscaled: 0.4855 (0.8257)  time: 0.0959  data: 0.0294  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:41  loss: 1.3102 (1.1948)  labels_encoder: 0.7452 (0.7781)  labels_decoder: 0.4518 (0.4167)  labels_encoder_unscaled: 0.7452 (0.7781)  labels_decoder_unscaled: 0.9035 (0.8333)  time: 0.0933  data: 0.0270  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:35  loss: 0.8698 (1.1756)  labels_encoder: 0.4742 (0.7609)  labels_decoder: 0.4092 (0.4147)  labels_encoder_unscaled: 0.4742 (0.7609)  labels_decoder_unscaled: 0.8183 (0.8294)  time: 0.0907  data: 0.0345  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:30  loss: 0.5491 (1.1466)  labels_encoder: 0.3346 (0.7411)  labels_decoder: 0.2267 (0.4056)  labels_encoder_unscaled: 0.3346 (0.7411)  labels_decoder_unscaled: 0.4533 (0.8111)  time: 0.0980  data: 0.0402  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:24  loss: 0.9296 (1.1301)  labels_encoder: 0.5383 (0.7288)  labels_decoder: 0.3381 (0.4013)  labels_encoder_unscaled: 0.5383 (0.7288)  labels_decoder_unscaled: 0.6762 (0.8026)  time: 0.0948  data: 0.0390  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:19  loss: 0.9530 (1.1226)  labels_encoder: 0.5389 (0.7245)  labels_decoder: 0.4119 (0.3981)  labels_encoder_unscaled: 0.5389 (0.7245)  labels_decoder_unscaled: 0.8237 (0.7963)  time: 0.0901  data: 0.0336  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:14  loss: 1.3993 (1.1276)  labels_encoder: 0.8123 (0.7248)  labels_decoder: 0.6133 (0.4028)  labels_encoder_unscaled: 0.8123 (0.7248)  labels_decoder_unscaled: 1.2267 (0.8057)  time: 0.1067  data: 0.0396  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:09  loss: 0.6708 (1.1539)  labels_encoder: 0.3879 (0.7432)  labels_decoder: 0.3187 (0.4107)  labels_encoder_unscaled: 0.3879 (0.7432)  labels_decoder_unscaled: 0.6374 (0.8215)  time: 0.1050  data: 0.0144  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:04  loss: 0.9704 (1.1443)  labels_encoder: 0.6628 (0.7377)  labels_decoder: 0.3520 (0.4066)  labels_encoder_unscaled: 0.6628 (0.7377)  labels_decoder_unscaled: 0.7041 (0.8132)  time: 0.0968  data: 0.0377  max mem: 2688
Test:  [1000/1613]  eta: 0:00:59  loss: 0.5989 (1.1289)  labels_encoder: 0.3439 (0.7266)  labels_decoder: 0.2591 (0.4023)  labels_encoder_unscaled: 0.3439 (0.7266)  labels_decoder_unscaled: 0.5182 (0.8046)  time: 0.0957  data: 0.0331  max mem: 2688
Test:  [1050/1613]  eta: 0:00:55  loss: 0.8647 (1.1176)  labels_encoder: 0.5112 (0.7188)  labels_decoder: 0.3246 (0.3989)  labels_encoder_unscaled: 0.5112 (0.7188)  labels_decoder_unscaled: 0.6491 (0.7978)  time: 0.0944  data: 0.0222  max mem: 2688
Test:  [1100/1613]  eta: 0:00:50  loss: 0.6112 (1.1217)  labels_encoder: 0.3454 (0.7235)  labels_decoder: 0.2719 (0.3983)  labels_encoder_unscaled: 0.3454 (0.7235)  labels_decoder_unscaled: 0.5437 (0.7965)  time: 0.0966  data: 0.0175  max mem: 2688
Test:  [1150/1613]  eta: 0:00:45  loss: 0.5094 (1.1070)  labels_encoder: 0.3259 (0.7127)  labels_decoder: 0.1890 (0.3943)  labels_encoder_unscaled: 0.3259 (0.7127)  labels_decoder_unscaled: 0.3780 (0.7886)  time: 0.0944  data: 0.0289  max mem: 2688
Test:  [1200/1613]  eta: 0:00:40  loss: 0.5383 (1.1108)  labels_encoder: 0.3658 (0.7153)  labels_decoder: 0.2268 (0.3955)  labels_encoder_unscaled: 0.3658 (0.7153)  labels_decoder_unscaled: 0.4535 (0.7910)  time: 0.0991  data: 0.0421  max mem: 2688
Test:  [1250/1613]  eta: 0:00:35  loss: 0.4991 (1.1132)  labels_encoder: 0.2742 (0.7169)  labels_decoder: 0.1957 (0.3963)  labels_encoder_unscaled: 0.2742 (0.7169)  labels_decoder_unscaled: 0.3913 (0.7927)  time: 0.0937  data: 0.0352  max mem: 2688
Test:  [1300/1613]  eta: 0:00:30  loss: 0.6035 (1.1107)  labels_encoder: 0.3862 (0.7155)  labels_decoder: 0.2600 (0.3952)  labels_encoder_unscaled: 0.3862 (0.7155)  labels_decoder_unscaled: 0.5200 (0.7905)  time: 0.0928  data: 0.0309  max mem: 2688
Test:  [1350/1613]  eta: 0:00:25  loss: 0.8997 (1.1318)  labels_encoder: 0.5427 (0.7316)  labels_decoder: 0.3611 (0.4002)  labels_encoder_unscaled: 0.5427 (0.7316)  labels_decoder_unscaled: 0.7221 (0.8004)  time: 0.0941  data: 0.0382  max mem: 2688
Test:  [1400/1613]  eta: 0:00:20  loss: 0.9727 (1.1247)  labels_encoder: 0.6280 (0.7267)  labels_decoder: 0.3554 (0.3980)  labels_encoder_unscaled: 0.6280 (0.7267)  labels_decoder_unscaled: 0.7108 (0.7961)  time: 0.0935  data: 0.0250  max mem: 2688
Test:  [1450/1613]  eta: 0:00:15  loss: 0.6666 (1.1398)  labels_encoder: 0.3734 (0.7371)  labels_decoder: 0.2453 (0.4027)  labels_encoder_unscaled: 0.3734 (0.7371)  labels_decoder_unscaled: 0.4906 (0.8054)  time: 0.0932  data: 0.0313  max mem: 2688
Test:  [1500/1613]  eta: 0:00:10  loss: 0.8460 (1.1472)  labels_encoder: 0.5076 (0.7423)  labels_decoder: 0.3223 (0.4049)  labels_encoder_unscaled: 0.5076 (0.7423)  labels_decoder_unscaled: 0.6446 (0.8098)  time: 0.1023  data: 0.0389  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.7669 (1.1436)  labels_encoder: 0.4637 (0.7403)  labels_decoder: 0.2846 (0.4032)  labels_encoder_unscaled: 0.4637 (0.7403)  labels_decoder_unscaled: 0.5693 (0.8065)  time: 0.0948  data: 0.0414  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.7758 (1.1396)  labels_encoder: 0.4731 (0.7372)  labels_decoder: 0.3532 (0.4024)  labels_encoder_unscaled: 0.4731 (0.7372)  labels_decoder_unscaled: 0.7063 (0.8048)  time: 0.0911  data: 0.0258  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7758 (1.1379)  labels_encoder: 0.4731 (0.7364)  labels_decoder: 0.3259 (0.4015)  labels_encoder_unscaled: 0.4731 (0.7364)  labels_decoder_unscaled: 0.6517 (0.8029)  time: 0.0841  data: 0.0284  max mem: 2688
Test: Total time: 0:02:36 (0.0971 s / it)
Averaged stats: loss: 0.7758 (1.1379)  labels_encoder: 0.4731 (0.7364)  labels_decoder: 0.3259 (0.4015)  labels_encoder_unscaled: 0.4731 (0.7364)  labels_decoder_unscaled: 0.6517 (0.8029)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5784

dec_mAP all together: | 0.456469990303765 |.
dec_mAP_pred | 0 : 0.5046602296566715 |.
dec_mAP_pred | 1 : 0.49542764489345414 |.
dec_mAP_pred | 2 : 0.4816167915524672 |.
dec_mAP_pred | 3 : 0.466350269811009 |.
dec_mAP_pred | 4 : 0.4509119612869945 |.
dec_mAP_pred | 5 : 0.43576476674635173 |.
dec_mAP_pred | 6 : 0.4211114725134334 |.
dec_mAP_pred | 7 : 0.40792322563966865 |.
all decoder map: | 0.4580 |.
BaseballPitch: 0.1583
BasketballDunk: 0.7689
Billiards: 0.4561
CleanAndJerk: 0.7575
CliffDiving: 0.8148
CricketBowling: 0.4498
CricketShot: 0.2650
Diving: 0.6739
FrisbeeCatch: 0.3449
GolfSwing: 0.6579
HammerThrow: 0.8419
HighJump: 0.5661
JavelinThrow: 0.6902
LongJump: 0.7770
PoleVault: 0.8702
Shotput: 0.6789
SoccerPenalty: 0.2748
TennisSwing: 0.5972
ThrowDiscus: 0.5562
VolleyballSpiking: 0.3678
Training time 0:28:48
