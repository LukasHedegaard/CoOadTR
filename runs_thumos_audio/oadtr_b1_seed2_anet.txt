Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:2
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  66.183 M, 99.815% Params, 1.896 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 11.071% Params, 0.47 GMac, 24.773% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    6.295 M, 9.493% Params, 0.409 GMac, 21.570% MACs, 
    (net): Sequential(
      6.295 M, 9.493% Params, 0.409 GMac, 21.570% MACs, 
      (0): Residual(
        4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
        (fn): PreNormDrop(
          4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
            (qkv): Linear(3.146 M, 4.744% Params, 0.204 GMac, 10.783% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
        (fn): PreNorm(
          2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
            (net): Sequential(
              2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
              (0): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.068% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 79.148% Params, 1.017 GMac, 53.645% MACs, 
    (layers): ModuleList(
      52.48 M, 79.148% Params, 1.017 GMac, 53.645% MACs, 
      (0): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.034% Params, 0.0 GMac, 0.010% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 1896244268.0
Model params: 66306092
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1405]  eta: 1:45:09  lr: 0.000100  loss: 4.6839 (4.6839)  labels_encoder: 3.2069 (3.2069)  labels_decoder: 1.4769 (1.4769)  labels_encoder_unscaled: 3.2069 (3.2069)  labels_decoder_unscaled: 2.9538 (2.9538)  time: 4.4906  data: 3.8311  max mem: 1929
Epoch: [1]  [  50/1405]  eta: 0:06:36  lr: 0.000100  loss: 1.1610 (1.6744)  labels_encoder: 0.7156 (1.0955)  labels_decoder: 0.4303 (0.5789)  labels_encoder_unscaled: 0.7156 (1.0955)  labels_decoder_unscaled: 0.8606 (1.1578)  time: 0.1741  data: 0.0005  max mem: 2688
Epoch: [1]  [ 100/1405]  eta: 0:05:03  lr: 0.000100  loss: 0.8024 (1.2925)  labels_encoder: 0.5171 (0.8324)  labels_decoder: 0.3007 (0.4601)  labels_encoder_unscaled: 0.5171 (0.8324)  labels_decoder_unscaled: 0.6014 (0.9202)  time: 0.1654  data: 0.0005  max mem: 2688
Epoch: [1]  [ 150/1405]  eta: 0:04:22  lr: 0.000100  loss: 0.7114 (1.1102)  labels_encoder: 0.4389 (0.7095)  labels_decoder: 0.2743 (0.4007)  labels_encoder_unscaled: 0.4389 (0.7095)  labels_decoder_unscaled: 0.5487 (0.8014)  time: 0.1564  data: 0.0003  max mem: 2688
Epoch: [1]  [ 200/1405]  eta: 0:03:57  lr: 0.000100  loss: 0.6019 (0.9974)  labels_encoder: 0.3794 (0.6349)  labels_decoder: 0.2279 (0.3625)  labels_encoder_unscaled: 0.3794 (0.6349)  labels_decoder_unscaled: 0.4558 (0.7250)  time: 0.1602  data: 0.0003  max mem: 2688
Epoch: [1]  [ 250/1405]  eta: 0:03:39  lr: 0.000100  loss: 0.6148 (0.9185)  labels_encoder: 0.3702 (0.5814)  labels_decoder: 0.2353 (0.3371)  labels_encoder_unscaled: 0.3702 (0.5814)  labels_decoder_unscaled: 0.4706 (0.6741)  time: 0.1602  data: 0.0004  max mem: 2688
Epoch: [1]  [ 300/1405]  eta: 0:03:25  lr: 0.000100  loss: 0.5218 (0.8635)  labels_encoder: 0.3175 (0.5440)  labels_decoder: 0.2185 (0.3195)  labels_encoder_unscaled: 0.3175 (0.5440)  labels_decoder_unscaled: 0.4370 (0.6390)  time: 0.1601  data: 0.0003  max mem: 2688
Epoch: [1]  [ 350/1405]  eta: 0:03:12  lr: 0.000100  loss: 0.5370 (0.8215)  labels_encoder: 0.3216 (0.5158)  labels_decoder: 0.2244 (0.3057)  labels_encoder_unscaled: 0.3216 (0.5158)  labels_decoder_unscaled: 0.4488 (0.6114)  time: 0.1683  data: 0.0003  max mem: 2688
Epoch: [1]  [ 400/1405]  eta: 0:03:01  lr: 0.000100  loss: 0.4656 (0.7829)  labels_encoder: 0.2789 (0.4895)  labels_decoder: 0.1992 (0.2934)  labels_encoder_unscaled: 0.2789 (0.4895)  labels_decoder_unscaled: 0.3985 (0.5868)  time: 0.1693  data: 0.0004  max mem: 2688
Epoch: [1]  [ 450/1405]  eta: 0:02:50  lr: 0.000100  loss: 0.5279 (0.7551)  labels_encoder: 0.3177 (0.4707)  labels_decoder: 0.2007 (0.2844)  labels_encoder_unscaled: 0.3177 (0.4707)  labels_decoder_unscaled: 0.4014 (0.5688)  time: 0.1704  data: 0.0003  max mem: 2688
Epoch: [1]  [ 500/1405]  eta: 0:02:40  lr: 0.000100  loss: 0.4602 (0.7296)  labels_encoder: 0.2708 (0.4536)  labels_decoder: 0.1811 (0.2759)  labels_encoder_unscaled: 0.2708 (0.4536)  labels_decoder_unscaled: 0.3623 (0.5519)  time: 0.1634  data: 0.0004  max mem: 2688
Epoch: [1]  [ 550/1405]  eta: 0:02:29  lr: 0.000100  loss: 0.4714 (0.7069)  labels_encoder: 0.2805 (0.4382)  labels_decoder: 0.1892 (0.2687)  labels_encoder_unscaled: 0.2805 (0.4382)  labels_decoder_unscaled: 0.3784 (0.5374)  time: 0.1522  data: 0.0003  max mem: 2688
Epoch: [1]  [ 600/1405]  eta: 0:02:20  lr: 0.000100  loss: 0.5003 (0.6877)  labels_encoder: 0.2901 (0.4251)  labels_decoder: 0.1981 (0.2627)  labels_encoder_unscaled: 0.2901 (0.4251)  labels_decoder_unscaled: 0.3961 (0.5253)  time: 0.1628  data: 0.0003  max mem: 2688
Epoch: [1]  [ 650/1405]  eta: 0:02:10  lr: 0.000100  loss: 0.4441 (0.6718)  labels_encoder: 0.2541 (0.4143)  labels_decoder: 0.1912 (0.2575)  labels_encoder_unscaled: 0.2541 (0.4143)  labels_decoder_unscaled: 0.3823 (0.5151)  time: 0.1630  data: 0.0003  max mem: 2688
Epoch: [1]  [ 700/1405]  eta: 0:02:01  lr: 0.000100  loss: 0.4686 (0.6570)  labels_encoder: 0.2759 (0.4045)  labels_decoder: 0.1841 (0.2525)  labels_encoder_unscaled: 0.2759 (0.4045)  labels_decoder_unscaled: 0.3683 (0.5050)  time: 0.1606  data: 0.0008  max mem: 2688
Epoch: [1]  [ 750/1405]  eta: 0:01:52  lr: 0.000100  loss: 0.4229 (0.6426)  labels_encoder: 0.2327 (0.3946)  labels_decoder: 0.1773 (0.2480)  labels_encoder_unscaled: 0.2327 (0.3946)  labels_decoder_unscaled: 0.3546 (0.4960)  time: 0.1770  data: 0.0041  max mem: 2688
Epoch: [1]  [ 800/1405]  eta: 0:01:43  lr: 0.000100  loss: 0.4851 (0.6310)  labels_encoder: 0.2816 (0.3869)  labels_decoder: 0.1868 (0.2441)  labels_encoder_unscaled: 0.2816 (0.3869)  labels_decoder_unscaled: 0.3736 (0.4881)  time: 0.1545  data: 0.0003  max mem: 2688
Epoch: [1]  [ 850/1405]  eta: 0:01:34  lr: 0.000100  loss: 0.4076 (0.6191)  labels_encoder: 0.2394 (0.3788)  labels_decoder: 0.1787 (0.2402)  labels_encoder_unscaled: 0.2394 (0.3788)  labels_decoder_unscaled: 0.3574 (0.4805)  time: 0.1538  data: 0.0003  max mem: 2688
Epoch: [1]  [ 900/1405]  eta: 0:01:25  lr: 0.000100  loss: 0.4198 (0.6082)  labels_encoder: 0.2384 (0.3715)  labels_decoder: 0.1777 (0.2367)  labels_encoder_unscaled: 0.2384 (0.3715)  labels_decoder_unscaled: 0.3554 (0.4734)  time: 0.1549  data: 0.0003  max mem: 2688
Epoch: [1]  [ 950/1405]  eta: 0:01:17  lr: 0.000100  loss: 0.3974 (0.5983)  labels_encoder: 0.2201 (0.3648)  labels_decoder: 0.1761 (0.2335)  labels_encoder_unscaled: 0.2201 (0.3648)  labels_decoder_unscaled: 0.3522 (0.4670)  time: 0.1661  data: 0.0003  max mem: 2688
Epoch: [1]  [1000/1405]  eta: 0:01:08  lr: 0.000100  loss: 0.4061 (0.5885)  labels_encoder: 0.2405 (0.3584)  labels_decoder: 0.1822 (0.2301)  labels_encoder_unscaled: 0.2405 (0.3584)  labels_decoder_unscaled: 0.3644 (0.4602)  time: 0.1465  data: 0.0003  max mem: 2688
Epoch: [1]  [1050/1405]  eta: 0:00:59  lr: 0.000100  loss: 0.3733 (0.5790)  labels_encoder: 0.2305 (0.3520)  labels_decoder: 0.1534 (0.2271)  labels_encoder_unscaled: 0.2305 (0.3520)  labels_decoder_unscaled: 0.3069 (0.4541)  time: 0.1612  data: 0.0003  max mem: 2688
Epoch: [1]  [1100/1405]  eta: 0:00:51  lr: 0.000100  loss: 0.3863 (0.5714)  labels_encoder: 0.2283 (0.3468)  labels_decoder: 0.1716 (0.2246)  labels_encoder_unscaled: 0.2283 (0.3468)  labels_decoder_unscaled: 0.3432 (0.4492)  time: 0.1524  data: 0.0003  max mem: 2688
Epoch: [1]  [1150/1405]  eta: 0:00:42  lr: 0.000100  loss: 0.3851 (0.5633)  labels_encoder: 0.2120 (0.3412)  labels_decoder: 0.1641 (0.2222)  labels_encoder_unscaled: 0.2120 (0.3412)  labels_decoder_unscaled: 0.3282 (0.4443)  time: 0.1645  data: 0.0003  max mem: 2688
Epoch: [1]  [1200/1405]  eta: 0:00:34  lr: 0.000100  loss: 0.3860 (0.5560)  labels_encoder: 0.2059 (0.3361)  labels_decoder: 0.1740 (0.2200)  labels_encoder_unscaled: 0.2059 (0.3361)  labels_decoder_unscaled: 0.3479 (0.4399)  time: 0.1578  data: 0.0003  max mem: 2688
Epoch: [1]  [1250/1405]  eta: 0:00:25  lr: 0.000100  loss: 0.3474 (0.5494)  labels_encoder: 0.1929 (0.3316)  labels_decoder: 0.1541 (0.2178)  labels_encoder_unscaled: 0.1929 (0.3316)  labels_decoder_unscaled: 0.3082 (0.4357)  time: 0.1503  data: 0.0003  max mem: 2688
Epoch: [1]  [1300/1405]  eta: 0:00:17  lr: 0.000100  loss: 0.3444 (0.5422)  labels_encoder: 0.1977 (0.3267)  labels_decoder: 0.1544 (0.2155)  labels_encoder_unscaled: 0.1977 (0.3267)  labels_decoder_unscaled: 0.3087 (0.4310)  time: 0.1645  data: 0.0027  max mem: 2688
Epoch: [1]  [1350/1405]  eta: 0:00:09  lr: 0.000100  loss: 0.3901 (0.5363)  labels_encoder: 0.2236 (0.3226)  labels_decoder: 0.1611 (0.2137)  labels_encoder_unscaled: 0.2236 (0.3226)  labels_decoder_unscaled: 0.3223 (0.4273)  time: 0.1556  data: 0.0003  max mem: 2688
Epoch: [1]  [1400/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3815 (0.5311)  labels_encoder: 0.2193 (0.3190)  labels_decoder: 0.1645 (0.2120)  labels_encoder_unscaled: 0.2193 (0.3190)  labels_decoder_unscaled: 0.3291 (0.4241)  time: 0.1276  data: 0.0005  max mem: 2688
Epoch: [1]  [1404/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3839 (0.5306)  labels_encoder: 0.2205 (0.3188)  labels_decoder: 0.1645 (0.2118)  labels_encoder_unscaled: 0.2205 (0.3188)  labels_decoder_unscaled: 0.3291 (0.4237)  time: 0.1171  data: 0.0004  max mem: 2688
Epoch: [1] Total time: 0:03:51 (0.1648 s / it)
Averaged stats: lr: 0.000100  loss: 0.3839 (0.5306)  labels_encoder: 0.2205 (0.3188)  labels_decoder: 0.1645 (0.2118)  labels_encoder_unscaled: 0.2205 (0.3188)  labels_decoder_unscaled: 0.3291 (0.4237)
Test:  [   0/1613]  eta: 1:21:39  loss: 1.3001 (1.3001)  labels_encoder: 0.7017 (0.7017)  labels_decoder: 0.5983 (0.5983)  labels_encoder_unscaled: 0.7017 (0.7017)  labels_decoder_unscaled: 1.1967 (1.1967)  time: 3.0374  data: 2.9286  max mem: 2688
Test:  [  50/1613]  eta: 0:04:08  loss: 0.3857 (0.7277)  labels_encoder: 0.2186 (0.4537)  labels_decoder: 0.1810 (0.2740)  labels_encoder_unscaled: 0.2186 (0.4537)  labels_decoder_unscaled: 0.3620 (0.5480)  time: 0.0967  data: 0.0345  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:26  loss: 0.3301 (0.5997)  labels_encoder: 0.2471 (0.3834)  labels_decoder: 0.0831 (0.2163)  labels_encoder_unscaled: 0.2471 (0.3834)  labels_decoder_unscaled: 0.1662 (0.4326)  time: 0.1110  data: 0.0456  max mem: 2688
Test:  [ 150/1613]  eta: 0:03:07  loss: 0.8350 (0.6226)  labels_encoder: 0.5506 (0.4021)  labels_decoder: 0.1880 (0.2205)  labels_encoder_unscaled: 0.5506 (0.4021)  labels_decoder_unscaled: 0.3760 (0.4409)  time: 0.1114  data: 0.0525  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:57  loss: 1.1237 (0.7874)  labels_encoder: 0.5835 (0.4999)  labels_decoder: 0.5035 (0.2874)  labels_encoder_unscaled: 0.5835 (0.4999)  labels_decoder_unscaled: 1.0070 (0.5749)  time: 0.1091  data: 0.0551  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:45  loss: 0.4521 (0.8361)  labels_encoder: 0.2627 (0.5323)  labels_decoder: 0.2210 (0.3038)  labels_encoder_unscaled: 0.2627 (0.5323)  labels_decoder_unscaled: 0.4420 (0.6076)  time: 0.1142  data: 0.0516  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:36  loss: 0.5299 (0.8478)  labels_encoder: 0.2828 (0.5419)  labels_decoder: 0.2244 (0.3059)  labels_encoder_unscaled: 0.2828 (0.5419)  labels_decoder_unscaled: 0.4487 (0.6118)  time: 0.1169  data: 0.0679  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:30  loss: 1.0716 (0.8539)  labels_encoder: 0.6346 (0.5445)  labels_decoder: 0.4139 (0.3094)  labels_encoder_unscaled: 0.6346 (0.5445)  labels_decoder_unscaled: 0.8279 (0.6189)  time: 0.1140  data: 0.0550  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:23  loss: 1.1054 (0.9718)  labels_encoder: 0.6657 (0.6267)  labels_decoder: 0.4108 (0.3451)  labels_encoder_unscaled: 0.6657 (0.6267)  labels_decoder_unscaled: 0.8216 (0.6902)  time: 0.1199  data: 0.0566  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:15  loss: 0.8129 (1.0317)  labels_encoder: 0.4651 (0.6648)  labels_decoder: 0.2970 (0.3669)  labels_encoder_unscaled: 0.4651 (0.6648)  labels_decoder_unscaled: 0.5941 (0.7339)  time: 0.1055  data: 0.0474  max mem: 2688
Test:  [ 500/1613]  eta: 0:02:10  loss: 0.3370 (0.9921)  labels_encoder: 0.1751 (0.6370)  labels_decoder: 0.1886 (0.3552)  labels_encoder_unscaled: 0.1751 (0.6370)  labels_decoder_unscaled: 0.3773 (0.7104)  time: 0.1195  data: 0.0616  max mem: 2688
Test:  [ 550/1613]  eta: 0:02:04  loss: 1.2426 (0.9882)  labels_encoder: 0.5853 (0.6295)  labels_decoder: 0.4850 (0.3587)  labels_encoder_unscaled: 0.5853 (0.6295)  labels_decoder_unscaled: 0.9700 (0.7174)  time: 0.1196  data: 0.0517  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:58  loss: 1.1888 (1.0151)  labels_encoder: 0.8944 (0.6470)  labels_decoder: 0.3311 (0.3680)  labels_encoder_unscaled: 0.8944 (0.6470)  labels_decoder_unscaled: 0.6622 (0.7360)  time: 0.1269  data: 0.0545  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:52  loss: 1.1693 (1.0070)  labels_encoder: 0.6360 (0.6370)  labels_decoder: 0.5005 (0.3699)  labels_encoder_unscaled: 0.6360 (0.6370)  labels_decoder_unscaled: 1.0010 (0.7399)  time: 0.1124  data: 0.0320  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:46  loss: 0.5628 (0.9935)  labels_encoder: 0.3173 (0.6271)  labels_decoder: 0.2384 (0.3664)  labels_encoder_unscaled: 0.3173 (0.6271)  labels_decoder_unscaled: 0.4767 (0.7329)  time: 0.1125  data: 0.0430  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:40  loss: 0.7330 (0.9874)  labels_encoder: 0.3730 (0.6212)  labels_decoder: 0.3637 (0.3662)  labels_encoder_unscaled: 0.3730 (0.6212)  labels_decoder_unscaled: 0.7274 (0.7324)  time: 0.1133  data: 0.0349  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:34  loss: 0.8879 (1.0034)  labels_encoder: 0.5424 (0.6333)  labels_decoder: 0.3316 (0.3701)  labels_encoder_unscaled: 0.5424 (0.6333)  labels_decoder_unscaled: 0.6632 (0.7402)  time: 0.1037  data: 0.0165  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:28  loss: 1.3153 (1.0064)  labels_encoder: 0.8121 (0.6328)  labels_decoder: 0.5032 (0.3736)  labels_encoder_unscaled: 0.8121 (0.6328)  labels_decoder_unscaled: 1.0064 (0.7471)  time: 0.1246  data: 0.0083  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:22  loss: 0.7904 (1.0215)  labels_encoder: 0.4669 (0.6437)  labels_decoder: 0.3059 (0.3778)  labels_encoder_unscaled: 0.4669 (0.6437)  labels_decoder_unscaled: 0.6117 (0.7555)  time: 0.1154  data: 0.0339  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:16  loss: 1.2729 (1.0196)  labels_encoder: 0.7688 (0.6434)  labels_decoder: 0.4244 (0.3762)  labels_encoder_unscaled: 0.7688 (0.6434)  labels_decoder_unscaled: 0.8488 (0.7523)  time: 0.1088  data: 0.0200  max mem: 2688
Test:  [1000/1613]  eta: 0:01:10  loss: 0.5201 (1.0121)  labels_encoder: 0.3105 (0.6376)  labels_decoder: 0.2303 (0.3744)  labels_encoder_unscaled: 0.3105 (0.6376)  labels_decoder_unscaled: 0.4606 (0.7489)  time: 0.1096  data: 0.0253  max mem: 2688
Test:  [1050/1613]  eta: 0:01:04  loss: 1.0372 (1.0197)  labels_encoder: 0.6389 (0.6437)  labels_decoder: 0.3739 (0.3760)  labels_encoder_unscaled: 0.6389 (0.6437)  labels_decoder_unscaled: 0.7477 (0.7520)  time: 0.1085  data: 0.0358  max mem: 2688
Test:  [1100/1613]  eta: 0:00:58  loss: 0.9809 (1.0295)  labels_encoder: 0.6433 (0.6522)  labels_decoder: 0.3375 (0.3773)  labels_encoder_unscaled: 0.6433 (0.6522)  labels_decoder_unscaled: 0.6751 (0.7546)  time: 0.1013  data: 0.0183  max mem: 2688
Test:  [1150/1613]  eta: 0:00:52  loss: 0.4880 (1.0210)  labels_encoder: 0.3082 (0.6464)  labels_decoder: 0.1798 (0.3747)  labels_encoder_unscaled: 0.3082 (0.6464)  labels_decoder_unscaled: 0.3596 (0.7493)  time: 0.1063  data: 0.0251  max mem: 2688
Test:  [1200/1613]  eta: 0:00:47  loss: 0.7434 (1.0292)  labels_encoder: 0.4085 (0.6515)  labels_decoder: 0.2971 (0.3778)  labels_encoder_unscaled: 0.4085 (0.6515)  labels_decoder_unscaled: 0.5941 (0.7555)  time: 0.1232  data: 0.0490  max mem: 2688
Test:  [1250/1613]  eta: 0:00:41  loss: 0.4000 (1.0350)  labels_encoder: 0.2093 (0.6556)  labels_decoder: 0.1675 (0.3794)  labels_encoder_unscaled: 0.2093 (0.6556)  labels_decoder_unscaled: 0.3350 (0.7589)  time: 0.1184  data: 0.0324  max mem: 2688
Test:  [1300/1613]  eta: 0:00:35  loss: 0.4711 (1.0235)  labels_encoder: 0.3140 (0.6480)  labels_decoder: 0.2012 (0.3755)  labels_encoder_unscaled: 0.3140 (0.6480)  labels_decoder_unscaled: 0.4024 (0.7511)  time: 0.1088  data: 0.0002  max mem: 2688
Test:  [1350/1613]  eta: 0:00:30  loss: 0.8575 (1.0374)  labels_encoder: 0.5207 (0.6572)  labels_decoder: 0.3368 (0.3803)  labels_encoder_unscaled: 0.5207 (0.6572)  labels_decoder_unscaled: 0.6737 (0.7605)  time: 0.1074  data: 0.0220  max mem: 2688
Test:  [1400/1613]  eta: 0:00:24  loss: 0.7265 (1.0353)  labels_encoder: 0.4194 (0.6549)  labels_decoder: 0.3071 (0.3804)  labels_encoder_unscaled: 0.4194 (0.6549)  labels_decoder_unscaled: 0.6142 (0.7608)  time: 0.1564  data: 0.0726  max mem: 2688
Test:  [1450/1613]  eta: 0:00:18  loss: 0.7151 (1.0388)  labels_encoder: 0.5038 (0.6566)  labels_decoder: 0.3618 (0.3822)  labels_encoder_unscaled: 0.5038 (0.6566)  labels_decoder_unscaled: 0.7236 (0.7644)  time: 0.1057  data: 0.0195  max mem: 2688
Test:  [1500/1613]  eta: 0:00:13  loss: 0.9685 (1.0573)  labels_encoder: 0.5328 (0.6691)  labels_decoder: 0.4428 (0.3882)  labels_encoder_unscaled: 0.5328 (0.6691)  labels_decoder_unscaled: 0.8856 (0.7764)  time: 0.1196  data: 0.0532  max mem: 2688
Test:  [1550/1613]  eta: 0:00:07  loss: 0.7442 (1.0558)  labels_encoder: 0.4864 (0.6688)  labels_decoder: 0.3079 (0.3870)  labels_encoder_unscaled: 0.4864 (0.6688)  labels_decoder_unscaled: 0.6159 (0.7740)  time: 0.0989  data: 0.0386  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.7877 (1.0530)  labels_encoder: 0.4308 (0.6662)  labels_decoder: 0.3344 (0.3868)  labels_encoder_unscaled: 0.4308 (0.6662)  labels_decoder_unscaled: 0.6689 (0.7736)  time: 0.1174  data: 0.0421  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7877 (1.0513)  labels_encoder: 0.4308 (0.6655)  labels_decoder: 0.3022 (0.3858)  labels_encoder_unscaled: 0.4308 (0.6655)  labels_decoder_unscaled: 0.6043 (0.7716)  time: 0.1044  data: 0.0433  max mem: 2688
Test: Total time: 0:03:05 (0.1152 s / it)
Averaged stats: loss: 0.7877 (1.0513)  labels_encoder: 0.4308 (0.6655)  labels_decoder: 0.3022 (0.3858)  labels_encoder_unscaled: 0.4308 (0.6655)  labels_decoder_unscaled: 0.6043 (0.7716)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.5728

dec_mAP all together: | 0.45940257439076 |.
dec_mAP_pred | 0 : 0.513194024706481 |.
dec_mAP_pred | 1 : 0.5013313246233658 |.
dec_mAP_pred | 2 : 0.48570651843548796 |.
dec_mAP_pred | 3 : 0.46956945420583 |.
dec_mAP_pred | 4 : 0.45336733906330007 |.
dec_mAP_pred | 5 : 0.4373841128070655 |.
dec_mAP_pred | 6 : 0.42216108972463273 |.
dec_mAP_pred | 7 : 0.40789261305158836 |.
all decoder map: | 0.4613 |.
BaseballPitch: 0.1377
BasketballDunk: 0.7733
Billiards: 0.4309
CleanAndJerk: 0.7070
CliffDiving: 0.7921
CricketBowling: 0.4255
CricketShot: 0.2280
Diving: 0.6857
FrisbeeCatch: 0.3556
GolfSwing: 0.6416
HammerThrow: 0.8681
HighJump: 0.6218
JavelinThrow: 0.7330
LongJump: 0.7983
PoleVault: 0.8768
Shotput: 0.6742
SoccerPenalty: 0.2543
TennisSwing: 0.5266
ThrowDiscus: 0.5856
VolleyballSpiking: 0.3403
Epoch: [2]  [   0/1405]  eta: 1:18:24  lr: 0.000010  loss: 0.3563 (0.3563)  labels_encoder: 0.2161 (0.2161)  labels_decoder: 0.1402 (0.1402)  labels_encoder_unscaled: 0.2161 (0.2161)  labels_decoder_unscaled: 0.2804 (0.2804)  time: 3.3487  data: 3.1565  max mem: 2688
Epoch: [2]  [  50/1405]  eta: 0:05:20  lr: 0.000010  loss: 0.2996 (0.3051)  labels_encoder: 0.1519 (0.1626)  labels_decoder: 0.1364 (0.1425)  labels_encoder_unscaled: 0.1519 (0.1626)  labels_decoder_unscaled: 0.2728 (0.2850)  time: 0.1676  data: 0.0003  max mem: 2688
Epoch: [2]  [ 100/1405]  eta: 0:04:16  lr: 0.000010  loss: 0.3004 (0.3069)  labels_encoder: 0.1631 (0.1662)  labels_decoder: 0.1289 (0.1407)  labels_encoder_unscaled: 0.1631 (0.1662)  labels_decoder_unscaled: 0.2579 (0.2813)  time: 0.1607  data: 0.0004  max mem: 2688
Epoch: [2]  [ 150/1405]  eta: 0:03:51  lr: 0.000010  loss: 0.2843 (0.3014)  labels_encoder: 0.1534 (0.1632)  labels_decoder: 0.1361 (0.1382)  labels_encoder_unscaled: 0.1534 (0.1632)  labels_decoder_unscaled: 0.2721 (0.2764)  time: 0.1576  data: 0.0003  max mem: 2688
Epoch: [2]  [ 200/1405]  eta: 0:03:32  lr: 0.000010  loss: 0.2999 (0.2966)  labels_encoder: 0.1754 (0.1612)  labels_decoder: 0.1242 (0.1354)  labels_encoder_unscaled: 0.1754 (0.1612)  labels_decoder_unscaled: 0.2483 (0.2708)  time: 0.1486  data: 0.0031  max mem: 2688
Epoch: [2]  [ 250/1405]  eta: 0:03:19  lr: 0.000010  loss: 0.3038 (0.2955)  labels_encoder: 0.1564 (0.1602)  labels_decoder: 0.1369 (0.1353)  labels_encoder_unscaled: 0.1564 (0.1602)  labels_decoder_unscaled: 0.2737 (0.2706)  time: 0.1557  data: 0.0003  max mem: 2688
Epoch: [2]  [ 300/1405]  eta: 0:03:08  lr: 0.000010  loss: 0.2827 (0.2928)  labels_encoder: 0.1457 (0.1590)  labels_decoder: 0.1227 (0.1338)  labels_encoder_unscaled: 0.1457 (0.1590)  labels_decoder_unscaled: 0.2454 (0.2676)  time: 0.1628  data: 0.0003  max mem: 2688
Epoch: [2]  [ 350/1405]  eta: 0:02:56  lr: 0.000010  loss: 0.2522 (0.2910)  labels_encoder: 0.1367 (0.1578)  labels_decoder: 0.1205 (0.1332)  labels_encoder_unscaled: 0.1367 (0.1578)  labels_decoder_unscaled: 0.2410 (0.2664)  time: 0.1500  data: 0.0003  max mem: 2688
Epoch: [2]  [ 400/1405]  eta: 0:02:46  lr: 0.000010  loss: 0.2791 (0.2899)  labels_encoder: 0.1477 (0.1573)  labels_decoder: 0.1275 (0.1326)  labels_encoder_unscaled: 0.1477 (0.1573)  labels_decoder_unscaled: 0.2551 (0.2651)  time: 0.1543  data: 0.0003  max mem: 2688
Epoch: [2]  [ 450/1405]  eta: 0:02:37  lr: 0.000010  loss: 0.2640 (0.2881)  labels_encoder: 0.1383 (0.1560)  labels_decoder: 0.1245 (0.1321)  labels_encoder_unscaled: 0.1383 (0.1560)  labels_decoder_unscaled: 0.2489 (0.2641)  time: 0.1564  data: 0.0003  max mem: 2688
Epoch: [2]  [ 500/1405]  eta: 0:02:28  lr: 0.000010  loss: 0.2757 (0.2873)  labels_encoder: 0.1354 (0.1556)  labels_decoder: 0.1219 (0.1317)  labels_encoder_unscaled: 0.1354 (0.1556)  labels_decoder_unscaled: 0.2438 (0.2633)  time: 0.1593  data: 0.0003  max mem: 2688
Epoch: [2]  [ 550/1405]  eta: 0:02:20  lr: 0.000010  loss: 0.2512 (0.2855)  labels_encoder: 0.1299 (0.1544)  labels_decoder: 0.1261 (0.1311)  labels_encoder_unscaled: 0.1299 (0.1544)  labels_decoder_unscaled: 0.2522 (0.2623)  time: 0.1632  data: 0.0004  max mem: 2688
Epoch: [2]  [ 600/1405]  eta: 0:02:11  lr: 0.000010  loss: 0.2626 (0.2838)  labels_encoder: 0.1355 (0.1534)  labels_decoder: 0.1205 (0.1304)  labels_encoder_unscaled: 0.1355 (0.1534)  labels_decoder_unscaled: 0.2409 (0.2607)  time: 0.1664  data: 0.0003  max mem: 2688
Epoch: [2]  [ 650/1405]  eta: 0:02:03  lr: 0.000010  loss: 0.2673 (0.2830)  labels_encoder: 0.1367 (0.1530)  labels_decoder: 0.1192 (0.1300)  labels_encoder_unscaled: 0.1367 (0.1530)  labels_decoder_unscaled: 0.2384 (0.2599)  time: 0.1652  data: 0.0011  max mem: 2688
Epoch: [2]  [ 700/1405]  eta: 0:01:55  lr: 0.000010  loss: 0.2612 (0.2818)  labels_encoder: 0.1362 (0.1522)  labels_decoder: 0.1141 (0.1296)  labels_encoder_unscaled: 0.1362 (0.1522)  labels_decoder_unscaled: 0.2283 (0.2592)  time: 0.1581  data: 0.0003  max mem: 2688
Epoch: [2]  [ 750/1405]  eta: 0:01:46  lr: 0.000010  loss: 0.2592 (0.2803)  labels_encoder: 0.1297 (0.1510)  labels_decoder: 0.1161 (0.1292)  labels_encoder_unscaled: 0.1297 (0.1510)  labels_decoder_unscaled: 0.2323 (0.2584)  time: 0.1541  data: 0.0003  max mem: 2688
Epoch: [2]  [ 800/1405]  eta: 0:01:38  lr: 0.000010  loss: 0.2644 (0.2793)  labels_encoder: 0.1320 (0.1505)  labels_decoder: 0.1180 (0.1288)  labels_encoder_unscaled: 0.1320 (0.1505)  labels_decoder_unscaled: 0.2360 (0.2577)  time: 0.1554  data: 0.0003  max mem: 2688
Epoch: [2]  [ 850/1405]  eta: 0:01:30  lr: 0.000010  loss: 0.2379 (0.2776)  labels_encoder: 0.1172 (0.1493)  labels_decoder: 0.1212 (0.1283)  labels_encoder_unscaled: 0.1172 (0.1493)  labels_decoder_unscaled: 0.2424 (0.2566)  time: 0.1582  data: 0.0003  max mem: 2688
Epoch: [2]  [ 900/1405]  eta: 0:01:21  lr: 0.000010  loss: 0.2348 (0.2765)  labels_encoder: 0.1206 (0.1484)  labels_decoder: 0.1156 (0.1281)  labels_encoder_unscaled: 0.1206 (0.1484)  labels_decoder_unscaled: 0.2311 (0.2562)  time: 0.1598  data: 0.0003  max mem: 2688
Epoch: [2]  [ 950/1405]  eta: 0:01:13  lr: 0.000010  loss: 0.2465 (0.2754)  labels_encoder: 0.1318 (0.1476)  labels_decoder: 0.1182 (0.1278)  labels_encoder_unscaled: 0.1318 (0.1476)  labels_decoder_unscaled: 0.2364 (0.2556)  time: 0.1543  data: 0.0003  max mem: 2688
Epoch: [2]  [1000/1405]  eta: 0:01:05  lr: 0.000010  loss: 0.2770 (0.2751)  labels_encoder: 0.1461 (0.1474)  labels_decoder: 0.1307 (0.1277)  labels_encoder_unscaled: 0.1461 (0.1474)  labels_decoder_unscaled: 0.2615 (0.2554)  time: 0.1452  data: 0.0003  max mem: 2688
Epoch: [2]  [1050/1405]  eta: 0:00:57  lr: 0.000010  loss: 0.2524 (0.2743)  labels_encoder: 0.1334 (0.1470)  labels_decoder: 0.1204 (0.1273)  labels_encoder_unscaled: 0.1334 (0.1470)  labels_decoder_unscaled: 0.2407 (0.2546)  time: 0.1457  data: 0.0003  max mem: 2688
Epoch: [2]  [1100/1405]  eta: 0:00:49  lr: 0.000010  loss: 0.2632 (0.2732)  labels_encoder: 0.1427 (0.1463)  labels_decoder: 0.1160 (0.1268)  labels_encoder_unscaled: 0.1427 (0.1463)  labels_decoder_unscaled: 0.2319 (0.2537)  time: 0.1495  data: 0.0004  max mem: 2688
Epoch: [2]  [1150/1405]  eta: 0:00:41  lr: 0.000010  loss: 0.2670 (0.2730)  labels_encoder: 0.1459 (0.1464)  labels_decoder: 0.1225 (0.1266)  labels_encoder_unscaled: 0.1459 (0.1464)  labels_decoder_unscaled: 0.2450 (0.2533)  time: 0.1674  data: 0.0003  max mem: 2688
Epoch: [2]  [1200/1405]  eta: 0:00:32  lr: 0.000010  loss: 0.2365 (0.2719)  labels_encoder: 0.1181 (0.1456)  labels_decoder: 0.1180 (0.1263)  labels_encoder_unscaled: 0.1181 (0.1456)  labels_decoder_unscaled: 0.2360 (0.2526)  time: 0.1632  data: 0.0003  max mem: 2688
Epoch: [2]  [1250/1405]  eta: 0:00:24  lr: 0.000010  loss: 0.2327 (0.2710)  labels_encoder: 0.1132 (0.1450)  labels_decoder: 0.1134 (0.1260)  labels_encoder_unscaled: 0.1132 (0.1450)  labels_decoder_unscaled: 0.2268 (0.2521)  time: 0.1525  data: 0.0003  max mem: 2688
Epoch: [2]  [1300/1405]  eta: 0:00:16  lr: 0.000010  loss: 0.2445 (0.2702)  labels_encoder: 0.1202 (0.1444)  labels_decoder: 0.1133 (0.1258)  labels_encoder_unscaled: 0.1202 (0.1444)  labels_decoder_unscaled: 0.2267 (0.2515)  time: 0.1560  data: 0.0004  max mem: 2688
Epoch: [2]  [1350/1405]  eta: 0:00:08  lr: 0.000010  loss: 0.2811 (0.2699)  labels_encoder: 0.1579 (0.1444)  labels_decoder: 0.1192 (0.1255)  labels_encoder_unscaled: 0.1579 (0.1444)  labels_decoder_unscaled: 0.2385 (0.2510)  time: 0.1560  data: 0.0003  max mem: 2688
Epoch: [2]  [1400/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2404 (0.2692)  labels_encoder: 0.1163 (0.1441)  labels_decoder: 0.1109 (0.1251)  labels_encoder_unscaled: 0.1163 (0.1441)  labels_decoder_unscaled: 0.2217 (0.2502)  time: 0.1374  data: 0.0004  max mem: 2688
Epoch: [2]  [1404/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2404 (0.2691)  labels_encoder: 0.1307 (0.1441)  labels_decoder: 0.1097 (0.1251)  labels_encoder_unscaled: 0.1307 (0.1441)  labels_decoder_unscaled: 0.2194 (0.2501)  time: 0.1237  data: 0.0004  max mem: 2688
Epoch: [2] Total time: 0:03:45 (0.1602 s / it)
Averaged stats: lr: 0.000010  loss: 0.2404 (0.2691)  labels_encoder: 0.1307 (0.1441)  labels_decoder: 0.1097 (0.1251)  labels_encoder_unscaled: 0.1307 (0.1441)  labels_decoder_unscaled: 0.2194 (0.2501)
Test:  [   0/1613]  eta: 1:38:25  loss: 0.9300 (0.9300)  labels_encoder: 0.6593 (0.6593)  labels_decoder: 0.2707 (0.2707)  labels_encoder_unscaled: 0.6593 (0.6593)  labels_decoder_unscaled: 0.5414 (0.5414)  time: 3.6610  data: 3.5915  max mem: 2688
Test:  [  50/1613]  eta: 0:04:38  loss: 0.4231 (0.7950)  labels_encoder: 0.2091 (0.4970)  labels_decoder: 0.1946 (0.2980)  labels_encoder_unscaled: 0.2091 (0.4970)  labels_decoder_unscaled: 0.3892 (0.5960)  time: 0.1091  data: 0.0363  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:36  loss: 0.1561 (0.6401)  labels_encoder: 0.1092 (0.4051)  labels_decoder: 0.0468 (0.2350)  labels_encoder_unscaled: 0.1092 (0.4051)  labels_decoder_unscaled: 0.0937 (0.4701)  time: 0.1063  data: 0.0165  max mem: 2688
Test:  [ 150/1613]  eta: 0:03:08  loss: 0.7524 (0.6485)  labels_encoder: 0.4393 (0.4126)  labels_decoder: 0.1020 (0.2360)  labels_encoder_unscaled: 0.4393 (0.4126)  labels_decoder_unscaled: 0.2039 (0.4719)  time: 0.0955  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:53  loss: 1.0171 (0.8152)  labels_encoder: 0.6301 (0.5296)  labels_decoder: 0.4022 (0.2855)  labels_encoder_unscaled: 0.6301 (0.5296)  labels_decoder_unscaled: 0.8043 (0.5711)  time: 0.1026  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:41  loss: 0.8651 (0.8992)  labels_encoder: 0.3561 (0.5800)  labels_decoder: 0.3194 (0.3192)  labels_encoder_unscaled: 0.3561 (0.5800)  labels_decoder_unscaled: 0.6387 (0.6384)  time: 0.1137  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:31  loss: 0.5228 (0.9268)  labels_encoder: 0.3175 (0.5975)  labels_decoder: 0.2303 (0.3293)  labels_encoder_unscaled: 0.3175 (0.5975)  labels_decoder_unscaled: 0.4606 (0.6586)  time: 0.0965  data: 0.0023  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:23  loss: 1.2559 (0.9299)  labels_encoder: 0.7801 (0.5968)  labels_decoder: 0.4786 (0.3331)  labels_encoder_unscaled: 0.7801 (0.5968)  labels_decoder_unscaled: 0.9572 (0.6663)  time: 0.1098  data: 0.0088  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:15  loss: 0.7800 (1.0367)  labels_encoder: 0.4516 (0.6735)  labels_decoder: 0.3263 (0.3631)  labels_encoder_unscaled: 0.4516 (0.6735)  labels_decoder_unscaled: 0.6527 (0.7263)  time: 0.1111  data: 0.0065  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:08  loss: 0.9792 (1.1097)  labels_encoder: 0.6108 (0.7199)  labels_decoder: 0.3635 (0.3898)  labels_encoder_unscaled: 0.6108 (0.7199)  labels_decoder_unscaled: 0.7270 (0.7795)  time: 0.1003  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:02:02  loss: 0.3722 (1.0641)  labels_encoder: 0.2070 (0.6884)  labels_decoder: 0.1964 (0.3756)  labels_encoder_unscaled: 0.2070 (0.6884)  labels_decoder_unscaled: 0.3928 (0.7512)  time: 0.1192  data: 0.0049  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:55  loss: 0.5598 (1.0636)  labels_encoder: 0.3136 (0.6881)  labels_decoder: 0.2886 (0.3755)  labels_encoder_unscaled: 0.3136 (0.6881)  labels_decoder_unscaled: 0.5772 (0.7511)  time: 0.0894  data: 0.0070  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:49  loss: 1.4781 (1.1190)  labels_encoder: 0.6302 (0.7357)  labels_decoder: 0.4974 (0.3832)  labels_encoder_unscaled: 0.6302 (0.7357)  labels_decoder_unscaled: 0.9947 (0.7665)  time: 0.1018  data: 0.0210  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:43  loss: 1.0634 (1.1140)  labels_encoder: 0.5665 (0.7268)  labels_decoder: 0.4627 (0.3872)  labels_encoder_unscaled: 0.5665 (0.7268)  labels_decoder_unscaled: 0.9253 (0.7743)  time: 0.1048  data: 0.0454  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:37  loss: 0.5983 (1.0923)  labels_encoder: 0.3137 (0.7102)  labels_decoder: 0.2448 (0.3821)  labels_encoder_unscaled: 0.3137 (0.7102)  labels_decoder_unscaled: 0.4895 (0.7641)  time: 0.0955  data: 0.0288  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:31  loss: 0.7576 (1.0825)  labels_encoder: 0.4391 (0.7019)  labels_decoder: 0.3186 (0.3806)  labels_encoder_unscaled: 0.4391 (0.7019)  labels_decoder_unscaled: 0.6371 (0.7613)  time: 0.0928  data: 0.0432  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:26  loss: 0.8707 (1.0819)  labels_encoder: 0.4802 (0.7016)  labels_decoder: 0.3811 (0.3802)  labels_encoder_unscaled: 0.4802 (0.7016)  labels_decoder_unscaled: 0.7623 (0.7604)  time: 0.1034  data: 0.0319  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:20  loss: 1.3784 (1.0827)  labels_encoder: 0.8692 (0.6994)  labels_decoder: 0.5865 (0.3833)  labels_encoder_unscaled: 0.8692 (0.6994)  labels_decoder_unscaled: 1.1730 (0.7666)  time: 0.1022  data: 0.0140  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:15  loss: 0.6543 (1.0955)  labels_encoder: 0.3898 (0.7083)  labels_decoder: 0.2710 (0.3872)  labels_encoder_unscaled: 0.3898 (0.7083)  labels_decoder_unscaled: 0.5419 (0.7744)  time: 0.1017  data: 0.0235  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:10  loss: 1.1773 (1.0930)  labels_encoder: 0.7461 (0.7069)  labels_decoder: 0.3913 (0.3861)  labels_encoder_unscaled: 0.7461 (0.7069)  labels_decoder_unscaled: 0.7826 (0.7722)  time: 0.1109  data: 0.0543  max mem: 2688
Test:  [1000/1613]  eta: 0:01:04  loss: 0.5126 (1.0846)  labels_encoder: 0.2689 (0.7001)  labels_decoder: 0.2442 (0.3845)  labels_encoder_unscaled: 0.2689 (0.7001)  labels_decoder_unscaled: 0.4885 (0.7691)  time: 0.0975  data: 0.0420  max mem: 2688
Test:  [1050/1613]  eta: 0:00:58  loss: 0.9205 (1.0821)  labels_encoder: 0.5664 (0.6981)  labels_decoder: 0.3194 (0.3840)  labels_encoder_unscaled: 0.5664 (0.6981)  labels_decoder_unscaled: 0.6388 (0.7679)  time: 0.0971  data: 0.0247  max mem: 2688
Test:  [1100/1613]  eta: 0:00:53  loss: 1.1127 (1.0928)  labels_encoder: 0.7642 (0.7071)  labels_decoder: 0.4023 (0.3857)  labels_encoder_unscaled: 0.7642 (0.7071)  labels_decoder_unscaled: 0.8046 (0.7714)  time: 0.0949  data: 0.0339  max mem: 2688
Test:  [1150/1613]  eta: 0:00:47  loss: 0.5945 (1.0832)  labels_encoder: 0.3563 (0.7004)  labels_decoder: 0.2306 (0.3828)  labels_encoder_unscaled: 0.3563 (0.7004)  labels_decoder_unscaled: 0.4613 (0.7656)  time: 0.0918  data: 0.0082  max mem: 2688
Test:  [1200/1613]  eta: 0:00:42  loss: 0.5780 (1.0880)  labels_encoder: 0.2938 (0.7032)  labels_decoder: 0.2333 (0.3848)  labels_encoder_unscaled: 0.2938 (0.7032)  labels_decoder_unscaled: 0.4667 (0.7696)  time: 0.0990  data: 0.0270  max mem: 2688
Test:  [1250/1613]  eta: 0:00:37  loss: 0.3921 (1.0870)  labels_encoder: 0.1802 (0.7020)  labels_decoder: 0.1704 (0.3850)  labels_encoder_unscaled: 0.1802 (0.7020)  labels_decoder_unscaled: 0.3408 (0.7700)  time: 0.0925  data: 0.0209  max mem: 2688
Test:  [1300/1613]  eta: 0:00:32  loss: 0.5967 (1.0780)  labels_encoder: 0.3980 (0.6954)  labels_decoder: 0.2342 (0.3826)  labels_encoder_unscaled: 0.3980 (0.6954)  labels_decoder_unscaled: 0.4683 (0.7652)  time: 0.0964  data: 0.0361  max mem: 2688
Test:  [1350/1613]  eta: 0:00:27  loss: 0.8763 (1.0938)  labels_encoder: 0.5137 (0.7060)  labels_decoder: 0.3623 (0.3878)  labels_encoder_unscaled: 0.5137 (0.7060)  labels_decoder_unscaled: 0.7245 (0.7755)  time: 0.1067  data: 0.0165  max mem: 2688
Test:  [1400/1613]  eta: 0:00:21  loss: 1.1261 (1.0887)  labels_encoder: 0.7553 (0.7026)  labels_decoder: 0.3685 (0.3861)  labels_encoder_unscaled: 0.7553 (0.7026)  labels_decoder_unscaled: 0.7370 (0.7721)  time: 0.0949  data: 0.0266  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.7743 (1.0995)  labels_encoder: 0.3949 (0.7103)  labels_decoder: 0.2728 (0.3892)  labels_encoder_unscaled: 0.3949 (0.7103)  labels_decoder_unscaled: 0.5456 (0.7784)  time: 0.1016  data: 0.0002  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.9298 (1.1167)  labels_encoder: 0.5964 (0.7232)  labels_decoder: 0.3302 (0.3935)  labels_encoder_unscaled: 0.5964 (0.7232)  labels_decoder_unscaled: 0.6604 (0.7871)  time: 0.0905  data: 0.0021  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.7615 (1.1127)  labels_encoder: 0.4913 (0.7207)  labels_decoder: 0.2531 (0.3920)  labels_encoder_unscaled: 0.4913 (0.7207)  labels_decoder_unscaled: 0.5063 (0.7840)  time: 0.1179  data: 0.0166  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8944 (1.1089)  labels_encoder: 0.5115 (0.7176)  labels_decoder: 0.3902 (0.3913)  labels_encoder_unscaled: 0.5115 (0.7176)  labels_decoder_unscaled: 0.7804 (0.7826)  time: 0.0943  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7579 (1.1074)  labels_encoder: 0.5042 (0.7172)  labels_decoder: 0.2608 (0.3902)  labels_encoder_unscaled: 0.5042 (0.7172)  labels_decoder_unscaled: 0.5216 (0.7803)  time: 0.0840  data: 0.0001  max mem: 2688
Test: Total time: 0:02:45 (0.1027 s / it)
Averaged stats: loss: 0.7579 (1.1074)  labels_encoder: 0.5042 (0.7172)  labels_decoder: 0.2608 (0.3902)  labels_encoder_unscaled: 0.5042 (0.7172)  labels_decoder_unscaled: 0.5216 (0.7803)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5756

dec_mAP all together: | 0.46199734007360416 |.
dec_mAP_pred | 0 : 0.5061526289963549 |.
dec_mAP_pred | 1 : 0.4985677323618864 |.
dec_mAP_pred | 2 : 0.4862430106736458 |.
dec_mAP_pred | 3 : 0.47224244293903894 |.
dec_mAP_pred | 4 : 0.4574274693525836 |.
dec_mAP_pred | 5 : 0.4422113839790918 |.
dec_mAP_pred | 6 : 0.4276428801734071 |.
dec_mAP_pred | 7 : 0.4142066526231993 |.
all decoder map: | 0.4631 |.
BaseballPitch: 0.1180
BasketballDunk: 0.7624
Billiards: 0.4436
CleanAndJerk: 0.7333
CliffDiving: 0.7982
CricketBowling: 0.4738
CricketShot: 0.2528
Diving: 0.6950
FrisbeeCatch: 0.3444
GolfSwing: 0.6018
HammerThrow: 0.8639
HighJump: 0.6296
JavelinThrow: 0.6994
LongJump: 0.7779
PoleVault: 0.8713
Shotput: 0.6916
SoccerPenalty: 0.2421
TennisSwing: 0.5582
ThrowDiscus: 0.6311
VolleyballSpiking: 0.3239
Epoch: [3]  [   0/1405]  eta: 1:27:55  lr: 0.000001  loss: 0.2710 (0.2710)  labels_encoder: 0.1236 (0.1236)  labels_decoder: 0.1474 (0.1474)  labels_encoder_unscaled: 0.1236 (0.1236)  labels_decoder_unscaled: 0.2947 (0.2947)  time: 3.7550  data: 3.5141  max mem: 2688
Epoch: [3]  [  50/1405]  eta: 0:05:18  lr: 0.000001  loss: 0.2335 (0.2480)  labels_encoder: 0.1256 (0.1293)  labels_decoder: 0.1158 (0.1187)  labels_encoder_unscaled: 0.1256 (0.1293)  labels_decoder_unscaled: 0.2316 (0.2374)  time: 0.1645  data: 0.0003  max mem: 2688
Epoch: [3]  [ 100/1405]  eta: 0:04:11  lr: 0.000001  loss: 0.2392 (0.2435)  labels_encoder: 0.1167 (0.1282)  labels_decoder: 0.1117 (0.1153)  labels_encoder_unscaled: 0.1167 (0.1282)  labels_decoder_unscaled: 0.2234 (0.2306)  time: 0.1500  data: 0.0003  max mem: 2688
Epoch: [3]  [ 150/1405]  eta: 0:03:46  lr: 0.000001  loss: 0.2131 (0.2390)  labels_encoder: 0.1108 (0.1258)  labels_decoder: 0.1037 (0.1132)  labels_encoder_unscaled: 0.1108 (0.1258)  labels_decoder_unscaled: 0.2075 (0.2264)  time: 0.1523  data: 0.0003  max mem: 2688
Epoch: [3]  [ 200/1405]  eta: 0:03:29  lr: 0.000001  loss: 0.2320 (0.2404)  labels_encoder: 0.1253 (0.1261)  labels_decoder: 0.1141 (0.1144)  labels_encoder_unscaled: 0.1253 (0.1261)  labels_decoder_unscaled: 0.2283 (0.2287)  time: 0.1568  data: 0.0003  max mem: 2688
Epoch: [3]  [ 250/1405]  eta: 0:03:16  lr: 0.000001  loss: 0.2401 (0.2389)  labels_encoder: 0.1232 (0.1245)  labels_decoder: 0.1205 (0.1144)  labels_encoder_unscaled: 0.1232 (0.1245)  labels_decoder_unscaled: 0.2409 (0.2288)  time: 0.1588  data: 0.0003  max mem: 2688
Epoch: [3]  [ 300/1405]  eta: 0:03:04  lr: 0.000001  loss: 0.2245 (0.2375)  labels_encoder: 0.1067 (0.1230)  labels_decoder: 0.1109 (0.1144)  labels_encoder_unscaled: 0.1067 (0.1230)  labels_decoder_unscaled: 0.2219 (0.2288)  time: 0.1499  data: 0.0003  max mem: 2688
Epoch: [3]  [ 350/1405]  eta: 0:02:53  lr: 0.000001  loss: 0.2222 (0.2371)  labels_encoder: 0.1132 (0.1228)  labels_decoder: 0.1097 (0.1143)  labels_encoder_unscaled: 0.1132 (0.1228)  labels_decoder_unscaled: 0.2193 (0.2287)  time: 0.1481  data: 0.0003  max mem: 2688
Epoch: [3]  [ 400/1405]  eta: 0:02:44  lr: 0.000001  loss: 0.2217 (0.2367)  labels_encoder: 0.1104 (0.1221)  labels_decoder: 0.1183 (0.1146)  labels_encoder_unscaled: 0.1104 (0.1221)  labels_decoder_unscaled: 0.2365 (0.2292)  time: 0.1515  data: 0.0003  max mem: 2688
Epoch: [3]  [ 450/1405]  eta: 0:02:35  lr: 0.000001  loss: 0.2123 (0.2346)  labels_encoder: 0.1018 (0.1207)  labels_decoder: 0.1061 (0.1139)  labels_encoder_unscaled: 0.1018 (0.1207)  labels_decoder_unscaled: 0.2123 (0.2277)  time: 0.1442  data: 0.0003  max mem: 2688
Epoch: [3]  [ 500/1405]  eta: 0:02:25  lr: 0.000001  loss: 0.2423 (0.2356)  labels_encoder: 0.1225 (0.1215)  labels_decoder: 0.1152 (0.1140)  labels_encoder_unscaled: 0.1225 (0.1215)  labels_decoder_unscaled: 0.2305 (0.2281)  time: 0.1541  data: 0.0003  max mem: 2688
Epoch: [3]  [ 550/1405]  eta: 0:02:17  lr: 0.000001  loss: 0.2239 (0.2355)  labels_encoder: 0.1093 (0.1215)  labels_decoder: 0.1138 (0.1141)  labels_encoder_unscaled: 0.1093 (0.1215)  labels_decoder_unscaled: 0.2276 (0.2281)  time: 0.1543  data: 0.0003  max mem: 2688
Epoch: [3]  [ 600/1405]  eta: 0:02:09  lr: 0.000001  loss: 0.2319 (0.2356)  labels_encoder: 0.1187 (0.1215)  labels_decoder: 0.1125 (0.1140)  labels_encoder_unscaled: 0.1187 (0.1215)  labels_decoder_unscaled: 0.2250 (0.2281)  time: 0.1544  data: 0.0003  max mem: 2688
Epoch: [3]  [ 650/1405]  eta: 0:02:00  lr: 0.000001  loss: 0.2444 (0.2361)  labels_encoder: 0.1245 (0.1218)  labels_decoder: 0.1167 (0.1143)  labels_encoder_unscaled: 0.1245 (0.1218)  labels_decoder_unscaled: 0.2334 (0.2286)  time: 0.1549  data: 0.0003  max mem: 2688
Epoch: [3]  [ 700/1405]  eta: 0:01:52  lr: 0.000001  loss: 0.2257 (0.2360)  labels_encoder: 0.1072 (0.1219)  labels_decoder: 0.1095 (0.1141)  labels_encoder_unscaled: 0.1072 (0.1219)  labels_decoder_unscaled: 0.2189 (0.2282)  time: 0.1616  data: 0.0003  max mem: 2688
Epoch: [3]  [ 750/1405]  eta: 0:01:43  lr: 0.000001  loss: 0.2403 (0.2361)  labels_encoder: 0.1256 (0.1220)  labels_decoder: 0.1117 (0.1141)  labels_encoder_unscaled: 0.1256 (0.1220)  labels_decoder_unscaled: 0.2234 (0.2282)  time: 0.1453  data: 0.0003  max mem: 2688
Epoch: [3]  [ 800/1405]  eta: 0:01:35  lr: 0.000001  loss: 0.2561 (0.2367)  labels_encoder: 0.1254 (0.1223)  labels_decoder: 0.1213 (0.1144)  labels_encoder_unscaled: 0.1254 (0.1223)  labels_decoder_unscaled: 0.2426 (0.2288)  time: 0.1577  data: 0.0003  max mem: 2688
Epoch: [3]  [ 850/1405]  eta: 0:01:27  lr: 0.000001  loss: 0.2266 (0.2363)  labels_encoder: 0.1081 (0.1220)  labels_decoder: 0.1071 (0.1144)  labels_encoder_unscaled: 0.1081 (0.1220)  labels_decoder_unscaled: 0.2142 (0.2287)  time: 0.1513  data: 0.0003  max mem: 2688
Epoch: [3]  [ 900/1405]  eta: 0:01:19  lr: 0.000001  loss: 0.2221 (0.2363)  labels_encoder: 0.1139 (0.1221)  labels_decoder: 0.1095 (0.1142)  labels_encoder_unscaled: 0.1139 (0.1221)  labels_decoder_unscaled: 0.2191 (0.2284)  time: 0.1446  data: 0.0003  max mem: 2688
Epoch: [3]  [ 950/1405]  eta: 0:01:11  lr: 0.000001  loss: 0.2248 (0.2365)  labels_encoder: 0.1171 (0.1223)  labels_decoder: 0.1079 (0.1142)  labels_encoder_unscaled: 0.1171 (0.1223)  labels_decoder_unscaled: 0.2157 (0.2285)  time: 0.1515  data: 0.0003  max mem: 2688
Epoch: [3]  [1000/1405]  eta: 0:01:03  lr: 0.000001  loss: 0.2190 (0.2361)  labels_encoder: 0.1064 (0.1219)  labels_decoder: 0.1122 (0.1142)  labels_encoder_unscaled: 0.1064 (0.1219)  labels_decoder_unscaled: 0.2244 (0.2284)  time: 0.1520  data: 0.0003  max mem: 2688
Epoch: [3]  [1050/1405]  eta: 0:00:55  lr: 0.000001  loss: 0.2262 (0.2361)  labels_encoder: 0.1080 (0.1218)  labels_decoder: 0.1151 (0.1143)  labels_encoder_unscaled: 0.1080 (0.1218)  labels_decoder_unscaled: 0.2301 (0.2286)  time: 0.1616  data: 0.0003  max mem: 2688
Epoch: [3]  [1100/1405]  eta: 0:00:48  lr: 0.000001  loss: 0.2269 (0.2363)  labels_encoder: 0.1084 (0.1220)  labels_decoder: 0.1184 (0.1143)  labels_encoder_unscaled: 0.1084 (0.1220)  labels_decoder_unscaled: 0.2368 (0.2286)  time: 0.1554  data: 0.0003  max mem: 2688
Epoch: [3]  [1150/1405]  eta: 0:00:40  lr: 0.000001  loss: 0.2292 (0.2363)  labels_encoder: 0.1092 (0.1220)  labels_decoder: 0.1163 (0.1142)  labels_encoder_unscaled: 0.1092 (0.1220)  labels_decoder_unscaled: 0.2327 (0.2285)  time: 0.1522  data: 0.0003  max mem: 2688
Epoch: [3]  [1200/1405]  eta: 0:00:32  lr: 0.000001  loss: 0.2348 (0.2366)  labels_encoder: 0.1189 (0.1222)  labels_decoder: 0.1116 (0.1143)  labels_encoder_unscaled: 0.1189 (0.1222)  labels_decoder_unscaled: 0.2233 (0.2287)  time: 0.1544  data: 0.0003  max mem: 2688
Epoch: [3]  [1250/1405]  eta: 0:00:24  lr: 0.000001  loss: 0.2286 (0.2365)  labels_encoder: 0.1176 (0.1222)  labels_decoder: 0.1094 (0.1143)  labels_encoder_unscaled: 0.1176 (0.1222)  labels_decoder_unscaled: 0.2189 (0.2286)  time: 0.1671  data: 0.0003  max mem: 2688
Epoch: [3]  [1300/1405]  eta: 0:00:16  lr: 0.000001  loss: 0.2488 (0.2368)  labels_encoder: 0.1242 (0.1224)  labels_decoder: 0.1137 (0.1143)  labels_encoder_unscaled: 0.1242 (0.1224)  labels_decoder_unscaled: 0.2273 (0.2287)  time: 0.1613  data: 0.0003  max mem: 2688
Epoch: [3]  [1350/1405]  eta: 0:00:08  lr: 0.000001  loss: 0.2125 (0.2366)  labels_encoder: 0.1200 (0.1225)  labels_decoder: 0.0959 (0.1141)  labels_encoder_unscaled: 0.1200 (0.1225)  labels_decoder_unscaled: 0.1917 (0.2282)  time: 0.1576  data: 0.0003  max mem: 2688
Epoch: [3]  [1400/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2309 (0.2363)  labels_encoder: 0.1339 (0.1223)  labels_decoder: 0.1128 (0.1139)  labels_encoder_unscaled: 0.1339 (0.1223)  labels_decoder_unscaled: 0.2255 (0.2278)  time: 0.1418  data: 0.0004  max mem: 2688
Epoch: [3]  [1404/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2309 (0.2363)  labels_encoder: 0.1286 (0.1224)  labels_decoder: 0.1052 (0.1139)  labels_encoder_unscaled: 0.1286 (0.1224)  labels_decoder_unscaled: 0.2104 (0.2278)  time: 0.1317  data: 0.0004  max mem: 2688
Epoch: [3] Total time: 0:03:41 (0.1575 s / it)
Averaged stats: lr: 0.000001  loss: 0.2309 (0.2363)  labels_encoder: 0.1286 (0.1224)  labels_decoder: 0.1052 (0.1139)  labels_encoder_unscaled: 0.1286 (0.1224)  labels_decoder_unscaled: 0.2104 (0.2278)
Test:  [   0/1613]  eta: 1:24:55  loss: 0.6195 (0.6195)  labels_encoder: 0.4050 (0.4050)  labels_decoder: 0.2144 (0.2144)  labels_encoder_unscaled: 0.4050 (0.4050)  labels_decoder_unscaled: 0.4289 (0.4289)  time: 3.1589  data: 3.0862  max mem: 2688
Test:  [  50/1613]  eta: 0:04:31  loss: 0.4061 (0.8532)  labels_encoder: 0.2676 (0.5449)  labels_decoder: 0.1808 (0.3083)  labels_encoder_unscaled: 0.2676 (0.5449)  labels_decoder_unscaled: 0.3616 (0.6166)  time: 0.1046  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:27  loss: 0.1640 (0.6746)  labels_encoder: 0.1091 (0.4329)  labels_decoder: 0.0549 (0.2417)  labels_encoder_unscaled: 0.1091 (0.4329)  labels_decoder_unscaled: 0.1098 (0.4833)  time: 0.1017  data: 0.0024  max mem: 2688
Test:  [ 150/1613]  eta: 0:03:03  loss: 0.8257 (0.6910)  labels_encoder: 0.5450 (0.4484)  labels_decoder: 0.1778 (0.2427)  labels_encoder_unscaled: 0.5450 (0.4484)  labels_decoder_unscaled: 0.3557 (0.4853)  time: 0.0968  data: 0.0042  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:51  loss: 1.1694 (0.8792)  labels_encoder: 0.7403 (0.5796)  labels_decoder: 0.4291 (0.2997)  labels_encoder_unscaled: 0.7403 (0.5796)  labels_decoder_unscaled: 0.8582 (0.5993)  time: 0.1104  data: 0.0372  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:42  loss: 0.6143 (0.9476)  labels_encoder: 0.3333 (0.6208)  labels_decoder: 0.3070 (0.3268)  labels_encoder_unscaled: 0.3333 (0.6208)  labels_decoder_unscaled: 0.6141 (0.6536)  time: 0.1017  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:34  loss: 0.6283 (0.9871)  labels_encoder: 0.4000 (0.6490)  labels_decoder: 0.2450 (0.3380)  labels_encoder_unscaled: 0.4000 (0.6490)  labels_decoder_unscaled: 0.4899 (0.6760)  time: 0.1005  data: 0.0030  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:25  loss: 1.0636 (0.9757)  labels_encoder: 0.6454 (0.6370)  labels_decoder: 0.4092 (0.3387)  labels_encoder_unscaled: 0.6454 (0.6370)  labels_decoder_unscaled: 0.8184 (0.6774)  time: 0.1052  data: 0.0219  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:18  loss: 0.8273 (1.0632)  labels_encoder: 0.4849 (0.6987)  labels_decoder: 0.3367 (0.3645)  labels_encoder_unscaled: 0.4849 (0.6987)  labels_decoder_unscaled: 0.6734 (0.7291)  time: 0.1181  data: 0.0002  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:11  loss: 0.9117 (1.1399)  labels_encoder: 0.5544 (0.7477)  labels_decoder: 0.3573 (0.3922)  labels_encoder_unscaled: 0.5544 (0.7477)  labels_decoder_unscaled: 0.7147 (0.7843)  time: 0.1091  data: 0.0170  max mem: 2688
Test:  [ 500/1613]  eta: 0:02:04  loss: 0.3761 (1.0943)  labels_encoder: 0.2061 (0.7155)  labels_decoder: 0.1964 (0.3788)  labels_encoder_unscaled: 0.2061 (0.7155)  labels_decoder_unscaled: 0.3929 (0.7575)  time: 0.0987  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:59  loss: 0.5720 (1.0920)  labels_encoder: 0.3505 (0.7131)  labels_decoder: 0.2720 (0.3790)  labels_encoder_unscaled: 0.3505 (0.7131)  labels_decoder_unscaled: 0.5440 (0.7580)  time: 0.1132  data: 0.0269  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:52  loss: 1.6130 (1.1477)  labels_encoder: 0.8930 (0.7588)  labels_decoder: 0.5813 (0.3889)  labels_encoder_unscaled: 0.8930 (0.7588)  labels_decoder_unscaled: 1.1626 (0.7777)  time: 0.0981  data: 0.0054  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:47  loss: 1.0828 (1.1365)  labels_encoder: 0.6086 (0.7453)  labels_decoder: 0.4479 (0.3913)  labels_encoder_unscaled: 0.6086 (0.7453)  labels_decoder_unscaled: 0.8957 (0.7825)  time: 0.1167  data: 0.0002  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:40  loss: 0.6111 (1.1152)  labels_encoder: 0.2965 (0.7289)  labels_decoder: 0.2581 (0.3863)  labels_encoder_unscaled: 0.2965 (0.7289)  labels_decoder_unscaled: 0.5162 (0.7726)  time: 0.0955  data: 0.0002  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:35  loss: 0.7445 (1.1018)  labels_encoder: 0.4568 (0.7186)  labels_decoder: 0.2946 (0.3832)  labels_encoder_unscaled: 0.4568 (0.7186)  labels_decoder_unscaled: 0.5893 (0.7664)  time: 0.1023  data: 0.0002  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:29  loss: 0.9236 (1.1053)  labels_encoder: 0.4997 (0.7215)  labels_decoder: 0.4244 (0.3838)  labels_encoder_unscaled: 0.4997 (0.7215)  labels_decoder_unscaled: 0.8488 (0.7676)  time: 0.1048  data: 0.0002  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:23  loss: 1.3876 (1.1055)  labels_encoder: 0.8766 (0.7183)  labels_decoder: 0.5578 (0.3872)  labels_encoder_unscaled: 0.8766 (0.7183)  labels_decoder_unscaled: 1.1156 (0.7743)  time: 0.0977  data: 0.0002  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:17  loss: 0.6693 (1.1229)  labels_encoder: 0.3901 (0.7303)  labels_decoder: 0.2705 (0.3926)  labels_encoder_unscaled: 0.3901 (0.7303)  labels_decoder_unscaled: 0.5410 (0.7852)  time: 0.1106  data: 0.0002  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:11  loss: 1.0811 (1.1169)  labels_encoder: 0.6722 (0.7272)  labels_decoder: 0.3581 (0.3897)  labels_encoder_unscaled: 0.6722 (0.7272)  labels_decoder_unscaled: 0.7163 (0.7794)  time: 0.0993  data: 0.0003  max mem: 2688
Test:  [1000/1613]  eta: 0:01:06  loss: 0.5362 (1.1056)  labels_encoder: 0.3058 (0.7185)  labels_decoder: 0.2304 (0.3871)  labels_encoder_unscaled: 0.3058 (0.7185)  labels_decoder_unscaled: 0.4609 (0.7743)  time: 0.1010  data: 0.0002  max mem: 2688
Test:  [1050/1613]  eta: 0:01:00  loss: 0.9470 (1.1024)  labels_encoder: 0.5557 (0.7164)  labels_decoder: 0.3304 (0.3860)  labels_encoder_unscaled: 0.5557 (0.7164)  labels_decoder_unscaled: 0.6608 (0.7720)  time: 0.1042  data: 0.0002  max mem: 2688
Test:  [1100/1613]  eta: 0:00:55  loss: 1.0911 (1.1134)  labels_encoder: 0.7670 (0.7259)  labels_decoder: 0.3909 (0.3875)  labels_encoder_unscaled: 0.7670 (0.7259)  labels_decoder_unscaled: 0.7818 (0.7749)  time: 0.0847  data: 0.0002  max mem: 2688
Test:  [1150/1613]  eta: 0:00:49  loss: 0.5626 (1.1020)  labels_encoder: 0.3572 (0.7176)  labels_decoder: 0.2126 (0.3844)  labels_encoder_unscaled: 0.3572 (0.7176)  labels_decoder_unscaled: 0.4251 (0.7688)  time: 0.1193  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:44  loss: 0.5476 (1.1066)  labels_encoder: 0.3297 (0.7200)  labels_decoder: 0.2444 (0.3866)  labels_encoder_unscaled: 0.3297 (0.7200)  labels_decoder_unscaled: 0.4889 (0.7733)  time: 0.0914  data: 0.0002  max mem: 2688
Test:  [1250/1613]  eta: 0:00:38  loss: 0.3862 (1.1070)  labels_encoder: 0.2453 (0.7196)  labels_decoder: 0.1778 (0.3874)  labels_encoder_unscaled: 0.2453 (0.7196)  labels_decoder_unscaled: 0.3556 (0.7747)  time: 0.0912  data: 0.0003  max mem: 2688
Test:  [1300/1613]  eta: 0:00:33  loss: 0.7226 (1.1007)  labels_encoder: 0.4812 (0.7152)  labels_decoder: 0.2386 (0.3856)  labels_encoder_unscaled: 0.4812 (0.7152)  labels_decoder_unscaled: 0.4773 (0.7711)  time: 0.0971  data: 0.0169  max mem: 2688
Test:  [1350/1613]  eta: 0:00:27  loss: 1.0813 (1.1188)  labels_encoder: 0.6290 (0.7277)  labels_decoder: 0.3971 (0.3911)  labels_encoder_unscaled: 0.6290 (0.7277)  labels_decoder_unscaled: 0.7943 (0.7821)  time: 0.0960  data: 0.0329  max mem: 2688
Test:  [1400/1613]  eta: 0:00:22  loss: 1.2011 (1.1138)  labels_encoder: 0.7226 (0.7243)  labels_decoder: 0.4034 (0.3895)  labels_encoder_unscaled: 0.7226 (0.7243)  labels_decoder_unscaled: 0.8068 (0.7790)  time: 0.0968  data: 0.0302  max mem: 2688
Test:  [1450/1613]  eta: 0:00:17  loss: 0.7719 (1.1248)  labels_encoder: 0.4283 (0.7318)  labels_decoder: 0.2959 (0.3931)  labels_encoder_unscaled: 0.4283 (0.7318)  labels_decoder_unscaled: 0.5917 (0.7861)  time: 0.0997  data: 0.0396  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.7990 (1.1343)  labels_encoder: 0.5234 (0.7388)  labels_decoder: 0.2913 (0.3955)  labels_encoder_unscaled: 0.5234 (0.7388)  labels_decoder_unscaled: 0.5826 (0.7911)  time: 0.1020  data: 0.0298  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.7971 (1.1302)  labels_encoder: 0.5282 (0.7362)  labels_decoder: 0.2626 (0.3940)  labels_encoder_unscaled: 0.5282 (0.7362)  labels_decoder_unscaled: 0.5251 (0.7879)  time: 0.0998  data: 0.0281  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 1.0295 (1.1284)  labels_encoder: 0.5784 (0.7343)  labels_decoder: 0.4413 (0.3941)  labels_encoder_unscaled: 0.5784 (0.7343)  labels_decoder_unscaled: 0.8826 (0.7882)  time: 0.0962  data: 0.0367  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7315 (1.1267)  labels_encoder: 0.4766 (0.7337)  labels_decoder: 0.2677 (0.3930)  labels_encoder_unscaled: 0.4766 (0.7337)  labels_decoder_unscaled: 0.5354 (0.7861)  time: 0.0892  data: 0.0420  max mem: 2688
Test: Total time: 0:02:48 (0.1046 s / it)
Averaged stats: loss: 0.7315 (1.1267)  labels_encoder: 0.4766 (0.7337)  labels_decoder: 0.2677 (0.3930)  labels_encoder_unscaled: 0.4766 (0.7337)  labels_decoder_unscaled: 0.5354 (0.7861)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5738

dec_mAP all together: | 0.4599962325515956 |.
dec_mAP_pred | 0 : 0.5051692642533127 |.
dec_mAP_pred | 1 : 0.49718588236181943 |.
dec_mAP_pred | 2 : 0.4844272955894298 |.
dec_mAP_pred | 3 : 0.47021497032996284 |.
dec_mAP_pred | 4 : 0.45533655980310994 |.
dec_mAP_pred | 5 : 0.4400597841427075 |.
dec_mAP_pred | 6 : 0.4253317730908754 |.
dec_mAP_pred | 7 : 0.4117663735862777 |.
all decoder map: | 0.4612 |.
BaseballPitch: 0.1169
BasketballDunk: 0.7556
Billiards: 0.4367
CleanAndJerk: 0.7211
CliffDiving: 0.7947
CricketBowling: 0.4711
CricketShot: 0.2464
Diving: 0.6893
FrisbeeCatch: 0.3463
GolfSwing: 0.6096
HammerThrow: 0.8615
HighJump: 0.6334
JavelinThrow: 0.7000
LongJump: 0.7820
PoleVault: 0.8756
Shotput: 0.6782
SoccerPenalty: 0.2645
TennisSwing: 0.5573
ThrowDiscus: 0.6185
VolleyballSpiking: 0.3179
Epoch: [4]  [   0/1405]  eta: 1:22:48  lr: 0.000000  loss: 0.2115 (0.2115)  labels_encoder: 0.1223 (0.1223)  labels_decoder: 0.0892 (0.0892)  labels_encoder_unscaled: 0.1223 (0.1223)  labels_decoder_unscaled: 0.1784 (0.1784)  time: 3.5361  data: 3.2893  max mem: 2688
Epoch: [4]  [  50/1405]  eta: 0:05:14  lr: 0.000000  loss: 0.2326 (0.2313)  labels_encoder: 0.1151 (0.1198)  labels_decoder: 0.1070 (0.1115)  labels_encoder_unscaled: 0.1151 (0.1198)  labels_decoder_unscaled: 0.2139 (0.2230)  time: 0.1610  data: 0.0003  max mem: 2688
Epoch: [4]  [ 100/1405]  eta: 0:04:12  lr: 0.000000  loss: 0.2427 (0.2348)  labels_encoder: 0.1246 (0.1225)  labels_decoder: 0.1142 (0.1124)  labels_encoder_unscaled: 0.1246 (0.1225)  labels_decoder_unscaled: 0.2284 (0.2247)  time: 0.1615  data: 0.0003  max mem: 2688
Epoch: [4]  [ 150/1405]  eta: 0:03:47  lr: 0.000000  loss: 0.2091 (0.2312)  labels_encoder: 0.1104 (0.1207)  labels_decoder: 0.1032 (0.1105)  labels_encoder_unscaled: 0.1104 (0.1207)  labels_decoder_unscaled: 0.2065 (0.2209)  time: 0.1571  data: 0.0003  max mem: 2688
Epoch: [4]  [ 200/1405]  eta: 0:03:30  lr: 0.000000  loss: 0.2673 (0.2345)  labels_encoder: 0.1412 (0.1228)  labels_decoder: 0.1239 (0.1117)  labels_encoder_unscaled: 0.1412 (0.1228)  labels_decoder_unscaled: 0.2477 (0.2234)  time: 0.1612  data: 0.0003  max mem: 2688
Epoch: [4]  [ 250/1405]  eta: 0:03:18  lr: 0.000000  loss: 0.2235 (0.2319)  labels_encoder: 0.1203 (0.1208)  labels_decoder: 0.1085 (0.1111)  labels_encoder_unscaled: 0.1203 (0.1208)  labels_decoder_unscaled: 0.2170 (0.2221)  time: 0.1601  data: 0.0003  max mem: 2688
Epoch: [4]  [ 300/1405]  eta: 0:03:05  lr: 0.000000  loss: 0.2402 (0.2326)  labels_encoder: 0.1346 (0.1210)  labels_decoder: 0.1130 (0.1115)  labels_encoder_unscaled: 0.1346 (0.1210)  labels_decoder_unscaled: 0.2260 (0.2231)  time: 0.1490  data: 0.0003  max mem: 2688
Epoch: [4]  [ 350/1405]  eta: 0:02:55  lr: 0.000000  loss: 0.2262 (0.2320)  labels_encoder: 0.1122 (0.1204)  labels_decoder: 0.1117 (0.1116)  labels_encoder_unscaled: 0.1122 (0.1204)  labels_decoder_unscaled: 0.2233 (0.2232)  time: 0.1580  data: 0.0003  max mem: 2688
Epoch: [4]  [ 400/1405]  eta: 0:02:45  lr: 0.000000  loss: 0.1938 (0.2315)  labels_encoder: 0.0958 (0.1201)  labels_decoder: 0.1065 (0.1114)  labels_encoder_unscaled: 0.0958 (0.1201)  labels_decoder_unscaled: 0.2131 (0.2227)  time: 0.1505  data: 0.0003  max mem: 2688
Epoch: [4]  [ 450/1405]  eta: 0:02:36  lr: 0.000000  loss: 0.2563 (0.2325)  labels_encoder: 0.1317 (0.1208)  labels_decoder: 0.1206 (0.1117)  labels_encoder_unscaled: 0.1317 (0.1208)  labels_decoder_unscaled: 0.2413 (0.2234)  time: 0.1520  data: 0.0003  max mem: 2688
Epoch: [4]  [ 500/1405]  eta: 0:02:27  lr: 0.000000  loss: 0.2271 (0.2330)  labels_encoder: 0.1202 (0.1209)  labels_decoder: 0.1085 (0.1121)  labels_encoder_unscaled: 0.1202 (0.1209)  labels_decoder_unscaled: 0.2169 (0.2242)  time: 0.1530  data: 0.0003  max mem: 2688
Epoch: [4]  [ 550/1405]  eta: 0:02:18  lr: 0.000000  loss: 0.2254 (0.2330)  labels_encoder: 0.1179 (0.1207)  labels_decoder: 0.1106 (0.1123)  labels_encoder_unscaled: 0.1179 (0.1207)  labels_decoder_unscaled: 0.2213 (0.2245)  time: 0.1501  data: 0.0003  max mem: 2688
Epoch: [4]  [ 600/1405]  eta: 0:02:09  lr: 0.000000  loss: 0.2355 (0.2335)  labels_encoder: 0.1238 (0.1209)  labels_decoder: 0.1194 (0.1126)  labels_encoder_unscaled: 0.1238 (0.1209)  labels_decoder_unscaled: 0.2389 (0.2252)  time: 0.1519  data: 0.0003  max mem: 2688
Epoch: [4]  [ 650/1405]  eta: 0:02:01  lr: 0.000000  loss: 0.2450 (0.2337)  labels_encoder: 0.1188 (0.1209)  labels_decoder: 0.1184 (0.1128)  labels_encoder_unscaled: 0.1188 (0.1209)  labels_decoder_unscaled: 0.2368 (0.2256)  time: 0.1464  data: 0.0004  max mem: 2688
Epoch: [4]  [ 700/1405]  eta: 0:01:52  lr: 0.000000  loss: 0.2096 (0.2329)  labels_encoder: 0.1047 (0.1205)  labels_decoder: 0.0998 (0.1124)  labels_encoder_unscaled: 0.1047 (0.1205)  labels_decoder_unscaled: 0.1997 (0.2249)  time: 0.1676  data: 0.0003  max mem: 2688
Epoch: [4]  [ 750/1405]  eta: 0:01:44  lr: 0.000000  loss: 0.2110 (0.2334)  labels_encoder: 0.1045 (0.1206)  labels_decoder: 0.1129 (0.1128)  labels_encoder_unscaled: 0.1045 (0.1206)  labels_decoder_unscaled: 0.2258 (0.2255)  time: 0.1613  data: 0.0003  max mem: 2688
Epoch: [4]  [ 800/1405]  eta: 0:01:36  lr: 0.000000  loss: 0.2366 (0.2325)  labels_encoder: 0.1211 (0.1202)  labels_decoder: 0.1088 (0.1123)  labels_encoder_unscaled: 0.1211 (0.1202)  labels_decoder_unscaled: 0.2175 (0.2247)  time: 0.1583  data: 0.0003  max mem: 2688
Epoch: [4]  [ 850/1405]  eta: 0:01:28  lr: 0.000000  loss: 0.2497 (0.2330)  labels_encoder: 0.1216 (0.1204)  labels_decoder: 0.1213 (0.1126)  labels_encoder_unscaled: 0.1216 (0.1204)  labels_decoder_unscaled: 0.2426 (0.2252)  time: 0.1670  data: 0.0003  max mem: 2688
Epoch: [4]  [ 900/1405]  eta: 0:01:20  lr: 0.000000  loss: 0.2124 (0.2332)  labels_encoder: 0.1066 (0.1205)  labels_decoder: 0.1050 (0.1126)  labels_encoder_unscaled: 0.1066 (0.1205)  labels_decoder_unscaled: 0.2101 (0.2253)  time: 0.1593  data: 0.0003  max mem: 2688
Epoch: [4]  [ 950/1405]  eta: 0:01:12  lr: 0.000000  loss: 0.2009 (0.2327)  labels_encoder: 0.0996 (0.1200)  labels_decoder: 0.1087 (0.1127)  labels_encoder_unscaled: 0.0996 (0.1200)  labels_decoder_unscaled: 0.2174 (0.2254)  time: 0.1550  data: 0.0003  max mem: 2688
Epoch: [4]  [1000/1405]  eta: 0:01:04  lr: 0.000000  loss: 0.2226 (0.2323)  labels_encoder: 0.1092 (0.1198)  labels_decoder: 0.1106 (0.1124)  labels_encoder_unscaled: 0.1092 (0.1198)  labels_decoder_unscaled: 0.2212 (0.2248)  time: 0.1518  data: 0.0003  max mem: 2688
Epoch: [4]  [1050/1405]  eta: 0:00:56  lr: 0.000000  loss: 0.2219 (0.2317)  labels_encoder: 0.1153 (0.1194)  labels_decoder: 0.1075 (0.1123)  labels_encoder_unscaled: 0.1153 (0.1194)  labels_decoder_unscaled: 0.2150 (0.2245)  time: 0.1459  data: 0.0003  max mem: 2688
Epoch: [4]  [1100/1405]  eta: 0:00:48  lr: 0.000000  loss: 0.2373 (0.2322)  labels_encoder: 0.1269 (0.1199)  labels_decoder: 0.1080 (0.1123)  labels_encoder_unscaled: 0.1269 (0.1199)  labels_decoder_unscaled: 0.2160 (0.2247)  time: 0.1496  data: 0.0003  max mem: 2688
Epoch: [4]  [1150/1405]  eta: 0:00:40  lr: 0.000000  loss: 0.2161 (0.2317)  labels_encoder: 0.1056 (0.1194)  labels_decoder: 0.1032 (0.1123)  labels_encoder_unscaled: 0.1056 (0.1194)  labels_decoder_unscaled: 0.2064 (0.2246)  time: 0.1441  data: 0.0003  max mem: 2688
Epoch: [4]  [1200/1405]  eta: 0:00:32  lr: 0.000000  loss: 0.2301 (0.2319)  labels_encoder: 0.1246 (0.1196)  labels_decoder: 0.1092 (0.1123)  labels_encoder_unscaled: 0.1246 (0.1196)  labels_decoder_unscaled: 0.2184 (0.2247)  time: 0.1487  data: 0.0003  max mem: 2688
Epoch: [4]  [1250/1405]  eta: 0:00:24  lr: 0.000000  loss: 0.2024 (0.2314)  labels_encoder: 0.1046 (0.1192)  labels_decoder: 0.1030 (0.1123)  labels_encoder_unscaled: 0.1046 (0.1192)  labels_decoder_unscaled: 0.2060 (0.2245)  time: 0.1498  data: 0.0003  max mem: 2688
Epoch: [4]  [1300/1405]  eta: 0:00:16  lr: 0.000000  loss: 0.2404 (0.2315)  labels_encoder: 0.1231 (0.1192)  labels_decoder: 0.1142 (0.1123)  labels_encoder_unscaled: 0.1231 (0.1192)  labels_decoder_unscaled: 0.2284 (0.2246)  time: 0.1544  data: 0.0003  max mem: 2688
Epoch: [4]  [1350/1405]  eta: 0:00:08  lr: 0.000000  loss: 0.2417 (0.2321)  labels_encoder: 0.1350 (0.1197)  labels_decoder: 0.1096 (0.1125)  labels_encoder_unscaled: 0.1350 (0.1197)  labels_decoder_unscaled: 0.2192 (0.2249)  time: 0.1545  data: 0.0003  max mem: 2688
Epoch: [4]  [1400/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2343 (0.2322)  labels_encoder: 0.1172 (0.1197)  labels_decoder: 0.1172 (0.1125)  labels_encoder_unscaled: 0.1172 (0.1197)  labels_decoder_unscaled: 0.2345 (0.2250)  time: 0.1359  data: 0.0003  max mem: 2688
Epoch: [4]  [1404/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2343 (0.2323)  labels_encoder: 0.1175 (0.1198)  labels_decoder: 0.1173 (0.1125)  labels_encoder_unscaled: 0.1175 (0.1198)  labels_decoder_unscaled: 0.2346 (0.2250)  time: 0.1306  data: 0.0003  max mem: 2688
Epoch: [4] Total time: 0:03:40 (0.1567 s / it)
Averaged stats: lr: 0.000000  loss: 0.2343 (0.2323)  labels_encoder: 0.1175 (0.1198)  labels_decoder: 0.1173 (0.1125)  labels_encoder_unscaled: 0.1175 (0.1198)  labels_decoder_unscaled: 0.2346 (0.2250)
Test:  [   0/1613]  eta: 1:24:21  loss: 0.6861 (0.6861)  labels_encoder: 0.4555 (0.4555)  labels_decoder: 0.2306 (0.2306)  labels_encoder_unscaled: 0.4555 (0.4555)  labels_decoder_unscaled: 0.4611 (0.4611)  time: 3.1382  data: 3.0033  max mem: 2688
Test:  [  50/1613]  eta: 0:04:27  loss: 0.4106 (0.8440)  labels_encoder: 0.2611 (0.5374)  labels_decoder: 0.1829 (0.3066)  labels_encoder_unscaled: 0.2611 (0.5374)  labels_decoder_unscaled: 0.3657 (0.6132)  time: 0.1044  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:30  loss: 0.1437 (0.6689)  labels_encoder: 0.0956 (0.4282)  labels_decoder: 0.0481 (0.2407)  labels_encoder_unscaled: 0.0956 (0.4282)  labels_decoder_unscaled: 0.0962 (0.4814)  time: 0.1118  data: 0.0164  max mem: 2688
Test:  [ 150/1613]  eta: 0:03:08  loss: 0.7653 (0.6842)  labels_encoder: 0.5482 (0.4429)  labels_decoder: 0.1655 (0.2413)  labels_encoder_unscaled: 0.5482 (0.4429)  labels_decoder_unscaled: 0.3310 (0.4825)  time: 0.1059  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:53  loss: 1.1460 (0.8668)  labels_encoder: 0.7156 (0.5700)  labels_decoder: 0.4260 (0.2968)  labels_encoder_unscaled: 0.7156 (0.5700)  labels_decoder_unscaled: 0.8519 (0.5936)  time: 0.1042  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:43  loss: 0.6067 (0.9370)  labels_encoder: 0.3391 (0.6127)  labels_decoder: 0.3077 (0.3243)  labels_encoder_unscaled: 0.3391 (0.6127)  labels_decoder_unscaled: 0.6154 (0.6487)  time: 0.1375  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:33  loss: 0.6140 (0.9758)  labels_encoder: 0.3916 (0.6401)  labels_decoder: 0.2420 (0.3357)  labels_encoder_unscaled: 0.3916 (0.6401)  labels_decoder_unscaled: 0.4841 (0.6713)  time: 0.0981  data: 0.0002  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:25  loss: 1.0429 (0.9659)  labels_encoder: 0.6826 (0.6292)  labels_decoder: 0.4207 (0.3367)  labels_encoder_unscaled: 0.6826 (0.6292)  labels_decoder_unscaled: 0.8413 (0.6734)  time: 0.0929  data: 0.0002  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:18  loss: 0.8501 (1.0575)  labels_encoder: 0.4919 (0.6940)  labels_decoder: 0.3442 (0.3636)  labels_encoder_unscaled: 0.4919 (0.6940)  labels_decoder_unscaled: 0.6883 (0.7272)  time: 0.1039  data: 0.0002  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:11  loss: 0.9071 (1.1343)  labels_encoder: 0.5534 (0.7432)  labels_decoder: 0.3536 (0.3911)  labels_encoder_unscaled: 0.5534 (0.7432)  labels_decoder_unscaled: 0.7073 (0.7822)  time: 0.0975  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:02:04  loss: 0.3587 (1.0890)  labels_encoder: 0.1982 (0.7113)  labels_decoder: 0.1974 (0.3777)  labels_encoder_unscaled: 0.1982 (0.7113)  labels_decoder_unscaled: 0.3947 (0.7554)  time: 0.1038  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:58  loss: 0.5757 (1.0877)  labels_encoder: 0.3498 (0.7095)  labels_decoder: 0.2737 (0.3782)  labels_encoder_unscaled: 0.3498 (0.7095)  labels_decoder_unscaled: 0.5475 (0.7564)  time: 0.1189  data: 0.0002  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:52  loss: 1.6061 (1.1437)  labels_encoder: 0.8964 (0.7556)  labels_decoder: 0.5782 (0.3881)  labels_encoder_unscaled: 0.8964 (0.7556)  labels_decoder_unscaled: 1.1565 (0.7762)  time: 0.1106  data: 0.0002  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:46  loss: 1.1305 (1.1347)  labels_encoder: 0.6320 (0.7436)  labels_decoder: 0.4523 (0.3911)  labels_encoder_unscaled: 0.6320 (0.7436)  labels_decoder_unscaled: 0.9046 (0.7823)  time: 0.1079  data: 0.0002  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:40  loss: 0.6156 (1.1133)  labels_encoder: 0.3001 (0.7272)  labels_decoder: 0.2608 (0.3862)  labels_encoder_unscaled: 0.3001 (0.7272)  labels_decoder_unscaled: 0.5216 (0.7723)  time: 0.1022  data: 0.0002  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:35  loss: 0.7776 (1.1010)  labels_encoder: 0.4841 (0.7175)  labels_decoder: 0.3085 (0.3835)  labels_encoder_unscaled: 0.4841 (0.7175)  labels_decoder_unscaled: 0.6171 (0.7670)  time: 0.1067  data: 0.0002  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:29  loss: 0.9098 (1.1038)  labels_encoder: 0.4943 (0.7200)  labels_decoder: 0.4201 (0.3839)  labels_encoder_unscaled: 0.4943 (0.7200)  labels_decoder_unscaled: 0.8401 (0.7677)  time: 0.1006  data: 0.0002  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:23  loss: 1.4067 (1.1046)  labels_encoder: 0.8438 (0.7172)  labels_decoder: 0.5629 (0.3874)  labels_encoder_unscaled: 0.8438 (0.7172)  labels_decoder_unscaled: 1.1258 (0.7748)  time: 0.0970  data: 0.0002  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:17  loss: 0.6776 (1.1229)  labels_encoder: 0.3769 (0.7298)  labels_decoder: 0.2711 (0.3931)  labels_encoder_unscaled: 0.3769 (0.7298)  labels_decoder_unscaled: 0.5422 (0.7862)  time: 0.1065  data: 0.0002  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:12  loss: 1.0924 (1.1160)  labels_encoder: 0.6733 (0.7260)  labels_decoder: 0.3686 (0.3900)  labels_encoder_unscaled: 0.6733 (0.7260)  labels_decoder_unscaled: 0.7372 (0.7799)  time: 0.1034  data: 0.0002  max mem: 2688
Test:  [1000/1613]  eta: 0:01:06  loss: 0.5337 (1.1047)  labels_encoder: 0.3029 (0.7172)  labels_decoder: 0.2307 (0.3875)  labels_encoder_unscaled: 0.3029 (0.7172)  labels_decoder_unscaled: 0.4615 (0.7750)  time: 0.1058  data: 0.0002  max mem: 2688
Test:  [1050/1613]  eta: 0:01:01  loss: 0.9426 (1.1011)  labels_encoder: 0.5447 (0.7149)  labels_decoder: 0.3298 (0.3863)  labels_encoder_unscaled: 0.5447 (0.7149)  labels_decoder_unscaled: 0.6596 (0.7725)  time: 0.1005  data: 0.0002  max mem: 2688
Test:  [1100/1613]  eta: 0:00:55  loss: 1.0675 (1.1117)  labels_encoder: 0.7537 (0.7241)  labels_decoder: 0.3850 (0.3876)  labels_encoder_unscaled: 0.7537 (0.7241)  labels_decoder_unscaled: 0.7699 (0.7753)  time: 0.0997  data: 0.0002  max mem: 2688
Test:  [1150/1613]  eta: 0:00:50  loss: 0.5512 (1.1006)  labels_encoder: 0.3459 (0.7160)  labels_decoder: 0.2093 (0.3846)  labels_encoder_unscaled: 0.3459 (0.7160)  labels_decoder_unscaled: 0.4186 (0.7692)  time: 0.1072  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:44  loss: 0.5576 (1.1057)  labels_encoder: 0.3370 (0.7187)  labels_decoder: 0.2507 (0.3870)  labels_encoder_unscaled: 0.3370 (0.7187)  labels_decoder_unscaled: 0.5014 (0.7740)  time: 0.0990  data: 0.0002  max mem: 2688
Test:  [1250/1613]  eta: 0:00:39  loss: 0.3925 (1.1061)  labels_encoder: 0.2395 (0.7185)  labels_decoder: 0.1682 (0.3877)  labels_encoder_unscaled: 0.2395 (0.7185)  labels_decoder_unscaled: 0.3364 (0.7754)  time: 0.1136  data: 0.0002  max mem: 2688
Test:  [1300/1613]  eta: 0:00:33  loss: 0.6977 (1.0994)  labels_encoder: 0.4682 (0.7137)  labels_decoder: 0.2356 (0.3858)  labels_encoder_unscaled: 0.4682 (0.7137)  labels_decoder_unscaled: 0.4712 (0.7715)  time: 0.1044  data: 0.0002  max mem: 2688
Test:  [1350/1613]  eta: 0:00:28  loss: 1.0633 (1.1170)  labels_encoder: 0.6139 (0.7258)  labels_decoder: 0.3946 (0.3911)  labels_encoder_unscaled: 0.6139 (0.7258)  labels_decoder_unscaled: 0.7891 (0.7823)  time: 0.1015  data: 0.0002  max mem: 2688
Test:  [1400/1613]  eta: 0:00:22  loss: 1.2124 (1.1122)  labels_encoder: 0.7262 (0.7226)  labels_decoder: 0.3949 (0.3896)  labels_encoder_unscaled: 0.7262 (0.7226)  labels_decoder_unscaled: 0.7898 (0.7793)  time: 0.0965  data: 0.0002  max mem: 2688
Test:  [1450/1613]  eta: 0:00:17  loss: 0.7962 (1.1237)  labels_encoder: 0.4374 (0.7303)  labels_decoder: 0.3028 (0.3934)  labels_encoder_unscaled: 0.4374 (0.7303)  labels_decoder_unscaled: 0.6056 (0.7868)  time: 0.0926  data: 0.0002  max mem: 2688
Test:  [1500/1613]  eta: 0:00:12  loss: 0.8124 (1.1345)  labels_encoder: 0.5433 (0.7383)  labels_decoder: 0.3025 (0.3962)  labels_encoder_unscaled: 0.5433 (0.7383)  labels_decoder_unscaled: 0.6049 (0.7925)  time: 0.1158  data: 0.0002  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.8068 (1.1302)  labels_encoder: 0.5323 (0.7356)  labels_decoder: 0.2647 (0.3946)  labels_encoder_unscaled: 0.5323 (0.7356)  labels_decoder_unscaled: 0.5294 (0.7892)  time: 0.1053  data: 0.0002  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 1.0353 (1.1284)  labels_encoder: 0.5712 (0.7337)  labels_decoder: 0.4417 (0.3948)  labels_encoder_unscaled: 0.5712 (0.7337)  labels_decoder_unscaled: 0.8834 (0.7895)  time: 0.1078  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7562 (1.1268)  labels_encoder: 0.4912 (0.7331)  labels_decoder: 0.2709 (0.3937)  labels_encoder_unscaled: 0.4912 (0.7331)  labels_decoder_unscaled: 0.5419 (0.7874)  time: 0.0736  data: 0.0001  max mem: 2688
Test: Total time: 0:02:52 (0.1071 s / it)
Averaged stats: loss: 0.7562 (1.1268)  labels_encoder: 0.4912 (0.7331)  labels_decoder: 0.2709 (0.3937)  labels_encoder_unscaled: 0.4912 (0.7331)  labels_decoder_unscaled: 0.5419 (0.7874)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5735

dec_mAP all together: | 0.4594649944018463 |.
dec_mAP_pred | 0 : 0.5043494623765123 |.
dec_mAP_pred | 1 : 0.49644850507527954 |.
dec_mAP_pred | 2 : 0.48380821310580807 |.
dec_mAP_pred | 3 : 0.46964966165126637 |.
dec_mAP_pred | 4 : 0.4548875192556567 |.
dec_mAP_pred | 5 : 0.43963371922695893 |.
dec_mAP_pred | 6 : 0.42498118976603827 |.
dec_mAP_pred | 7 : 0.4114565826903337 |.
all decoder map: | 0.4607 |.
BaseballPitch: 0.1157
BasketballDunk: 0.7559
Billiards: 0.4372
CleanAndJerk: 0.7207
CliffDiving: 0.7937
CricketBowling: 0.4709
CricketShot: 0.2458
Diving: 0.6878
FrisbeeCatch: 0.3480
GolfSwing: 0.6100
HammerThrow: 0.8615
HighJump: 0.6330
JavelinThrow: 0.6998
LongJump: 0.7807
PoleVault: 0.8747
Shotput: 0.6783
SoccerPenalty: 0.2613
TennisSwing: 0.5563
ThrowDiscus: 0.6195
VolleyballSpiking: 0.3186
Training time 0:30:39
