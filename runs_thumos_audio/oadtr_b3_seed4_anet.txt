Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:4
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  78.772 M, 99.834% Params, 2.714 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 9.304% Params, 0.47 GMac, 17.307% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 23.933% Params, 1.227 GMac, 45.207% MACs, 
    (net): Sequential(
      18.884 M, 23.933% Params, 1.227 GMac, 45.207% MACs, 
      (0): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.057% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 66.512% Params, 1.017 GMac, 37.478% MACs, 
    (layers): ModuleList(
      52.48 M, 66.512% Params, 1.017 GMac, 37.478% MACs, 
      (0): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.029% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2714272812.0
Model params: 78903340
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1404]  eta: 1:27:19  lr: 0.000100  loss: 4.8645 (4.8645)  labels_encoder: 3.1808 (3.1808)  labels_decoder: 1.6837 (1.6837)  labels_encoder_unscaled: 3.1808 (3.1808)  labels_decoder_unscaled: 3.3674 (3.3674)  time: 3.7315  data: 3.0020  max mem: 2800
Epoch: [1]  [  50/1404]  eta: 0:06:32  lr: 0.000100  loss: 0.9550 (1.6342)  labels_encoder: 0.6214 (1.0579)  labels_decoder: 0.3681 (0.5763)  labels_encoder_unscaled: 0.6214 (1.0579)  labels_decoder_unscaled: 0.7361 (1.1527)  time: 0.1986  data: 0.0003  max mem: 3702
Epoch: [1]  [ 100/1404]  eta: 0:05:20  lr: 0.000100  loss: 0.7455 (1.2488)  labels_encoder: 0.4491 (0.7990)  labels_decoder: 0.2864 (0.4498)  labels_encoder_unscaled: 0.4491 (0.7990)  labels_decoder_unscaled: 0.5729 (0.8997)  time: 0.1993  data: 0.0003  max mem: 3702
Epoch: [1]  [ 150/1404]  eta: 0:04:47  lr: 0.000100  loss: 0.7215 (1.0808)  labels_encoder: 0.4490 (0.6878)  labels_decoder: 0.2599 (0.3929)  labels_encoder_unscaled: 0.4490 (0.6878)  labels_decoder_unscaled: 0.5197 (0.7859)  time: 0.2017  data: 0.0003  max mem: 3702
Epoch: [1]  [ 200/1404]  eta: 0:04:24  lr: 0.000100  loss: 0.6572 (0.9782)  labels_encoder: 0.3978 (0.6187)  labels_decoder: 0.2571 (0.3595)  labels_encoder_unscaled: 0.3978 (0.6187)  labels_decoder_unscaled: 0.5142 (0.7189)  time: 0.1849  data: 0.0003  max mem: 3702
Epoch: [1]  [ 250/1404]  eta: 0:04:04  lr: 0.000100  loss: 0.5711 (0.9066)  labels_encoder: 0.3558 (0.5703)  labels_decoder: 0.2359 (0.3363)  labels_encoder_unscaled: 0.3558 (0.5703)  labels_decoder_unscaled: 0.4718 (0.6726)  time: 0.1792  data: 0.0003  max mem: 3702
Epoch: [1]  [ 300/1404]  eta: 0:03:47  lr: 0.000100  loss: 0.5275 (0.8543)  labels_encoder: 0.3237 (0.5351)  labels_decoder: 0.2172 (0.3192)  labels_encoder_unscaled: 0.3237 (0.5351)  labels_decoder_unscaled: 0.4344 (0.6384)  time: 0.1815  data: 0.0003  max mem: 3702
Epoch: [1]  [ 350/1404]  eta: 0:03:34  lr: 0.000100  loss: 0.5346 (0.8157)  labels_encoder: 0.3362 (0.5097)  labels_decoder: 0.2115 (0.3060)  labels_encoder_unscaled: 0.3362 (0.5097)  labels_decoder_unscaled: 0.4229 (0.6120)  time: 0.1895  data: 0.0003  max mem: 3702
Epoch: [1]  [ 400/1404]  eta: 0:03:22  lr: 0.000100  loss: 0.5956 (0.7845)  labels_encoder: 0.3424 (0.4880)  labels_decoder: 0.2464 (0.2966)  labels_encoder_unscaled: 0.3424 (0.4880)  labels_decoder_unscaled: 0.4927 (0.5932)  time: 0.1935  data: 0.0003  max mem: 3702
Epoch: [1]  [ 450/1404]  eta: 0:03:11  lr: 0.000100  loss: 0.5000 (0.7557)  labels_encoder: 0.3097 (0.4690)  labels_decoder: 0.2185 (0.2868)  labels_encoder_unscaled: 0.3097 (0.4690)  labels_decoder_unscaled: 0.4370 (0.5735)  time: 0.1846  data: 0.0003  max mem: 3702
Epoch: [1]  [ 500/1404]  eta: 0:03:00  lr: 0.000100  loss: 0.4950 (0.7307)  labels_encoder: 0.2859 (0.4521)  labels_decoder: 0.1983 (0.2786)  labels_encoder_unscaled: 0.2859 (0.4521)  labels_decoder_unscaled: 0.3967 (0.5572)  time: 0.2013  data: 0.0003  max mem: 3702
Epoch: [1]  [ 550/1404]  eta: 0:02:49  lr: 0.000100  loss: 0.4815 (0.7109)  labels_encoder: 0.2797 (0.4388)  labels_decoder: 0.2137 (0.2722)  labels_encoder_unscaled: 0.2797 (0.4388)  labels_decoder_unscaled: 0.4274 (0.5443)  time: 0.1876  data: 0.0003  max mem: 3702
Epoch: [1]  [ 600/1404]  eta: 0:02:38  lr: 0.000100  loss: 0.4712 (0.6925)  labels_encoder: 0.2895 (0.4265)  labels_decoder: 0.1851 (0.2661)  labels_encoder_unscaled: 0.2895 (0.4265)  labels_decoder_unscaled: 0.3701 (0.5322)  time: 0.1871  data: 0.0003  max mem: 3702
Epoch: [1]  [ 650/1404]  eta: 0:02:28  lr: 0.000100  loss: 0.4868 (0.6762)  labels_encoder: 0.2866 (0.4156)  labels_decoder: 0.1928 (0.2606)  labels_encoder_unscaled: 0.2866 (0.4156)  labels_decoder_unscaled: 0.3857 (0.5211)  time: 0.1966  data: 0.0003  max mem: 3702
Epoch: [1]  [ 700/1404]  eta: 0:02:18  lr: 0.000100  loss: 0.4865 (0.6625)  labels_encoder: 0.2852 (0.4069)  labels_decoder: 0.1764 (0.2556)  labels_encoder_unscaled: 0.2852 (0.4069)  labels_decoder_unscaled: 0.3527 (0.5112)  time: 0.1905  data: 0.0003  max mem: 3702
Epoch: [1]  [ 750/1404]  eta: 0:02:08  lr: 0.000100  loss: 0.4666 (0.6498)  labels_encoder: 0.2830 (0.3985)  labels_decoder: 0.1964 (0.2513)  labels_encoder_unscaled: 0.2830 (0.3985)  labels_decoder_unscaled: 0.3929 (0.5027)  time: 0.1875  data: 0.0005  max mem: 3702
Epoch: [1]  [ 800/1404]  eta: 0:01:58  lr: 0.000100  loss: 0.4620 (0.6387)  labels_encoder: 0.2928 (0.3911)  labels_decoder: 0.1911 (0.2475)  labels_encoder_unscaled: 0.2928 (0.3911)  labels_decoder_unscaled: 0.3821 (0.4951)  time: 0.1917  data: 0.0003  max mem: 3702
Epoch: [1]  [ 850/1404]  eta: 0:01:48  lr: 0.000100  loss: 0.3965 (0.6266)  labels_encoder: 0.2258 (0.3826)  labels_decoder: 0.1737 (0.2440)  labels_encoder_unscaled: 0.2258 (0.3826)  labels_decoder_unscaled: 0.3473 (0.4879)  time: 0.1995  data: 0.0003  max mem: 3702
Epoch: [1]  [ 900/1404]  eta: 0:01:38  lr: 0.000100  loss: 0.4554 (0.6164)  labels_encoder: 0.2624 (0.3758)  labels_decoder: 0.1827 (0.2406)  labels_encoder_unscaled: 0.2624 (0.3758)  labels_decoder_unscaled: 0.3654 (0.4811)  time: 0.1912  data: 0.0003  max mem: 3702
Epoch: [1]  [ 950/1404]  eta: 0:01:28  lr: 0.000100  loss: 0.4046 (0.6070)  labels_encoder: 0.2337 (0.3693)  labels_decoder: 0.1726 (0.2377)  labels_encoder_unscaled: 0.2337 (0.3693)  labels_decoder_unscaled: 0.3452 (0.4753)  time: 0.1787  data: 0.0003  max mem: 3702
Epoch: [1]  [1000/1404]  eta: 0:01:18  lr: 0.000100  loss: 0.4136 (0.5982)  labels_encoder: 0.2514 (0.3633)  labels_decoder: 0.1659 (0.2348)  labels_encoder_unscaled: 0.2514 (0.3633)  labels_decoder_unscaled: 0.3317 (0.4697)  time: 0.1885  data: 0.0004  max mem: 3702
Epoch: [1]  [1050/1404]  eta: 0:01:08  lr: 0.000100  loss: 0.4158 (0.5900)  labels_encoder: 0.2539 (0.3582)  labels_decoder: 0.1678 (0.2318)  labels_encoder_unscaled: 0.2539 (0.3582)  labels_decoder_unscaled: 0.3355 (0.4636)  time: 0.1812  data: 0.0003  max mem: 3702
Epoch: [1]  [1100/1404]  eta: 0:00:58  lr: 0.000100  loss: 0.4315 (0.5821)  labels_encoder: 0.2305 (0.3528)  labels_decoder: 0.1684 (0.2293)  labels_encoder_unscaled: 0.2305 (0.3528)  labels_decoder_unscaled: 0.3368 (0.4585)  time: 0.1845  data: 0.0003  max mem: 3702
Epoch: [1]  [1150/1404]  eta: 0:00:49  lr: 0.000100  loss: 0.4173 (0.5745)  labels_encoder: 0.2216 (0.3477)  labels_decoder: 0.1774 (0.2268)  labels_encoder_unscaled: 0.2216 (0.3477)  labels_decoder_unscaled: 0.3548 (0.4536)  time: 0.1883  data: 0.0005  max mem: 3702
Epoch: [1]  [1200/1404]  eta: 0:00:39  lr: 0.000100  loss: 0.4149 (0.5681)  labels_encoder: 0.2392 (0.3435)  labels_decoder: 0.1718 (0.2246)  labels_encoder_unscaled: 0.2392 (0.3435)  labels_decoder_unscaled: 0.3435 (0.4492)  time: 0.1889  data: 0.0003  max mem: 3702
Epoch: [1]  [1250/1404]  eta: 0:00:29  lr: 0.000100  loss: 0.3894 (0.5614)  labels_encoder: 0.2286 (0.3391)  labels_decoder: 0.1600 (0.2223)  labels_encoder_unscaled: 0.2286 (0.3391)  labels_decoder_unscaled: 0.3199 (0.4446)  time: 0.2248  data: 0.0006  max mem: 3702
Epoch: [1]  [1300/1404]  eta: 0:00:20  lr: 0.000100  loss: 0.3842 (0.5549)  labels_encoder: 0.2172 (0.3348)  labels_decoder: 0.1694 (0.2201)  labels_encoder_unscaled: 0.2172 (0.3348)  labels_decoder_unscaled: 0.3388 (0.4402)  time: 0.1940  data: 0.0004  max mem: 3702
Epoch: [1]  [1350/1404]  eta: 0:00:10  lr: 0.000100  loss: 0.3597 (0.5486)  labels_encoder: 0.1979 (0.3306)  labels_decoder: 0.1540 (0.2180)  labels_encoder_unscaled: 0.1979 (0.3306)  labels_decoder_unscaled: 0.3080 (0.4361)  time: 0.1782  data: 0.0004  max mem: 3702
Epoch: [1]  [1400/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3989 (0.5431)  labels_encoder: 0.2348 (0.3269)  labels_decoder: 0.1879 (0.2162)  labels_encoder_unscaled: 0.2348 (0.3269)  labels_decoder_unscaled: 0.3758 (0.4325)  time: 0.1636  data: 0.0005  max mem: 3702
Epoch: [1]  [1403/1404]  eta: 0:00:00  lr: 0.000100  loss: 0.3989 (0.5428)  labels_encoder: 0.2323 (0.3267)  labels_decoder: 0.1879 (0.2161)  labels_encoder_unscaled: 0.2323 (0.3267)  labels_decoder_unscaled: 0.3758 (0.4323)  time: 0.1558  data: 0.0004  max mem: 3702
Epoch: [1] Total time: 0:04:31 (0.1932 s / it)
Averaged stats: lr: 0.000100  loss: 0.3989 (0.5428)  labels_encoder: 0.2323 (0.3267)  labels_decoder: 0.1879 (0.2161)  labels_encoder_unscaled: 0.2323 (0.3267)  labels_decoder_unscaled: 0.3758 (0.4323)
Test:  [   0/1613]  eta: 1:21:15  loss: 0.5516 (0.5516)  labels_encoder: 0.2714 (0.2714)  labels_decoder: 0.2802 (0.2802)  labels_encoder_unscaled: 0.2714 (0.2714)  labels_decoder_unscaled: 0.5604 (0.5604)  time: 3.0229  data: 2.9586  max mem: 3702
Test:  [  50/1613]  eta: 0:04:12  loss: 0.6258 (0.9674)  labels_encoder: 0.3809 (0.6016)  labels_decoder: 0.2334 (0.3658)  labels_encoder_unscaled: 0.3809 (0.6016)  labels_decoder_unscaled: 0.4667 (0.7316)  time: 0.1010  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:24  loss: 0.1320 (0.8122)  labels_encoder: 0.0779 (0.5059)  labels_decoder: 0.0542 (0.3063)  labels_encoder_unscaled: 0.0779 (0.5059)  labels_decoder_unscaled: 0.1083 (0.6126)  time: 0.1120  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:04  loss: 0.7412 (0.7552)  labels_encoder: 0.4196 (0.4795)  labels_decoder: 0.1980 (0.2756)  labels_encoder_unscaled: 0.4196 (0.4795)  labels_decoder_unscaled: 0.3959 (0.5513)  time: 0.1011  data: 0.0002  max mem: 3702
Test:  [ 200/1613]  eta: 0:02:50  loss: 0.9541 (0.8317)  labels_encoder: 0.5987 (0.5343)  labels_decoder: 0.3543 (0.2974)  labels_encoder_unscaled: 0.5987 (0.5343)  labels_decoder_unscaled: 0.7087 (0.5948)  time: 0.1020  data: 0.0002  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:40  loss: 0.4680 (0.8728)  labels_encoder: 0.3305 (0.5619)  labels_decoder: 0.1438 (0.3109)  labels_encoder_unscaled: 0.3305 (0.5619)  labels_decoder_unscaled: 0.2875 (0.6218)  time: 0.1114  data: 0.0002  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:31  loss: 0.5288 (0.9150)  labels_encoder: 0.3066 (0.5863)  labels_decoder: 0.2016 (0.3287)  labels_encoder_unscaled: 0.3066 (0.5863)  labels_decoder_unscaled: 0.4032 (0.6574)  time: 0.1075  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:22  loss: 1.2567 (0.9284)  labels_encoder: 0.6101 (0.5884)  labels_decoder: 0.6133 (0.3400)  labels_encoder_unscaled: 0.6101 (0.5884)  labels_decoder_unscaled: 1.2267 (0.6800)  time: 0.0982  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:15  loss: 0.8439 (1.0763)  labels_encoder: 0.4562 (0.6833)  labels_decoder: 0.3674 (0.3930)  labels_encoder_unscaled: 0.4562 (0.6833)  labels_decoder_unscaled: 0.7349 (0.7860)  time: 0.1024  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:08  loss: 0.9107 (1.1512)  labels_encoder: 0.5719 (0.7321)  labels_decoder: 0.3443 (0.4191)  labels_encoder_unscaled: 0.5719 (0.7321)  labels_decoder_unscaled: 0.6886 (0.8381)  time: 0.1017  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:01  loss: 0.3203 (1.0956)  labels_encoder: 0.1549 (0.6956)  labels_decoder: 0.1693 (0.4000)  labels_encoder_unscaled: 0.1549 (0.6956)  labels_decoder_unscaled: 0.3386 (0.8001)  time: 0.0983  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:01:55  loss: 0.5074 (1.1041)  labels_encoder: 0.2852 (0.7013)  labels_decoder: 0.2000 (0.4028)  labels_encoder_unscaled: 0.2852 (0.7013)  labels_decoder_unscaled: 0.3999 (0.8056)  time: 0.1040  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:01:49  loss: 0.5181 (1.1311)  labels_encoder: 0.2671 (0.7276)  labels_decoder: 0.2511 (0.4035)  labels_encoder_unscaled: 0.2671 (0.7276)  labels_decoder_unscaled: 0.5021 (0.8070)  time: 0.1061  data: 0.0002  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:44  loss: 1.2817 (1.1298)  labels_encoder: 0.8910 (0.7231)  labels_decoder: 0.5304 (0.4067)  labels_encoder_unscaled: 0.8910 (0.7231)  labels_decoder_unscaled: 1.0608 (0.8134)  time: 0.1111  data: 0.0002  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:38  loss: 0.5955 (1.1026)  labels_encoder: 0.3128 (0.7037)  labels_decoder: 0.2709 (0.3990)  labels_encoder_unscaled: 0.3128 (0.7037)  labels_decoder_unscaled: 0.5419 (0.7979)  time: 0.1038  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:32  loss: 1.0831 (1.0908)  labels_encoder: 0.6114 (0.6935)  labels_decoder: 0.4433 (0.3973)  labels_encoder_unscaled: 0.6114 (0.6935)  labels_decoder_unscaled: 0.8865 (0.7945)  time: 0.0979  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:27  loss: 0.5403 (1.0664)  labels_encoder: 0.3003 (0.6770)  labels_decoder: 0.2192 (0.3894)  labels_encoder_unscaled: 0.3003 (0.6770)  labels_decoder_unscaled: 0.4385 (0.7788)  time: 0.1112  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:21  loss: 1.3366 (1.0716)  labels_encoder: 0.7894 (0.6773)  labels_decoder: 0.5154 (0.3943)  labels_encoder_unscaled: 0.7894 (0.6773)  labels_decoder_unscaled: 1.0308 (0.7885)  time: 0.1044  data: 0.0002  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:16  loss: 0.8690 (1.0879)  labels_encoder: 0.5427 (0.6873)  labels_decoder: 0.3263 (0.4006)  labels_encoder_unscaled: 0.5427 (0.6873)  labels_decoder_unscaled: 0.6526 (0.8013)  time: 0.0994  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:10  loss: 0.6889 (1.0718)  labels_encoder: 0.4274 (0.6762)  labels_decoder: 0.2512 (0.3955)  labels_encoder_unscaled: 0.4274 (0.6762)  labels_decoder_unscaled: 0.5024 (0.7910)  time: 0.1047  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:05  loss: 0.6418 (1.0656)  labels_encoder: 0.3240 (0.6699)  labels_decoder: 0.2138 (0.3958)  labels_encoder_unscaled: 0.3240 (0.6699)  labels_decoder_unscaled: 0.4276 (0.7915)  time: 0.1108  data: 0.0002  max mem: 3702
Test:  [1050/1613]  eta: 0:00:59  loss: 0.9106 (1.0572)  labels_encoder: 0.5224 (0.6652)  labels_decoder: 0.3461 (0.3920)  labels_encoder_unscaled: 0.5224 (0.6652)  labels_decoder_unscaled: 0.6921 (0.7840)  time: 0.1028  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:00:54  loss: 0.7376 (1.0499)  labels_encoder: 0.5008 (0.6611)  labels_decoder: 0.3027 (0.3888)  labels_encoder_unscaled: 0.5008 (0.6611)  labels_decoder_unscaled: 0.6054 (0.7776)  time: 0.1087  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:49  loss: 0.5452 (1.0447)  labels_encoder: 0.3908 (0.6572)  labels_decoder: 0.2057 (0.3875)  labels_encoder_unscaled: 0.3908 (0.6572)  labels_decoder_unscaled: 0.4114 (0.7750)  time: 0.1087  data: 0.0002  max mem: 3702
Test:  [1200/1613]  eta: 0:00:43  loss: 0.7108 (1.0498)  labels_encoder: 0.4007 (0.6592)  labels_decoder: 0.3101 (0.3906)  labels_encoder_unscaled: 0.4007 (0.6592)  labels_decoder_unscaled: 0.6202 (0.7811)  time: 0.1126  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:38  loss: 0.4217 (1.0482)  labels_encoder: 0.2840 (0.6573)  labels_decoder: 0.1887 (0.3909)  labels_encoder_unscaled: 0.2840 (0.6573)  labels_decoder_unscaled: 0.3773 (0.7818)  time: 0.1058  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:33  loss: 0.3452 (1.0323)  labels_encoder: 0.2259 (0.6468)  labels_decoder: 0.1648 (0.3855)  labels_encoder_unscaled: 0.2259 (0.6468)  labels_decoder_unscaled: 0.3296 (0.7709)  time: 0.1036  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:27  loss: 0.8064 (1.0417)  labels_encoder: 0.4513 (0.6527)  labels_decoder: 0.3365 (0.3890)  labels_encoder_unscaled: 0.4513 (0.6527)  labels_decoder_unscaled: 0.6731 (0.7780)  time: 0.1099  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:22  loss: 1.0983 (1.0392)  labels_encoder: 0.6867 (0.6508)  labels_decoder: 0.4343 (0.3884)  labels_encoder_unscaled: 0.6867 (0.6508)  labels_decoder_unscaled: 0.8685 (0.7767)  time: 0.1006  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:17  loss: 0.7823 (1.0581)  labels_encoder: 0.3406 (0.6631)  labels_decoder: 0.4055 (0.3950)  labels_encoder_unscaled: 0.3406 (0.6631)  labels_decoder_unscaled: 0.8111 (0.7899)  time: 0.1074  data: 0.0003  max mem: 3702
Test:  [1500/1613]  eta: 0:00:12  loss: 1.1682 (1.1018)  labels_encoder: 0.6304 (0.6906)  labels_decoder: 0.5401 (0.4112)  labels_encoder_unscaled: 0.6304 (0.6906)  labels_decoder_unscaled: 1.0803 (0.8225)  time: 0.1106  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6419 (1.0983)  labels_encoder: 0.4139 (0.6879)  labels_decoder: 0.2631 (0.4103)  labels_encoder_unscaled: 0.4139 (0.6879)  labels_decoder_unscaled: 0.5262 (0.8207)  time: 0.1165  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8717 (1.0941)  labels_encoder: 0.4757 (0.6845)  labels_decoder: 0.4306 (0.4096)  labels_encoder_unscaled: 0.4757 (0.6845)  labels_decoder_unscaled: 0.8613 (0.8192)  time: 0.1072  data: 0.0002  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8717 (1.0921)  labels_encoder: 0.4757 (0.6835)  labels_decoder: 0.4445 (0.4087)  labels_encoder_unscaled: 0.4757 (0.6835)  labels_decoder_unscaled: 0.8891 (0.8173)  time: 0.0830  data: 0.0001  max mem: 3702
Test: Total time: 0:02:53 (0.1073 s / it)
Averaged stats: loss: 0.8717 (1.0921)  labels_encoder: 0.4757 (0.6835)  labels_decoder: 0.4445 (0.4087)  labels_encoder_unscaled: 0.4757 (0.6835)  labels_decoder_unscaled: 0.8891 (0.8173)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.5643

dec_mAP all together: | 0.44180012651949657 |.
dec_mAP_pred | 0 : 0.4950805335051485 |.
dec_mAP_pred | 1 : 0.48441511408731097 |.
dec_mAP_pred | 2 : 0.4689499821128763 |.
dec_mAP_pred | 3 : 0.4523779860497442 |.
dec_mAP_pred | 4 : 0.4355573436742123 |.
dec_mAP_pred | 5 : 0.4193574397515768 |.
dec_mAP_pred | 6 : 0.4037363673994589 |.
dec_mAP_pred | 7 : 0.3899417044573763 |.
all decoder map: | 0.4437 |.
BaseballPitch: 0.1863
BasketballDunk: 0.7754
Billiards: 0.5097
CleanAndJerk: 0.7540
CliffDiving: 0.8282
CricketBowling: 0.3819
CricketShot: 0.2308
Diving: 0.6926
FrisbeeCatch: 0.3529
GolfSwing: 0.5184
HammerThrow: 0.8499
HighJump: 0.5737
JavelinThrow: 0.6920
LongJump: 0.7562
PoleVault: 0.8755
Shotput: 0.6783
SoccerPenalty: 0.2073
TennisSwing: 0.4750
ThrowDiscus: 0.6405
VolleyballSpiking: 0.3080
Epoch: [2]  [   0/1404]  eta: 1:21:20  lr: 0.000010  loss: 0.3613 (0.3613)  labels_encoder: 0.1814 (0.1814)  labels_decoder: 0.1799 (0.1799)  labels_encoder_unscaled: 0.1814 (0.1814)  labels_decoder_unscaled: 0.3597 (0.3597)  time: 3.4759  data: 3.2265  max mem: 3702
Epoch: [2]  [  50/1404]  eta: 0:06:12  lr: 0.000010  loss: 0.3080 (0.3213)  labels_encoder: 0.1607 (0.1758)  labels_decoder: 0.1355 (0.1455)  labels_encoder_unscaled: 0.1607 (0.1758)  labels_decoder_unscaled: 0.2711 (0.2910)  time: 0.1989  data: 0.0003  max mem: 3702
Epoch: [2]  [ 100/1404]  eta: 0:04:57  lr: 0.000010  loss: 0.2826 (0.3112)  labels_encoder: 0.1520 (0.1693)  labels_decoder: 0.1266 (0.1418)  labels_encoder_unscaled: 0.1520 (0.1693)  labels_decoder_unscaled: 0.2532 (0.2837)  time: 0.1783  data: 0.0003  max mem: 3702
Epoch: [2]  [ 150/1404]  eta: 0:04:30  lr: 0.000010  loss: 0.2710 (0.3059)  labels_encoder: 0.1316 (0.1655)  labels_decoder: 0.1267 (0.1404)  labels_encoder_unscaled: 0.1316 (0.1655)  labels_decoder_unscaled: 0.2535 (0.2807)  time: 0.1886  data: 0.0003  max mem: 3702
Epoch: [2]  [ 200/1404]  eta: 0:04:08  lr: 0.000010  loss: 0.2811 (0.3009)  labels_encoder: 0.1429 (0.1620)  labels_decoder: 0.1350 (0.1388)  labels_encoder_unscaled: 0.1429 (0.1620)  labels_decoder_unscaled: 0.2699 (0.2777)  time: 0.1760  data: 0.0003  max mem: 3702
Epoch: [2]  [ 250/1404]  eta: 0:03:53  lr: 0.000010  loss: 0.2971 (0.2958)  labels_encoder: 0.1405 (0.1584)  labels_decoder: 0.1307 (0.1374)  labels_encoder_unscaled: 0.1405 (0.1584)  labels_decoder_unscaled: 0.2614 (0.2747)  time: 0.1792  data: 0.0003  max mem: 3702
Epoch: [2]  [ 300/1404]  eta: 0:03:38  lr: 0.000010  loss: 0.2638 (0.2934)  labels_encoder: 0.1350 (0.1574)  labels_decoder: 0.1221 (0.1360)  labels_encoder_unscaled: 0.1350 (0.1574)  labels_decoder_unscaled: 0.2442 (0.2721)  time: 0.1831  data: 0.0003  max mem: 3702
Epoch: [2]  [ 350/1404]  eta: 0:03:27  lr: 0.000010  loss: 0.2863 (0.2928)  labels_encoder: 0.1594 (0.1572)  labels_decoder: 0.1317 (0.1356)  labels_encoder_unscaled: 0.1594 (0.1572)  labels_decoder_unscaled: 0.2634 (0.2712)  time: 0.1886  data: 0.0003  max mem: 3702
Epoch: [2]  [ 400/1404]  eta: 0:03:14  lr: 0.000010  loss: 0.2606 (0.2910)  labels_encoder: 0.1322 (0.1563)  labels_decoder: 0.1150 (0.1347)  labels_encoder_unscaled: 0.1322 (0.1563)  labels_decoder_unscaled: 0.2300 (0.2693)  time: 0.1754  data: 0.0003  max mem: 3702
Epoch: [2]  [ 450/1404]  eta: 0:03:03  lr: 0.000010  loss: 0.2666 (0.2891)  labels_encoder: 0.1428 (0.1553)  labels_decoder: 0.1205 (0.1338)  labels_encoder_unscaled: 0.1428 (0.1553)  labels_decoder_unscaled: 0.2409 (0.2677)  time: 0.1810  data: 0.0003  max mem: 3702
Epoch: [2]  [ 500/1404]  eta: 0:02:52  lr: 0.000010  loss: 0.2861 (0.2895)  labels_encoder: 0.1607 (0.1562)  labels_decoder: 0.1203 (0.1334)  labels_encoder_unscaled: 0.1607 (0.1562)  labels_decoder_unscaled: 0.2406 (0.2667)  time: 0.1792  data: 0.0004  max mem: 3702
Epoch: [2]  [ 550/1404]  eta: 0:02:42  lr: 0.000010  loss: 0.2463 (0.2881)  labels_encoder: 0.1247 (0.1555)  labels_decoder: 0.1233 (0.1326)  labels_encoder_unscaled: 0.1247 (0.1555)  labels_decoder_unscaled: 0.2467 (0.2651)  time: 0.1851  data: 0.0003  max mem: 3702
Epoch: [2]  [ 600/1404]  eta: 0:02:31  lr: 0.000010  loss: 0.2728 (0.2880)  labels_encoder: 0.1509 (0.1555)  labels_decoder: 0.1240 (0.1325)  labels_encoder_unscaled: 0.1509 (0.1555)  labels_decoder_unscaled: 0.2480 (0.2650)  time: 0.1709  data: 0.0003  max mem: 3702
Epoch: [2]  [ 650/1404]  eta: 0:02:21  lr: 0.000010  loss: 0.2595 (0.2870)  labels_encoder: 0.1416 (0.1549)  labels_decoder: 0.1277 (0.1321)  labels_encoder_unscaled: 0.1416 (0.1549)  labels_decoder_unscaled: 0.2554 (0.2642)  time: 0.1947  data: 0.0003  max mem: 3702
Epoch: [2]  [ 700/1404]  eta: 0:02:11  lr: 0.000010  loss: 0.2746 (0.2867)  labels_encoder: 0.1490 (0.1548)  labels_decoder: 0.1293 (0.1318)  labels_encoder_unscaled: 0.1490 (0.1548)  labels_decoder_unscaled: 0.2586 (0.2636)  time: 0.1831  data: 0.0003  max mem: 3702
Epoch: [2]  [ 750/1404]  eta: 0:02:02  lr: 0.000010  loss: 0.2749 (0.2855)  labels_encoder: 0.1421 (0.1539)  labels_decoder: 0.1226 (0.1316)  labels_encoder_unscaled: 0.1421 (0.1539)  labels_decoder_unscaled: 0.2452 (0.2632)  time: 0.1889  data: 0.0003  max mem: 3702
Epoch: [2]  [ 800/1404]  eta: 0:01:52  lr: 0.000010  loss: 0.2649 (0.2852)  labels_encoder: 0.1460 (0.1537)  labels_decoder: 0.1308 (0.1315)  labels_encoder_unscaled: 0.1460 (0.1537)  labels_decoder_unscaled: 0.2617 (0.2631)  time: 0.1724  data: 0.0003  max mem: 3702
Epoch: [2]  [ 850/1404]  eta: 0:01:42  lr: 0.000010  loss: 0.2731 (0.2841)  labels_encoder: 0.1361 (0.1529)  labels_decoder: 0.1211 (0.1311)  labels_encoder_unscaled: 0.1361 (0.1529)  labels_decoder_unscaled: 0.2423 (0.2622)  time: 0.1781  data: 0.0003  max mem: 3702
Epoch: [2]  [ 900/1404]  eta: 0:01:33  lr: 0.000010  loss: 0.2552 (0.2834)  labels_encoder: 0.1369 (0.1526)  labels_decoder: 0.1263 (0.1308)  labels_encoder_unscaled: 0.1369 (0.1526)  labels_decoder_unscaled: 0.2527 (0.2615)  time: 0.1749  data: 0.0003  max mem: 3702
Epoch: [2]  [ 950/1404]  eta: 0:01:23  lr: 0.000010  loss: 0.2789 (0.2829)  labels_encoder: 0.1437 (0.1522)  labels_decoder: 0.1314 (0.1306)  labels_encoder_unscaled: 0.1437 (0.1522)  labels_decoder_unscaled: 0.2629 (0.2613)  time: 0.1746  data: 0.0004  max mem: 3702
Epoch: [2]  [1000/1404]  eta: 0:01:14  lr: 0.000010  loss: 0.2810 (0.2826)  labels_encoder: 0.1498 (0.1521)  labels_decoder: 0.1274 (0.1304)  labels_encoder_unscaled: 0.1498 (0.1521)  labels_decoder_unscaled: 0.2547 (0.2609)  time: 0.1898  data: 0.0003  max mem: 3702
Epoch: [2]  [1050/1404]  eta: 0:01:05  lr: 0.000010  loss: 0.2511 (0.2817)  labels_encoder: 0.1314 (0.1514)  labels_decoder: 0.1232 (0.1303)  labels_encoder_unscaled: 0.1314 (0.1514)  labels_decoder_unscaled: 0.2464 (0.2605)  time: 0.1899  data: 0.0003  max mem: 3702
Epoch: [2]  [1100/1404]  eta: 0:00:56  lr: 0.000010  loss: 0.2558 (0.2816)  labels_encoder: 0.1371 (0.1515)  labels_decoder: 0.1175 (0.1302)  labels_encoder_unscaled: 0.1371 (0.1515)  labels_decoder_unscaled: 0.2350 (0.2603)  time: 0.1809  data: 0.0003  max mem: 3702
Epoch: [2]  [1150/1404]  eta: 0:00:46  lr: 0.000010  loss: 0.2772 (0.2814)  labels_encoder: 0.1415 (0.1515)  labels_decoder: 0.1231 (0.1299)  labels_encoder_unscaled: 0.1415 (0.1515)  labels_decoder_unscaled: 0.2462 (0.2599)  time: 0.1797  data: 0.0003  max mem: 3702
Epoch: [2]  [1200/1404]  eta: 0:00:37  lr: 0.000010  loss: 0.2583 (0.2802)  labels_encoder: 0.1325 (0.1507)  labels_decoder: 0.1221 (0.1295)  labels_encoder_unscaled: 0.1325 (0.1507)  labels_decoder_unscaled: 0.2442 (0.2590)  time: 0.1860  data: 0.0003  max mem: 3702
Epoch: [2]  [1250/1404]  eta: 0:00:28  lr: 0.000010  loss: 0.2755 (0.2800)  labels_encoder: 0.1409 (0.1506)  labels_decoder: 0.1234 (0.1294)  labels_encoder_unscaled: 0.1409 (0.1506)  labels_decoder_unscaled: 0.2468 (0.2589)  time: 0.1864  data: 0.0003  max mem: 3702
Epoch: [2]  [1300/1404]  eta: 0:00:19  lr: 0.000010  loss: 0.2480 (0.2791)  labels_encoder: 0.1330 (0.1501)  labels_decoder: 0.1143 (0.1290)  labels_encoder_unscaled: 0.1330 (0.1501)  labels_decoder_unscaled: 0.2287 (0.2581)  time: 0.1818  data: 0.0003  max mem: 3702
Epoch: [2]  [1350/1404]  eta: 0:00:09  lr: 0.000010  loss: 0.2478 (0.2782)  labels_encoder: 0.1352 (0.1494)  labels_decoder: 0.1207 (0.1288)  labels_encoder_unscaled: 0.1352 (0.1494)  labels_decoder_unscaled: 0.2413 (0.2575)  time: 0.1788  data: 0.0003  max mem: 3702
Epoch: [2]  [1400/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2564 (0.2773)  labels_encoder: 0.1296 (0.1488)  labels_decoder: 0.1201 (0.1285)  labels_encoder_unscaled: 0.1296 (0.1488)  labels_decoder_unscaled: 0.2401 (0.2570)  time: 0.1670  data: 0.0004  max mem: 3702
Epoch: [2]  [1403/1404]  eta: 0:00:00  lr: 0.000010  loss: 0.2564 (0.2773)  labels_encoder: 0.1269 (0.1488)  labels_decoder: 0.1264 (0.1285)  labels_encoder_unscaled: 0.1269 (0.1488)  labels_decoder_unscaled: 0.2528 (0.2570)  time: 0.1663  data: 0.0003  max mem: 3702
Epoch: [2] Total time: 0:04:18 (0.1843 s / it)
Averaged stats: lr: 0.000010  loss: 0.2564 (0.2773)  labels_encoder: 0.1269 (0.1488)  labels_decoder: 0.1264 (0.1285)  labels_encoder_unscaled: 0.1269 (0.1488)  labels_decoder_unscaled: 0.2528 (0.2570)
Test:  [   0/1613]  eta: 1:35:06  loss: 0.7294 (0.7294)  labels_encoder: 0.4241 (0.4241)  labels_decoder: 0.3053 (0.3053)  labels_encoder_unscaled: 0.4241 (0.4241)  labels_decoder_unscaled: 0.6107 (0.6107)  time: 3.5379  data: 3.4087  max mem: 3702
Test:  [  50/1613]  eta: 0:04:57  loss: 0.4362 (1.0222)  labels_encoder: 0.2271 (0.6488)  labels_decoder: 0.1764 (0.3734)  labels_encoder_unscaled: 0.2271 (0.6488)  labels_decoder_unscaled: 0.3527 (0.7468)  time: 0.1103  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:54  loss: 0.1471 (0.8057)  labels_encoder: 0.1168 (0.5179)  labels_decoder: 0.0304 (0.2878)  labels_encoder_unscaled: 0.1168 (0.5179)  labels_decoder_unscaled: 0.0607 (0.5756)  time: 0.1221  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:29  loss: 0.9646 (0.7851)  labels_encoder: 0.5855 (0.5058)  labels_decoder: 0.2394 (0.2793)  labels_encoder_unscaled: 0.5855 (0.5058)  labels_decoder_unscaled: 0.4788 (0.5586)  time: 0.1218  data: 0.0002  max mem: 3702
Test:  [ 200/1613]  eta: 0:03:11  loss: 0.9981 (0.9598)  labels_encoder: 0.5956 (0.6216)  labels_decoder: 0.4097 (0.3382)  labels_encoder_unscaled: 0.5956 (0.6216)  labels_decoder_unscaled: 0.8195 (0.6763)  time: 0.1158  data: 0.0002  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:57  loss: 0.6471 (1.0065)  labels_encoder: 0.3838 (0.6504)  labels_decoder: 0.2505 (0.3561)  labels_encoder_unscaled: 0.3838 (0.6504)  labels_decoder_unscaled: 0.5010 (0.7122)  time: 0.1091  data: 0.0002  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:48  loss: 0.6585 (1.0223)  labels_encoder: 0.3723 (0.6611)  labels_decoder: 0.2384 (0.3612)  labels_encoder_unscaled: 0.3723 (0.6611)  labels_decoder_unscaled: 0.4769 (0.7224)  time: 0.1251  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:40  loss: 1.3042 (1.0210)  labels_encoder: 0.8324 (0.6563)  labels_decoder: 0.4586 (0.3647)  labels_encoder_unscaled: 0.8324 (0.6563)  labels_decoder_unscaled: 0.9173 (0.7294)  time: 0.1173  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:32  loss: 0.7981 (1.1700)  labels_encoder: 0.5299 (0.7634)  labels_decoder: 0.3782 (0.4066)  labels_encoder_unscaled: 0.5299 (0.7634)  labels_decoder_unscaled: 0.7564 (0.8132)  time: 0.1269  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:25  loss: 0.9053 (1.2607)  labels_encoder: 0.6236 (0.8254)  labels_decoder: 0.3472 (0.4353)  labels_encoder_unscaled: 0.6236 (0.8254)  labels_decoder_unscaled: 0.6943 (0.8706)  time: 0.1219  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:17  loss: 0.3562 (1.1969)  labels_encoder: 0.1717 (0.7814)  labels_decoder: 0.1588 (0.4155)  labels_encoder_unscaled: 0.1717 (0.7814)  labels_decoder_unscaled: 0.3176 (0.8310)  time: 0.1146  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:02:10  loss: 0.5722 (1.1916)  labels_encoder: 0.3484 (0.7790)  labels_decoder: 0.1972 (0.4126)  labels_encoder_unscaled: 0.3484 (0.7790)  labels_decoder_unscaled: 0.3943 (0.8252)  time: 0.1265  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:02:04  loss: 0.6271 (1.2399)  labels_encoder: 0.3572 (0.8239)  labels_decoder: 0.2956 (0.4160)  labels_encoder_unscaled: 0.3572 (0.8239)  labels_decoder_unscaled: 0.5913 (0.8319)  time: 0.1128  data: 0.0002  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:57  loss: 0.9165 (1.2197)  labels_encoder: 0.4854 (0.8054)  labels_decoder: 0.4355 (0.4143)  labels_encoder_unscaled: 0.4854 (0.8054)  labels_decoder_unscaled: 0.8710 (0.8285)  time: 0.1122  data: 0.0019  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:50  loss: 0.5770 (1.1884)  labels_encoder: 0.3637 (0.7830)  labels_decoder: 0.2419 (0.4054)  labels_encoder_unscaled: 0.3637 (0.7830)  labels_decoder_unscaled: 0.4838 (0.8108)  time: 0.1262  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:44  loss: 0.9864 (1.1702)  labels_encoder: 0.5466 (0.7685)  labels_decoder: 0.4069 (0.4018)  labels_encoder_unscaled: 0.5466 (0.7685)  labels_decoder_unscaled: 0.8137 (0.8036)  time: 0.1209  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:38  loss: 0.7082 (1.1555)  labels_encoder: 0.4055 (0.7585)  labels_decoder: 0.3367 (0.3970)  labels_encoder_unscaled: 0.4055 (0.7585)  labels_decoder_unscaled: 0.6735 (0.7939)  time: 0.1212  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:31  loss: 1.1204 (1.1486)  labels_encoder: 0.7878 (0.7510)  labels_decoder: 0.4281 (0.3976)  labels_encoder_unscaled: 0.7878 (0.7510)  labels_decoder_unscaled: 0.8563 (0.7952)  time: 0.1122  data: 0.0020  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:25  loss: 0.8766 (1.1616)  labels_encoder: 0.5514 (0.7590)  labels_decoder: 0.3044 (0.4026)  labels_encoder_unscaled: 0.5514 (0.7590)  labels_decoder_unscaled: 0.6087 (0.8052)  time: 0.1064  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:18  loss: 1.0450 (1.1520)  labels_encoder: 0.7273 (0.7533)  labels_decoder: 0.3518 (0.3987)  labels_encoder_unscaled: 0.7273 (0.7533)  labels_decoder_unscaled: 0.7036 (0.7973)  time: 0.1074  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:12  loss: 0.6414 (1.1402)  labels_encoder: 0.3892 (0.7448)  labels_decoder: 0.2358 (0.3953)  labels_encoder_unscaled: 0.3892 (0.7448)  labels_decoder_unscaled: 0.4716 (0.7907)  time: 0.0986  data: 0.0016  max mem: 3702
Test:  [1050/1613]  eta: 0:01:06  loss: 0.8411 (1.1330)  labels_encoder: 0.5045 (0.7398)  labels_decoder: 0.3331 (0.3931)  labels_encoder_unscaled: 0.5045 (0.7398)  labels_decoder_unscaled: 0.6662 (0.7863)  time: 0.1056  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:01:00  loss: 0.8308 (1.1333)  labels_encoder: 0.5791 (0.7409)  labels_decoder: 0.2896 (0.3924)  labels_encoder_unscaled: 0.5791 (0.7409)  labels_decoder_unscaled: 0.5791 (0.7848)  time: 0.1085  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:54  loss: 0.5513 (1.1219)  labels_encoder: 0.3568 (0.7332)  labels_decoder: 0.1945 (0.3887)  labels_encoder_unscaled: 0.3568 (0.7332)  labels_decoder_unscaled: 0.3891 (0.7774)  time: 0.1100  data: 0.0002  max mem: 3702
Test:  [1200/1613]  eta: 0:00:48  loss: 0.5589 (1.1250)  labels_encoder: 0.3302 (0.7339)  labels_decoder: 0.2403 (0.3911)  labels_encoder_unscaled: 0.3302 (0.7339)  labels_decoder_unscaled: 0.4806 (0.7822)  time: 0.1185  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:42  loss: 0.4281 (1.1229)  labels_encoder: 0.2542 (0.7318)  labels_decoder: 0.1738 (0.3910)  labels_encoder_unscaled: 0.2542 (0.7318)  labels_decoder_unscaled: 0.3476 (0.7820)  time: 0.1116  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:36  loss: 0.7087 (1.1167)  labels_encoder: 0.3726 (0.7270)  labels_decoder: 0.2664 (0.3897)  labels_encoder_unscaled: 0.3726 (0.7270)  labels_decoder_unscaled: 0.5329 (0.7794)  time: 0.1120  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:30  loss: 0.9927 (1.1308)  labels_encoder: 0.5347 (0.7364)  labels_decoder: 0.4346 (0.3944)  labels_encoder_unscaled: 0.5347 (0.7364)  labels_decoder_unscaled: 0.8692 (0.7887)  time: 0.1073  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:24  loss: 1.1665 (1.1243)  labels_encoder: 0.7484 (0.7321)  labels_decoder: 0.4089 (0.3922)  labels_encoder_unscaled: 0.7484 (0.7321)  labels_decoder_unscaled: 0.8179 (0.7844)  time: 0.1174  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:18  loss: 0.6240 (1.1405)  labels_encoder: 0.4035 (0.7426)  labels_decoder: 0.3606 (0.3979)  labels_encoder_unscaled: 0.4035 (0.7426)  labels_decoder_unscaled: 0.7212 (0.7958)  time: 0.1091  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:13  loss: 0.7501 (1.1666)  labels_encoder: 0.5217 (0.7618)  labels_decoder: 0.3186 (0.4049)  labels_encoder_unscaled: 0.5217 (0.7618)  labels_decoder_unscaled: 0.6372 (0.8097)  time: 0.1189  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:07  loss: 0.6952 (1.1610)  labels_encoder: 0.3987 (0.7584)  labels_decoder: 0.2617 (0.4026)  labels_encoder_unscaled: 0.3987 (0.7584)  labels_decoder_unscaled: 0.5234 (0.8052)  time: 0.1040  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 1.0278 (1.1554)  labels_encoder: 0.5808 (0.7540)  labels_decoder: 0.4470 (0.4014)  labels_encoder_unscaled: 0.5808 (0.7540)  labels_decoder_unscaled: 0.8941 (0.8027)  time: 0.1047  data: 0.0001  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8201 (1.1534)  labels_encoder: 0.4652 (0.7530)  labels_decoder: 0.3549 (0.4004)  labels_encoder_unscaled: 0.4652 (0.7530)  labels_decoder_unscaled: 0.7098 (0.8009)  time: 0.0829  data: 0.0001  max mem: 3702
Test: Total time: 0:03:07 (0.1163 s / it)
Averaged stats: loss: 0.8201 (1.1534)  labels_encoder: 0.4652 (0.7530)  labels_decoder: 0.3549 (0.4004)  labels_encoder_unscaled: 0.4652 (0.7530)  labels_decoder_unscaled: 0.7098 (0.8009)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5771

dec_mAP all together: | 0.4573467749590363 |.
dec_mAP_pred | 0 : 0.5039872356568867 |.
dec_mAP_pred | 1 : 0.4952164521481183 |.
dec_mAP_pred | 2 : 0.4820430213658974 |.
dec_mAP_pred | 3 : 0.46766518102513377 |.
dec_mAP_pred | 4 : 0.4523569890015458 |.
dec_mAP_pred | 5 : 0.43737423246308643 |.
dec_mAP_pred | 6 : 0.42272364975566895 |.
dec_mAP_pred | 7 : 0.4096285362161522 |.
all decoder map: | 0.4589 |.
BaseballPitch: 0.1431
BasketballDunk: 0.7739
Billiards: 0.4770
CleanAndJerk: 0.7553
CliffDiving: 0.8058
CricketBowling: 0.4385
CricketShot: 0.2243
Diving: 0.6809
FrisbeeCatch: 0.3403
GolfSwing: 0.6335
HammerThrow: 0.8506
HighJump: 0.6030
JavelinThrow: 0.6877
LongJump: 0.7627
PoleVault: 0.8717
Shotput: 0.6852
SoccerPenalty: 0.2988
TennisSwing: 0.5765
ThrowDiscus: 0.5980
VolleyballSpiking: 0.3353
Epoch: [3]  [   0/1404]  eta: 1:27:08  lr: 0.000001  loss: 0.2417 (0.2417)  labels_encoder: 0.0919 (0.0919)  labels_decoder: 0.1498 (0.1498)  labels_encoder_unscaled: 0.0919 (0.0919)  labels_decoder_unscaled: 0.2995 (0.2995)  time: 3.7238  data: 3.4627  max mem: 3702
Epoch: [3]  [  50/1404]  eta: 0:05:49  lr: 0.000001  loss: 0.2434 (0.2503)  labels_encoder: 0.1251 (0.1312)  labels_decoder: 0.1198 (0.1191)  labels_encoder_unscaled: 0.1251 (0.1312)  labels_decoder_unscaled: 0.2396 (0.2381)  time: 0.1826  data: 0.0003  max mem: 3702
Epoch: [3]  [ 100/1404]  eta: 0:04:53  lr: 0.000001  loss: 0.2411 (0.2510)  labels_encoder: 0.1244 (0.1326)  labels_decoder: 0.1207 (0.1184)  labels_encoder_unscaled: 0.1244 (0.1326)  labels_decoder_unscaled: 0.2413 (0.2368)  time: 0.1944  data: 0.0003  max mem: 3702
Epoch: [3]  [ 150/1404]  eta: 0:04:22  lr: 0.000001  loss: 0.2581 (0.2524)  labels_encoder: 0.1333 (0.1329)  labels_decoder: 0.1148 (0.1194)  labels_encoder_unscaled: 0.1333 (0.1329)  labels_decoder_unscaled: 0.2296 (0.2389)  time: 0.1757  data: 0.0003  max mem: 3702
Epoch: [3]  [ 200/1404]  eta: 0:04:04  lr: 0.000001  loss: 0.2598 (0.2513)  labels_encoder: 0.1366 (0.1320)  labels_decoder: 0.1250 (0.1193)  labels_encoder_unscaled: 0.1366 (0.1320)  labels_decoder_unscaled: 0.2501 (0.2387)  time: 0.1914  data: 0.0003  max mem: 3702
Epoch: [3]  [ 250/1404]  eta: 0:03:47  lr: 0.000001  loss: 0.2338 (0.2523)  labels_encoder: 0.1260 (0.1324)  labels_decoder: 0.1176 (0.1199)  labels_encoder_unscaled: 0.1260 (0.1324)  labels_decoder_unscaled: 0.2352 (0.2399)  time: 0.1758  data: 0.0003  max mem: 3702
Epoch: [3]  [ 300/1404]  eta: 0:03:34  lr: 0.000001  loss: 0.2377 (0.2513)  labels_encoder: 0.1207 (0.1316)  labels_decoder: 0.1169 (0.1197)  labels_encoder_unscaled: 0.1207 (0.1316)  labels_decoder_unscaled: 0.2337 (0.2393)  time: 0.1834  data: 0.0003  max mem: 3702
Epoch: [3]  [ 350/1404]  eta: 0:03:23  lr: 0.000001  loss: 0.2400 (0.2506)  labels_encoder: 0.1312 (0.1314)  labels_decoder: 0.1126 (0.1191)  labels_encoder_unscaled: 0.1312 (0.1314)  labels_decoder_unscaled: 0.2253 (0.2383)  time: 0.1924  data: 0.0003  max mem: 3702
Epoch: [3]  [ 400/1404]  eta: 0:03:11  lr: 0.000001  loss: 0.2874 (0.2516)  labels_encoder: 0.1564 (0.1324)  labels_decoder: 0.1237 (0.1191)  labels_encoder_unscaled: 0.1564 (0.1324)  labels_decoder_unscaled: 0.2474 (0.2383)  time: 0.1788  data: 0.0003  max mem: 3702
Epoch: [3]  [ 450/1404]  eta: 0:03:01  lr: 0.000001  loss: 0.2518 (0.2501)  labels_encoder: 0.1361 (0.1313)  labels_decoder: 0.1149 (0.1187)  labels_encoder_unscaled: 0.1361 (0.1313)  labels_decoder_unscaled: 0.2299 (0.2375)  time: 0.1988  data: 0.0003  max mem: 3702
Epoch: [3]  [ 500/1404]  eta: 0:02:51  lr: 0.000001  loss: 0.2333 (0.2486)  labels_encoder: 0.1275 (0.1302)  labels_decoder: 0.1178 (0.1184)  labels_encoder_unscaled: 0.1275 (0.1302)  labels_decoder_unscaled: 0.2357 (0.2369)  time: 0.1841  data: 0.0003  max mem: 3702
Epoch: [3]  [ 550/1404]  eta: 0:02:40  lr: 0.000001  loss: 0.2205 (0.2481)  labels_encoder: 0.1171 (0.1299)  labels_decoder: 0.1074 (0.1182)  labels_encoder_unscaled: 0.1171 (0.1299)  labels_decoder_unscaled: 0.2147 (0.2363)  time: 0.1739  data: 0.0003  max mem: 3702
Epoch: [3]  [ 600/1404]  eta: 0:02:30  lr: 0.000001  loss: 0.2299 (0.2471)  labels_encoder: 0.1183 (0.1293)  labels_decoder: 0.1131 (0.1179)  labels_encoder_unscaled: 0.1183 (0.1293)  labels_decoder_unscaled: 0.2262 (0.2357)  time: 0.1805  data: 0.0003  max mem: 3702
Epoch: [3]  [ 650/1404]  eta: 0:02:20  lr: 0.000001  loss: 0.2425 (0.2469)  labels_encoder: 0.1274 (0.1288)  labels_decoder: 0.1204 (0.1181)  labels_encoder_unscaled: 0.1274 (0.1288)  labels_decoder_unscaled: 0.2408 (0.2362)  time: 0.1755  data: 0.0003  max mem: 3702
Epoch: [3]  [ 700/1404]  eta: 0:02:10  lr: 0.000001  loss: 0.2241 (0.2458)  labels_encoder: 0.1145 (0.1281)  labels_decoder: 0.1123 (0.1178)  labels_encoder_unscaled: 0.1145 (0.1281)  labels_decoder_unscaled: 0.2246 (0.2355)  time: 0.1744  data: 0.0003  max mem: 3702
Epoch: [3]  [ 750/1404]  eta: 0:02:00  lr: 0.000001  loss: 0.2277 (0.2457)  labels_encoder: 0.1173 (0.1281)  labels_decoder: 0.1124 (0.1176)  labels_encoder_unscaled: 0.1173 (0.1281)  labels_decoder_unscaled: 0.2247 (0.2352)  time: 0.1799  data: 0.0003  max mem: 3702
Epoch: [3]  [ 800/1404]  eta: 0:01:51  lr: 0.000001  loss: 0.2351 (0.2456)  labels_encoder: 0.1177 (0.1280)  labels_decoder: 0.1175 (0.1176)  labels_encoder_unscaled: 0.1177 (0.1280)  labels_decoder_unscaled: 0.2350 (0.2352)  time: 0.1726  data: 0.0003  max mem: 3702
Epoch: [3]  [ 850/1404]  eta: 0:01:41  lr: 0.000001  loss: 0.2288 (0.2454)  labels_encoder: 0.1132 (0.1277)  labels_decoder: 0.1178 (0.1177)  labels_encoder_unscaled: 0.1132 (0.1277)  labels_decoder_unscaled: 0.2357 (0.2354)  time: 0.1790  data: 0.0003  max mem: 3702
Epoch: [3]  [ 900/1404]  eta: 0:01:32  lr: 0.000001  loss: 0.2720 (0.2460)  labels_encoder: 0.1452 (0.1282)  labels_decoder: 0.1221 (0.1178)  labels_encoder_unscaled: 0.1452 (0.1282)  labels_decoder_unscaled: 0.2443 (0.2356)  time: 0.1824  data: 0.0003  max mem: 3702
Epoch: [3]  [ 950/1404]  eta: 0:01:23  lr: 0.000001  loss: 0.2380 (0.2461)  labels_encoder: 0.1217 (0.1281)  labels_decoder: 0.1129 (0.1179)  labels_encoder_unscaled: 0.1217 (0.1281)  labels_decoder_unscaled: 0.2259 (0.2359)  time: 0.1682  data: 0.0003  max mem: 3702
Epoch: [3]  [1000/1404]  eta: 0:01:14  lr: 0.000001  loss: 0.2436 (0.2462)  labels_encoder: 0.1232 (0.1281)  labels_decoder: 0.1214 (0.1181)  labels_encoder_unscaled: 0.1232 (0.1281)  labels_decoder_unscaled: 0.2428 (0.2361)  time: 0.1787  data: 0.0003  max mem: 3702
Epoch: [3]  [1050/1404]  eta: 0:01:04  lr: 0.000001  loss: 0.2484 (0.2464)  labels_encoder: 0.1241 (0.1284)  labels_decoder: 0.1151 (0.1180)  labels_encoder_unscaled: 0.1241 (0.1284)  labels_decoder_unscaled: 0.2301 (0.2360)  time: 0.1945  data: 0.0003  max mem: 3702
Epoch: [3]  [1100/1404]  eta: 0:00:55  lr: 0.000001  loss: 0.2322 (0.2462)  labels_encoder: 0.1180 (0.1283)  labels_decoder: 0.1129 (0.1179)  labels_encoder_unscaled: 0.1180 (0.1283)  labels_decoder_unscaled: 0.2259 (0.2359)  time: 0.1836  data: 0.0003  max mem: 3702
Epoch: [3]  [1150/1404]  eta: 0:00:46  lr: 0.000001  loss: 0.2224 (0.2458)  labels_encoder: 0.1228 (0.1281)  labels_decoder: 0.1123 (0.1178)  labels_encoder_unscaled: 0.1228 (0.1281)  labels_decoder_unscaled: 0.2246 (0.2355)  time: 0.1840  data: 0.0003  max mem: 3702
Epoch: [3]  [1200/1404]  eta: 0:00:37  lr: 0.000001  loss: 0.2178 (0.2454)  labels_encoder: 0.1065 (0.1277)  labels_decoder: 0.1090 (0.1177)  labels_encoder_unscaled: 0.1065 (0.1277)  labels_decoder_unscaled: 0.2179 (0.2354)  time: 0.1914  data: 0.0003  max mem: 3702
Epoch: [3]  [1250/1404]  eta: 0:00:28  lr: 0.000001  loss: 0.2162 (0.2450)  labels_encoder: 0.1071 (0.1273)  labels_decoder: 0.1156 (0.1177)  labels_encoder_unscaled: 0.1071 (0.1273)  labels_decoder_unscaled: 0.2313 (0.2354)  time: 0.1869  data: 0.0003  max mem: 3702
Epoch: [3]  [1300/1404]  eta: 0:00:19  lr: 0.000001  loss: 0.2279 (0.2445)  labels_encoder: 0.1165 (0.1270)  labels_decoder: 0.1082 (0.1175)  labels_encoder_unscaled: 0.1165 (0.1270)  labels_decoder_unscaled: 0.2164 (0.2351)  time: 0.1834  data: 0.0003  max mem: 3702
Epoch: [3]  [1350/1404]  eta: 0:00:09  lr: 0.000001  loss: 0.2311 (0.2443)  labels_encoder: 0.1155 (0.1268)  labels_decoder: 0.1135 (0.1175)  labels_encoder_unscaled: 0.1155 (0.1268)  labels_decoder_unscaled: 0.2269 (0.2350)  time: 0.1919  data: 0.0003  max mem: 3702
Epoch: [3]  [1400/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2234 (0.2442)  labels_encoder: 0.1080 (0.1267)  labels_decoder: 0.1071 (0.1174)  labels_encoder_unscaled: 0.1080 (0.1267)  labels_decoder_unscaled: 0.2142 (0.2349)  time: 0.1801  data: 0.0003  max mem: 3702
Epoch: [3]  [1403/1404]  eta: 0:00:00  lr: 0.000001  loss: 0.2234 (0.2442)  labels_encoder: 0.1076 (0.1267)  labels_decoder: 0.1186 (0.1175)  labels_encoder_unscaled: 0.1076 (0.1267)  labels_decoder_unscaled: 0.2372 (0.2349)  time: 0.1702  data: 0.0003  max mem: 3702
Epoch: [3] Total time: 0:04:19 (0.1845 s / it)
Averaged stats: lr: 0.000001  loss: 0.2234 (0.2442)  labels_encoder: 0.1076 (0.1267)  labels_decoder: 0.1186 (0.1175)  labels_encoder_unscaled: 0.1076 (0.1267)  labels_decoder_unscaled: 0.2372 (0.2349)
Test:  [   0/1613]  eta: 1:45:08  loss: 0.7809 (0.7809)  labels_encoder: 0.4687 (0.4687)  labels_decoder: 0.3121 (0.3121)  labels_encoder_unscaled: 0.4687 (0.4687)  labels_decoder_unscaled: 0.6243 (0.6243)  time: 3.9108  data: 3.7766  max mem: 3702
Test:  [  50/1613]  eta: 0:05:11  loss: 0.4349 (1.0110)  labels_encoder: 0.2393 (0.6378)  labels_decoder: 0.1835 (0.3731)  labels_encoder_unscaled: 0.2393 (0.6378)  labels_decoder_unscaled: 0.3669 (0.7463)  time: 0.1194  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:58  loss: 0.1465 (0.7995)  labels_encoder: 0.1099 (0.5108)  labels_decoder: 0.0366 (0.2886)  labels_encoder_unscaled: 0.1099 (0.5108)  labels_decoder_unscaled: 0.0732 (0.5773)  time: 0.1074  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:29  loss: 0.9760 (0.7876)  labels_encoder: 0.6574 (0.5055)  labels_decoder: 0.2956 (0.2821)  labels_encoder_unscaled: 0.6574 (0.5055)  labels_decoder_unscaled: 0.5913 (0.5642)  time: 0.1179  data: 0.0002  max mem: 3702
Test:  [ 200/1613]  eta: 0:03:13  loss: 1.0280 (0.9691)  labels_encoder: 0.6037 (0.6239)  labels_decoder: 0.4098 (0.3452)  labels_encoder_unscaled: 0.6037 (0.6239)  labels_decoder_unscaled: 0.8197 (0.6904)  time: 0.1142  data: 0.0002  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:59  loss: 0.4981 (1.0144)  labels_encoder: 0.3084 (0.6510)  labels_decoder: 0.2352 (0.3634)  labels_encoder_unscaled: 0.3084 (0.6510)  labels_decoder_unscaled: 0.4704 (0.7268)  time: 0.1054  data: 0.0002  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:48  loss: 0.6540 (1.0274)  labels_encoder: 0.3788 (0.6606)  labels_decoder: 0.2323 (0.3668)  labels_encoder_unscaled: 0.3788 (0.6606)  labels_decoder_unscaled: 0.4646 (0.7336)  time: 0.1110  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:39  loss: 1.1731 (1.0215)  labels_encoder: 0.7159 (0.6517)  labels_decoder: 0.4817 (0.3698)  labels_encoder_unscaled: 0.7159 (0.6517)  labels_decoder_unscaled: 0.9634 (0.7396)  time: 0.1159  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:32  loss: 0.7886 (1.1395)  labels_encoder: 0.4685 (0.7364)  labels_decoder: 0.3730 (0.4031)  labels_encoder_unscaled: 0.4685 (0.7364)  labels_decoder_unscaled: 0.7460 (0.8063)  time: 0.1223  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:24  loss: 0.9947 (1.2319)  labels_encoder: 0.6262 (0.8001)  labels_decoder: 0.3610 (0.4318)  labels_encoder_unscaled: 0.6262 (0.8001)  labels_decoder_unscaled: 0.7220 (0.8637)  time: 0.1178  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:18  loss: 0.3726 (1.1726)  labels_encoder: 0.1773 (0.7598)  labels_decoder: 0.1677 (0.4128)  labels_encoder_unscaled: 0.1773 (0.7598)  labels_decoder_unscaled: 0.3353 (0.8256)  time: 0.1184  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:02:11  loss: 0.6006 (1.1666)  labels_encoder: 0.3983 (0.7562)  labels_decoder: 0.1985 (0.4104)  labels_encoder_unscaled: 0.3983 (0.7562)  labels_decoder_unscaled: 0.3970 (0.8208)  time: 0.1252  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:02:05  loss: 0.9350 (1.2158)  labels_encoder: 0.5028 (0.8015)  labels_decoder: 0.4527 (0.4143)  labels_encoder_unscaled: 0.5028 (0.8015)  labels_decoder_unscaled: 0.9054 (0.8286)  time: 0.1234  data: 0.0002  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:57  loss: 0.8688 (1.1949)  labels_encoder: 0.4892 (0.7836)  labels_decoder: 0.3726 (0.4113)  labels_encoder_unscaled: 0.4892 (0.7836)  labels_decoder_unscaled: 0.7452 (0.8226)  time: 0.1060  data: 0.0002  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:51  loss: 0.5609 (1.1647)  labels_encoder: 0.3366 (0.7623)  labels_decoder: 0.2252 (0.4024)  labels_encoder_unscaled: 0.3366 (0.7623)  labels_decoder_unscaled: 0.4503 (0.8048)  time: 0.1270  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:45  loss: 0.9169 (1.1466)  labels_encoder: 0.5774 (0.7486)  labels_decoder: 0.3696 (0.3980)  labels_encoder_unscaled: 0.5774 (0.7486)  labels_decoder_unscaled: 0.7391 (0.7960)  time: 0.1230  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:39  loss: 0.6498 (1.1361)  labels_encoder: 0.4361 (0.7419)  labels_decoder: 0.2934 (0.3942)  labels_encoder_unscaled: 0.4361 (0.7419)  labels_decoder_unscaled: 0.5868 (0.7884)  time: 0.1250  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:32  loss: 1.2064 (1.1323)  labels_encoder: 0.8925 (0.7367)  labels_decoder: 0.4665 (0.3956)  labels_encoder_unscaled: 0.8925 (0.7367)  labels_decoder_unscaled: 0.9329 (0.7913)  time: 0.1120  data: 0.0002  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:26  loss: 0.8633 (1.1504)  labels_encoder: 0.4926 (0.7493)  labels_decoder: 0.3083 (0.4011)  labels_encoder_unscaled: 0.4926 (0.7493)  labels_decoder_unscaled: 0.6166 (0.8023)  time: 0.1146  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:20  loss: 1.0588 (1.1401)  labels_encoder: 0.6890 (0.7421)  labels_decoder: 0.3538 (0.3980)  labels_encoder_unscaled: 0.6890 (0.7421)  labels_decoder_unscaled: 0.7076 (0.7960)  time: 0.1273  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:14  loss: 0.6275 (1.1283)  labels_encoder: 0.4024 (0.7335)  labels_decoder: 0.2295 (0.3947)  labels_encoder_unscaled: 0.4024 (0.7335)  labels_decoder_unscaled: 0.4590 (0.7895)  time: 0.1155  data: 0.0002  max mem: 3702
Test:  [1050/1613]  eta: 0:01:07  loss: 0.8550 (1.1211)  labels_encoder: 0.4937 (0.7285)  labels_decoder: 0.3302 (0.3926)  labels_encoder_unscaled: 0.4937 (0.7285)  labels_decoder_unscaled: 0.6605 (0.7852)  time: 0.1040  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:01:01  loss: 0.6443 (1.1273)  labels_encoder: 0.4540 (0.7336)  labels_decoder: 0.3149 (0.3938)  labels_encoder_unscaled: 0.4540 (0.7336)  labels_decoder_unscaled: 0.6298 (0.7876)  time: 0.1097  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:55  loss: 0.5684 (1.1144)  labels_encoder: 0.3337 (0.7248)  labels_decoder: 0.2351 (0.3896)  labels_encoder_unscaled: 0.3337 (0.7248)  labels_decoder_unscaled: 0.4701 (0.7793)  time: 0.0987  data: 0.0002  max mem: 3702
Test:  [1200/1613]  eta: 0:00:48  loss: 0.5414 (1.1179)  labels_encoder: 0.3048 (0.7263)  labels_decoder: 0.2081 (0.3915)  labels_encoder_unscaled: 0.3048 (0.7263)  labels_decoder_unscaled: 0.4161 (0.7831)  time: 0.1042  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:42  loss: 0.4057 (1.1172)  labels_encoder: 0.2151 (0.7254)  labels_decoder: 0.1633 (0.3918)  labels_encoder_unscaled: 0.2151 (0.7254)  labels_decoder_unscaled: 0.3267 (0.7836)  time: 0.1056  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:36  loss: 0.8432 (1.1111)  labels_encoder: 0.5174 (0.7207)  labels_decoder: 0.2712 (0.3905)  labels_encoder_unscaled: 0.5174 (0.7207)  labels_decoder_unscaled: 0.5423 (0.7810)  time: 0.1157  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:30  loss: 0.8880 (1.1264)  labels_encoder: 0.5376 (0.7310)  labels_decoder: 0.4022 (0.3953)  labels_encoder_unscaled: 0.5376 (0.7310)  labels_decoder_unscaled: 0.8044 (0.7906)  time: 0.1077  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:24  loss: 1.0922 (1.1189)  labels_encoder: 0.6792 (0.7260)  labels_decoder: 0.3823 (0.3929)  labels_encoder_unscaled: 0.6792 (0.7260)  labels_decoder_unscaled: 0.7646 (0.7858)  time: 0.1017  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:19  loss: 0.6813 (1.1338)  labels_encoder: 0.4613 (0.7357)  labels_decoder: 0.3840 (0.3981)  labels_encoder_unscaled: 0.4613 (0.7357)  labels_decoder_unscaled: 0.7680 (0.7962)  time: 0.1054  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:13  loss: 0.6410 (1.1502)  labels_encoder: 0.4352 (0.7481)  labels_decoder: 0.2303 (0.4021)  labels_encoder_unscaled: 0.4352 (0.7481)  labels_decoder_unscaled: 0.4606 (0.8042)  time: 0.1173  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:07  loss: 0.7257 (1.1447)  labels_encoder: 0.4298 (0.7446)  labels_decoder: 0.2539 (0.4001)  labels_encoder_unscaled: 0.4298 (0.7446)  labels_decoder_unscaled: 0.5078 (0.8001)  time: 0.1145  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8990 (1.1402)  labels_encoder: 0.5353 (0.7411)  labels_decoder: 0.4070 (0.3990)  labels_encoder_unscaled: 0.5353 (0.7411)  labels_decoder_unscaled: 0.8140 (0.7981)  time: 0.1040  data: 0.0002  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6631 (1.1381)  labels_encoder: 0.3923 (0.7401)  labels_decoder: 0.2812 (0.3980)  labels_encoder_unscaled: 0.3923 (0.7401)  labels_decoder_unscaled: 0.5625 (0.7960)  time: 0.0779  data: 0.0001  max mem: 3702
Test: Total time: 0:03:08 (0.1166 s / it)
Averaged stats: loss: 0.6631 (1.1381)  labels_encoder: 0.3923 (0.7401)  labels_decoder: 0.2812 (0.3980)  labels_encoder_unscaled: 0.3923 (0.7401)  labels_decoder_unscaled: 0.5625 (0.7960)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5769

dec_mAP all together: | 0.45585859470409656 |.
dec_mAP_pred | 0 : 0.5009985029028557 |.
dec_mAP_pred | 1 : 0.4927751554843522 |.
dec_mAP_pred | 2 : 0.4801128425970762 |.
dec_mAP_pred | 3 : 0.4661369761368678 |.
dec_mAP_pred | 4 : 0.4511077300592272 |.
dec_mAP_pred | 5 : 0.43634831902676935 |.
dec_mAP_pred | 6 : 0.4218708985861097 |.
dec_mAP_pred | 7 : 0.4089097687075133 |.
all decoder map: | 0.4573 |.
BaseballPitch: 0.1484
BasketballDunk: 0.7746
Billiards: 0.4812
CleanAndJerk: 0.7502
CliffDiving: 0.8018
CricketBowling: 0.4312
CricketShot: 0.2303
Diving: 0.6810
FrisbeeCatch: 0.3277
GolfSwing: 0.6233
HammerThrow: 0.8479
HighJump: 0.6104
JavelinThrow: 0.6901
LongJump: 0.7669
PoleVault: 0.8675
Shotput: 0.6855
SoccerPenalty: 0.2894
TennisSwing: 0.5789
ThrowDiscus: 0.6165
VolleyballSpiking: 0.3347
Epoch: [4]  [   0/1404]  eta: 1:19:57  lr: 0.000000  loss: 0.2066 (0.2066)  labels_encoder: 0.0923 (0.0923)  labels_decoder: 0.1143 (0.1143)  labels_encoder_unscaled: 0.0923 (0.0923)  labels_decoder_unscaled: 0.2287 (0.2287)  time: 3.4168  data: 3.1074  max mem: 3702
Epoch: [4]  [  50/1404]  eta: 0:05:54  lr: 0.000000  loss: 0.2426 (0.2411)  labels_encoder: 0.1267 (0.1255)  labels_decoder: 0.1175 (0.1155)  labels_encoder_unscaled: 0.1267 (0.1255)  labels_decoder_unscaled: 0.2350 (0.2311)  time: 0.1909  data: 0.0004  max mem: 3702
Epoch: [4]  [ 100/1404]  eta: 0:04:47  lr: 0.000000  loss: 0.2443 (0.2424)  labels_encoder: 0.1238 (0.1243)  labels_decoder: 0.1216 (0.1182)  labels_encoder_unscaled: 0.1238 (0.1243)  labels_decoder_unscaled: 0.2432 (0.2364)  time: 0.1695  data: 0.0004  max mem: 3702
Epoch: [4]  [ 150/1404]  eta: 0:04:20  lr: 0.000000  loss: 0.2406 (0.2404)  labels_encoder: 0.1161 (0.1224)  labels_decoder: 0.1174 (0.1180)  labels_encoder_unscaled: 0.1161 (0.1224)  labels_decoder_unscaled: 0.2349 (0.2360)  time: 0.1858  data: 0.0004  max mem: 3702
Epoch: [4]  [ 200/1404]  eta: 0:04:01  lr: 0.000000  loss: 0.2296 (0.2371)  labels_encoder: 0.1147 (0.1206)  labels_decoder: 0.1135 (0.1165)  labels_encoder_unscaled: 0.1147 (0.1206)  labels_decoder_unscaled: 0.2271 (0.2331)  time: 0.1761  data: 0.0003  max mem: 3702
Epoch: [4]  [ 250/1404]  eta: 0:03:46  lr: 0.000000  loss: 0.2473 (0.2377)  labels_encoder: 0.1196 (0.1210)  labels_decoder: 0.1182 (0.1167)  labels_encoder_unscaled: 0.1196 (0.1210)  labels_decoder_unscaled: 0.2365 (0.2335)  time: 0.1840  data: 0.0003  max mem: 3702
Epoch: [4]  [ 300/1404]  eta: 0:03:33  lr: 0.000000  loss: 0.2264 (0.2376)  labels_encoder: 0.1207 (0.1212)  labels_decoder: 0.1124 (0.1165)  labels_encoder_unscaled: 0.1207 (0.1212)  labels_decoder_unscaled: 0.2247 (0.2330)  time: 0.1779  data: 0.0003  max mem: 3702
Epoch: [4]  [ 350/1404]  eta: 0:03:20  lr: 0.000000  loss: 0.2367 (0.2385)  labels_encoder: 0.1262 (0.1219)  labels_decoder: 0.1135 (0.1166)  labels_encoder_unscaled: 0.1262 (0.1219)  labels_decoder_unscaled: 0.2270 (0.2333)  time: 0.1712  data: 0.0003  max mem: 3702
Epoch: [4]  [ 400/1404]  eta: 0:03:11  lr: 0.000000  loss: 0.2470 (0.2384)  labels_encoder: 0.1252 (0.1220)  labels_decoder: 0.1199 (0.1165)  labels_encoder_unscaled: 0.1252 (0.1220)  labels_decoder_unscaled: 0.2397 (0.2329)  time: 0.1836  data: 0.0004  max mem: 3702
Epoch: [4]  [ 450/1404]  eta: 0:03:00  lr: 0.000000  loss: 0.2325 (0.2379)  labels_encoder: 0.1165 (0.1219)  labels_decoder: 0.1058 (0.1160)  labels_encoder_unscaled: 0.1165 (0.1219)  labels_decoder_unscaled: 0.2116 (0.2320)  time: 0.1770  data: 0.0003  max mem: 3702
Epoch: [4]  [ 500/1404]  eta: 0:02:51  lr: 0.000000  loss: 0.2315 (0.2395)  labels_encoder: 0.1182 (0.1233)  labels_decoder: 0.1150 (0.1162)  labels_encoder_unscaled: 0.1182 (0.1233)  labels_decoder_unscaled: 0.2300 (0.2324)  time: 0.1971  data: 0.0003  max mem: 3702
Epoch: [4]  [ 550/1404]  eta: 0:02:41  lr: 0.000000  loss: 0.2334 (0.2394)  labels_encoder: 0.1119 (0.1233)  labels_decoder: 0.1170 (0.1161)  labels_encoder_unscaled: 0.1119 (0.1233)  labels_decoder_unscaled: 0.2340 (0.2322)  time: 0.1789  data: 0.0003  max mem: 3702
Epoch: [4]  [ 600/1404]  eta: 0:02:30  lr: 0.000000  loss: 0.2316 (0.2393)  labels_encoder: 0.1151 (0.1235)  labels_decoder: 0.1084 (0.1158)  labels_encoder_unscaled: 0.1151 (0.1235)  labels_decoder_unscaled: 0.2168 (0.2317)  time: 0.1706  data: 0.0003  max mem: 3702
Epoch: [4]  [ 650/1404]  eta: 0:02:21  lr: 0.000000  loss: 0.2083 (0.2389)  labels_encoder: 0.0971 (0.1231)  labels_decoder: 0.1101 (0.1158)  labels_encoder_unscaled: 0.0971 (0.1231)  labels_decoder_unscaled: 0.2202 (0.2316)  time: 0.1912  data: 0.0003  max mem: 3702
Epoch: [4]  [ 700/1404]  eta: 0:02:11  lr: 0.000000  loss: 0.2491 (0.2392)  labels_encoder: 0.1266 (0.1232)  labels_decoder: 0.1260 (0.1160)  labels_encoder_unscaled: 0.1266 (0.1232)  labels_decoder_unscaled: 0.2519 (0.2321)  time: 0.1837  data: 0.0003  max mem: 3702
Epoch: [4]  [ 750/1404]  eta: 0:02:01  lr: 0.000000  loss: 0.2287 (0.2394)  labels_encoder: 0.1238 (0.1233)  labels_decoder: 0.1156 (0.1161)  labels_encoder_unscaled: 0.1238 (0.1233)  labels_decoder_unscaled: 0.2312 (0.2322)  time: 0.1905  data: 0.0003  max mem: 3702
Epoch: [4]  [ 800/1404]  eta: 0:01:52  lr: 0.000000  loss: 0.2183 (0.2392)  labels_encoder: 0.1107 (0.1231)  labels_decoder: 0.1127 (0.1161)  labels_encoder_unscaled: 0.1107 (0.1231)  labels_decoder_unscaled: 0.2255 (0.2323)  time: 0.1744  data: 0.0004  max mem: 3702
Epoch: [4]  [ 850/1404]  eta: 0:01:42  lr: 0.000000  loss: 0.2383 (0.2389)  labels_encoder: 0.1181 (0.1229)  labels_decoder: 0.1142 (0.1160)  labels_encoder_unscaled: 0.1181 (0.1229)  labels_decoder_unscaled: 0.2284 (0.2320)  time: 0.1780  data: 0.0003  max mem: 3702
Epoch: [4]  [ 900/1404]  eta: 0:01:33  lr: 0.000000  loss: 0.2311 (0.2389)  labels_encoder: 0.1246 (0.1229)  labels_decoder: 0.1087 (0.1159)  labels_encoder_unscaled: 0.1246 (0.1229)  labels_decoder_unscaled: 0.2174 (0.2319)  time: 0.1920  data: 0.0003  max mem: 3702
Epoch: [4]  [ 950/1404]  eta: 0:01:24  lr: 0.000000  loss: 0.2333 (0.2387)  labels_encoder: 0.1202 (0.1226)  labels_decoder: 0.1125 (0.1161)  labels_encoder_unscaled: 0.1202 (0.1226)  labels_decoder_unscaled: 0.2249 (0.2321)  time: 0.1803  data: 0.0003  max mem: 3702
Epoch: [4]  [1000/1404]  eta: 0:01:14  lr: 0.000000  loss: 0.2210 (0.2396)  labels_encoder: 0.1179 (0.1232)  labels_decoder: 0.1176 (0.1164)  labels_encoder_unscaled: 0.1179 (0.1232)  labels_decoder_unscaled: 0.2353 (0.2328)  time: 0.1809  data: 0.0003  max mem: 3702
Epoch: [4]  [1050/1404]  eta: 0:01:05  lr: 0.000000  loss: 0.2322 (0.2397)  labels_encoder: 0.1271 (0.1235)  labels_decoder: 0.1063 (0.1162)  labels_encoder_unscaled: 0.1271 (0.1235)  labels_decoder_unscaled: 0.2126 (0.2324)  time: 0.1789  data: 0.0003  max mem: 3702
Epoch: [4]  [1100/1404]  eta: 0:00:56  lr: 0.000000  loss: 0.2383 (0.2397)  labels_encoder: 0.1184 (0.1235)  labels_decoder: 0.1125 (0.1162)  labels_encoder_unscaled: 0.1184 (0.1235)  labels_decoder_unscaled: 0.2249 (0.2323)  time: 0.1916  data: 0.0003  max mem: 3702
Epoch: [4]  [1150/1404]  eta: 0:00:46  lr: 0.000000  loss: 0.2439 (0.2401)  labels_encoder: 0.1301 (0.1238)  labels_decoder: 0.1173 (0.1163)  labels_encoder_unscaled: 0.1301 (0.1238)  labels_decoder_unscaled: 0.2347 (0.2325)  time: 0.1792  data: 0.0004  max mem: 3702
Epoch: [4]  [1200/1404]  eta: 0:00:37  lr: 0.000000  loss: 0.2336 (0.2402)  labels_encoder: 0.1154 (0.1239)  labels_decoder: 0.1127 (0.1163)  labels_encoder_unscaled: 0.1154 (0.1239)  labels_decoder_unscaled: 0.2254 (0.2325)  time: 0.1957  data: 0.0004  max mem: 3702
Epoch: [4]  [1250/1404]  eta: 0:00:28  lr: 0.000000  loss: 0.2552 (0.2401)  labels_encoder: 0.1212 (0.1238)  labels_decoder: 0.1166 (0.1163)  labels_encoder_unscaled: 0.1212 (0.1238)  labels_decoder_unscaled: 0.2331 (0.2326)  time: 0.1855  data: 0.0004  max mem: 3702
Epoch: [4]  [1300/1404]  eta: 0:00:19  lr: 0.000000  loss: 0.2379 (0.2402)  labels_encoder: 0.1201 (0.1238)  labels_decoder: 0.1194 (0.1163)  labels_encoder_unscaled: 0.1201 (0.1238)  labels_decoder_unscaled: 0.2387 (0.2327)  time: 0.1769  data: 0.0004  max mem: 3702
Epoch: [4]  [1350/1404]  eta: 0:00:09  lr: 0.000000  loss: 0.2205 (0.2399)  labels_encoder: 0.1092 (0.1237)  labels_decoder: 0.1028 (0.1162)  labels_encoder_unscaled: 0.1092 (0.1237)  labels_decoder_unscaled: 0.2055 (0.2325)  time: 0.1887  data: 0.0028  max mem: 3702
Epoch: [4]  [1400/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2582 (0.2402)  labels_encoder: 0.1353 (0.1239)  labels_decoder: 0.1206 (0.1163)  labels_encoder_unscaled: 0.1353 (0.1239)  labels_decoder_unscaled: 0.2412 (0.2326)  time: 0.1600  data: 0.0004  max mem: 3702
Epoch: [4]  [1403/1404]  eta: 0:00:00  lr: 0.000000  loss: 0.2619 (0.2402)  labels_encoder: 0.1353 (0.1239)  labels_decoder: 0.1227 (0.1163)  labels_encoder_unscaled: 0.1353 (0.1239)  labels_decoder_unscaled: 0.2454 (0.2326)  time: 0.1584  data: 0.0003  max mem: 3702
Epoch: [4] Total time: 0:04:19 (0.1846 s / it)
Averaged stats: lr: 0.000000  loss: 0.2619 (0.2402)  labels_encoder: 0.1353 (0.1239)  labels_decoder: 0.1227 (0.1163)  labels_encoder_unscaled: 0.1353 (0.1239)  labels_decoder_unscaled: 0.2454 (0.2326)
Test:  [   0/1613]  eta: 1:24:07  loss: 0.7487 (0.7487)  labels_encoder: 0.4360 (0.4360)  labels_decoder: 0.3127 (0.3127)  labels_encoder_unscaled: 0.4360 (0.4360)  labels_decoder_unscaled: 0.6254 (0.6254)  time: 3.1296  data: 3.0414  max mem: 3702
Test:  [  50/1613]  eta: 0:04:52  loss: 0.4280 (1.0104)  labels_encoder: 0.2292 (0.6382)  labels_decoder: 0.1824 (0.3722)  labels_encoder_unscaled: 0.2292 (0.6382)  labels_decoder_unscaled: 0.3648 (0.7444)  time: 0.1249  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:50  loss: 0.1315 (0.7936)  labels_encoder: 0.0967 (0.5073)  labels_decoder: 0.0348 (0.2863)  labels_encoder_unscaled: 0.0967 (0.5073)  labels_decoder_unscaled: 0.0696 (0.5725)  time: 0.1125  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:26  loss: 0.9663 (0.7827)  labels_encoder: 0.6502 (0.5025)  labels_decoder: 0.2938 (0.2802)  labels_encoder_unscaled: 0.6502 (0.5025)  labels_decoder_unscaled: 0.5876 (0.5603)  time: 0.1190  data: 0.0002  max mem: 3702
Test:  [ 200/1613]  eta: 0:03:10  loss: 1.0335 (0.9660)  labels_encoder: 0.6069 (0.6218)  labels_decoder: 0.4111 (0.3442)  labels_encoder_unscaled: 0.6069 (0.6218)  labels_decoder_unscaled: 0.8223 (0.6884)  time: 0.1182  data: 0.0002  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:58  loss: 0.4664 (1.0142)  labels_encoder: 0.3125 (0.6511)  labels_decoder: 0.2188 (0.3631)  labels_encoder_unscaled: 0.3125 (0.6511)  labels_decoder_unscaled: 0.4376 (0.7263)  time: 0.1188  data: 0.0002  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:49  loss: 0.6469 (1.0283)  labels_encoder: 0.3666 (0.6619)  labels_decoder: 0.2299 (0.3664)  labels_encoder_unscaled: 0.3666 (0.6619)  labels_decoder_unscaled: 0.4597 (0.7327)  time: 0.1213  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:39  loss: 1.1785 (1.0223)  labels_encoder: 0.7324 (0.6528)  labels_decoder: 0.4975 (0.3695)  labels_encoder_unscaled: 0.7324 (0.6528)  labels_decoder_unscaled: 0.9949 (0.7390)  time: 0.1099  data: 0.0003  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:32  loss: 0.7973 (1.1375)  labels_encoder: 0.4859 (0.7354)  labels_decoder: 0.3703 (0.4020)  labels_encoder_unscaled: 0.4859 (0.7354)  labels_decoder_unscaled: 0.7406 (0.8041)  time: 0.1180  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:24  loss: 0.9679 (1.2286)  labels_encoder: 0.6033 (0.7982)  labels_decoder: 0.3618 (0.4304)  labels_encoder_unscaled: 0.6033 (0.7982)  labels_decoder_unscaled: 0.7237 (0.8607)  time: 0.1029  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:16  loss: 0.3554 (1.1710)  labels_encoder: 0.1638 (0.7592)  labels_decoder: 0.1626 (0.4119)  labels_encoder_unscaled: 0.1638 (0.7592)  labels_decoder_unscaled: 0.3252 (0.8237)  time: 0.1144  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:02:09  loss: 0.5892 (1.1645)  labels_encoder: 0.3688 (0.7549)  labels_decoder: 0.2068 (0.4096)  labels_encoder_unscaled: 0.3688 (0.7549)  labels_decoder_unscaled: 0.4137 (0.8192)  time: 0.1086  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:02:03  loss: 1.0695 (1.2089)  labels_encoder: 0.5717 (0.7960)  labels_decoder: 0.4659 (0.4129)  labels_encoder_unscaled: 0.5717 (0.7960)  labels_decoder_unscaled: 0.9318 (0.8258)  time: 0.1126  data: 0.0002  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:56  loss: 0.8969 (1.1882)  labels_encoder: 0.5136 (0.7784)  labels_decoder: 0.3798 (0.4099)  labels_encoder_unscaled: 0.5136 (0.7784)  labels_decoder_unscaled: 0.7597 (0.8197)  time: 0.1086  data: 0.0002  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:50  loss: 0.5433 (1.1590)  labels_encoder: 0.3372 (0.7577)  labels_decoder: 0.2240 (0.4013)  labels_encoder_unscaled: 0.3372 (0.7577)  labels_decoder_unscaled: 0.4480 (0.8025)  time: 0.1184  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:43  loss: 0.9558 (1.1429)  labels_encoder: 0.6143 (0.7455)  labels_decoder: 0.3809 (0.3974)  labels_encoder_unscaled: 0.6143 (0.7455)  labels_decoder_unscaled: 0.7618 (0.7948)  time: 0.1147  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:37  loss: 0.6605 (1.1340)  labels_encoder: 0.4265 (0.7399)  labels_decoder: 0.2963 (0.3941)  labels_encoder_unscaled: 0.4265 (0.7399)  labels_decoder_unscaled: 0.5925 (0.7882)  time: 0.1135  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:30  loss: 1.1673 (1.1307)  labels_encoder: 0.8946 (0.7351)  labels_decoder: 0.4630 (0.3957)  labels_encoder_unscaled: 0.8946 (0.7351)  labels_decoder_unscaled: 0.9259 (0.7913)  time: 0.1148  data: 0.0003  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:24  loss: 0.8150 (1.1489)  labels_encoder: 0.4624 (0.7478)  labels_decoder: 0.3046 (0.4011)  labels_encoder_unscaled: 0.4624 (0.7478)  labels_decoder_unscaled: 0.6092 (0.8023)  time: 0.1024  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:18  loss: 1.0769 (1.1407)  labels_encoder: 0.7080 (0.7422)  labels_decoder: 0.3689 (0.3985)  labels_encoder_unscaled: 0.7080 (0.7422)  labels_decoder_unscaled: 0.7378 (0.7971)  time: 0.1054  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:12  loss: 0.6183 (1.1293)  labels_encoder: 0.3964 (0.7340)  labels_decoder: 0.2261 (0.3954)  labels_encoder_unscaled: 0.3964 (0.7340)  labels_decoder_unscaled: 0.4523 (0.7907)  time: 0.1237  data: 0.0005  max mem: 3702
Test:  [1050/1613]  eta: 0:01:06  loss: 0.8528 (1.1226)  labels_encoder: 0.4947 (0.7293)  labels_decoder: 0.3280 (0.3933)  labels_encoder_unscaled: 0.4947 (0.7293)  labels_decoder_unscaled: 0.6559 (0.7865)  time: 0.1189  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:01:00  loss: 0.6662 (1.1314)  labels_encoder: 0.4472 (0.7362)  labels_decoder: 0.3271 (0.3952)  labels_encoder_unscaled: 0.4472 (0.7362)  labels_decoder_unscaled: 0.6542 (0.7905)  time: 0.1203  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:54  loss: 0.5275 (1.1180)  labels_encoder: 0.3300 (0.7270)  labels_decoder: 0.2168 (0.3910)  labels_encoder_unscaled: 0.3300 (0.7270)  labels_decoder_unscaled: 0.4336 (0.7819)  time: 0.0980  data: 0.0002  max mem: 3702
Test:  [1200/1613]  eta: 0:00:48  loss: 0.5397 (1.1211)  labels_encoder: 0.3215 (0.7283)  labels_decoder: 0.2099 (0.3928)  labels_encoder_unscaled: 0.3215 (0.7283)  labels_decoder_unscaled: 0.4198 (0.7856)  time: 0.1078  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:42  loss: 0.4055 (1.1209)  labels_encoder: 0.2377 (0.7278)  labels_decoder: 0.1623 (0.3932)  labels_encoder_unscaled: 0.2377 (0.7278)  labels_decoder_unscaled: 0.3247 (0.7864)  time: 0.0999  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:36  loss: 0.8370 (1.1153)  labels_encoder: 0.5094 (0.7234)  labels_decoder: 0.2709 (0.3919)  labels_encoder_unscaled: 0.5094 (0.7234)  labels_decoder_unscaled: 0.5418 (0.7839)  time: 0.1008  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:30  loss: 0.8886 (1.1323)  labels_encoder: 0.5026 (0.7350)  labels_decoder: 0.4005 (0.3973)  labels_encoder_unscaled: 0.5026 (0.7350)  labels_decoder_unscaled: 0.8010 (0.7945)  time: 0.1102  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:24  loss: 1.1127 (1.1249)  labels_encoder: 0.6940 (0.7300)  labels_decoder: 0.3820 (0.3948)  labels_encoder_unscaled: 0.6940 (0.7300)  labels_decoder_unscaled: 0.7641 (0.7897)  time: 0.1051  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:18  loss: 0.6850 (1.1396)  labels_encoder: 0.4593 (0.7396)  labels_decoder: 0.3899 (0.4000)  labels_encoder_unscaled: 0.4593 (0.7396)  labels_decoder_unscaled: 0.7799 (0.8000)  time: 0.1129  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:13  loss: 0.6294 (1.1547)  labels_encoder: 0.4281 (0.7511)  labels_decoder: 0.2224 (0.4036)  labels_encoder_unscaled: 0.4281 (0.7511)  labels_decoder_unscaled: 0.4447 (0.8072)  time: 0.1077  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:07  loss: 0.7082 (1.1497)  labels_encoder: 0.4323 (0.7480)  labels_decoder: 0.2479 (0.4017)  labels_encoder_unscaled: 0.4323 (0.7480)  labels_decoder_unscaled: 0.4959 (0.8033)  time: 0.1022  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9055 (1.1455)  labels_encoder: 0.5446 (0.7448)  labels_decoder: 0.4036 (0.4007)  labels_encoder_unscaled: 0.5446 (0.7448)  labels_decoder_unscaled: 0.8072 (0.8015)  time: 0.1076  data: 0.0002  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6875 (1.1434)  labels_encoder: 0.4119 (0.7437)  labels_decoder: 0.2814 (0.3997)  labels_encoder_unscaled: 0.4119 (0.7437)  labels_decoder_unscaled: 0.5629 (0.7994)  time: 0.0842  data: 0.0001  max mem: 3702
Test: Total time: 0:03:04 (0.1145 s / it)
Averaged stats: loss: 0.6875 (1.1434)  labels_encoder: 0.4119 (0.7437)  labels_decoder: 0.2814 (0.3997)  labels_encoder_unscaled: 0.4119 (0.7437)  labels_decoder_unscaled: 0.5629 (0.7994)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5770

dec_mAP all together: | 0.45625597535483 |.
dec_mAP_pred | 0 : 0.5018410574308942 |.
dec_mAP_pred | 1 : 0.4934741702080395 |.
dec_mAP_pred | 2 : 0.48066841982428254 |.
dec_mAP_pred | 3 : 0.4665745664782651 |.
dec_mAP_pred | 4 : 0.4514305201327177 |.
dec_mAP_pred | 5 : 0.43656428921943097 |.
dec_mAP_pred | 6 : 0.42199875467320574 |.
dec_mAP_pred | 7 : 0.40895091200318107 |.
all decoder map: | 0.4577 |.
BaseballPitch: 0.1485
BasketballDunk: 0.7741
Billiards: 0.4797
CleanAndJerk: 0.7502
CliffDiving: 0.8016
CricketBowling: 0.4301
CricketShot: 0.2305
Diving: 0.6830
FrisbeeCatch: 0.3275
GolfSwing: 0.6270
HammerThrow: 0.8477
HighJump: 0.6115
JavelinThrow: 0.6897
LongJump: 0.7674
PoleVault: 0.8678
Shotput: 0.6824
SoccerPenalty: 0.2900
TennisSwing: 0.5799
ThrowDiscus: 0.6163
VolleyballSpiking: 0.3348
Training time 0:34:04
