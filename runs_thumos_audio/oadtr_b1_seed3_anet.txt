Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:3
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  66.183 M, 99.815% Params, 1.896 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 11.071% Params, 0.47 GMac, 24.773% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    6.295 M, 9.493% Params, 0.409 GMac, 21.570% MACs, 
    (net): Sequential(
      6.295 M, 9.493% Params, 0.409 GMac, 21.570% MACs, 
      (0): Residual(
        4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
        (fn): PreNormDrop(
          4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 6.327% Params, 0.273 GMac, 14.377% MACs, 
            (qkv): Linear(3.146 M, 4.744% Params, 0.204 GMac, 10.783% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
        (fn): PreNorm(
          2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
            (net): Sequential(
              2.099 M, 3.166% Params, 0.136 GMac, 7.192% MACs, 
              (0): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.068% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 79.148% Params, 1.017 GMac, 53.645% MACs, 
    (layers): ModuleList(
      52.48 M, 79.148% Params, 1.017 GMac, 53.645% MACs, 
      (0): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 15.830% Params, 0.203 GMac, 10.729% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.034 GMac, 1.770% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.332% Params, 0.153 GMac, 8.074% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.583% Params, 0.068 GMac, 3.594% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.583% Params, 0.008 GMac, 0.442% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.583% Params, 0.008 GMac, 0.443% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.034% Params, 0.0 GMac, 0.010% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 1896244268.0
Model params: 66306092
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1406]  eta: 1:32:21  lr: 0.000100  loss: 5.0173 (5.0173)  labels_encoder: 3.4878 (3.4878)  labels_decoder: 1.5295 (1.5295)  labels_encoder_unscaled: 3.4878 (3.4878)  labels_decoder_unscaled: 3.0589 (3.0589)  time: 3.9413  data: 3.0335  max mem: 1929
Epoch: [1]  [  50/1406]  eta: 0:05:54  lr: 0.000100  loss: 1.1230 (1.6130)  labels_encoder: 0.7274 (1.0576)  labels_decoder: 0.4076 (0.5554)  labels_encoder_unscaled: 0.7274 (1.0576)  labels_decoder_unscaled: 0.8152 (1.1108)  time: 0.1470  data: 0.0003  max mem: 2688
Epoch: [1]  [ 100/1406]  eta: 0:04:31  lr: 0.000100  loss: 0.8599 (1.2485)  labels_encoder: 0.5503 (0.8068)  labels_decoder: 0.3242 (0.4417)  labels_encoder_unscaled: 0.5503 (0.8068)  labels_decoder_unscaled: 0.6484 (0.8834)  time: 0.1567  data: 0.0003  max mem: 2688
Epoch: [1]  [ 150/1406]  eta: 0:03:58  lr: 0.000100  loss: 0.6962 (1.0674)  labels_encoder: 0.4334 (0.6814)  labels_decoder: 0.2689 (0.3860)  labels_encoder_unscaled: 0.4334 (0.6814)  labels_decoder_unscaled: 0.5377 (0.7720)  time: 0.1543  data: 0.0003  max mem: 2688
Epoch: [1]  [ 200/1406]  eta: 0:03:37  lr: 0.000100  loss: 0.6689 (0.9691)  labels_encoder: 0.4064 (0.6143)  labels_decoder: 0.2538 (0.3548)  labels_encoder_unscaled: 0.4064 (0.6143)  labels_decoder_unscaled: 0.5076 (0.7096)  time: 0.1541  data: 0.0003  max mem: 2688
Epoch: [1]  [ 250/1406]  eta: 0:03:22  lr: 0.000100  loss: 0.5732 (0.9023)  labels_encoder: 0.3333 (0.5678)  labels_decoder: 0.2332 (0.3346)  labels_encoder_unscaled: 0.3333 (0.5678)  labels_decoder_unscaled: 0.4665 (0.6691)  time: 0.1594  data: 0.0006  max mem: 2688
Epoch: [1]  [ 300/1406]  eta: 0:03:09  lr: 0.000100  loss: 0.6016 (0.8572)  labels_encoder: 0.3785 (0.5385)  labels_decoder: 0.2337 (0.3188)  labels_encoder_unscaled: 0.3785 (0.5385)  labels_decoder_unscaled: 0.4675 (0.6375)  time: 0.1490  data: 0.0003  max mem: 2688
Epoch: [1]  [ 350/1406]  eta: 0:02:57  lr: 0.000100  loss: 0.5557 (0.8178)  labels_encoder: 0.3244 (0.5125)  labels_decoder: 0.2205 (0.3053)  labels_encoder_unscaled: 0.3244 (0.5125)  labels_decoder_unscaled: 0.4409 (0.6106)  time: 0.1517  data: 0.0003  max mem: 2688
Epoch: [1]  [ 400/1406]  eta: 0:02:47  lr: 0.000100  loss: 0.4960 (0.7850)  labels_encoder: 0.2944 (0.4903)  labels_decoder: 0.2041 (0.2948)  labels_encoder_unscaled: 0.2944 (0.4903)  labels_decoder_unscaled: 0.4083 (0.5895)  time: 0.1559  data: 0.0003  max mem: 2688
Epoch: [1]  [ 450/1406]  eta: 0:02:37  lr: 0.000100  loss: 0.4908 (0.7553)  labels_encoder: 0.2891 (0.4700)  labels_decoder: 0.2002 (0.2853)  labels_encoder_unscaled: 0.2891 (0.4700)  labels_decoder_unscaled: 0.4005 (0.5707)  time: 0.1564  data: 0.0003  max mem: 2688
Epoch: [1]  [ 500/1406]  eta: 0:02:28  lr: 0.000100  loss: 0.4938 (0.7310)  labels_encoder: 0.2959 (0.4539)  labels_decoder: 0.1911 (0.2771)  labels_encoder_unscaled: 0.2959 (0.4539)  labels_decoder_unscaled: 0.3823 (0.5542)  time: 0.1439  data: 0.0003  max mem: 2688
Epoch: [1]  [ 550/1406]  eta: 0:02:18  lr: 0.000100  loss: 0.4866 (0.7081)  labels_encoder: 0.3052 (0.4385)  labels_decoder: 0.1939 (0.2696)  labels_encoder_unscaled: 0.3052 (0.4385)  labels_decoder_unscaled: 0.3877 (0.5392)  time: 0.1452  data: 0.0003  max mem: 2688
Epoch: [1]  [ 600/1406]  eta: 0:02:09  lr: 0.000100  loss: 0.4721 (0.6890)  labels_encoder: 0.2757 (0.4259)  labels_decoder: 0.1901 (0.2631)  labels_encoder_unscaled: 0.2757 (0.4259)  labels_decoder_unscaled: 0.3802 (0.5262)  time: 0.1490  data: 0.0003  max mem: 2688
Epoch: [1]  [ 650/1406]  eta: 0:02:01  lr: 0.000100  loss: 0.4567 (0.6727)  labels_encoder: 0.2626 (0.4148)  labels_decoder: 0.2011 (0.2579)  labels_encoder_unscaled: 0.2626 (0.4148)  labels_decoder_unscaled: 0.4021 (0.5159)  time: 0.1563  data: 0.0003  max mem: 2688
Epoch: [1]  [ 700/1406]  eta: 0:01:52  lr: 0.000100  loss: 0.4516 (0.6574)  labels_encoder: 0.2566 (0.4045)  labels_decoder: 0.1884 (0.2529)  labels_encoder_unscaled: 0.2566 (0.4045)  labels_decoder_unscaled: 0.3768 (0.5057)  time: 0.1578  data: 0.0003  max mem: 2688
Epoch: [1]  [ 750/1406]  eta: 0:01:44  lr: 0.000100  loss: 0.4424 (0.6437)  labels_encoder: 0.2654 (0.3954)  labels_decoder: 0.1716 (0.2483)  labels_encoder_unscaled: 0.2654 (0.3954)  labels_decoder_unscaled: 0.3432 (0.4965)  time: 0.1495  data: 0.0016  max mem: 2688
Epoch: [1]  [ 800/1406]  eta: 0:01:36  lr: 0.000100  loss: 0.4513 (0.6310)  labels_encoder: 0.2599 (0.3866)  labels_decoder: 0.1773 (0.2444)  labels_encoder_unscaled: 0.2599 (0.3866)  labels_decoder_unscaled: 0.3545 (0.4888)  time: 0.1452  data: 0.0003  max mem: 2688
Epoch: [1]  [ 850/1406]  eta: 0:01:27  lr: 0.000100  loss: 0.4587 (0.6196)  labels_encoder: 0.2695 (0.3791)  labels_decoder: 0.1851 (0.2405)  labels_encoder_unscaled: 0.2695 (0.3791)  labels_decoder_unscaled: 0.3702 (0.4810)  time: 0.1461  data: 0.0003  max mem: 2688
Epoch: [1]  [ 900/1406]  eta: 0:01:19  lr: 0.000100  loss: 0.4198 (0.6090)  labels_encoder: 0.2475 (0.3722)  labels_decoder: 0.1658 (0.2368)  labels_encoder_unscaled: 0.2475 (0.3722)  labels_decoder_unscaled: 0.3317 (0.4736)  time: 0.1584  data: 0.0003  max mem: 2688
Epoch: [1]  [ 950/1406]  eta: 0:01:11  lr: 0.000100  loss: 0.4375 (0.5997)  labels_encoder: 0.2636 (0.3660)  labels_decoder: 0.1843 (0.2337)  labels_encoder_unscaled: 0.2636 (0.3660)  labels_decoder_unscaled: 0.3685 (0.4674)  time: 0.1562  data: 0.0003  max mem: 2688
Epoch: [1]  [1000/1406]  eta: 0:01:03  lr: 0.000100  loss: 0.4115 (0.5915)  labels_encoder: 0.2432 (0.3603)  labels_decoder: 0.1812 (0.2312)  labels_encoder_unscaled: 0.2432 (0.3603)  labels_decoder_unscaled: 0.3624 (0.4624)  time: 0.1419  data: 0.0003  max mem: 2688
Epoch: [1]  [1050/1406]  eta: 0:00:55  lr: 0.000100  loss: 0.3609 (0.5819)  labels_encoder: 0.2018 (0.3536)  labels_decoder: 0.1633 (0.2283)  labels_encoder_unscaled: 0.2018 (0.3536)  labels_decoder_unscaled: 0.3266 (0.4565)  time: 0.1499  data: 0.0003  max mem: 2688
Epoch: [1]  [1100/1406]  eta: 0:00:48  lr: 0.000100  loss: 0.4225 (0.5741)  labels_encoder: 0.2448 (0.3482)  labels_decoder: 0.1811 (0.2259)  labels_encoder_unscaled: 0.2448 (0.3482)  labels_decoder_unscaled: 0.3623 (0.4517)  time: 0.1497  data: 0.0003  max mem: 2688
Epoch: [1]  [1150/1406]  eta: 0:00:40  lr: 0.000100  loss: 0.3702 (0.5659)  labels_encoder: 0.2014 (0.3426)  labels_decoder: 0.1668 (0.2233)  labels_encoder_unscaled: 0.2014 (0.3426)  labels_decoder_unscaled: 0.3336 (0.4466)  time: 0.1505  data: 0.0003  max mem: 2688
Epoch: [1]  [1200/1406]  eta: 0:00:32  lr: 0.000100  loss: 0.3936 (0.5590)  labels_encoder: 0.2281 (0.3379)  labels_decoder: 0.1581 (0.2211)  labels_encoder_unscaled: 0.2281 (0.3379)  labels_decoder_unscaled: 0.3162 (0.4423)  time: 0.1501  data: 0.0003  max mem: 2688
Epoch: [1]  [1250/1406]  eta: 0:00:24  lr: 0.000100  loss: 0.4019 (0.5526)  labels_encoder: 0.2256 (0.3336)  labels_decoder: 0.1622 (0.2190)  labels_encoder_unscaled: 0.2256 (0.3336)  labels_decoder_unscaled: 0.3244 (0.4381)  time: 0.1478  data: 0.0003  max mem: 2688
Epoch: [1]  [1300/1406]  eta: 0:00:16  lr: 0.000100  loss: 0.3942 (0.5467)  labels_encoder: 0.2309 (0.3295)  labels_decoder: 0.1738 (0.2173)  labels_encoder_unscaled: 0.2309 (0.3295)  labels_decoder_unscaled: 0.3476 (0.4345)  time: 0.1491  data: 0.0003  max mem: 2688
Epoch: [1]  [1350/1406]  eta: 0:00:08  lr: 0.000100  loss: 0.3759 (0.5404)  labels_encoder: 0.2301 (0.3253)  labels_decoder: 0.1507 (0.2152)  labels_encoder_unscaled: 0.2301 (0.3253)  labels_decoder_unscaled: 0.3014 (0.4303)  time: 0.1434  data: 0.0003  max mem: 2688
Epoch: [1]  [1400/1406]  eta: 0:00:00  lr: 0.000100  loss: 0.3521 (0.5343)  labels_encoder: 0.1890 (0.3211)  labels_decoder: 0.1559 (0.2132)  labels_encoder_unscaled: 0.1890 (0.3211)  labels_decoder_unscaled: 0.3118 (0.4264)  time: 0.1280  data: 0.0005  max mem: 2688
Epoch: [1]  [1405/1406]  eta: 0:00:00  lr: 0.000100  loss: 0.3706 (0.5337)  labels_encoder: 0.2044 (0.3207)  labels_decoder: 0.1571 (0.2130)  labels_encoder_unscaled: 0.2044 (0.3207)  labels_decoder_unscaled: 0.3143 (0.4261)  time: 0.1168  data: 0.0005  max mem: 2688
Epoch: [1] Total time: 0:03:38 (0.1552 s / it)
Averaged stats: lr: 0.000100  loss: 0.3706 (0.5337)  labels_encoder: 0.2044 (0.3207)  labels_decoder: 0.1571 (0.2130)  labels_encoder_unscaled: 0.2044 (0.3207)  labels_decoder_unscaled: 0.3143 (0.4261)
Test:  [   0/1613]  eta: 1:06:27  loss: 0.6348 (0.6348)  labels_encoder: 0.3124 (0.3124)  labels_decoder: 0.3224 (0.3224)  labels_encoder_unscaled: 0.3124 (0.3124)  labels_decoder_unscaled: 0.6448 (0.6448)  time: 2.4720  data: 2.3209  max mem: 2688
Test:  [  50/1613]  eta: 0:04:04  loss: 0.5298 (0.8269)  labels_encoder: 0.3217 (0.5263)  labels_decoder: 0.2013 (0.3006)  labels_encoder_unscaled: 0.3217 (0.5263)  labels_decoder_unscaled: 0.4026 (0.6013)  time: 0.0920  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:17  loss: 0.0900 (0.6872)  labels_encoder: 0.0635 (0.4439)  labels_decoder: 0.0328 (0.2433)  labels_encoder_unscaled: 0.0635 (0.4439)  labels_decoder_unscaled: 0.0656 (0.4865)  time: 0.1100  data: 0.0002  max mem: 2688
Test:  [ 150/1613]  eta: 0:02:56  loss: 0.8678 (0.6747)  labels_encoder: 0.5317 (0.4331)  labels_decoder: 0.2910 (0.2416)  labels_encoder_unscaled: 0.5317 (0.4331)  labels_decoder_unscaled: 0.5820 (0.4833)  time: 0.0970  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:41  loss: 1.0567 (0.8115)  labels_encoder: 0.6842 (0.5243)  labels_decoder: 0.3726 (0.2872)  labels_encoder_unscaled: 0.6842 (0.5243)  labels_decoder_unscaled: 0.7451 (0.5744)  time: 0.0924  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:31  loss: 0.4374 (0.8726)  labels_encoder: 0.2163 (0.5635)  labels_decoder: 0.1988 (0.3092)  labels_encoder_unscaled: 0.2163 (0.5635)  labels_decoder_unscaled: 0.3976 (0.6184)  time: 0.1063  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:24  loss: 0.7425 (0.8979)  labels_encoder: 0.4271 (0.5830)  labels_decoder: 0.2197 (0.3150)  labels_encoder_unscaled: 0.4271 (0.5830)  labels_decoder_unscaled: 0.4394 (0.6300)  time: 0.1260  data: 0.0002  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:17  loss: 1.1278 (0.9172)  labels_encoder: 0.7442 (0.5937)  labels_decoder: 0.4645 (0.3235)  labels_encoder_unscaled: 0.7442 (0.5937)  labels_decoder_unscaled: 0.9291 (0.6469)  time: 0.1116  data: 0.0002  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:10  loss: 0.7608 (1.0469)  labels_encoder: 0.4202 (0.6824)  labels_decoder: 0.3376 (0.3645)  labels_encoder_unscaled: 0.4202 (0.6824)  labels_decoder_unscaled: 0.6752 (0.7290)  time: 0.1064  data: 0.0002  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:03  loss: 0.6242 (1.1106)  labels_encoder: 0.3999 (0.7267)  labels_decoder: 0.2151 (0.3840)  labels_encoder_unscaled: 0.3999 (0.7267)  labels_decoder_unscaled: 0.4302 (0.7679)  time: 0.0967  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:58  loss: 0.3126 (1.0606)  labels_encoder: 0.1349 (0.6922)  labels_decoder: 0.1727 (0.3684)  labels_encoder_unscaled: 0.1349 (0.6922)  labels_decoder_unscaled: 0.3454 (0.7367)  time: 0.0993  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:53  loss: 0.7047 (1.0551)  labels_encoder: 0.3962 (0.6853)  labels_decoder: 0.2927 (0.3697)  labels_encoder_unscaled: 0.3962 (0.6853)  labels_decoder_unscaled: 0.5854 (0.7395)  time: 0.1196  data: 0.0002  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:47  loss: 1.1198 (1.0787)  labels_encoder: 0.7145 (0.7039)  labels_decoder: 0.4043 (0.3747)  labels_encoder_unscaled: 0.7145 (0.7039)  labels_decoder_unscaled: 0.8086 (0.7495)  time: 0.1071  data: 0.0002  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:41  loss: 1.2643 (1.0662)  labels_encoder: 0.7589 (0.6922)  labels_decoder: 0.4335 (0.3740)  labels_encoder_unscaled: 0.7589 (0.6922)  labels_decoder_unscaled: 0.8671 (0.7480)  time: 0.0966  data: 0.0002  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:35  loss: 0.5638 (1.0427)  labels_encoder: 0.3010 (0.6758)  labels_decoder: 0.2628 (0.3669)  labels_encoder_unscaled: 0.3010 (0.6758)  labels_decoder_unscaled: 0.5256 (0.7338)  time: 0.1068  data: 0.0002  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:30  loss: 0.9690 (1.0337)  labels_encoder: 0.6045 (0.6693)  labels_decoder: 0.3433 (0.3644)  labels_encoder_unscaled: 0.6045 (0.6693)  labels_decoder_unscaled: 0.6866 (0.7288)  time: 0.1023  data: 0.0002  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:24  loss: 0.8271 (1.0338)  labels_encoder: 0.4918 (0.6716)  labels_decoder: 0.2705 (0.3622)  labels_encoder_unscaled: 0.4918 (0.6716)  labels_decoder_unscaled: 0.5409 (0.7245)  time: 0.1030  data: 0.0023  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:19  loss: 1.1908 (1.0344)  labels_encoder: 0.6736 (0.6694)  labels_decoder: 0.5172 (0.3650)  labels_encoder_unscaled: 0.6736 (0.6694)  labels_decoder_unscaled: 1.0343 (0.7301)  time: 0.1023  data: 0.0002  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:14  loss: 0.6253 (1.0531)  labels_encoder: 0.3317 (0.6840)  labels_decoder: 0.2882 (0.3691)  labels_encoder_unscaled: 0.3317 (0.6840)  labels_decoder_unscaled: 0.5763 (0.7383)  time: 0.0943  data: 0.0002  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:08  loss: 1.1081 (1.0522)  labels_encoder: 0.7820 (0.6853)  labels_decoder: 0.3275 (0.3669)  labels_encoder_unscaled: 0.7820 (0.6853)  labels_decoder_unscaled: 0.6550 (0.7338)  time: 0.1010  data: 0.0002  max mem: 2688
Test:  [1000/1613]  eta: 0:01:03  loss: 0.6574 (1.0493)  labels_encoder: 0.3850 (0.6834)  labels_decoder: 0.2407 (0.3658)  labels_encoder_unscaled: 0.3850 (0.6834)  labels_decoder_unscaled: 0.4814 (0.7317)  time: 0.0982  data: 0.0002  max mem: 2688
Test:  [1050/1613]  eta: 0:00:58  loss: 0.9147 (1.0484)  labels_encoder: 0.5714 (0.6838)  labels_decoder: 0.3182 (0.3646)  labels_encoder_unscaled: 0.5714 (0.6838)  labels_decoder_unscaled: 0.6363 (0.7293)  time: 0.1209  data: 0.0003  max mem: 2688
Test:  [1100/1613]  eta: 0:00:53  loss: 0.5871 (1.0465)  labels_encoder: 0.4300 (0.6837)  labels_decoder: 0.1938 (0.3628)  labels_encoder_unscaled: 0.4300 (0.6837)  labels_decoder_unscaled: 0.3876 (0.7256)  time: 0.1115  data: 0.0002  max mem: 2688
Test:  [1150/1613]  eta: 0:00:48  loss: 0.5824 (1.0325)  labels_encoder: 0.3800 (0.6739)  labels_decoder: 0.1988 (0.3586)  labels_encoder_unscaled: 0.3800 (0.6739)  labels_decoder_unscaled: 0.3976 (0.7172)  time: 0.1054  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:42  loss: 0.7030 (1.0330)  labels_encoder: 0.4359 (0.6737)  labels_decoder: 0.2775 (0.3593)  labels_encoder_unscaled: 0.4359 (0.6737)  labels_decoder_unscaled: 0.5549 (0.7186)  time: 0.0975  data: 0.0002  max mem: 2688
Test:  [1250/1613]  eta: 0:00:37  loss: 0.4089 (1.0394)  labels_encoder: 0.2652 (0.6785)  labels_decoder: 0.1717 (0.3610)  labels_encoder_unscaled: 0.2652 (0.6785)  labels_decoder_unscaled: 0.3435 (0.7220)  time: 0.1003  data: 0.0002  max mem: 2688
Test:  [1300/1613]  eta: 0:00:32  loss: 0.3830 (1.0315)  labels_encoder: 0.2051 (0.6724)  labels_decoder: 0.2163 (0.3591)  labels_encoder_unscaled: 0.2051 (0.6724)  labels_decoder_unscaled: 0.4326 (0.7182)  time: 0.1174  data: 0.0002  max mem: 2688
Test:  [1350/1613]  eta: 0:00:27  loss: 0.7849 (1.0419)  labels_encoder: 0.4479 (0.6785)  labels_decoder: 0.3531 (0.3635)  labels_encoder_unscaled: 0.4479 (0.6785)  labels_decoder_unscaled: 0.7062 (0.7269)  time: 0.1058  data: 0.0002  max mem: 2688
Test:  [1400/1613]  eta: 0:00:22  loss: 0.7038 (1.0392)  labels_encoder: 0.4262 (0.6757)  labels_decoder: 0.2958 (0.3635)  labels_encoder_unscaled: 0.4262 (0.6757)  labels_decoder_unscaled: 0.5917 (0.7270)  time: 0.1220  data: 0.0002  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.7385 (1.0476)  labels_encoder: 0.4665 (0.6809)  labels_decoder: 0.3185 (0.3667)  labels_encoder_unscaled: 0.4665 (0.6809)  labels_decoder_unscaled: 0.6369 (0.7334)  time: 0.1044  data: 0.0026  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.9245 (1.0658)  labels_encoder: 0.5855 (0.6950)  labels_decoder: 0.3391 (0.3708)  labels_encoder_unscaled: 0.5855 (0.6950)  labels_decoder_unscaled: 0.6781 (0.7416)  time: 0.0962  data: 0.0002  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6002 (1.0616)  labels_encoder: 0.3640 (0.6927)  labels_decoder: 0.2119 (0.3689)  labels_encoder_unscaled: 0.3640 (0.6927)  labels_decoder_unscaled: 0.4238 (0.7378)  time: 0.1182  data: 0.0002  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 1.0551 (1.0605)  labels_encoder: 0.6430 (0.6916)  labels_decoder: 0.4899 (0.3689)  labels_encoder_unscaled: 0.6430 (0.6916)  labels_decoder_unscaled: 0.9797 (0.7379)  time: 0.0980  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 1.0551 (1.0612)  labels_encoder: 0.6430 (0.6922)  labels_decoder: 0.4121 (0.3691)  labels_encoder_unscaled: 0.6430 (0.6922)  labels_decoder_unscaled: 0.8241 (0.7381)  time: 0.0701  data: 0.0001  max mem: 2688
Test: Total time: 0:02:47 (0.1037 s / it)
Averaged stats: loss: 1.0551 (1.0612)  labels_encoder: 0.6430 (0.6922)  labels_decoder: 0.4121 (0.3691)  labels_encoder_unscaled: 0.6430 (0.6922)  labels_decoder_unscaled: 0.8241 (0.7381)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.5716

dec_mAP all together: | 0.46934263840035567 |.
dec_mAP_pred | 0 : 0.5219712775495723 |.
dec_mAP_pred | 1 : 0.5112193275094749 |.
dec_mAP_pred | 2 : 0.4964012888819414 |.
dec_mAP_pred | 3 : 0.4798297557898577 |.
dec_mAP_pred | 4 : 0.4637378830141616 |.
dec_mAP_pred | 5 : 0.4475834387381841 |.
dec_mAP_pred | 6 : 0.4314500495476204 |.
dec_mAP_pred | 7 : 0.41666271447056313 |.
all decoder map: | 0.4711 |.
BaseballPitch: 0.1124
BasketballDunk: 0.7780
Billiards: 0.4880
CleanAndJerk: 0.7685
CliffDiving: 0.7993
CricketBowling: 0.4448
CricketShot: 0.2038
Diving: 0.7073
FrisbeeCatch: 0.3461
GolfSwing: 0.5363
HammerThrow: 0.8601
HighJump: 0.6368
JavelinThrow: 0.7091
LongJump: 0.7803
PoleVault: 0.8858
Shotput: 0.6862
SoccerPenalty: 0.2231
TennisSwing: 0.5080
ThrowDiscus: 0.6422
VolleyballSpiking: 0.3153
Epoch: [2]  [   0/1406]  eta: 1:24:38  lr: 0.000010  loss: 0.3768 (0.3768)  labels_encoder: 0.2385 (0.2385)  labels_decoder: 0.1383 (0.1383)  labels_encoder_unscaled: 0.2385 (0.2385)  labels_decoder_unscaled: 0.2766 (0.2766)  time: 3.6118  data: 3.4503  max mem: 2688
Epoch: [2]  [  50/1406]  eta: 0:05:03  lr: 0.000010  loss: 0.2865 (0.3188)  labels_encoder: 0.1481 (0.1772)  labels_decoder: 0.1371 (0.1416)  labels_encoder_unscaled: 0.1481 (0.1772)  labels_decoder_unscaled: 0.2742 (0.2832)  time: 0.1517  data: 0.0003  max mem: 2688
Epoch: [2]  [ 100/1406]  eta: 0:04:04  lr: 0.000010  loss: 0.2954 (0.3124)  labels_encoder: 0.1612 (0.1726)  labels_decoder: 0.1309 (0.1398)  labels_encoder_unscaled: 0.1612 (0.1726)  labels_decoder_unscaled: 0.2619 (0.2796)  time: 0.1507  data: 0.0003  max mem: 2688
Epoch: [2]  [ 150/1406]  eta: 0:03:39  lr: 0.000010  loss: 0.3001 (0.3070)  labels_encoder: 0.1579 (0.1680)  labels_decoder: 0.1327 (0.1390)  labels_encoder_unscaled: 0.1579 (0.1680)  labels_decoder_unscaled: 0.2655 (0.2780)  time: 0.1481  data: 0.0003  max mem: 2688
Epoch: [2]  [ 200/1406]  eta: 0:03:23  lr: 0.000010  loss: 0.2959 (0.3030)  labels_encoder: 0.1633 (0.1654)  labels_decoder: 0.1329 (0.1377)  labels_encoder_unscaled: 0.1633 (0.1654)  labels_decoder_unscaled: 0.2658 (0.2753)  time: 0.1519  data: 0.0003  max mem: 2688
Epoch: [2]  [ 250/1406]  eta: 0:03:10  lr: 0.000010  loss: 0.2731 (0.2979)  labels_encoder: 0.1425 (0.1625)  labels_decoder: 0.1319 (0.1353)  labels_encoder_unscaled: 0.1425 (0.1625)  labels_decoder_unscaled: 0.2638 (0.2707)  time: 0.1532  data: 0.0003  max mem: 2688
Epoch: [2]  [ 300/1406]  eta: 0:02:59  lr: 0.000010  loss: 0.2893 (0.2967)  labels_encoder: 0.1626 (0.1620)  labels_decoder: 0.1354 (0.1347)  labels_encoder_unscaled: 0.1626 (0.1620)  labels_decoder_unscaled: 0.2707 (0.2694)  time: 0.1461  data: 0.0003  max mem: 2688
Epoch: [2]  [ 350/1406]  eta: 0:02:50  lr: 0.000010  loss: 0.2810 (0.2937)  labels_encoder: 0.1536 (0.1599)  labels_decoder: 0.1267 (0.1338)  labels_encoder_unscaled: 0.1536 (0.1599)  labels_decoder_unscaled: 0.2533 (0.2676)  time: 0.1616  data: 0.0003  max mem: 2688
Epoch: [2]  [ 400/1406]  eta: 0:02:41  lr: 0.000010  loss: 0.2874 (0.2927)  labels_encoder: 0.1576 (0.1596)  labels_decoder: 0.1317 (0.1331)  labels_encoder_unscaled: 0.1576 (0.1596)  labels_decoder_unscaled: 0.2634 (0.2662)  time: 0.1464  data: 0.0003  max mem: 2688
Epoch: [2]  [ 450/1406]  eta: 0:02:31  lr: 0.000010  loss: 0.2368 (0.2896)  labels_encoder: 0.1257 (0.1575)  labels_decoder: 0.1224 (0.1321)  labels_encoder_unscaled: 0.1257 (0.1575)  labels_decoder_unscaled: 0.2448 (0.2642)  time: 0.1414  data: 0.0003  max mem: 2688
Epoch: [2]  [ 500/1406]  eta: 0:02:23  lr: 0.000010  loss: 0.2759 (0.2888)  labels_encoder: 0.1491 (0.1571)  labels_decoder: 0.1272 (0.1317)  labels_encoder_unscaled: 0.1491 (0.1571)  labels_decoder_unscaled: 0.2544 (0.2634)  time: 0.1502  data: 0.0003  max mem: 2688
Epoch: [2]  [ 550/1406]  eta: 0:02:14  lr: 0.000010  loss: 0.2687 (0.2860)  labels_encoder: 0.1550 (0.1554)  labels_decoder: 0.1243 (0.1307)  labels_encoder_unscaled: 0.1550 (0.1554)  labels_decoder_unscaled: 0.2486 (0.2614)  time: 0.1446  data: 0.0002  max mem: 2688
Epoch: [2]  [ 600/1406]  eta: 0:02:06  lr: 0.000010  loss: 0.2426 (0.2839)  labels_encoder: 0.1250 (0.1539)  labels_decoder: 0.1164 (0.1300)  labels_encoder_unscaled: 0.1250 (0.1539)  labels_decoder_unscaled: 0.2328 (0.2601)  time: 0.1602  data: 0.0003  max mem: 2688
Epoch: [2]  [ 650/1406]  eta: 0:01:59  lr: 0.000010  loss: 0.2654 (0.2827)  labels_encoder: 0.1357 (0.1530)  labels_decoder: 0.1200 (0.1297)  labels_encoder_unscaled: 0.1357 (0.1530)  labels_decoder_unscaled: 0.2400 (0.2594)  time: 0.1665  data: 0.0003  max mem: 2688
Epoch: [2]  [ 700/1406]  eta: 0:01:51  lr: 0.000010  loss: 0.2736 (0.2826)  labels_encoder: 0.1450 (0.1530)  labels_decoder: 0.1296 (0.1296)  labels_encoder_unscaled: 0.1450 (0.1530)  labels_decoder_unscaled: 0.2591 (0.2592)  time: 0.1626  data: 0.0003  max mem: 2688
Epoch: [2]  [ 750/1406]  eta: 0:01:43  lr: 0.000010  loss: 0.2593 (0.2817)  labels_encoder: 0.1457 (0.1525)  labels_decoder: 0.1193 (0.1292)  labels_encoder_unscaled: 0.1457 (0.1525)  labels_decoder_unscaled: 0.2386 (0.2584)  time: 0.1545  data: 0.0003  max mem: 2688
Epoch: [2]  [ 800/1406]  eta: 0:01:35  lr: 0.000010  loss: 0.2608 (0.2814)  labels_encoder: 0.1338 (0.1524)  labels_decoder: 0.1288 (0.1291)  labels_encoder_unscaled: 0.1338 (0.1524)  labels_decoder_unscaled: 0.2576 (0.2582)  time: 0.1618  data: 0.0003  max mem: 2688
Epoch: [2]  [ 850/1406]  eta: 0:01:27  lr: 0.000010  loss: 0.2499 (0.2800)  labels_encoder: 0.1269 (0.1515)  labels_decoder: 0.1230 (0.1285)  labels_encoder_unscaled: 0.1269 (0.1515)  labels_decoder_unscaled: 0.2460 (0.2571)  time: 0.1584  data: 0.0003  max mem: 2688
Epoch: [2]  [ 900/1406]  eta: 0:01:19  lr: 0.000010  loss: 0.2580 (0.2789)  labels_encoder: 0.1447 (0.1508)  labels_decoder: 0.1227 (0.1281)  labels_encoder_unscaled: 0.1447 (0.1508)  labels_decoder_unscaled: 0.2454 (0.2563)  time: 0.1543  data: 0.0003  max mem: 2688
Epoch: [2]  [ 950/1406]  eta: 0:01:11  lr: 0.000010  loss: 0.2563 (0.2780)  labels_encoder: 0.1309 (0.1503)  labels_decoder: 0.1192 (0.1278)  labels_encoder_unscaled: 0.1309 (0.1503)  labels_decoder_unscaled: 0.2383 (0.2555)  time: 0.1583  data: 0.0003  max mem: 2688
Epoch: [2]  [1000/1406]  eta: 0:01:03  lr: 0.000010  loss: 0.2489 (0.2773)  labels_encoder: 0.1236 (0.1498)  labels_decoder: 0.1236 (0.1275)  labels_encoder_unscaled: 0.1236 (0.1498)  labels_decoder_unscaled: 0.2471 (0.2550)  time: 0.1529  data: 0.0003  max mem: 2688
Epoch: [2]  [1050/1406]  eta: 0:00:56  lr: 0.000010  loss: 0.2477 (0.2759)  labels_encoder: 0.1268 (0.1488)  labels_decoder: 0.1217 (0.1271)  labels_encoder_unscaled: 0.1268 (0.1488)  labels_decoder_unscaled: 0.2435 (0.2543)  time: 0.1573  data: 0.0003  max mem: 2688
Epoch: [2]  [1100/1406]  eta: 0:00:48  lr: 0.000010  loss: 0.2348 (0.2752)  labels_encoder: 0.1164 (0.1483)  labels_decoder: 0.1145 (0.1269)  labels_encoder_unscaled: 0.1164 (0.1483)  labels_decoder_unscaled: 0.2290 (0.2539)  time: 0.1568  data: 0.0006  max mem: 2688
Epoch: [2]  [1150/1406]  eta: 0:00:40  lr: 0.000010  loss: 0.2610 (0.2745)  labels_encoder: 0.1371 (0.1480)  labels_decoder: 0.1199 (0.1265)  labels_encoder_unscaled: 0.1371 (0.1480)  labels_decoder_unscaled: 0.2398 (0.2530)  time: 0.1556  data: 0.0003  max mem: 2688
Epoch: [2]  [1200/1406]  eta: 0:00:32  lr: 0.000010  loss: 0.2608 (0.2740)  labels_encoder: 0.1345 (0.1476)  labels_decoder: 0.1157 (0.1264)  labels_encoder_unscaled: 0.1345 (0.1476)  labels_decoder_unscaled: 0.2314 (0.2527)  time: 0.1562  data: 0.0003  max mem: 2688
Epoch: [2]  [1250/1406]  eta: 0:00:24  lr: 0.000010  loss: 0.2412 (0.2730)  labels_encoder: 0.1280 (0.1469)  labels_decoder: 0.1074 (0.1261)  labels_encoder_unscaled: 0.1280 (0.1469)  labels_decoder_unscaled: 0.2148 (0.2522)  time: 0.1556  data: 0.0003  max mem: 2688
Epoch: [2]  [1300/1406]  eta: 0:00:16  lr: 0.000010  loss: 0.2367 (0.2719)  labels_encoder: 0.1217 (0.1462)  labels_decoder: 0.1177 (0.1257)  labels_encoder_unscaled: 0.1217 (0.1462)  labels_decoder_unscaled: 0.2353 (0.2514)  time: 0.1545  data: 0.0004  max mem: 2688
Epoch: [2]  [1350/1406]  eta: 0:00:08  lr: 0.000010  loss: 0.2207 (0.2714)  labels_encoder: 0.1056 (0.1458)  labels_decoder: 0.1099 (0.1255)  labels_encoder_unscaled: 0.1056 (0.1458)  labels_decoder_unscaled: 0.2197 (0.2510)  time: 0.1582  data: 0.0003  max mem: 2688
Epoch: [2]  [1400/1406]  eta: 0:00:00  lr: 0.000010  loss: 0.2508 (0.2709)  labels_encoder: 0.1284 (0.1456)  labels_decoder: 0.1207 (0.1253)  labels_encoder_unscaled: 0.1284 (0.1456)  labels_decoder_unscaled: 0.2414 (0.2506)  time: 0.1373  data: 0.0003  max mem: 2688
Epoch: [2]  [1405/1406]  eta: 0:00:00  lr: 0.000010  loss: 0.2508 (0.2707)  labels_encoder: 0.1284 (0.1455)  labels_decoder: 0.1184 (0.1252)  labels_encoder_unscaled: 0.1284 (0.1455)  labels_decoder_unscaled: 0.2367 (0.2505)  time: 0.1246  data: 0.0003  max mem: 2688
Epoch: [2] Total time: 0:03:40 (0.1570 s / it)
Averaged stats: lr: 0.000010  loss: 0.2508 (0.2707)  labels_encoder: 0.1284 (0.1455)  labels_decoder: 0.1184 (0.1252)  labels_encoder_unscaled: 0.1284 (0.1455)  labels_decoder_unscaled: 0.2367 (0.2505)
Test:  [   0/1613]  eta: 1:31:19  loss: 0.8722 (0.8722)  labels_encoder: 0.5000 (0.5000)  labels_decoder: 0.3722 (0.3722)  labels_encoder_unscaled: 0.5000 (0.5000)  labels_decoder_unscaled: 0.7444 (0.7444)  time: 3.3968  data: 3.3381  max mem: 2688
Test:  [  50/1613]  eta: 0:04:28  loss: 0.4070 (0.8807)  labels_encoder: 0.2290 (0.5577)  labels_decoder: 0.1685 (0.3230)  labels_encoder_unscaled: 0.2290 (0.5577)  labels_decoder_unscaled: 0.3371 (0.6460)  time: 0.0966  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:20  loss: 0.2556 (0.7236)  labels_encoder: 0.1738 (0.4665)  labels_decoder: 0.0981 (0.2571)  labels_encoder_unscaled: 0.1738 (0.4665)  labels_decoder_unscaled: 0.1961 (0.5142)  time: 0.0907  data: 0.0028  max mem: 2688
Test:  [ 150/1613]  eta: 0:02:59  loss: 0.9848 (0.7435)  labels_encoder: 0.6059 (0.4797)  labels_decoder: 0.3239 (0.2638)  labels_encoder_unscaled: 0.6059 (0.4797)  labels_decoder_unscaled: 0.6478 (0.5276)  time: 0.1002  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:45  loss: 1.0569 (0.9430)  labels_encoder: 0.6517 (0.6172)  labels_decoder: 0.4336 (0.3258)  labels_encoder_unscaled: 0.6517 (0.6172)  labels_decoder_unscaled: 0.8672 (0.6516)  time: 0.1116  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:34  loss: 0.6152 (1.0090)  labels_encoder: 0.3455 (0.6582)  labels_decoder: 0.2473 (0.3507)  labels_encoder_unscaled: 0.3455 (0.6582)  labels_decoder_unscaled: 0.4946 (0.7015)  time: 0.1026  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:26  loss: 0.6921 (1.0231)  labels_encoder: 0.4401 (0.6687)  labels_decoder: 0.2586 (0.3545)  labels_encoder_unscaled: 0.4401 (0.6687)  labels_decoder_unscaled: 0.5171 (0.7089)  time: 0.0940  data: 0.0002  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:19  loss: 1.1763 (1.0161)  labels_encoder: 0.7147 (0.6575)  labels_decoder: 0.4525 (0.3586)  labels_encoder_unscaled: 0.7147 (0.6575)  labels_decoder_unscaled: 0.9051 (0.7172)  time: 0.0970  data: 0.0002  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:11  loss: 0.8219 (1.1419)  labels_encoder: 0.4678 (0.7417)  labels_decoder: 0.3298 (0.4002)  labels_encoder_unscaled: 0.4678 (0.7417)  labels_decoder_unscaled: 0.6597 (0.8003)  time: 0.0877  data: 0.0024  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:05  loss: 0.7139 (1.2177)  labels_encoder: 0.4789 (0.7927)  labels_decoder: 0.2568 (0.4250)  labels_encoder_unscaled: 0.4789 (0.7927)  labels_decoder_unscaled: 0.5135 (0.8500)  time: 0.1177  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:58  loss: 0.3188 (1.1689)  labels_encoder: 0.1503 (0.7590)  labels_decoder: 0.1728 (0.4100)  labels_encoder_unscaled: 0.1503 (0.7590)  labels_decoder_unscaled: 0.3456 (0.8199)  time: 0.0974  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:53  loss: 0.7857 (1.1571)  labels_encoder: 0.4609 (0.7502)  labels_decoder: 0.2968 (0.4069)  labels_encoder_unscaled: 0.4609 (0.7502)  labels_decoder_unscaled: 0.5937 (0.8138)  time: 0.1025  data: 0.0002  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:47  loss: 0.9842 (1.1847)  labels_encoder: 0.6357 (0.7752)  labels_decoder: 0.4689 (0.4095)  labels_encoder_unscaled: 0.6357 (0.7752)  labels_decoder_unscaled: 0.9377 (0.8190)  time: 0.0989  data: 0.0002  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:41  loss: 0.9295 (1.1644)  labels_encoder: 0.5152 (0.7571)  labels_decoder: 0.4294 (0.4073)  labels_encoder_unscaled: 0.5152 (0.7571)  labels_decoder_unscaled: 0.8587 (0.8145)  time: 0.1005  data: 0.0002  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:36  loss: 0.5427 (1.1416)  labels_encoder: 0.3194 (0.7411)  labels_decoder: 0.2242 (0.4004)  labels_encoder_unscaled: 0.3194 (0.7411)  labels_decoder_unscaled: 0.4484 (0.8009)  time: 0.1055  data: 0.0002  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:30  loss: 0.9128 (1.1248)  labels_encoder: 0.5254 (0.7293)  labels_decoder: 0.3321 (0.3955)  labels_encoder_unscaled: 0.5254 (0.7293)  labels_decoder_unscaled: 0.6642 (0.7909)  time: 0.0989  data: 0.0051  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:24  loss: 1.4386 (1.1326)  labels_encoder: 0.9325 (0.7365)  labels_decoder: 0.4914 (0.3961)  labels_encoder_unscaled: 0.9325 (0.7365)  labels_decoder_unscaled: 0.9828 (0.7922)  time: 0.1020  data: 0.0043  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:19  loss: 1.2067 (1.1279)  labels_encoder: 0.7437 (0.7309)  labels_decoder: 0.5007 (0.3970)  labels_encoder_unscaled: 0.7437 (0.7309)  labels_decoder_unscaled: 1.0014 (0.7939)  time: 0.0989  data: 0.0002  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:13  loss: 0.6935 (1.1477)  labels_encoder: 0.4117 (0.7448)  labels_decoder: 0.2818 (0.4029)  labels_encoder_unscaled: 0.4117 (0.7448)  labels_decoder_unscaled: 0.5635 (0.8057)  time: 0.0889  data: 0.0077  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:08  loss: 1.0264 (1.1373)  labels_encoder: 0.7314 (0.7396)  labels_decoder: 0.3048 (0.3976)  labels_encoder_unscaled: 0.7314 (0.7396)  labels_decoder_unscaled: 0.6096 (0.7952)  time: 0.1007  data: 0.0157  max mem: 2688
Test:  [1000/1613]  eta: 0:01:03  loss: 0.5526 (1.1248)  labels_encoder: 0.3144 (0.7306)  labels_decoder: 0.2117 (0.3942)  labels_encoder_unscaled: 0.3144 (0.7306)  labels_decoder_unscaled: 0.4234 (0.7884)  time: 0.1105  data: 0.0002  max mem: 2688
Test:  [1050/1613]  eta: 0:00:58  loss: 0.8660 (1.1216)  labels_encoder: 0.5301 (0.7294)  labels_decoder: 0.3396 (0.3923)  labels_encoder_unscaled: 0.5301 (0.7294)  labels_decoder_unscaled: 0.6792 (0.7845)  time: 0.1088  data: 0.0133  max mem: 2688
Test:  [1100/1613]  eta: 0:00:52  loss: 0.8560 (1.1345)  labels_encoder: 0.5410 (0.7396)  labels_decoder: 0.3478 (0.3949)  labels_encoder_unscaled: 0.5410 (0.7396)  labels_decoder_unscaled: 0.6956 (0.7897)  time: 0.1007  data: 0.0002  max mem: 2688
Test:  [1150/1613]  eta: 0:00:47  loss: 0.5887 (1.1186)  labels_encoder: 0.3623 (0.7283)  labels_decoder: 0.2360 (0.3902)  labels_encoder_unscaled: 0.3623 (0.7283)  labels_decoder_unscaled: 0.4720 (0.7805)  time: 0.1066  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:42  loss: 0.5421 (1.1239)  labels_encoder: 0.3587 (0.7314)  labels_decoder: 0.2170 (0.3925)  labels_encoder_unscaled: 0.3587 (0.7314)  labels_decoder_unscaled: 0.4340 (0.7851)  time: 0.0867  data: 0.0002  max mem: 2688
Test:  [1250/1613]  eta: 0:00:37  loss: 0.3348 (1.1245)  labels_encoder: 0.2115 (0.7316)  labels_decoder: 0.1508 (0.3929)  labels_encoder_unscaled: 0.2115 (0.7316)  labels_decoder_unscaled: 0.3016 (0.7858)  time: 0.1011  data: 0.0002  max mem: 2688
Test:  [1300/1613]  eta: 0:00:32  loss: 0.8124 (1.1164)  labels_encoder: 0.5481 (0.7258)  labels_decoder: 0.2850 (0.3906)  labels_encoder_unscaled: 0.5481 (0.7258)  labels_decoder_unscaled: 0.5699 (0.7813)  time: 0.1128  data: 0.0003  max mem: 2688
Test:  [1350/1613]  eta: 0:00:27  loss: 0.9077 (1.1411)  labels_encoder: 0.6644 (0.7437)  labels_decoder: 0.3463 (0.3974)  labels_encoder_unscaled: 0.6644 (0.7437)  labels_decoder_unscaled: 0.6927 (0.7949)  time: 0.0989  data: 0.0002  max mem: 2688
Test:  [1400/1613]  eta: 0:00:22  loss: 0.9170 (1.1331)  labels_encoder: 0.6117 (0.7381)  labels_decoder: 0.3522 (0.3950)  labels_encoder_unscaled: 0.6117 (0.7381)  labels_decoder_unscaled: 0.7045 (0.7899)  time: 0.1035  data: 0.0002  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.6573 (1.1467)  labels_encoder: 0.4369 (0.7468)  labels_decoder: 0.2737 (0.3999)  labels_encoder_unscaled: 0.4369 (0.7468)  labels_decoder_unscaled: 0.5475 (0.7998)  time: 0.1098  data: 0.0002  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.8154 (1.1546)  labels_encoder: 0.4985 (0.7523)  labels_decoder: 0.2924 (0.4022)  labels_encoder_unscaled: 0.4985 (0.7523)  labels_decoder_unscaled: 0.5847 (0.8044)  time: 0.0999  data: 0.0002  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6372 (1.1506)  labels_encoder: 0.3955 (0.7506)  labels_decoder: 0.2503 (0.4001)  labels_encoder_unscaled: 0.3955 (0.7506)  labels_decoder_unscaled: 0.5005 (0.8002)  time: 0.1004  data: 0.0002  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9426 (1.1479)  labels_encoder: 0.5561 (0.7482)  labels_decoder: 0.4306 (0.3997)  labels_encoder_unscaled: 0.5561 (0.7482)  labels_decoder_unscaled: 0.8611 (0.7995)  time: 0.0993  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.9426 (1.1474)  labels_encoder: 0.5561 (0.7481)  labels_decoder: 0.3865 (0.3993)  labels_encoder_unscaled: 0.5561 (0.7481)  labels_decoder_unscaled: 0.7729 (0.7986)  time: 0.0816  data: 0.0001  max mem: 2688
Test: Total time: 0:02:47 (0.1041 s / it)
Averaged stats: loss: 0.9426 (1.1474)  labels_encoder: 0.5561 (0.7481)  labels_decoder: 0.3865 (0.3993)  labels_encoder_unscaled: 0.5561 (0.7481)  labels_decoder_unscaled: 0.7729 (0.7986)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5788

dec_mAP all together: | 0.4594746865213887 |.
dec_mAP_pred | 0 : 0.5065237694716097 |.
dec_mAP_pred | 1 : 0.4973703460847685 |.
dec_mAP_pred | 2 : 0.48422198817640066 |.
dec_mAP_pred | 3 : 0.46965743022865264 |.
dec_mAP_pred | 4 : 0.45455982121867045 |.
dec_mAP_pred | 5 : 0.43958829217634976 |.
dec_mAP_pred | 6 : 0.4249313111376313 |.
dec_mAP_pred | 7 : 0.4115524524760506 |.
all decoder map: | 0.4611 |.
BaseballPitch: 0.0949
BasketballDunk: 0.7614
Billiards: 0.4892
CleanAndJerk: 0.7623
CliffDiving: 0.7951
CricketBowling: 0.4786
CricketShot: 0.1985
Diving: 0.6771
FrisbeeCatch: 0.2973
GolfSwing: 0.6334
HammerThrow: 0.8617
HighJump: 0.6278
JavelinThrow: 0.6990
LongJump: 0.7761
PoleVault: 0.8758
Shotput: 0.6938
SoccerPenalty: 0.3126
TennisSwing: 0.5124
ThrowDiscus: 0.6680
VolleyballSpiking: 0.3607
Epoch: [3]  [   0/1406]  eta: 1:12:20  lr: 0.000001  loss: 0.2244 (0.2244)  labels_encoder: 0.1117 (0.1117)  labels_decoder: 0.1126 (0.1126)  labels_encoder_unscaled: 0.1117 (0.1117)  labels_decoder_unscaled: 0.2253 (0.2253)  time: 3.0868  data: 2.7755  max mem: 2688
Epoch: [3]  [  50/1406]  eta: 0:05:10  lr: 0.000001  loss: 0.2333 (0.2375)  labels_encoder: 0.1166 (0.1208)  labels_decoder: 0.1116 (0.1167)  labels_encoder_unscaled: 0.1166 (0.1208)  labels_decoder_unscaled: 0.2232 (0.2335)  time: 0.1606  data: 0.0003  max mem: 2688
Epoch: [3]  [ 100/1406]  eta: 0:04:14  lr: 0.000001  loss: 0.2484 (0.2395)  labels_encoder: 0.1347 (0.1238)  labels_decoder: 0.1157 (0.1157)  labels_encoder_unscaled: 0.1347 (0.1238)  labels_decoder_unscaled: 0.2315 (0.2314)  time: 0.1539  data: 0.0003  max mem: 2688
Epoch: [3]  [ 150/1406]  eta: 0:03:47  lr: 0.000001  loss: 0.2308 (0.2387)  labels_encoder: 0.1095 (0.1231)  labels_decoder: 0.1180 (0.1155)  labels_encoder_unscaled: 0.1095 (0.1231)  labels_decoder_unscaled: 0.2359 (0.2310)  time: 0.1537  data: 0.0003  max mem: 2688
Epoch: [3]  [ 200/1406]  eta: 0:03:33  lr: 0.000001  loss: 0.2350 (0.2381)  labels_encoder: 0.1252 (0.1236)  labels_decoder: 0.1044 (0.1145)  labels_encoder_unscaled: 0.1252 (0.1236)  labels_decoder_unscaled: 0.2089 (0.2290)  time: 0.1606  data: 0.0003  max mem: 2688
Epoch: [3]  [ 250/1406]  eta: 0:03:19  lr: 0.000001  loss: 0.2406 (0.2387)  labels_encoder: 0.1238 (0.1236)  labels_decoder: 0.1162 (0.1150)  labels_encoder_unscaled: 0.1238 (0.1236)  labels_decoder_unscaled: 0.2324 (0.2300)  time: 0.1571  data: 0.0003  max mem: 2688
Epoch: [3]  [ 300/1406]  eta: 0:03:08  lr: 0.000001  loss: 0.2317 (0.2373)  labels_encoder: 0.1171 (0.1227)  labels_decoder: 0.1117 (0.1146)  labels_encoder_unscaled: 0.1171 (0.1227)  labels_decoder_unscaled: 0.2233 (0.2291)  time: 0.1626  data: 0.0003  max mem: 2688
Epoch: [3]  [ 350/1406]  eta: 0:02:58  lr: 0.000001  loss: 0.2172 (0.2367)  labels_encoder: 0.1235 (0.1225)  labels_decoder: 0.1031 (0.1142)  labels_encoder_unscaled: 0.1235 (0.1225)  labels_decoder_unscaled: 0.2061 (0.2284)  time: 0.1675  data: 0.0003  max mem: 2688
Epoch: [3]  [ 400/1406]  eta: 0:02:48  lr: 0.000001  loss: 0.2584 (0.2372)  labels_encoder: 0.1369 (0.1229)  labels_decoder: 0.1131 (0.1143)  labels_encoder_unscaled: 0.1369 (0.1229)  labels_decoder_unscaled: 0.2261 (0.2286)  time: 0.1530  data: 0.0003  max mem: 2688
Epoch: [3]  [ 450/1406]  eta: 0:02:38  lr: 0.000001  loss: 0.2328 (0.2368)  labels_encoder: 0.1114 (0.1230)  labels_decoder: 0.1096 (0.1138)  labels_encoder_unscaled: 0.1114 (0.1230)  labels_decoder_unscaled: 0.2192 (0.2276)  time: 0.1518  data: 0.0003  max mem: 2688
Epoch: [3]  [ 500/1406]  eta: 0:02:29  lr: 0.000001  loss: 0.2305 (0.2359)  labels_encoder: 0.1205 (0.1222)  labels_decoder: 0.1126 (0.1136)  labels_encoder_unscaled: 0.1205 (0.1222)  labels_decoder_unscaled: 0.2252 (0.2273)  time: 0.1586  data: 0.0003  max mem: 2688
Epoch: [3]  [ 550/1406]  eta: 0:02:20  lr: 0.000001  loss: 0.2243 (0.2366)  labels_encoder: 0.1105 (0.1224)  labels_decoder: 0.1177 (0.1141)  labels_encoder_unscaled: 0.1105 (0.1224)  labels_decoder_unscaled: 0.2354 (0.2282)  time: 0.1550  data: 0.0003  max mem: 2688
Epoch: [3]  [ 600/1406]  eta: 0:02:11  lr: 0.000001  loss: 0.2372 (0.2373)  labels_encoder: 0.1329 (0.1231)  labels_decoder: 0.1183 (0.1142)  labels_encoder_unscaled: 0.1329 (0.1231)  labels_decoder_unscaled: 0.2367 (0.2283)  time: 0.1486  data: 0.0004  max mem: 2688
Epoch: [3]  [ 650/1406]  eta: 0:02:02  lr: 0.000001  loss: 0.2407 (0.2372)  labels_encoder: 0.1275 (0.1231)  labels_decoder: 0.1159 (0.1141)  labels_encoder_unscaled: 0.1275 (0.1231)  labels_decoder_unscaled: 0.2318 (0.2282)  time: 0.1480  data: 0.0003  max mem: 2688
Epoch: [3]  [ 700/1406]  eta: 0:01:53  lr: 0.000001  loss: 0.2284 (0.2371)  labels_encoder: 0.1103 (0.1227)  labels_decoder: 0.1161 (0.1144)  labels_encoder_unscaled: 0.1103 (0.1227)  labels_decoder_unscaled: 0.2322 (0.2288)  time: 0.1466  data: 0.0003  max mem: 2688
Epoch: [3]  [ 750/1406]  eta: 0:01:44  lr: 0.000001  loss: 0.2370 (0.2374)  labels_encoder: 0.1185 (0.1230)  labels_decoder: 0.1119 (0.1144)  labels_encoder_unscaled: 0.1185 (0.1230)  labels_decoder_unscaled: 0.2239 (0.2288)  time: 0.1459  data: 0.0003  max mem: 2688
Epoch: [3]  [ 800/1406]  eta: 0:01:36  lr: 0.000001  loss: 0.2256 (0.2375)  labels_encoder: 0.1111 (0.1231)  labels_decoder: 0.1103 (0.1144)  labels_encoder_unscaled: 0.1111 (0.1231)  labels_decoder_unscaled: 0.2206 (0.2289)  time: 0.1546  data: 0.0003  max mem: 2688
Epoch: [3]  [ 850/1406]  eta: 0:01:28  lr: 0.000001  loss: 0.2224 (0.2371)  labels_encoder: 0.1110 (0.1228)  labels_decoder: 0.1122 (0.1142)  labels_encoder_unscaled: 0.1110 (0.1228)  labels_decoder_unscaled: 0.2244 (0.2285)  time: 0.1458  data: 0.0003  max mem: 2688
Epoch: [3]  [ 900/1406]  eta: 0:01:19  lr: 0.000001  loss: 0.2370 (0.2373)  labels_encoder: 0.1287 (0.1231)  labels_decoder: 0.1077 (0.1143)  labels_encoder_unscaled: 0.1287 (0.1231)  labels_decoder_unscaled: 0.2154 (0.2285)  time: 0.1507  data: 0.0003  max mem: 2688
Epoch: [3]  [ 950/1406]  eta: 0:01:12  lr: 0.000001  loss: 0.2463 (0.2377)  labels_encoder: 0.1268 (0.1234)  labels_decoder: 0.1202 (0.1143)  labels_encoder_unscaled: 0.1268 (0.1234)  labels_decoder_unscaled: 0.2403 (0.2285)  time: 0.1753  data: 0.0003  max mem: 2688
Epoch: [3]  [1000/1406]  eta: 0:01:04  lr: 0.000001  loss: 0.2303 (0.2378)  labels_encoder: 0.1176 (0.1236)  labels_decoder: 0.1162 (0.1142)  labels_encoder_unscaled: 0.1176 (0.1236)  labels_decoder_unscaled: 0.2325 (0.2285)  time: 0.1566  data: 0.0003  max mem: 2688
Epoch: [3]  [1050/1406]  eta: 0:00:56  lr: 0.000001  loss: 0.2499 (0.2380)  labels_encoder: 0.1243 (0.1237)  labels_decoder: 0.1152 (0.1144)  labels_encoder_unscaled: 0.1243 (0.1237)  labels_decoder_unscaled: 0.2303 (0.2287)  time: 0.1568  data: 0.0003  max mem: 2688
Epoch: [3]  [1100/1406]  eta: 0:00:48  lr: 0.000001  loss: 0.2561 (0.2379)  labels_encoder: 0.1380 (0.1237)  labels_decoder: 0.1154 (0.1143)  labels_encoder_unscaled: 0.1380 (0.1237)  labels_decoder_unscaled: 0.2308 (0.2285)  time: 0.1529  data: 0.0003  max mem: 2688
Epoch: [3]  [1150/1406]  eta: 0:00:40  lr: 0.000001  loss: 0.2299 (0.2379)  labels_encoder: 0.1194 (0.1237)  labels_decoder: 0.1074 (0.1142)  labels_encoder_unscaled: 0.1194 (0.1237)  labels_decoder_unscaled: 0.2149 (0.2285)  time: 0.1550  data: 0.0003  max mem: 2688
Epoch: [3]  [1200/1406]  eta: 0:00:32  lr: 0.000001  loss: 0.2397 (0.2381)  labels_encoder: 0.1158 (0.1236)  labels_decoder: 0.1222 (0.1145)  labels_encoder_unscaled: 0.1158 (0.1236)  labels_decoder_unscaled: 0.2444 (0.2290)  time: 0.1535  data: 0.0003  max mem: 2688
Epoch: [3]  [1250/1406]  eta: 0:00:24  lr: 0.000001  loss: 0.2477 (0.2381)  labels_encoder: 0.1303 (0.1237)  labels_decoder: 0.1085 (0.1145)  labels_encoder_unscaled: 0.1303 (0.1237)  labels_decoder_unscaled: 0.2169 (0.2289)  time: 0.1560  data: 0.0003  max mem: 2688
Epoch: [3]  [1300/1406]  eta: 0:00:16  lr: 0.000001  loss: 0.2204 (0.2379)  labels_encoder: 0.1122 (0.1236)  labels_decoder: 0.1082 (0.1143)  labels_encoder_unscaled: 0.1122 (0.1236)  labels_decoder_unscaled: 0.2164 (0.2287)  time: 0.1551  data: 0.0003  max mem: 2688
Epoch: [3]  [1350/1406]  eta: 0:00:08  lr: 0.000001  loss: 0.2175 (0.2378)  labels_encoder: 0.1029 (0.1234)  labels_decoder: 0.1101 (0.1144)  labels_encoder_unscaled: 0.1029 (0.1234)  labels_decoder_unscaled: 0.2202 (0.2287)  time: 0.1509  data: 0.0003  max mem: 2688
Epoch: [3]  [1400/1406]  eta: 0:00:00  lr: 0.000001  loss: 0.2113 (0.2375)  labels_encoder: 0.1019 (0.1232)  labels_decoder: 0.1124 (0.1144)  labels_encoder_unscaled: 0.1019 (0.1232)  labels_decoder_unscaled: 0.2248 (0.2288)  time: 0.1342  data: 0.0005  max mem: 2688
Epoch: [3]  [1405/1406]  eta: 0:00:00  lr: 0.000001  loss: 0.2068 (0.2375)  labels_encoder: 0.1010 (0.1232)  labels_decoder: 0.1076 (0.1144)  labels_encoder_unscaled: 0.1010 (0.1232)  labels_decoder_unscaled: 0.2152 (0.2287)  time: 0.1202  data: 0.0004  max mem: 2688
Epoch: [3] Total time: 0:03:40 (0.1570 s / it)
Averaged stats: lr: 0.000001  loss: 0.2068 (0.2375)  labels_encoder: 0.1010 (0.1232)  labels_decoder: 0.1076 (0.1144)  labels_encoder_unscaled: 0.1010 (0.1232)  labels_decoder_unscaled: 0.2152 (0.2287)
Test:  [   0/1613]  eta: 1:18:29  loss: 0.9100 (0.9100)  labels_encoder: 0.5642 (0.5642)  labels_decoder: 0.3458 (0.3458)  labels_encoder_unscaled: 0.5642 (0.5642)  labels_decoder_unscaled: 0.6915 (0.6915)  time: 2.9198  data: 2.7817  max mem: 2688
Test:  [  50/1613]  eta: 0:04:08  loss: 0.4856 (0.8947)  labels_encoder: 0.2353 (0.5650)  labels_decoder: 0.1941 (0.3296)  labels_encoder_unscaled: 0.2353 (0.5650)  labels_decoder_unscaled: 0.3881 (0.6593)  time: 0.1018  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:14  loss: 0.2281 (0.7221)  labels_encoder: 0.1406 (0.4616)  labels_decoder: 0.0593 (0.2605)  labels_encoder_unscaled: 0.1406 (0.4616)  labels_decoder_unscaled: 0.1187 (0.5210)  time: 0.0954  data: 0.0002  max mem: 2688
Test:  [ 150/1613]  eta: 0:02:51  loss: 0.9469 (0.7597)  labels_encoder: 0.6476 (0.4858)  labels_decoder: 0.3259 (0.2739)  labels_encoder_unscaled: 0.6476 (0.4858)  labels_decoder_unscaled: 0.6518 (0.5479)  time: 0.0913  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:37  loss: 1.0465 (0.9372)  labels_encoder: 0.6401 (0.6079)  labels_decoder: 0.4147 (0.3293)  labels_encoder_unscaled: 0.6401 (0.6079)  labels_decoder_unscaled: 0.8294 (0.6586)  time: 0.0958  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:29  loss: 0.6552 (1.0048)  labels_encoder: 0.3588 (0.6500)  labels_decoder: 0.2382 (0.3548)  labels_encoder_unscaled: 0.3588 (0.6500)  labels_decoder_unscaled: 0.4764 (0.7097)  time: 0.1025  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:20  loss: 0.7194 (1.0211)  labels_encoder: 0.4492 (0.6623)  labels_decoder: 0.2742 (0.3588)  labels_encoder_unscaled: 0.4492 (0.6623)  labels_decoder_unscaled: 0.5484 (0.7176)  time: 0.0960  data: 0.0002  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:14  loss: 1.1601 (1.0166)  labels_encoder: 0.6789 (0.6538)  labels_decoder: 0.4463 (0.3628)  labels_encoder_unscaled: 0.6789 (0.6538)  labels_decoder_unscaled: 0.8925 (0.7257)  time: 0.1049  data: 0.0002  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:07  loss: 0.8129 (1.1349)  labels_encoder: 0.4323 (0.7346)  labels_decoder: 0.3299 (0.4003)  labels_encoder_unscaled: 0.4323 (0.7346)  labels_decoder_unscaled: 0.6599 (0.8005)  time: 0.0922  data: 0.0002  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:00  loss: 0.7087 (1.2173)  labels_encoder: 0.4364 (0.7903)  labels_decoder: 0.2910 (0.4270)  labels_encoder_unscaled: 0.4364 (0.7903)  labels_decoder_unscaled: 0.5820 (0.8540)  time: 0.0936  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:55  loss: 0.3319 (1.1658)  labels_encoder: 0.1595 (0.7550)  labels_decoder: 0.1771 (0.4108)  labels_encoder_unscaled: 0.1595 (0.7550)  labels_decoder_unscaled: 0.3542 (0.8216)  time: 0.1038  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:50  loss: 0.8945 (1.1540)  labels_encoder: 0.5309 (0.7465)  labels_decoder: 0.2972 (0.4075)  labels_encoder_unscaled: 0.5309 (0.7465)  labels_decoder_unscaled: 0.5944 (0.8149)  time: 0.1022  data: 0.0002  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:44  loss: 1.0190 (1.1866)  labels_encoder: 0.6409 (0.7750)  labels_decoder: 0.4499 (0.4117)  labels_encoder_unscaled: 0.6409 (0.7750)  labels_decoder_unscaled: 0.8997 (0.8233)  time: 0.0954  data: 0.0002  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:39  loss: 1.0406 (1.1702)  labels_encoder: 0.5231 (0.7597)  labels_decoder: 0.4348 (0.4106)  labels_encoder_unscaled: 0.5231 (0.7597)  labels_decoder_unscaled: 0.8695 (0.8211)  time: 0.1042  data: 0.0024  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:34  loss: 0.5374 (1.1459)  labels_encoder: 0.2831 (0.7429)  labels_decoder: 0.2124 (0.4030)  labels_encoder_unscaled: 0.2831 (0.7429)  labels_decoder_unscaled: 0.4247 (0.8061)  time: 0.1102  data: 0.0002  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:29  loss: 1.0393 (1.1299)  labels_encoder: 0.5855 (0.7314)  labels_decoder: 0.3499 (0.3984)  labels_encoder_unscaled: 0.5855 (0.7314)  labels_decoder_unscaled: 0.6998 (0.7969)  time: 0.1077  data: 0.0002  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:23  loss: 1.1520 (1.1317)  labels_encoder: 0.7494 (0.7343)  labels_decoder: 0.4027 (0.3974)  labels_encoder_unscaled: 0.7494 (0.7343)  labels_decoder_unscaled: 0.8053 (0.7947)  time: 0.0921  data: 0.0002  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:18  loss: 1.4015 (1.1281)  labels_encoder: 0.7770 (0.7297)  labels_decoder: 0.5395 (0.3984)  labels_encoder_unscaled: 0.7770 (0.7297)  labels_decoder_unscaled: 1.0789 (0.7968)  time: 0.0998  data: 0.0002  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:13  loss: 0.7528 (1.1491)  labels_encoder: 0.4453 (0.7446)  labels_decoder: 0.3099 (0.4044)  labels_encoder_unscaled: 0.4453 (0.7446)  labels_decoder_unscaled: 0.6199 (0.8089)  time: 0.0863  data: 0.0002  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:07  loss: 0.8759 (1.1365)  labels_encoder: 0.6400 (0.7377)  labels_decoder: 0.3075 (0.3989)  labels_encoder_unscaled: 0.6400 (0.7377)  labels_decoder_unscaled: 0.6151 (0.7977)  time: 0.0990  data: 0.0002  max mem: 2688
Test:  [1000/1613]  eta: 0:01:02  loss: 0.5381 (1.1232)  labels_encoder: 0.2976 (0.7280)  labels_decoder: 0.2405 (0.3952)  labels_encoder_unscaled: 0.2976 (0.7280)  labels_decoder_unscaled: 0.4810 (0.7904)  time: 0.1026  data: 0.0002  max mem: 2688
Test:  [1050/1613]  eta: 0:00:57  loss: 0.8582 (1.1186)  labels_encoder: 0.5087 (0.7257)  labels_decoder: 0.3553 (0.3929)  labels_encoder_unscaled: 0.5087 (0.7257)  labels_decoder_unscaled: 0.7106 (0.7859)  time: 0.1062  data: 0.0025  max mem: 2688
Test:  [1100/1613]  eta: 0:00:52  loss: 0.9161 (1.1241)  labels_encoder: 0.5393 (0.7310)  labels_decoder: 0.3414 (0.3932)  labels_encoder_unscaled: 0.5393 (0.7310)  labels_decoder_unscaled: 0.6829 (0.7863)  time: 0.0986  data: 0.0021  max mem: 2688
Test:  [1150/1613]  eta: 0:00:47  loss: 0.6148 (1.1103)  labels_encoder: 0.3684 (0.7208)  labels_decoder: 0.2739 (0.3895)  labels_encoder_unscaled: 0.3684 (0.7208)  labels_decoder_unscaled: 0.5478 (0.7789)  time: 0.0890  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:42  loss: 0.5265 (1.1174)  labels_encoder: 0.3511 (0.7252)  labels_decoder: 0.2357 (0.3921)  labels_encoder_unscaled: 0.3511 (0.7252)  labels_decoder_unscaled: 0.4714 (0.7843)  time: 0.1032  data: 0.0002  max mem: 2688
Test:  [1250/1613]  eta: 0:00:36  loss: 0.3398 (1.1179)  labels_encoder: 0.2276 (0.7254)  labels_decoder: 0.1487 (0.3925)  labels_encoder_unscaled: 0.2276 (0.7254)  labels_decoder_unscaled: 0.2974 (0.7850)  time: 0.1031  data: 0.0026  max mem: 2688
Test:  [1300/1613]  eta: 0:00:31  loss: 0.6465 (1.1083)  labels_encoder: 0.4291 (0.7186)  labels_decoder: 0.2647 (0.3898)  labels_encoder_unscaled: 0.4291 (0.7186)  labels_decoder_unscaled: 0.5294 (0.7795)  time: 0.1055  data: 0.0002  max mem: 2688
Test:  [1350/1613]  eta: 0:00:26  loss: 0.8057 (1.1281)  labels_encoder: 0.5668 (0.7330)  labels_decoder: 0.3533 (0.3951)  labels_encoder_unscaled: 0.5668 (0.7330)  labels_decoder_unscaled: 0.7067 (0.7902)  time: 0.0992  data: 0.0002  max mem: 2688
Test:  [1400/1613]  eta: 0:00:21  loss: 0.9336 (1.1202)  labels_encoder: 0.6066 (0.7276)  labels_decoder: 0.3624 (0.3926)  labels_encoder_unscaled: 0.6066 (0.7276)  labels_decoder_unscaled: 0.7249 (0.7852)  time: 0.0947  data: 0.0002  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.6697 (1.1337)  labels_encoder: 0.4301 (0.7365)  labels_decoder: 0.2722 (0.3972)  labels_encoder_unscaled: 0.4301 (0.7365)  labels_decoder_unscaled: 0.5444 (0.7944)  time: 0.1030  data: 0.0002  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.8487 (1.1421)  labels_encoder: 0.5506 (0.7426)  labels_decoder: 0.3040 (0.3995)  labels_encoder_unscaled: 0.5506 (0.7426)  labels_decoder_unscaled: 0.6080 (0.7990)  time: 0.0848  data: 0.0002  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6420 (1.1383)  labels_encoder: 0.4403 (0.7407)  labels_decoder: 0.2537 (0.3976)  labels_encoder_unscaled: 0.4403 (0.7407)  labels_decoder_unscaled: 0.5074 (0.7951)  time: 0.0986  data: 0.0039  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9130 (1.1342)  labels_encoder: 0.5355 (0.7376)  labels_decoder: 0.4011 (0.3966)  labels_encoder_unscaled: 0.5355 (0.7376)  labels_decoder_unscaled: 0.8022 (0.7933)  time: 0.1075  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.9130 (1.1337)  labels_encoder: 0.5355 (0.7376)  labels_decoder: 0.3775 (0.3962)  labels_encoder_unscaled: 0.5355 (0.7376)  labels_decoder_unscaled: 0.7551 (0.7923)  time: 0.0820  data: 0.0001  max mem: 2688
Test: Total time: 0:02:43 (0.1013 s / it)
Averaged stats: loss: 0.9130 (1.1337)  labels_encoder: 0.5355 (0.7376)  labels_decoder: 0.3775 (0.3962)  labels_encoder_unscaled: 0.5355 (0.7376)  labels_decoder_unscaled: 0.7551 (0.7923)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5772

dec_mAP all together: | 0.45700994041178805 |.
dec_mAP_pred | 0 : 0.5035395606073363 |.
dec_mAP_pred | 1 : 0.4946031235319642 |.
dec_mAP_pred | 2 : 0.4815280969706531 |.
dec_mAP_pred | 3 : 0.46703801802405415 |.
dec_mAP_pred | 4 : 0.4521016334535869 |.
dec_mAP_pred | 5 : 0.43730255296344966 |.
dec_mAP_pred | 6 : 0.4227594879695853 |.
dec_mAP_pred | 7 : 0.4095262628850384 |.
all decoder map: | 0.4585 |.
BaseballPitch: 0.0983
BasketballDunk: 0.7628
Billiards: 0.4942
CleanAndJerk: 0.7550
CliffDiving: 0.7932
CricketBowling: 0.4700
CricketShot: 0.2039
Diving: 0.6778
FrisbeeCatch: 0.2870
GolfSwing: 0.6195
HammerThrow: 0.8588
HighJump: 0.6359
JavelinThrow: 0.7000
LongJump: 0.7778
PoleVault: 0.8716
Shotput: 0.6967
SoccerPenalty: 0.3063
TennisSwing: 0.5107
ThrowDiscus: 0.6568
VolleyballSpiking: 0.3668
Epoch: [4]  [   0/1406]  eta: 1:28:45  lr: 0.000000  loss: 0.2118 (0.2118)  labels_encoder: 0.0988 (0.0988)  labels_decoder: 0.1130 (0.1130)  labels_encoder_unscaled: 0.0988 (0.0988)  labels_decoder_unscaled: 0.2260 (0.2260)  time: 3.7878  data: 3.5851  max mem: 2688
Epoch: [4]  [  50/1406]  eta: 0:05:19  lr: 0.000000  loss: 0.2265 (0.2402)  labels_encoder: 0.1135 (0.1250)  labels_decoder: 0.1091 (0.1152)  labels_encoder_unscaled: 0.1135 (0.1250)  labels_decoder_unscaled: 0.2182 (0.2305)  time: 0.1583  data: 0.0003  max mem: 2688
Epoch: [4]  [ 100/1406]  eta: 0:04:12  lr: 0.000000  loss: 0.2152 (0.2362)  labels_encoder: 0.1142 (0.1226)  labels_decoder: 0.1040 (0.1136)  labels_encoder_unscaled: 0.1142 (0.1226)  labels_decoder_unscaled: 0.2080 (0.2272)  time: 0.1468  data: 0.0003  max mem: 2688
Epoch: [4]  [ 150/1406]  eta: 0:03:48  lr: 0.000000  loss: 0.2256 (0.2356)  labels_encoder: 0.1104 (0.1211)  labels_decoder: 0.1192 (0.1145)  labels_encoder_unscaled: 0.1104 (0.1211)  labels_decoder_unscaled: 0.2383 (0.2290)  time: 0.1576  data: 0.0005  max mem: 2688
Epoch: [4]  [ 200/1406]  eta: 0:03:30  lr: 0.000000  loss: 0.2082 (0.2347)  labels_encoder: 0.1025 (0.1208)  labels_decoder: 0.1106 (0.1139)  labels_encoder_unscaled: 0.1025 (0.1208)  labels_decoder_unscaled: 0.2213 (0.2277)  time: 0.1463  data: 0.0003  max mem: 2688
Epoch: [4]  [ 250/1406]  eta: 0:03:18  lr: 0.000000  loss: 0.2111 (0.2320)  labels_encoder: 0.0989 (0.1189)  labels_decoder: 0.1148 (0.1131)  labels_encoder_unscaled: 0.0989 (0.1189)  labels_decoder_unscaled: 0.2295 (0.2262)  time: 0.1635  data: 0.0003  max mem: 2688
Epoch: [4]  [ 300/1406]  eta: 0:03:06  lr: 0.000000  loss: 0.2232 (0.2318)  labels_encoder: 0.1155 (0.1192)  labels_decoder: 0.1137 (0.1126)  labels_encoder_unscaled: 0.1155 (0.1192)  labels_decoder_unscaled: 0.2274 (0.2253)  time: 0.1593  data: 0.0003  max mem: 2688
Epoch: [4]  [ 350/1406]  eta: 0:02:56  lr: 0.000000  loss: 0.2260 (0.2315)  labels_encoder: 0.1155 (0.1187)  labels_decoder: 0.1076 (0.1127)  labels_encoder_unscaled: 0.1155 (0.1187)  labels_decoder_unscaled: 0.2151 (0.2255)  time: 0.1502  data: 0.0003  max mem: 2688
Epoch: [4]  [ 400/1406]  eta: 0:02:46  lr: 0.000000  loss: 0.2525 (0.2325)  labels_encoder: 0.1499 (0.1199)  labels_decoder: 0.1177 (0.1126)  labels_encoder_unscaled: 0.1499 (0.1199)  labels_decoder_unscaled: 0.2353 (0.2253)  time: 0.1461  data: 0.0003  max mem: 2688
Epoch: [4]  [ 450/1406]  eta: 0:02:36  lr: 0.000000  loss: 0.2198 (0.2325)  labels_encoder: 0.1055 (0.1195)  labels_decoder: 0.1123 (0.1130)  labels_encoder_unscaled: 0.1055 (0.1195)  labels_decoder_unscaled: 0.2247 (0.2259)  time: 0.1652  data: 0.0003  max mem: 2688
Epoch: [4]  [ 500/1406]  eta: 0:02:27  lr: 0.000000  loss: 0.2384 (0.2330)  labels_encoder: 0.1204 (0.1198)  labels_decoder: 0.1087 (0.1132)  labels_encoder_unscaled: 0.1204 (0.1198)  labels_decoder_unscaled: 0.2175 (0.2263)  time: 0.1511  data: 0.0003  max mem: 2688
Epoch: [4]  [ 550/1406]  eta: 0:02:19  lr: 0.000000  loss: 0.2217 (0.2326)  labels_encoder: 0.1040 (0.1194)  labels_decoder: 0.1142 (0.1132)  labels_encoder_unscaled: 0.1040 (0.1194)  labels_decoder_unscaled: 0.2285 (0.2264)  time: 0.1545  data: 0.0003  max mem: 2688
Epoch: [4]  [ 600/1406]  eta: 0:02:11  lr: 0.000000  loss: 0.2262 (0.2327)  labels_encoder: 0.1115 (0.1194)  labels_decoder: 0.1078 (0.1132)  labels_encoder_unscaled: 0.1115 (0.1194)  labels_decoder_unscaled: 0.2156 (0.2265)  time: 0.1584  data: 0.0003  max mem: 2688
Epoch: [4]  [ 650/1406]  eta: 0:02:02  lr: 0.000000  loss: 0.2442 (0.2324)  labels_encoder: 0.1252 (0.1194)  labels_decoder: 0.1144 (0.1129)  labels_encoder_unscaled: 0.1252 (0.1194)  labels_decoder_unscaled: 0.2287 (0.2258)  time: 0.1606  data: 0.0003  max mem: 2688
Epoch: [4]  [ 700/1406]  eta: 0:01:53  lr: 0.000000  loss: 0.2340 (0.2327)  labels_encoder: 0.1241 (0.1198)  labels_decoder: 0.1161 (0.1129)  labels_encoder_unscaled: 0.1241 (0.1198)  labels_decoder_unscaled: 0.2322 (0.2259)  time: 0.1553  data: 0.0003  max mem: 2688
Epoch: [4]  [ 750/1406]  eta: 0:01:45  lr: 0.000000  loss: 0.2275 (0.2330)  labels_encoder: 0.1017 (0.1198)  labels_decoder: 0.1192 (0.1132)  labels_encoder_unscaled: 0.1017 (0.1198)  labels_decoder_unscaled: 0.2385 (0.2264)  time: 0.1550  data: 0.0003  max mem: 2688
Epoch: [4]  [ 800/1406]  eta: 0:01:37  lr: 0.000000  loss: 0.2217 (0.2332)  labels_encoder: 0.1108 (0.1202)  labels_decoder: 0.1045 (0.1131)  labels_encoder_unscaled: 0.1108 (0.1202)  labels_decoder_unscaled: 0.2089 (0.2262)  time: 0.1756  data: 0.0003  max mem: 2688
Epoch: [4]  [ 850/1406]  eta: 0:01:29  lr: 0.000000  loss: 0.2379 (0.2333)  labels_encoder: 0.1350 (0.1202)  labels_decoder: 0.1134 (0.1132)  labels_encoder_unscaled: 0.1350 (0.1202)  labels_decoder_unscaled: 0.2268 (0.2263)  time: 0.1586  data: 0.0003  max mem: 2688
Epoch: [4]  [ 900/1406]  eta: 0:01:20  lr: 0.000000  loss: 0.2199 (0.2333)  labels_encoder: 0.1096 (0.1201)  labels_decoder: 0.1137 (0.1131)  labels_encoder_unscaled: 0.1096 (0.1201)  labels_decoder_unscaled: 0.2273 (0.2263)  time: 0.1534  data: 0.0003  max mem: 2688
Epoch: [4]  [ 950/1406]  eta: 0:01:12  lr: 0.000000  loss: 0.2415 (0.2333)  labels_encoder: 0.1225 (0.1201)  labels_decoder: 0.1175 (0.1133)  labels_encoder_unscaled: 0.1225 (0.1201)  labels_decoder_unscaled: 0.2350 (0.2265)  time: 0.1496  data: 0.0003  max mem: 2688
Epoch: [4]  [1000/1406]  eta: 0:01:04  lr: 0.000000  loss: 0.2302 (0.2332)  labels_encoder: 0.1119 (0.1201)  labels_decoder: 0.1092 (0.1131)  labels_encoder_unscaled: 0.1119 (0.1201)  labels_decoder_unscaled: 0.2184 (0.2262)  time: 0.1444  data: 0.0003  max mem: 2688
Epoch: [4]  [1050/1406]  eta: 0:00:56  lr: 0.000000  loss: 0.2536 (0.2338)  labels_encoder: 0.1342 (0.1204)  labels_decoder: 0.1186 (0.1134)  labels_encoder_unscaled: 0.1342 (0.1204)  labels_decoder_unscaled: 0.2371 (0.2267)  time: 0.1471  data: 0.0003  max mem: 2688
Epoch: [4]  [1100/1406]  eta: 0:00:48  lr: 0.000000  loss: 0.2133 (0.2335)  labels_encoder: 0.1036 (0.1202)  labels_decoder: 0.1059 (0.1133)  labels_encoder_unscaled: 0.1036 (0.1202)  labels_decoder_unscaled: 0.2118 (0.2267)  time: 0.1546  data: 0.0003  max mem: 2688
Epoch: [4]  [1150/1406]  eta: 0:00:40  lr: 0.000000  loss: 0.2300 (0.2335)  labels_encoder: 0.1186 (0.1203)  labels_decoder: 0.1084 (0.1132)  labels_encoder_unscaled: 0.1186 (0.1203)  labels_decoder_unscaled: 0.2168 (0.2265)  time: 0.1547  data: 0.0003  max mem: 2688
Epoch: [4]  [1200/1406]  eta: 0:00:32  lr: 0.000000  loss: 0.2121 (0.2334)  labels_encoder: 0.1142 (0.1202)  labels_decoder: 0.1094 (0.1132)  labels_encoder_unscaled: 0.1142 (0.1202)  labels_decoder_unscaled: 0.2188 (0.2264)  time: 0.1511  data: 0.0003  max mem: 2688
Epoch: [4]  [1250/1406]  eta: 0:00:24  lr: 0.000000  loss: 0.2292 (0.2333)  labels_encoder: 0.1076 (0.1202)  labels_decoder: 0.1101 (0.1132)  labels_encoder_unscaled: 0.1076 (0.1202)  labels_decoder_unscaled: 0.2203 (0.2264)  time: 0.1620  data: 0.0003  max mem: 2688
Epoch: [4]  [1300/1406]  eta: 0:00:16  lr: 0.000000  loss: 0.2125 (0.2332)  labels_encoder: 0.1142 (0.1201)  labels_decoder: 0.1091 (0.1131)  labels_encoder_unscaled: 0.1142 (0.1201)  labels_decoder_unscaled: 0.2183 (0.2263)  time: 0.1597  data: 0.0003  max mem: 2688
Epoch: [4]  [1350/1406]  eta: 0:00:08  lr: 0.000000  loss: 0.2475 (0.2336)  labels_encoder: 0.1262 (0.1204)  labels_decoder: 0.1123 (0.1132)  labels_encoder_unscaled: 0.1262 (0.1204)  labels_decoder_unscaled: 0.2246 (0.2263)  time: 0.1490  data: 0.0003  max mem: 2688
Epoch: [4]  [1400/1406]  eta: 0:00:00  lr: 0.000000  loss: 0.2362 (0.2337)  labels_encoder: 0.1221 (0.1205)  labels_decoder: 0.1141 (0.1132)  labels_encoder_unscaled: 0.1221 (0.1205)  labels_decoder_unscaled: 0.2282 (0.2265)  time: 0.1350  data: 0.0004  max mem: 2688
Epoch: [4]  [1405/1406]  eta: 0:00:00  lr: 0.000000  loss: 0.2361 (0.2336)  labels_encoder: 0.1221 (0.1204)  labels_decoder: 0.1082 (0.1132)  labels_encoder_unscaled: 0.1221 (0.1204)  labels_decoder_unscaled: 0.2164 (0.2263)  time: 0.1276  data: 0.0003  max mem: 2688
Epoch: [4] Total time: 0:03:40 (0.1568 s / it)
Averaged stats: lr: 0.000000  loss: 0.2361 (0.2336)  labels_encoder: 0.1221 (0.1204)  labels_decoder: 0.1082 (0.1132)  labels_encoder_unscaled: 0.1221 (0.1204)  labels_decoder_unscaled: 0.2164 (0.2263)
Test:  [   0/1613]  eta: 1:30:05  loss: 0.9225 (0.9225)  labels_encoder: 0.5741 (0.5741)  labels_decoder: 0.3484 (0.3484)  labels_encoder_unscaled: 0.5741 (0.5741)  labels_decoder_unscaled: 0.6967 (0.6967)  time: 3.3511  data: 3.2985  max mem: 2688
Test:  [  50/1613]  eta: 0:04:25  loss: 0.4949 (0.8965)  labels_encoder: 0.2411 (0.5655)  labels_decoder: 0.1997 (0.3309)  labels_encoder_unscaled: 0.2411 (0.5655)  labels_decoder_unscaled: 0.3993 (0.6618)  time: 0.1095  data: 0.0002  max mem: 2688
Test:  [ 100/1613]  eta: 0:03:24  loss: 0.2327 (0.7234)  labels_encoder: 0.1435 (0.4620)  labels_decoder: 0.0615 (0.2614)  labels_encoder_unscaled: 0.1435 (0.4620)  labels_decoder_unscaled: 0.1231 (0.5228)  time: 0.0954  data: 0.0002  max mem: 2688
Test:  [ 150/1613]  eta: 0:02:57  loss: 0.9402 (0.7616)  labels_encoder: 0.6545 (0.4873)  labels_decoder: 0.3248 (0.2743)  labels_encoder_unscaled: 0.6545 (0.4873)  labels_decoder_unscaled: 0.6497 (0.5485)  time: 0.0926  data: 0.0002  max mem: 2688
Test:  [ 200/1613]  eta: 0:02:44  loss: 1.0610 (0.9444)  labels_encoder: 0.6577 (0.6130)  labels_decoder: 0.4283 (0.3315)  labels_encoder_unscaled: 0.6577 (0.6130)  labels_decoder_unscaled: 0.8566 (0.6629)  time: 0.0941  data: 0.0002  max mem: 2688
Test:  [ 250/1613]  eta: 0:02:36  loss: 0.6422 (1.0101)  labels_encoder: 0.3618 (0.6538)  labels_decoder: 0.2415 (0.3563)  labels_encoder_unscaled: 0.3618 (0.6538)  labels_decoder_unscaled: 0.4830 (0.7127)  time: 0.1021  data: 0.0002  max mem: 2688
Test:  [ 300/1613]  eta: 0:02:27  loss: 0.7138 (1.0240)  labels_encoder: 0.4455 (0.6644)  labels_decoder: 0.2727 (0.3596)  labels_encoder_unscaled: 0.4455 (0.6644)  labels_decoder_unscaled: 0.5453 (0.7193)  time: 0.0958  data: 0.0002  max mem: 2688
Test:  [ 350/1613]  eta: 0:02:18  loss: 1.1467 (1.0191)  labels_encoder: 0.6634 (0.6555)  labels_decoder: 0.4467 (0.3636)  labels_encoder_unscaled: 0.6634 (0.6555)  labels_decoder_unscaled: 0.8934 (0.7271)  time: 0.0915  data: 0.0002  max mem: 2688
Test:  [ 400/1613]  eta: 0:02:11  loss: 0.8231 (1.1361)  labels_encoder: 0.4370 (0.7354)  labels_decoder: 0.3304 (0.4006)  labels_encoder_unscaled: 0.4370 (0.7354)  labels_decoder_unscaled: 0.6609 (0.8012)  time: 0.0967  data: 0.0002  max mem: 2688
Test:  [ 450/1613]  eta: 0:02:05  loss: 0.7069 (1.2178)  labels_encoder: 0.4306 (0.7906)  labels_decoder: 0.2838 (0.4272)  labels_encoder_unscaled: 0.4306 (0.7906)  labels_decoder_unscaled: 0.5676 (0.8543)  time: 0.0907  data: 0.0002  max mem: 2688
Test:  [ 500/1613]  eta: 0:01:58  loss: 0.3289 (1.1669)  labels_encoder: 0.1575 (0.7558)  labels_decoder: 0.1758 (0.4111)  labels_encoder_unscaled: 0.1575 (0.7558)  labels_decoder_unscaled: 0.3516 (0.8223)  time: 0.0947  data: 0.0002  max mem: 2688
Test:  [ 550/1613]  eta: 0:01:52  loss: 0.8840 (1.1548)  labels_encoder: 0.5251 (0.7471)  labels_decoder: 0.2936 (0.4078)  labels_encoder_unscaled: 0.5251 (0.7471)  labels_decoder_unscaled: 0.5873 (0.8155)  time: 0.0994  data: 0.0002  max mem: 2688
Test:  [ 600/1613]  eta: 0:01:46  loss: 1.0485 (1.1885)  labels_encoder: 0.6587 (0.7763)  labels_decoder: 0.4384 (0.4122)  labels_encoder_unscaled: 0.6587 (0.7763)  labels_decoder_unscaled: 0.8768 (0.8243)  time: 0.0972  data: 0.0002  max mem: 2688
Test:  [ 650/1613]  eta: 0:01:41  loss: 1.0375 (1.1718)  labels_encoder: 0.5237 (0.7609)  labels_decoder: 0.4327 (0.4109)  labels_encoder_unscaled: 0.5237 (0.7609)  labels_decoder_unscaled: 0.8653 (0.8219)  time: 0.1044  data: 0.0002  max mem: 2688
Test:  [ 700/1613]  eta: 0:01:35  loss: 0.5371 (1.1477)  labels_encoder: 0.2879 (0.7442)  labels_decoder: 0.2118 (0.4035)  labels_encoder_unscaled: 0.2879 (0.7442)  labels_decoder_unscaled: 0.4237 (0.8070)  time: 0.0988  data: 0.0002  max mem: 2688
Test:  [ 750/1613]  eta: 0:01:30  loss: 1.0417 (1.1315)  labels_encoder: 0.5896 (0.7326)  labels_decoder: 0.3472 (0.3988)  labels_encoder_unscaled: 0.5896 (0.7326)  labels_decoder_unscaled: 0.6945 (0.7977)  time: 0.1055  data: 0.0002  max mem: 2688
Test:  [ 800/1613]  eta: 0:01:25  loss: 1.1703 (1.1343)  labels_encoder: 0.7619 (0.7362)  labels_decoder: 0.4084 (0.3981)  labels_encoder_unscaled: 0.7619 (0.7362)  labels_decoder_unscaled: 0.8167 (0.7962)  time: 0.1023  data: 0.0002  max mem: 2688
Test:  [ 850/1613]  eta: 0:01:19  loss: 1.4325 (1.1311)  labels_encoder: 0.7992 (0.7317)  labels_decoder: 0.5417 (0.3994)  labels_encoder_unscaled: 0.7992 (0.7317)  labels_decoder_unscaled: 1.0835 (0.7987)  time: 0.1078  data: 0.0002  max mem: 2688
Test:  [ 900/1613]  eta: 0:01:14  loss: 0.7448 (1.1522)  labels_encoder: 0.4441 (0.7467)  labels_decoder: 0.2997 (0.4055)  labels_encoder_unscaled: 0.4441 (0.7467)  labels_decoder_unscaled: 0.5995 (0.8110)  time: 0.0932  data: 0.0002  max mem: 2688
Test:  [ 950/1613]  eta: 0:01:09  loss: 0.8725 (1.1395)  labels_encoder: 0.6350 (0.7396)  labels_decoder: 0.3065 (0.3999)  labels_encoder_unscaled: 0.6350 (0.7396)  labels_decoder_unscaled: 0.6131 (0.7998)  time: 0.0905  data: 0.0002  max mem: 2688
Test:  [1000/1613]  eta: 0:01:03  loss: 0.5458 (1.1258)  labels_encoder: 0.3027 (0.7297)  labels_decoder: 0.2431 (0.3962)  labels_encoder_unscaled: 0.3027 (0.7297)  labels_decoder_unscaled: 0.4862 (0.7923)  time: 0.1065  data: 0.0002  max mem: 2688
Test:  [1050/1613]  eta: 0:00:58  loss: 0.8681 (1.1214)  labels_encoder: 0.5256 (0.7274)  labels_decoder: 0.3505 (0.3940)  labels_encoder_unscaled: 0.5256 (0.7274)  labels_decoder_unscaled: 0.7010 (0.7880)  time: 0.1043  data: 0.0002  max mem: 2688
Test:  [1100/1613]  eta: 0:00:53  loss: 0.9097 (1.1278)  labels_encoder: 0.5559 (0.7332)  labels_decoder: 0.3403 (0.3946)  labels_encoder_unscaled: 0.5559 (0.7332)  labels_decoder_unscaled: 0.6805 (0.7891)  time: 0.1059  data: 0.0002  max mem: 2688
Test:  [1150/1613]  eta: 0:00:47  loss: 0.6095 (1.1137)  labels_encoder: 0.3630 (0.7229)  labels_decoder: 0.2699 (0.3908)  labels_encoder_unscaled: 0.3630 (0.7229)  labels_decoder_unscaled: 0.5399 (0.7815)  time: 0.0939  data: 0.0002  max mem: 2688
Test:  [1200/1613]  eta: 0:00:42  loss: 0.5258 (1.1206)  labels_encoder: 0.3555 (0.7272)  labels_decoder: 0.2324 (0.3934)  labels_encoder_unscaled: 0.3555 (0.7272)  labels_decoder_unscaled: 0.4648 (0.7868)  time: 0.0962  data: 0.0002  max mem: 2688
Test:  [1250/1613]  eta: 0:00:37  loss: 0.3398 (1.1210)  labels_encoder: 0.2280 (0.7273)  labels_decoder: 0.1488 (0.3938)  labels_encoder_unscaled: 0.2280 (0.7273)  labels_decoder_unscaled: 0.2977 (0.7875)  time: 0.0978  data: 0.0002  max mem: 2688
Test:  [1300/1613]  eta: 0:00:32  loss: 0.6631 (1.1114)  labels_encoder: 0.4403 (0.7204)  labels_decoder: 0.2700 (0.3910)  labels_encoder_unscaled: 0.4403 (0.7204)  labels_decoder_unscaled: 0.5399 (0.7820)  time: 0.1104  data: 0.0002  max mem: 2688
Test:  [1350/1613]  eta: 0:00:27  loss: 0.8074 (1.1316)  labels_encoder: 0.5582 (0.7351)  labels_decoder: 0.3543 (0.3965)  labels_encoder_unscaled: 0.5582 (0.7351)  labels_decoder_unscaled: 0.7087 (0.7930)  time: 0.0998  data: 0.0002  max mem: 2688
Test:  [1400/1613]  eta: 0:00:21  loss: 0.9320 (1.1236)  labels_encoder: 0.6158 (0.7297)  labels_decoder: 0.3614 (0.3940)  labels_encoder_unscaled: 0.6158 (0.7297)  labels_decoder_unscaled: 0.7228 (0.7879)  time: 0.0942  data: 0.0002  max mem: 2688
Test:  [1450/1613]  eta: 0:00:16  loss: 0.6694 (1.1367)  labels_encoder: 0.4296 (0.7382)  labels_decoder: 0.2740 (0.3985)  labels_encoder_unscaled: 0.4296 (0.7382)  labels_decoder_unscaled: 0.5480 (0.7970)  time: 0.1142  data: 0.0002  max mem: 2688
Test:  [1500/1613]  eta: 0:00:11  loss: 0.8437 (1.1447)  labels_encoder: 0.5460 (0.7441)  labels_decoder: 0.2991 (0.4007)  labels_encoder_unscaled: 0.5460 (0.7441)  labels_decoder_unscaled: 0.5982 (0.8013)  time: 0.0973  data: 0.0002  max mem: 2688
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6325 (1.1408)  labels_encoder: 0.4338 (0.7421)  labels_decoder: 0.2536 (0.3987)  labels_encoder_unscaled: 0.4338 (0.7421)  labels_decoder_unscaled: 0.5073 (0.7975)  time: 0.0991  data: 0.0002  max mem: 2688
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9038 (1.1371)  labels_encoder: 0.5291 (0.7392)  labels_decoder: 0.3981 (0.3979)  labels_encoder_unscaled: 0.5291 (0.7392)  labels_decoder_unscaled: 0.7963 (0.7959)  time: 0.0913  data: 0.0002  max mem: 2688
Test:  [1612/1613]  eta: 0:00:00  loss: 0.9038 (1.1367)  labels_encoder: 0.5291 (0.7392)  labels_decoder: 0.3747 (0.3975)  labels_encoder_unscaled: 0.5291 (0.7392)  labels_decoder_unscaled: 0.7493 (0.7950)  time: 0.0653  data: 0.0001  max mem: 2688
Test: Total time: 0:02:44 (0.1021 s / it)
Averaged stats: loss: 0.9038 (1.1367)  labels_encoder: 0.5291 (0.7392)  labels_decoder: 0.3747 (0.3975)  labels_encoder_unscaled: 0.5291 (0.7392)  labels_decoder_unscaled: 0.7493 (0.7950)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5770

dec_mAP all together: | 0.4566859725294462 |.
dec_mAP_pred | 0 : 0.5032006052556965 |.
dec_mAP_pred | 1 : 0.49426013681898634 |.
dec_mAP_pred | 2 : 0.4812067565669185 |.
dec_mAP_pred | 3 : 0.46671226917715425 |.
dec_mAP_pred | 4 : 0.45180256102442107 |.
dec_mAP_pred | 5 : 0.4369873419366045 |.
dec_mAP_pred | 6 : 0.4224640410999386 |.
dec_mAP_pred | 7 : 0.4092205034410769 |.
all decoder map: | 0.4582 |.
BaseballPitch: 0.1000
BasketballDunk: 0.7621
Billiards: 0.4938
CleanAndJerk: 0.7548
CliffDiving: 0.7925
CricketBowling: 0.4699
CricketShot: 0.2037
Diving: 0.6769
FrisbeeCatch: 0.2867
GolfSwing: 0.6191
HammerThrow: 0.8588
HighJump: 0.6358
JavelinThrow: 0.6991
LongJump: 0.7780
PoleVault: 0.8710
Shotput: 0.6963
SoccerPenalty: 0.3055
TennisSwing: 0.5109
ThrowDiscus: 0.6572
VolleyballSpiking: 0.3673
Training time 0:29:38
