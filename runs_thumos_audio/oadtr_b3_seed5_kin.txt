Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:kin_audio
dim_feature:8192
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:5
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  79.821 M, 99.836% Params, 2.781 GMac, 100.000% MACs, 
  (linear_encoding): Linear(8.39 M, 10.493% Params, 0.537 GMac, 19.302% MACs, in_features=8192, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 23.619% Params, 1.227 GMac, 44.116% MACs, 
    (net): Sequential(
      18.884 M, 23.619% Params, 1.227 GMac, 44.116% MACs, 
      (0): Residual(
        4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
            (qkv): Linear(3.146 M, 3.935% Params, 0.204 GMac, 7.351% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
        (fn): PreNorm(
          2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
            (net): Sequential(
              2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
              (0): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
            (qkv): Linear(3.146 M, 3.935% Params, 0.204 GMac, 7.351% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
        (fn): PreNorm(
          2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
            (net): Sequential(
              2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
              (0): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
            (qkv): Linear(3.146 M, 3.935% Params, 0.204 GMac, 7.351% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
        (fn): PreNorm(
          2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
            (net): Sequential(
              2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
              (0): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.056% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 65.639% Params, 1.017 GMac, 36.573% MACs, 
    (layers): ModuleList(
      52.48 M, 65.639% Params, 1.017 GMac, 36.573% MACs, 
      (0): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.028% Params, 0.0 GMac, 0.006% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2781381676.0
Model params: 79951916
Loaded data/thumos_kin_plus_audio_val.pickle
Loaded data/thumos_kin_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1412]  eta: 1:54:33  lr: 0.000100  loss: 4.4961 (4.4961)  labels_encoder: 2.7107 (2.7107)  labels_decoder: 1.7854 (1.7854)  labels_encoder_unscaled: 2.7107 (2.7107)  labels_decoder_unscaled: 3.5708 (3.5708)  time: 4.8678  data: 3.9636  max mem: 2868
Epoch: [1]  [  50/1412]  eta: 0:08:08  lr: 0.000100  loss: 0.9672 (1.5870)  labels_encoder: 0.5954 (1.0079)  labels_decoder: 0.3729 (0.5791)  labels_encoder_unscaled: 0.5954 (1.0079)  labels_decoder_unscaled: 0.7458 (1.1581)  time: 0.2054  data: 0.0005  max mem: 3781
Epoch: [1]  [ 100/1412]  eta: 0:06:10  lr: 0.000100  loss: 0.7274 (1.1955)  labels_encoder: 0.4393 (0.7544)  labels_decoder: 0.2707 (0.4412)  labels_encoder_unscaled: 0.4393 (0.7544)  labels_decoder_unscaled: 0.5414 (0.8823)  time: 0.2075  data: 0.0005  max mem: 3781
Epoch: [1]  [ 150/1412]  eta: 0:05:22  lr: 0.000100  loss: 0.6208 (1.0193)  labels_encoder: 0.3882 (0.6398)  labels_decoder: 0.2511 (0.3795)  labels_encoder_unscaled: 0.3882 (0.6398)  labels_decoder_unscaled: 0.5022 (0.7590)  time: 0.1944  data: 0.0004  max mem: 3781
Epoch: [1]  [ 200/1412]  eta: 0:04:53  lr: 0.000100  loss: 0.5685 (0.9154)  labels_encoder: 0.3161 (0.5715)  labels_decoder: 0.2385 (0.3439)  labels_encoder_unscaled: 0.3161 (0.5715)  labels_decoder_unscaled: 0.4769 (0.6877)  time: 0.2039  data: 0.0007  max mem: 3781
Epoch: [1]  [ 250/1412]  eta: 0:04:32  lr: 0.000100  loss: 0.5033 (0.8420)  labels_encoder: 0.2852 (0.5227)  labels_decoder: 0.2099 (0.3193)  labels_encoder_unscaled: 0.2852 (0.5227)  labels_decoder_unscaled: 0.4197 (0.6386)  time: 0.1995  data: 0.0004  max mem: 3781
Epoch: [1]  [ 300/1412]  eta: 0:04:16  lr: 0.000100  loss: 0.5439 (0.7958)  labels_encoder: 0.3333 (0.4930)  labels_decoder: 0.2026 (0.3027)  labels_encoder_unscaled: 0.3333 (0.4930)  labels_decoder_unscaled: 0.4052 (0.6055)  time: 0.2008  data: 0.0005  max mem: 3781
Epoch: [1]  [ 350/1412]  eta: 0:04:01  lr: 0.000100  loss: 0.5150 (0.7568)  labels_encoder: 0.2965 (0.4670)  labels_decoder: 0.1956 (0.2899)  labels_encoder_unscaled: 0.2965 (0.4670)  labels_decoder_unscaled: 0.3913 (0.5797)  time: 0.2047  data: 0.0006  max mem: 3781
Epoch: [1]  [ 400/1412]  eta: 0:03:46  lr: 0.000100  loss: 0.4710 (0.7238)  labels_encoder: 0.2743 (0.4454)  labels_decoder: 0.1925 (0.2784)  labels_encoder_unscaled: 0.2743 (0.4454)  labels_decoder_unscaled: 0.3849 (0.5568)  time: 0.1956  data: 0.0005  max mem: 3781
Epoch: [1]  [ 450/1412]  eta: 0:03:32  lr: 0.000100  loss: 0.4734 (0.6970)  labels_encoder: 0.2829 (0.4272)  labels_decoder: 0.1961 (0.2698)  labels_encoder_unscaled: 0.2829 (0.4272)  labels_decoder_unscaled: 0.3922 (0.5395)  time: 0.1981  data: 0.0004  max mem: 3781
Epoch: [1]  [ 500/1412]  eta: 0:03:20  lr: 0.000100  loss: 0.4571 (0.6741)  labels_encoder: 0.2577 (0.4118)  labels_decoder: 0.1899 (0.2623)  labels_encoder_unscaled: 0.2577 (0.4118)  labels_decoder_unscaled: 0.3797 (0.5247)  time: 0.2195  data: 0.0004  max mem: 3781
Epoch: [1]  [ 550/1412]  eta: 0:03:07  lr: 0.000100  loss: 0.4257 (0.6559)  labels_encoder: 0.2495 (0.3994)  labels_decoder: 0.1912 (0.2565)  labels_encoder_unscaled: 0.2495 (0.3994)  labels_decoder_unscaled: 0.3823 (0.5130)  time: 0.1960  data: 0.0004  max mem: 3781
Epoch: [1]  [ 600/1412]  eta: 0:02:55  lr: 0.000100  loss: 0.4835 (0.6396)  labels_encoder: 0.2806 (0.3887)  labels_decoder: 0.2036 (0.2510)  labels_encoder_unscaled: 0.2806 (0.3887)  labels_decoder_unscaled: 0.4072 (0.5020)  time: 0.1971  data: 0.0004  max mem: 3781
Epoch: [1]  [ 650/1412]  eta: 0:02:43  lr: 0.000100  loss: 0.4518 (0.6249)  labels_encoder: 0.2616 (0.3790)  labels_decoder: 0.1926 (0.2459)  labels_encoder_unscaled: 0.2616 (0.3790)  labels_decoder_unscaled: 0.3852 (0.4919)  time: 0.2054  data: 0.0023  max mem: 3781
Epoch: [1]  [ 700/1412]  eta: 0:02:31  lr: 0.000100  loss: 0.4009 (0.6116)  labels_encoder: 0.2368 (0.3702)  labels_decoder: 0.1681 (0.2413)  labels_encoder_unscaled: 0.2368 (0.3702)  labels_decoder_unscaled: 0.3363 (0.4827)  time: 0.2003  data: 0.0006  max mem: 3781
Epoch: [1]  [ 750/1412]  eta: 0:02:21  lr: 0.000100  loss: 0.4178 (0.5995)  labels_encoder: 0.2387 (0.3621)  labels_decoder: 0.1800 (0.2374)  labels_encoder_unscaled: 0.2387 (0.3621)  labels_decoder_unscaled: 0.3599 (0.4748)  time: 0.2108  data: 0.0004  max mem: 3781
Epoch: [1]  [ 800/1412]  eta: 0:02:10  lr: 0.000100  loss: 0.4578 (0.5895)  labels_encoder: 0.2648 (0.3555)  labels_decoder: 0.1712 (0.2340)  labels_encoder_unscaled: 0.2648 (0.3555)  labels_decoder_unscaled: 0.3424 (0.4680)  time: 0.2068  data: 0.0003  max mem: 3781
Epoch: [1]  [ 850/1412]  eta: 0:01:59  lr: 0.000100  loss: 0.3881 (0.5794)  labels_encoder: 0.2369 (0.3491)  labels_decoder: 0.1612 (0.2303)  labels_encoder_unscaled: 0.2369 (0.3491)  labels_decoder_unscaled: 0.3225 (0.4607)  time: 0.1968  data: 0.0004  max mem: 3781
Epoch: [1]  [ 900/1412]  eta: 0:01:48  lr: 0.000100  loss: 0.3810 (0.5694)  labels_encoder: 0.1999 (0.3422)  labels_decoder: 0.1702 (0.2272)  labels_encoder_unscaled: 0.1999 (0.3422)  labels_decoder_unscaled: 0.3403 (0.4545)  time: 0.2031  data: 0.0004  max mem: 3781
Epoch: [1]  [ 950/1412]  eta: 0:01:37  lr: 0.000100  loss: 0.3635 (0.5604)  labels_encoder: 0.2134 (0.3364)  labels_decoder: 0.1509 (0.2240)  labels_encoder_unscaled: 0.2134 (0.3364)  labels_decoder_unscaled: 0.3017 (0.4480)  time: 0.2077  data: 0.0004  max mem: 3781
Epoch: [1]  [1000/1412]  eta: 0:01:26  lr: 0.000100  loss: 0.3733 (0.5522)  labels_encoder: 0.2206 (0.3310)  labels_decoder: 0.1626 (0.2212)  labels_encoder_unscaled: 0.2206 (0.3310)  labels_decoder_unscaled: 0.3252 (0.4425)  time: 0.2085  data: 0.0004  max mem: 3781
Epoch: [1]  [1050/1412]  eta: 0:01:16  lr: 0.000100  loss: 0.4076 (0.5451)  labels_encoder: 0.2451 (0.3261)  labels_decoder: 0.1652 (0.2190)  labels_encoder_unscaled: 0.2451 (0.3261)  labels_decoder_unscaled: 0.3305 (0.4379)  time: 0.2081  data: 0.0027  max mem: 3781
Epoch: [1]  [1100/1412]  eta: 0:01:05  lr: 0.000100  loss: 0.3823 (0.5385)  labels_encoder: 0.2063 (0.3217)  labels_decoder: 0.1711 (0.2168)  labels_encoder_unscaled: 0.2063 (0.3217)  labels_decoder_unscaled: 0.3422 (0.4336)  time: 0.2082  data: 0.0004  max mem: 3781
Epoch: [1]  [1150/1412]  eta: 0:00:54  lr: 0.000100  loss: 0.3617 (0.5315)  labels_encoder: 0.1873 (0.3172)  labels_decoder: 0.1685 (0.2143)  labels_encoder_unscaled: 0.1873 (0.3172)  labels_decoder_unscaled: 0.3370 (0.4287)  time: 0.1949  data: 0.0004  max mem: 3781
Epoch: [1]  [1200/1412]  eta: 0:00:44  lr: 0.000100  loss: 0.3443 (0.5243)  labels_encoder: 0.1902 (0.3124)  labels_decoder: 0.1529 (0.2119)  labels_encoder_unscaled: 0.1902 (0.3124)  labels_decoder_unscaled: 0.3058 (0.4238)  time: 0.2181  data: 0.0004  max mem: 3781
Epoch: [1]  [1250/1412]  eta: 0:00:33  lr: 0.000100  loss: 0.3629 (0.5184)  labels_encoder: 0.2137 (0.3085)  labels_decoder: 0.1566 (0.2099)  labels_encoder_unscaled: 0.2137 (0.3085)  labels_decoder_unscaled: 0.3132 (0.4198)  time: 0.2172  data: 0.0004  max mem: 3781
Epoch: [1]  [1300/1412]  eta: 0:00:23  lr: 0.000100  loss: 0.3388 (0.5123)  labels_encoder: 0.1960 (0.3044)  labels_decoder: 0.1428 (0.2078)  labels_encoder_unscaled: 0.1960 (0.3044)  labels_decoder_unscaled: 0.2856 (0.4156)  time: 0.1950  data: 0.0004  max mem: 3781
Epoch: [1]  [1350/1412]  eta: 0:00:12  lr: 0.000100  loss: 0.3610 (0.5071)  labels_encoder: 0.2054 (0.3011)  labels_decoder: 0.1549 (0.2059)  labels_encoder_unscaled: 0.2054 (0.3011)  labels_decoder_unscaled: 0.3098 (0.4119)  time: 0.2174  data: 0.0004  max mem: 3781
Epoch: [1]  [1400/1412]  eta: 0:00:02  lr: 0.000100  loss: 0.3345 (0.5012)  labels_encoder: 0.1862 (0.2970)  labels_decoder: 0.1487 (0.2041)  labels_encoder_unscaled: 0.1862 (0.2970)  labels_decoder_unscaled: 0.2975 (0.4082)  time: 0.1873  data: 0.0005  max mem: 3781
Epoch: [1]  [1411/1412]  eta: 0:00:00  lr: 0.000100  loss: 0.3640 (0.5001)  labels_encoder: 0.2016 (0.2963)  labels_decoder: 0.1585 (0.2038)  labels_encoder_unscaled: 0.2016 (0.2963)  labels_decoder_unscaled: 0.3171 (0.4076)  time: 0.1604  data: 0.0004  max mem: 3781
Epoch: [1] Total time: 0:04:55 (0.2093 s / it)
Averaged stats: lr: 0.000100  loss: 0.3640 (0.5001)  labels_encoder: 0.2016 (0.2963)  labels_decoder: 0.1585 (0.2038)  labels_encoder_unscaled: 0.2016 (0.2963)  labels_decoder_unscaled: 0.3171 (0.4076)
Test:  [   0/1613]  eta: 2:08:02  loss: 2.0244 (2.0244)  labels_encoder: 1.4366 (1.4366)  labels_decoder: 0.5878 (0.5878)  labels_encoder_unscaled: 1.4366 (1.4366)  labels_decoder_unscaled: 1.1757 (1.1757)  time: 4.7628  data: 4.6644  max mem: 3781
Test:  [  50/1613]  eta: 0:05:50  loss: 0.4437 (0.7569)  labels_encoder: 0.1973 (0.4662)  labels_decoder: 0.2206 (0.2907)  labels_encoder_unscaled: 0.1973 (0.4662)  labels_decoder_unscaled: 0.4412 (0.5814)  time: 0.1514  data: 0.0583  max mem: 3781
Test:  [ 100/1613]  eta: 0:04:32  loss: 0.3001 (0.6982)  labels_encoder: 0.1940 (0.4414)  labels_decoder: 0.1061 (0.2568)  labels_encoder_unscaled: 0.1940 (0.4414)  labels_decoder_unscaled: 0.2122 (0.5136)  time: 0.1361  data: 0.0571  max mem: 3781
Test:  [ 150/1613]  eta: 0:04:07  loss: 1.0108 (0.7007)  labels_encoder: 0.7388 (0.4416)  labels_decoder: 0.3039 (0.2591)  labels_encoder_unscaled: 0.7388 (0.4416)  labels_decoder_unscaled: 0.6078 (0.5182)  time: 0.1518  data: 0.0395  max mem: 3781
Test:  [ 200/1613]  eta: 0:03:56  loss: 0.9814 (0.8270)  labels_encoder: 0.5375 (0.5171)  labels_decoder: 0.4647 (0.3100)  labels_encoder_unscaled: 0.5375 (0.5171)  labels_decoder_unscaled: 0.9294 (0.6199)  time: 0.1669  data: 0.0770  max mem: 3781
Test:  [ 250/1613]  eta: 0:03:45  loss: 0.3367 (0.8519)  labels_encoder: 0.1935 (0.5356)  labels_decoder: 0.1588 (0.3163)  labels_encoder_unscaled: 0.1935 (0.5356)  labels_decoder_unscaled: 0.3177 (0.6325)  time: 0.1733  data: 0.0605  max mem: 3781
Test:  [ 300/1613]  eta: 0:03:35  loss: 0.6800 (0.8377)  labels_encoder: 0.3410 (0.5226)  labels_decoder: 0.2615 (0.3150)  labels_encoder_unscaled: 0.3410 (0.5226)  labels_decoder_unscaled: 0.5230 (0.6301)  time: 0.1497  data: 0.0239  max mem: 3781
Test:  [ 350/1613]  eta: 0:03:20  loss: 1.2136 (0.8615)  labels_encoder: 0.6558 (0.5363)  labels_decoder: 0.4531 (0.3252)  labels_encoder_unscaled: 0.6558 (0.5363)  labels_decoder_unscaled: 0.9062 (0.6505)  time: 0.1285  data: 0.0245  max mem: 3781
Test:  [ 400/1613]  eta: 0:03:12  loss: 0.6493 (0.9186)  labels_encoder: 0.3939 (0.5831)  labels_decoder: 0.3125 (0.3355)  labels_encoder_unscaled: 0.3939 (0.5831)  labels_decoder_unscaled: 0.6250 (0.6710)  time: 0.1642  data: 0.0385  max mem: 3781
Test:  [ 450/1613]  eta: 0:03:03  loss: 0.8509 (0.9856)  labels_encoder: 0.5164 (0.6299)  labels_decoder: 0.2932 (0.3557)  labels_encoder_unscaled: 0.5164 (0.6299)  labels_decoder_unscaled: 0.5865 (0.7115)  time: 0.1449  data: 0.0543  max mem: 3781
Test:  [ 500/1613]  eta: 0:02:54  loss: 0.4573 (0.9565)  labels_encoder: 0.2345 (0.6107)  labels_decoder: 0.1895 (0.3458)  labels_encoder_unscaled: 0.2345 (0.6107)  labels_decoder_unscaled: 0.3789 (0.6916)  time: 0.1410  data: 0.0482  max mem: 3781
Test:  [ 550/1613]  eta: 0:02:46  loss: 0.5922 (0.9359)  labels_encoder: 0.3858 (0.5977)  labels_decoder: 0.2235 (0.3382)  labels_encoder_unscaled: 0.3858 (0.5977)  labels_decoder_unscaled: 0.4469 (0.6765)  time: 0.1502  data: 0.0682  max mem: 3781
Test:  [ 600/1613]  eta: 0:02:38  loss: 0.7431 (0.9720)  labels_encoder: 0.4287 (0.6268)  labels_decoder: 0.2733 (0.3453)  labels_encoder_unscaled: 0.4287 (0.6268)  labels_decoder_unscaled: 0.5466 (0.6905)  time: 0.1576  data: 0.0733  max mem: 3781
Test:  [ 650/1613]  eta: 0:02:30  loss: 1.1397 (0.9775)  labels_encoder: 0.7078 (0.6285)  labels_decoder: 0.4319 (0.3490)  labels_encoder_unscaled: 0.7078 (0.6285)  labels_decoder_unscaled: 0.8638 (0.6980)  time: 0.1560  data: 0.0560  max mem: 3781
Test:  [ 700/1613]  eta: 0:02:22  loss: 0.4848 (0.9601)  labels_encoder: 0.2941 (0.6175)  labels_decoder: 0.1895 (0.3426)  labels_encoder_unscaled: 0.2941 (0.6175)  labels_decoder_unscaled: 0.3790 (0.6853)  time: 0.1532  data: 0.0709  max mem: 3781
Test:  [ 750/1613]  eta: 0:02:14  loss: 0.6371 (0.9397)  labels_encoder: 0.3221 (0.6036)  labels_decoder: 0.2394 (0.3362)  labels_encoder_unscaled: 0.3221 (0.6036)  labels_decoder_unscaled: 0.4788 (0.6723)  time: 0.1512  data: 0.0320  max mem: 3781
Test:  [ 800/1613]  eta: 0:02:05  loss: 0.9288 (0.9369)  labels_encoder: 0.4441 (0.6012)  labels_decoder: 0.2795 (0.3358)  labels_encoder_unscaled: 0.4441 (0.6012)  labels_decoder_unscaled: 0.5590 (0.6715)  time: 0.1443  data: 0.0426  max mem: 3781
Test:  [ 850/1613]  eta: 0:01:57  loss: 0.9306 (0.9471)  labels_encoder: 0.5383 (0.6032)  labels_decoder: 0.3561 (0.3439)  labels_encoder_unscaled: 0.5383 (0.6032)  labels_decoder_unscaled: 0.7121 (0.6879)  time: 0.1587  data: 0.0651  max mem: 3781
Test:  [ 900/1613]  eta: 0:01:49  loss: 0.5238 (0.9373)  labels_encoder: 0.2917 (0.5967)  labels_decoder: 0.2554 (0.3405)  labels_encoder_unscaled: 0.2917 (0.5967)  labels_decoder_unscaled: 0.5108 (0.6811)  time: 0.1444  data: 0.0546  max mem: 3781
Test:  [ 950/1613]  eta: 0:01:41  loss: 0.8358 (0.9326)  labels_encoder: 0.5359 (0.5951)  labels_decoder: 0.3271 (0.3375)  labels_encoder_unscaled: 0.5359 (0.5951)  labels_decoder_unscaled: 0.6541 (0.6749)  time: 0.1398  data: 0.0375  max mem: 3781
Test:  [1000/1613]  eta: 0:01:33  loss: 0.4460 (0.9160)  labels_encoder: 0.2314 (0.5835)  labels_decoder: 0.1830 (0.3324)  labels_encoder_unscaled: 0.2314 (0.5835)  labels_decoder_unscaled: 0.3661 (0.6648)  time: 0.1394  data: 0.0433  max mem: 3781
Test:  [1050/1613]  eta: 0:01:25  loss: 1.0766 (0.9257)  labels_encoder: 0.6787 (0.5912)  labels_decoder: 0.4699 (0.3345)  labels_encoder_unscaled: 0.6787 (0.5912)  labels_decoder_unscaled: 0.9397 (0.6690)  time: 0.1443  data: 0.0570  max mem: 3781
Test:  [1100/1613]  eta: 0:01:18  loss: 0.5279 (0.9383)  labels_encoder: 0.3201 (0.6025)  labels_decoder: 0.2263 (0.3357)  labels_encoder_unscaled: 0.3201 (0.6025)  labels_decoder_unscaled: 0.4526 (0.6715)  time: 0.1517  data: 0.0639  max mem: 3781
Test:  [1150/1613]  eta: 0:01:10  loss: 0.4854 (0.9340)  labels_encoder: 0.2814 (0.5980)  labels_decoder: 0.2147 (0.3360)  labels_encoder_unscaled: 0.2814 (0.5980)  labels_decoder_unscaled: 0.4293 (0.6719)  time: 0.1439  data: 0.0478  max mem: 3781
Test:  [1200/1613]  eta: 0:01:02  loss: 0.5671 (0.9484)  labels_encoder: 0.3426 (0.6089)  labels_decoder: 0.2194 (0.3395)  labels_encoder_unscaled: 0.3426 (0.6089)  labels_decoder_unscaled: 0.4388 (0.6790)  time: 0.1473  data: 0.0447  max mem: 3781
Test:  [1250/1613]  eta: 0:00:54  loss: 0.3656 (0.9448)  labels_encoder: 0.2000 (0.6059)  labels_decoder: 0.1655 (0.3389)  labels_encoder_unscaled: 0.2000 (0.6059)  labels_decoder_unscaled: 0.3311 (0.6778)  time: 0.1438  data: 0.0286  max mem: 3781
Test:  [1300/1613]  eta: 0:00:47  loss: 0.5354 (0.9377)  labels_encoder: 0.3637 (0.6014)  labels_decoder: 0.2228 (0.3363)  labels_encoder_unscaled: 0.3637 (0.6014)  labels_decoder_unscaled: 0.4456 (0.6727)  time: 0.1453  data: 0.0660  max mem: 3781
Test:  [1350/1613]  eta: 0:00:39  loss: 1.3215 (0.9492)  labels_encoder: 0.9818 (0.6110)  labels_decoder: 0.4217 (0.3382)  labels_encoder_unscaled: 0.9818 (0.6110)  labels_decoder_unscaled: 0.8434 (0.6764)  time: 0.1481  data: 0.0509  max mem: 3781
Test:  [1400/1613]  eta: 0:00:32  loss: 0.7902 (0.9520)  labels_encoder: 0.5429 (0.6125)  labels_decoder: 0.2882 (0.3395)  labels_encoder_unscaled: 0.5429 (0.6125)  labels_decoder_unscaled: 0.5764 (0.6790)  time: 0.1439  data: 0.0500  max mem: 3781
Test:  [1450/1613]  eta: 0:00:24  loss: 0.5297 (0.9532)  labels_encoder: 0.3117 (0.6135)  labels_decoder: 0.2380 (0.3397)  labels_encoder_unscaled: 0.3117 (0.6135)  labels_decoder_unscaled: 0.4760 (0.6794)  time: 0.1440  data: 0.0322  max mem: 3781
Test:  [1500/1613]  eta: 0:00:16  loss: 0.6207 (0.9554)  labels_encoder: 0.3695 (0.6155)  labels_decoder: 0.2810 (0.3399)  labels_encoder_unscaled: 0.3695 (0.6155)  labels_decoder_unscaled: 0.5619 (0.6797)  time: 0.1458  data: 0.0805  max mem: 3781
Test:  [1550/1613]  eta: 0:00:09  loss: 0.9029 (0.9556)  labels_encoder: 0.6083 (0.6159)  labels_decoder: 0.3072 (0.3397)  labels_encoder_unscaled: 0.6083 (0.6159)  labels_decoder_unscaled: 0.6145 (0.6793)  time: 0.1402  data: 0.0751  max mem: 3781
Test:  [1600/1613]  eta: 0:00:01  loss: 1.1364 (0.9580)  labels_encoder: 0.6527 (0.6170)  labels_decoder: 0.4136 (0.3410)  labels_encoder_unscaled: 0.6527 (0.6170)  labels_decoder_unscaled: 0.8273 (0.6820)  time: 0.1463  data: 0.0776  max mem: 3781
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7068 (0.9549)  labels_encoder: 0.3440 (0.6149)  labels_decoder: 0.3134 (0.3401)  labels_encoder_unscaled: 0.3440 (0.6149)  labels_decoder_unscaled: 0.6268 (0.6801)  time: 0.1315  data: 0.0458  max mem: 3781
Test: Total time: 0:04:01 (0.1499 s / it)
Averaged stats: loss: 0.7068 (0.9549)  labels_encoder: 0.3440 (0.6149)  labels_decoder: 0.3134 (0.3401)  labels_encoder_unscaled: 0.3440 (0.6149)  labels_decoder_unscaled: 0.6268 (0.6801)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-kin_audio] mAP: 0.6384

dec_mAP all together: | 0.5203465116806938 |.
dec_mAP_pred | 0 : 0.5762273386116676 |.
dec_mAP_pred | 1 : 0.5649769420113426 |.
dec_mAP_pred | 2 : 0.5491738235998446 |.
dec_mAP_pred | 3 : 0.5318038753668815 |.
dec_mAP_pred | 4 : 0.5139308189085771 |.
dec_mAP_pred | 5 : 0.4962845126443593 |.
dec_mAP_pred | 6 : 0.47960953378963145 |.
dec_mAP_pred | 7 : 0.4636494146660525 |.
all decoder map: | 0.5220 |.
BaseballPitch: 0.1603
BasketballDunk: 0.7844
Billiards: 0.3203
CleanAndJerk: 0.7646
CliffDiving: 0.8739
CricketBowling: 0.4677
CricketShot: 0.2635
Diving: 0.8822
FrisbeeCatch: 0.3773
GolfSwing: 0.7916
HammerThrow: 0.8525
HighJump: 0.7899
JavelinThrow: 0.7599
LongJump: 0.8314
PoleVault: 0.8867
Shotput: 0.7607
SoccerPenalty: 0.4606
TennisSwing: 0.5936
ThrowDiscus: 0.6905
VolleyballSpiking: 0.4567
Epoch: [2]  [   0/1412]  eta: 1:35:38  lr: 0.000010  loss: 0.3132 (0.3132)  labels_encoder: 0.1564 (0.1564)  labels_decoder: 0.1568 (0.1568)  labels_encoder_unscaled: 0.1564 (0.1564)  labels_decoder_unscaled: 0.3136 (0.3136)  time: 4.0640  data: 3.8967  max mem: 3781
Epoch: [2]  [  50/1412]  eta: 0:06:54  lr: 0.000010  loss: 0.3043 (0.3139)  labels_encoder: 0.1618 (0.1742)  labels_decoder: 0.1453 (0.1396)  labels_encoder_unscaled: 0.1618 (0.1742)  labels_decoder_unscaled: 0.2905 (0.2793)  time: 0.1972  data: 0.0003  max mem: 3781
Epoch: [2]  [ 100/1412]  eta: 0:05:30  lr: 0.000010  loss: 0.2724 (0.3008)  labels_encoder: 0.1293 (0.1630)  labels_decoder: 0.1384 (0.1378)  labels_encoder_unscaled: 0.1293 (0.1630)  labels_decoder_unscaled: 0.2768 (0.2756)  time: 0.1902  data: 0.0004  max mem: 3781
Epoch: [2]  [ 150/1412]  eta: 0:04:56  lr: 0.000010  loss: 0.3224 (0.2988)  labels_encoder: 0.1752 (0.1625)  labels_decoder: 0.1335 (0.1363)  labels_encoder_unscaled: 0.1752 (0.1625)  labels_decoder_unscaled: 0.2670 (0.2727)  time: 0.2043  data: 0.0003  max mem: 3781
Epoch: [2]  [ 200/1412]  eta: 0:04:33  lr: 0.000010  loss: 0.2982 (0.2933)  labels_encoder: 0.1529 (0.1584)  labels_decoder: 0.1250 (0.1349)  labels_encoder_unscaled: 0.1529 (0.1584)  labels_decoder_unscaled: 0.2500 (0.2698)  time: 0.1993  data: 0.0003  max mem: 3781
Epoch: [2]  [ 250/1412]  eta: 0:04:15  lr: 0.000010  loss: 0.2601 (0.2870)  labels_encoder: 0.1423 (0.1549)  labels_decoder: 0.1148 (0.1321)  labels_encoder_unscaled: 0.1423 (0.1549)  labels_decoder_unscaled: 0.2296 (0.2642)  time: 0.1958  data: 0.0003  max mem: 3781
Epoch: [2]  [ 300/1412]  eta: 0:04:00  lr: 0.000010  loss: 0.2591 (0.2838)  labels_encoder: 0.1277 (0.1529)  labels_decoder: 0.1205 (0.1309)  labels_encoder_unscaled: 0.1277 (0.1529)  labels_decoder_unscaled: 0.2410 (0.2618)  time: 0.1931  data: 0.0003  max mem: 3781
Epoch: [2]  [ 350/1412]  eta: 0:03:47  lr: 0.000010  loss: 0.2551 (0.2792)  labels_encoder: 0.1289 (0.1501)  labels_decoder: 0.1122 (0.1291)  labels_encoder_unscaled: 0.1289 (0.1501)  labels_decoder_unscaled: 0.2243 (0.2582)  time: 0.2126  data: 0.0003  max mem: 3781
Epoch: [2]  [ 400/1412]  eta: 0:03:34  lr: 0.000010  loss: 0.2388 (0.2774)  labels_encoder: 0.1250 (0.1486)  labels_decoder: 0.1214 (0.1288)  labels_encoder_unscaled: 0.1250 (0.1486)  labels_decoder_unscaled: 0.2428 (0.2576)  time: 0.1915  data: 0.0003  max mem: 3781
Epoch: [2]  [ 450/1412]  eta: 0:03:22  lr: 0.000010  loss: 0.2845 (0.2760)  labels_encoder: 0.1529 (0.1476)  labels_decoder: 0.1337 (0.1284)  labels_encoder_unscaled: 0.1529 (0.1476)  labels_decoder_unscaled: 0.2673 (0.2569)  time: 0.1986  data: 0.0003  max mem: 3781
Epoch: [2]  [ 500/1412]  eta: 0:03:10  lr: 0.000010  loss: 0.2721 (0.2750)  labels_encoder: 0.1481 (0.1470)  labels_decoder: 0.1278 (0.1280)  labels_encoder_unscaled: 0.1481 (0.1470)  labels_decoder_unscaled: 0.2555 (0.2559)  time: 0.1923  data: 0.0003  max mem: 3781
Epoch: [2]  [ 550/1412]  eta: 0:02:59  lr: 0.000010  loss: 0.2359 (0.2730)  labels_encoder: 0.1151 (0.1458)  labels_decoder: 0.1149 (0.1272)  labels_encoder_unscaled: 0.1151 (0.1458)  labels_decoder_unscaled: 0.2297 (0.2543)  time: 0.2055  data: 0.0003  max mem: 3781
Epoch: [2]  [ 600/1412]  eta: 0:02:48  lr: 0.000010  loss: 0.2598 (0.2719)  labels_encoder: 0.1347 (0.1448)  labels_decoder: 0.1180 (0.1271)  labels_encoder_unscaled: 0.1347 (0.1448)  labels_decoder_unscaled: 0.2361 (0.2541)  time: 0.1959  data: 0.0004  max mem: 3781
Epoch: [2]  [ 650/1412]  eta: 0:02:37  lr: 0.000010  loss: 0.2560 (0.2706)  labels_encoder: 0.1340 (0.1440)  labels_decoder: 0.1220 (0.1265)  labels_encoder_unscaled: 0.1340 (0.1440)  labels_decoder_unscaled: 0.2439 (0.2531)  time: 0.1941  data: 0.0003  max mem: 3781
Epoch: [2]  [ 700/1412]  eta: 0:02:26  lr: 0.000010  loss: 0.2334 (0.2693)  labels_encoder: 0.1117 (0.1433)  labels_decoder: 0.1213 (0.1260)  labels_encoder_unscaled: 0.1117 (0.1433)  labels_decoder_unscaled: 0.2425 (0.2520)  time: 0.2025  data: 0.0003  max mem: 3781
Epoch: [2]  [ 750/1412]  eta: 0:02:16  lr: 0.000010  loss: 0.2364 (0.2680)  labels_encoder: 0.1169 (0.1423)  labels_decoder: 0.1266 (0.1257)  labels_encoder_unscaled: 0.1169 (0.1423)  labels_decoder_unscaled: 0.2532 (0.2515)  time: 0.2033  data: 0.0003  max mem: 3781
Epoch: [2]  [ 800/1412]  eta: 0:02:06  lr: 0.000010  loss: 0.2236 (0.2671)  labels_encoder: 0.1105 (0.1416)  labels_decoder: 0.1149 (0.1256)  labels_encoder_unscaled: 0.1105 (0.1416)  labels_decoder_unscaled: 0.2297 (0.2511)  time: 0.2145  data: 0.0003  max mem: 3781
Epoch: [2]  [ 850/1412]  eta: 0:01:55  lr: 0.000010  loss: 0.2632 (0.2659)  labels_encoder: 0.1362 (0.1406)  labels_decoder: 0.1292 (0.1253)  labels_encoder_unscaled: 0.1362 (0.1406)  labels_decoder_unscaled: 0.2584 (0.2506)  time: 0.1988  data: 0.0003  max mem: 3781
Epoch: [2]  [ 900/1412]  eta: 0:01:45  lr: 0.000010  loss: 0.2353 (0.2649)  labels_encoder: 0.1255 (0.1399)  labels_decoder: 0.1141 (0.1250)  labels_encoder_unscaled: 0.1255 (0.1399)  labels_decoder_unscaled: 0.2282 (0.2500)  time: 0.1952  data: 0.0003  max mem: 3781
Epoch: [2]  [ 950/1412]  eta: 0:01:34  lr: 0.000010  loss: 0.2405 (0.2638)  labels_encoder: 0.1270 (0.1393)  labels_decoder: 0.1137 (0.1245)  labels_encoder_unscaled: 0.1270 (0.1393)  labels_decoder_unscaled: 0.2274 (0.2489)  time: 0.2008  data: 0.0003  max mem: 3781
Epoch: [2]  [1000/1412]  eta: 0:01:24  lr: 0.000010  loss: 0.2392 (0.2629)  labels_encoder: 0.1210 (0.1387)  labels_decoder: 0.1167 (0.1242)  labels_encoder_unscaled: 0.1210 (0.1387)  labels_decoder_unscaled: 0.2335 (0.2484)  time: 0.2010  data: 0.0003  max mem: 3781
Epoch: [2]  [1050/1412]  eta: 0:01:14  lr: 0.000010  loss: 0.2462 (0.2621)  labels_encoder: 0.1314 (0.1382)  labels_decoder: 0.1177 (0.1239)  labels_encoder_unscaled: 0.1314 (0.1382)  labels_decoder_unscaled: 0.2355 (0.2478)  time: 0.2092  data: 0.0003  max mem: 3781
Epoch: [2]  [1100/1412]  eta: 0:01:03  lr: 0.000010  loss: 0.2385 (0.2613)  labels_encoder: 0.1296 (0.1377)  labels_decoder: 0.1238 (0.1236)  labels_encoder_unscaled: 0.1296 (0.1377)  labels_decoder_unscaled: 0.2476 (0.2472)  time: 0.1952  data: 0.0004  max mem: 3781
Epoch: [2]  [1150/1412]  eta: 0:00:53  lr: 0.000010  loss: 0.2623 (0.2608)  labels_encoder: 0.1395 (0.1375)  labels_decoder: 0.1166 (0.1233)  labels_encoder_unscaled: 0.1395 (0.1375)  labels_decoder_unscaled: 0.2331 (0.2465)  time: 0.1972  data: 0.0003  max mem: 3781
Epoch: [2]  [1200/1412]  eta: 0:00:43  lr: 0.000010  loss: 0.2577 (0.2607)  labels_encoder: 0.1356 (0.1375)  labels_decoder: 0.1251 (0.1232)  labels_encoder_unscaled: 0.1356 (0.1375)  labels_decoder_unscaled: 0.2503 (0.2464)  time: 0.2043  data: 0.0003  max mem: 3781
Epoch: [2]  [1250/1412]  eta: 0:00:33  lr: 0.000010  loss: 0.2286 (0.2598)  labels_encoder: 0.1202 (0.1370)  labels_decoder: 0.1153 (0.1228)  labels_encoder_unscaled: 0.1202 (0.1370)  labels_decoder_unscaled: 0.2306 (0.2456)  time: 0.2197  data: 0.0006  max mem: 3781
Epoch: [2]  [1300/1412]  eta: 0:00:22  lr: 0.000010  loss: 0.2362 (0.2594)  labels_encoder: 0.1102 (0.1367)  labels_decoder: 0.1138 (0.1227)  labels_encoder_unscaled: 0.1102 (0.1367)  labels_decoder_unscaled: 0.2276 (0.2454)  time: 0.1996  data: 0.0003  max mem: 3781
Epoch: [2]  [1350/1412]  eta: 0:00:12  lr: 0.000010  loss: 0.2369 (0.2587)  labels_encoder: 0.1143 (0.1363)  labels_decoder: 0.1160 (0.1224)  labels_encoder_unscaled: 0.1143 (0.1363)  labels_decoder_unscaled: 0.2319 (0.2448)  time: 0.2068  data: 0.0004  max mem: 3781
Epoch: [2]  [1400/1412]  eta: 0:00:02  lr: 0.000010  loss: 0.2436 (0.2585)  labels_encoder: 0.1316 (0.1363)  labels_decoder: 0.1056 (0.1222)  labels_encoder_unscaled: 0.1316 (0.1363)  labels_decoder_unscaled: 0.2113 (0.2444)  time: 0.2128  data: 0.0006  max mem: 3781
Epoch: [2]  [1411/1412]  eta: 0:00:00  lr: 0.000010  loss: 0.2538 (0.2583)  labels_encoder: 0.1297 (0.1361)  labels_decoder: 0.1145 (0.1222)  labels_encoder_unscaled: 0.1297 (0.1361)  labels_decoder_unscaled: 0.2290 (0.2444)  time: 0.1696  data: 0.0005  max mem: 3781
Epoch: [2] Total time: 0:04:49 (0.2052 s / it)
Averaged stats: lr: 0.000010  loss: 0.2538 (0.2583)  labels_encoder: 0.1297 (0.1361)  labels_decoder: 0.1145 (0.1222)  labels_encoder_unscaled: 0.1297 (0.1361)  labels_decoder_unscaled: 0.2290 (0.2444)
Test:  [   0/1613]  eta: 1:57:36  loss: 0.9814 (0.9814)  labels_encoder: 0.6071 (0.6071)  labels_decoder: 0.3743 (0.3743)  labels_encoder_unscaled: 0.6071 (0.6071)  labels_decoder_unscaled: 0.7486 (0.7486)  time: 4.3747  data: 4.1853  max mem: 3781
Test:  [  50/1613]  eta: 0:06:01  loss: 0.4951 (0.8111)  labels_encoder: 0.3140 (0.5128)  labels_decoder: 0.2105 (0.2983)  labels_encoder_unscaled: 0.3140 (0.5128)  labels_decoder_unscaled: 0.4210 (0.5965)  time: 0.1413  data: 0.0249  max mem: 3781
Test:  [ 100/1613]  eta: 0:04:48  loss: 0.4877 (0.7510)  labels_encoder: 0.3382 (0.4862)  labels_decoder: 0.1631 (0.2648)  labels_encoder_unscaled: 0.3382 (0.4862)  labels_decoder_unscaled: 0.3262 (0.5297)  time: 0.1398  data: 0.0589  max mem: 3781
Test:  [ 150/1613]  eta: 0:04:17  loss: 0.9102 (0.7568)  labels_encoder: 0.6747 (0.4848)  labels_decoder: 0.2673 (0.2720)  labels_encoder_unscaled: 0.6747 (0.4848)  labels_decoder_unscaled: 0.5346 (0.5441)  time: 0.1413  data: 0.0469  max mem: 3781
Test:  [ 200/1613]  eta: 0:03:58  loss: 0.8960 (0.9085)  labels_encoder: 0.5248 (0.5820)  labels_decoder: 0.3873 (0.3264)  labels_encoder_unscaled: 0.5248 (0.5820)  labels_decoder_unscaled: 0.7747 (0.6528)  time: 0.1515  data: 0.0555  max mem: 3781
Test:  [ 250/1613]  eta: 0:03:46  loss: 0.3615 (0.9450)  labels_encoder: 0.1901 (0.6014)  labels_decoder: 0.2167 (0.3436)  labels_encoder_unscaled: 0.1901 (0.6014)  labels_decoder_unscaled: 0.4334 (0.6873)  time: 0.1484  data: 0.0480  max mem: 3781
Test:  [ 300/1613]  eta: 0:03:36  loss: 1.1891 (0.9868)  labels_encoder: 0.7098 (0.6325)  labels_decoder: 0.4473 (0.3543)  labels_encoder_unscaled: 0.7098 (0.6325)  labels_decoder_unscaled: 0.8946 (0.7085)  time: 0.1581  data: 0.0466  max mem: 3781
Test:  [ 350/1613]  eta: 0:03:24  loss: 1.5005 (1.0197)  labels_encoder: 0.9012 (0.6548)  labels_decoder: 0.6341 (0.3649)  labels_encoder_unscaled: 0.9012 (0.6548)  labels_decoder_unscaled: 1.2682 (0.7298)  time: 0.1415  data: 0.0500  max mem: 3781
Test:  [ 400/1613]  eta: 0:03:13  loss: 0.7879 (1.0713)  labels_encoder: 0.3951 (0.6930)  labels_decoder: 0.2993 (0.3784)  labels_encoder_unscaled: 0.3951 (0.6930)  labels_decoder_unscaled: 0.5987 (0.7567)  time: 0.1478  data: 0.0656  max mem: 3781
Test:  [ 450/1613]  eta: 0:03:04  loss: 1.4284 (1.1700)  labels_encoder: 1.0923 (0.7647)  labels_decoder: 0.3361 (0.4053)  labels_encoder_unscaled: 1.0923 (0.7647)  labels_decoder_unscaled: 0.6722 (0.8106)  time: 0.1549  data: 0.0689  max mem: 3781
Test:  [ 500/1613]  eta: 0:02:56  loss: 0.4249 (1.1211)  labels_encoder: 0.2241 (0.7306)  labels_decoder: 0.1953 (0.3905)  labels_encoder_unscaled: 0.2241 (0.7306)  labels_decoder_unscaled: 0.3907 (0.7809)  time: 0.1552  data: 0.0351  max mem: 3781
Test:  [ 550/1613]  eta: 0:02:47  loss: 0.5081 (1.0884)  labels_encoder: 0.3117 (0.7085)  labels_decoder: 0.1821 (0.3799)  labels_encoder_unscaled: 0.3117 (0.7085)  labels_decoder_unscaled: 0.3641 (0.7598)  time: 0.1659  data: 0.0652  max mem: 3781
Test:  [ 600/1613]  eta: 0:02:39  loss: 0.8879 (1.1320)  labels_encoder: 0.4912 (0.7452)  labels_decoder: 0.3753 (0.3868)  labels_encoder_unscaled: 0.4912 (0.7452)  labels_decoder_unscaled: 0.7506 (0.7735)  time: 0.1540  data: 0.0606  max mem: 3781
Test:  [ 650/1613]  eta: 0:02:31  loss: 1.2212 (1.1343)  labels_encoder: 0.7655 (0.7430)  labels_decoder: 0.5237 (0.3913)  labels_encoder_unscaled: 0.7655 (0.7430)  labels_decoder_unscaled: 1.0474 (0.7826)  time: 0.1518  data: 0.0602  max mem: 3781
Test:  [ 700/1613]  eta: 0:02:23  loss: 0.4992 (1.0997)  labels_encoder: 0.3436 (0.7187)  labels_decoder: 0.1985 (0.3810)  labels_encoder_unscaled: 0.3436 (0.7187)  labels_decoder_unscaled: 0.3969 (0.7619)  time: 0.1539  data: 0.0657  max mem: 3781
Test:  [ 750/1613]  eta: 0:02:15  loss: 0.9022 (1.0735)  labels_encoder: 0.4826 (0.6994)  labels_decoder: 0.3574 (0.3740)  labels_encoder_unscaled: 0.4826 (0.6994)  labels_decoder_unscaled: 0.7148 (0.7481)  time: 0.1593  data: 0.0628  max mem: 3781
Test:  [ 800/1613]  eta: 0:02:07  loss: 0.5788 (1.0641)  labels_encoder: 0.3699 (0.6931)  labels_decoder: 0.2567 (0.3709)  labels_encoder_unscaled: 0.3699 (0.6931)  labels_decoder_unscaled: 0.5135 (0.7418)  time: 0.1533  data: 0.0754  max mem: 3781
Test:  [ 850/1613]  eta: 0:01:59  loss: 0.9695 (1.0686)  labels_encoder: 0.6047 (0.6922)  labels_decoder: 0.3648 (0.3764)  labels_encoder_unscaled: 0.6047 (0.6922)  labels_decoder_unscaled: 0.7296 (0.7528)  time: 0.1595  data: 0.0625  max mem: 3781
Test:  [ 900/1613]  eta: 0:01:51  loss: 0.4769 (1.0487)  labels_encoder: 0.2729 (0.6774)  labels_decoder: 0.2614 (0.3713)  labels_encoder_unscaled: 0.2729 (0.6774)  labels_decoder_unscaled: 0.5228 (0.7427)  time: 0.1504  data: 0.0598  max mem: 3781
Test:  [ 950/1613]  eta: 0:01:43  loss: 1.1708 (1.0526)  labels_encoder: 0.8278 (0.6787)  labels_decoder: 0.3823 (0.3738)  labels_encoder_unscaled: 0.8278 (0.6787)  labels_decoder_unscaled: 0.7646 (0.7476)  time: 0.1538  data: 0.0573  max mem: 3781
Test:  [1000/1613]  eta: 0:01:35  loss: 0.7166 (1.0397)  labels_encoder: 0.4380 (0.6693)  labels_decoder: 0.2679 (0.3704)  labels_encoder_unscaled: 0.4380 (0.6693)  labels_decoder_unscaled: 0.5357 (0.7407)  time: 0.1432  data: 0.0716  max mem: 3781
Test:  [1050/1613]  eta: 0:01:27  loss: 1.0282 (1.0447)  labels_encoder: 0.6567 (0.6734)  labels_decoder: 0.3480 (0.3712)  labels_encoder_unscaled: 0.6567 (0.6734)  labels_decoder_unscaled: 0.6960 (0.7425)  time: 0.1489  data: 0.0535  max mem: 3781
Test:  [1100/1613]  eta: 0:01:19  loss: 0.4534 (1.0539)  labels_encoder: 0.2411 (0.6802)  labels_decoder: 0.2606 (0.3737)  labels_encoder_unscaled: 0.2411 (0.6802)  labels_decoder_unscaled: 0.5212 (0.7474)  time: 0.1344  data: 0.0609  max mem: 3781
Test:  [1150/1613]  eta: 0:01:11  loss: 0.4988 (1.0446)  labels_encoder: 0.2771 (0.6738)  labels_decoder: 0.2217 (0.3708)  labels_encoder_unscaled: 0.2771 (0.6738)  labels_decoder_unscaled: 0.4434 (0.7416)  time: 0.1356  data: 0.0600  max mem: 3781
Test:  [1200/1613]  eta: 0:01:03  loss: 0.5546 (1.0484)  labels_encoder: 0.2549 (0.6766)  labels_decoder: 0.2356 (0.3718)  labels_encoder_unscaled: 0.2549 (0.6766)  labels_decoder_unscaled: 0.4712 (0.7437)  time: 0.1444  data: 0.0567  max mem: 3781
Test:  [1250/1613]  eta: 0:00:55  loss: 0.5984 (1.0522)  labels_encoder: 0.3085 (0.6791)  labels_decoder: 0.2805 (0.3732)  labels_encoder_unscaled: 0.3085 (0.6791)  labels_decoder_unscaled: 0.5611 (0.7464)  time: 0.1414  data: 0.0665  max mem: 3781
Test:  [1300/1613]  eta: 0:00:47  loss: 0.6171 (1.0490)  labels_encoder: 0.4230 (0.6763)  labels_decoder: 0.3066 (0.3727)  labels_encoder_unscaled: 0.4230 (0.6763)  labels_decoder_unscaled: 0.6131 (0.7453)  time: 0.1354  data: 0.0557  max mem: 3781
Test:  [1350/1613]  eta: 0:00:39  loss: 1.0556 (1.0526)  labels_encoder: 0.6823 (0.6795)  labels_decoder: 0.3907 (0.3731)  labels_encoder_unscaled: 0.6823 (0.6795)  labels_decoder_unscaled: 0.7815 (0.7462)  time: 0.1363  data: 0.0632  max mem: 3781
Test:  [1400/1613]  eta: 0:00:32  loss: 0.9539 (1.0562)  labels_encoder: 0.5727 (0.6816)  labels_decoder: 0.3813 (0.3746)  labels_encoder_unscaled: 0.5727 (0.6816)  labels_decoder_unscaled: 0.7625 (0.7492)  time: 0.1522  data: 0.0704  max mem: 3781
Test:  [1450/1613]  eta: 0:00:24  loss: 0.6542 (1.0581)  labels_encoder: 0.4712 (0.6829)  labels_decoder: 0.2437 (0.3753)  labels_encoder_unscaled: 0.4712 (0.6829)  labels_decoder_unscaled: 0.4874 (0.7505)  time: 0.1437  data: 0.0623  max mem: 3781
Test:  [1500/1613]  eta: 0:00:17  loss: 0.5805 (1.0559)  labels_encoder: 0.4070 (0.6813)  labels_decoder: 0.2580 (0.3747)  labels_encoder_unscaled: 0.4070 (0.6813)  labels_decoder_unscaled: 0.5160 (0.7494)  time: 0.1516  data: 0.0669  max mem: 3781
Test:  [1550/1613]  eta: 0:00:09  loss: 0.7444 (1.0593)  labels_encoder: 0.5043 (0.6840)  labels_decoder: 0.3167 (0.3753)  labels_encoder_unscaled: 0.5043 (0.6840)  labels_decoder_unscaled: 0.6334 (0.7506)  time: 0.1458  data: 0.0579  max mem: 3781
Test:  [1600/1613]  eta: 0:00:01  loss: 1.1389 (1.0579)  labels_encoder: 0.6271 (0.6823)  labels_decoder: 0.4187 (0.3756)  labels_encoder_unscaled: 0.6271 (0.6823)  labels_decoder_unscaled: 0.8374 (0.7511)  time: 0.1457  data: 0.0713  max mem: 3781
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6752 (1.0558)  labels_encoder: 0.4276 (0.6810)  labels_decoder: 0.2746 (0.3749)  labels_encoder_unscaled: 0.4276 (0.6810)  labels_decoder_unscaled: 0.5491 (0.7497)  time: 0.1362  data: 0.0652  max mem: 3781
Test: Total time: 0:04:04 (0.1515 s / it)
Averaged stats: loss: 0.6752 (1.0558)  labels_encoder: 0.4276 (0.6810)  labels_decoder: 0.2746 (0.3749)  labels_encoder_unscaled: 0.4276 (0.6810)  labels_decoder_unscaled: 0.5491 (0.7497)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-kin_audio] mAP: 0.6401

dec_mAP all together: | 0.5135268918687628 |.
dec_mAP_pred | 0 : 0.5651931501056671 |.
dec_mAP_pred | 1 : 0.5565342550102801 |.
dec_mAP_pred | 2 : 0.542316194842053 |.
dec_mAP_pred | 3 : 0.5258293173284223 |.
dec_mAP_pred | 4 : 0.5079229709172834 |.
dec_mAP_pred | 5 : 0.4900904883202181 |.
dec_mAP_pred | 6 : 0.4732803613133715 |.
dec_mAP_pred | 7 : 0.45738255259838195 |.
all decoder map: | 0.5148 |.
BaseballPitch: 0.3021
BasketballDunk: 0.8130
Billiards: 0.3299
CleanAndJerk: 0.7577
CliffDiving: 0.8587
CricketBowling: 0.4894
CricketShot: 0.3094
Diving: 0.8743
FrisbeeCatch: 0.3675
GolfSwing: 0.7934
HammerThrow: 0.8313
HighJump: 0.7938
JavelinThrow: 0.7379
LongJump: 0.7738
PoleVault: 0.8693
Shotput: 0.7188
SoccerPenalty: 0.4313
TennisSwing: 0.6176
ThrowDiscus: 0.6661
VolleyballSpiking: 0.4675
Epoch: [3]  [   0/1412]  eta: 2:02:01  lr: 0.000001  loss: 0.2373 (0.2373)  labels_encoder: 0.1035 (0.1035)  labels_decoder: 0.1337 (0.1337)  labels_encoder_unscaled: 0.1035 (0.1035)  labels_decoder_unscaled: 0.2675 (0.2675)  time: 5.1853  data: 4.8949  max mem: 3781
Epoch: [3]  [  50/1412]  eta: 0:07:03  lr: 0.000001  loss: 0.2170 (0.2313)  labels_encoder: 0.1213 (0.1207)  labels_decoder: 0.1033 (0.1106)  labels_encoder_unscaled: 0.1213 (0.1207)  labels_decoder_unscaled: 0.2066 (0.2211)  time: 0.2058  data: 0.0003  max mem: 3781
Epoch: [3]  [ 100/1412]  eta: 0:05:41  lr: 0.000001  loss: 0.2153 (0.2306)  labels_encoder: 0.1038 (0.1192)  labels_decoder: 0.1099 (0.1114)  labels_encoder_unscaled: 0.1038 (0.1192)  labels_decoder_unscaled: 0.2198 (0.2227)  time: 0.2117  data: 0.0003  max mem: 3781
Epoch: [3]  [ 150/1412]  eta: 0:05:01  lr: 0.000001  loss: 0.2103 (0.2273)  labels_encoder: 0.1023 (0.1170)  labels_decoder: 0.1038 (0.1103)  labels_encoder_unscaled: 0.1023 (0.1170)  labels_decoder_unscaled: 0.2076 (0.2207)  time: 0.2028  data: 0.0003  max mem: 3781
Epoch: [3]  [ 200/1412]  eta: 0:04:38  lr: 0.000001  loss: 0.2288 (0.2256)  labels_encoder: 0.1105 (0.1153)  labels_decoder: 0.1109 (0.1103)  labels_encoder_unscaled: 0.1105 (0.1153)  labels_decoder_unscaled: 0.2218 (0.2206)  time: 0.2012  data: 0.0003  max mem: 3781
Epoch: [3]  [ 250/1412]  eta: 0:04:19  lr: 0.000001  loss: 0.2178 (0.2272)  labels_encoder: 0.0938 (0.1157)  labels_decoder: 0.1144 (0.1114)  labels_encoder_unscaled: 0.0938 (0.1157)  labels_decoder_unscaled: 0.2289 (0.2229)  time: 0.1865  data: 0.0003  max mem: 3781
Epoch: [3]  [ 300/1412]  eta: 0:04:03  lr: 0.000001  loss: 0.2044 (0.2262)  labels_encoder: 0.0947 (0.1151)  labels_decoder: 0.1101 (0.1112)  labels_encoder_unscaled: 0.0947 (0.1151)  labels_decoder_unscaled: 0.2202 (0.2223)  time: 0.2010  data: 0.0003  max mem: 3781
Epoch: [3]  [ 350/1412]  eta: 0:03:50  lr: 0.000001  loss: 0.2213 (0.2266)  labels_encoder: 0.0960 (0.1150)  labels_decoder: 0.1146 (0.1117)  labels_encoder_unscaled: 0.0960 (0.1150)  labels_decoder_unscaled: 0.2292 (0.2233)  time: 0.2143  data: 0.0003  max mem: 3781
Epoch: [3]  [ 400/1412]  eta: 0:03:38  lr: 0.000001  loss: 0.2067 (0.2267)  labels_encoder: 0.1049 (0.1151)  labels_decoder: 0.1046 (0.1117)  labels_encoder_unscaled: 0.1049 (0.1151)  labels_decoder_unscaled: 0.2093 (0.2233)  time: 0.2112  data: 0.0004  max mem: 3781
Epoch: [3]  [ 450/1412]  eta: 0:03:26  lr: 0.000001  loss: 0.2360 (0.2274)  labels_encoder: 0.1182 (0.1155)  labels_decoder: 0.1175 (0.1120)  labels_encoder_unscaled: 0.1182 (0.1155)  labels_decoder_unscaled: 0.2350 (0.2240)  time: 0.2022  data: 0.0003  max mem: 3781
Epoch: [3]  [ 500/1412]  eta: 0:03:15  lr: 0.000001  loss: 0.2174 (0.2278)  labels_encoder: 0.1177 (0.1156)  labels_decoder: 0.1140 (0.1121)  labels_encoder_unscaled: 0.1177 (0.1156)  labels_decoder_unscaled: 0.2280 (0.2243)  time: 0.2054  data: 0.0003  max mem: 3781
Epoch: [3]  [ 550/1412]  eta: 0:03:03  lr: 0.000001  loss: 0.2126 (0.2273)  labels_encoder: 0.1037 (0.1156)  labels_decoder: 0.1084 (0.1118)  labels_encoder_unscaled: 0.1037 (0.1156)  labels_decoder_unscaled: 0.2167 (0.2236)  time: 0.1968  data: 0.0003  max mem: 3781
Epoch: [3]  [ 600/1412]  eta: 0:02:52  lr: 0.000001  loss: 0.2166 (0.2274)  labels_encoder: 0.1094 (0.1156)  labels_decoder: 0.1085 (0.1118)  labels_encoder_unscaled: 0.1094 (0.1156)  labels_decoder_unscaled: 0.2170 (0.2235)  time: 0.2028  data: 0.0003  max mem: 3781
Epoch: [3]  [ 650/1412]  eta: 0:02:41  lr: 0.000001  loss: 0.2179 (0.2272)  labels_encoder: 0.1091 (0.1156)  labels_decoder: 0.1061 (0.1116)  labels_encoder_unscaled: 0.1091 (0.1156)  labels_decoder_unscaled: 0.2122 (0.2232)  time: 0.2065  data: 0.0003  max mem: 3781
Epoch: [3]  [ 700/1412]  eta: 0:02:30  lr: 0.000001  loss: 0.2061 (0.2266)  labels_encoder: 0.1067 (0.1153)  labels_decoder: 0.0989 (0.1113)  labels_encoder_unscaled: 0.1067 (0.1153)  labels_decoder_unscaled: 0.1979 (0.2226)  time: 0.2116  data: 0.0003  max mem: 3781
Epoch: [3]  [ 750/1412]  eta: 0:02:19  lr: 0.000001  loss: 0.2074 (0.2265)  labels_encoder: 0.0955 (0.1151)  labels_decoder: 0.1161 (0.1114)  labels_encoder_unscaled: 0.0955 (0.1151)  labels_decoder_unscaled: 0.2322 (0.2227)  time: 0.1881  data: 0.0005  max mem: 3781
Epoch: [3]  [ 800/1412]  eta: 0:02:09  lr: 0.000001  loss: 0.2297 (0.2269)  labels_encoder: 0.1092 (0.1152)  labels_decoder: 0.1141 (0.1117)  labels_encoder_unscaled: 0.1092 (0.1152)  labels_decoder_unscaled: 0.2283 (0.2233)  time: 0.2058  data: 0.0004  max mem: 3781
Epoch: [3]  [ 850/1412]  eta: 0:01:58  lr: 0.000001  loss: 0.2153 (0.2268)  labels_encoder: 0.1145 (0.1153)  labels_decoder: 0.1068 (0.1115)  labels_encoder_unscaled: 0.1145 (0.1153)  labels_decoder_unscaled: 0.2135 (0.2230)  time: 0.2015  data: 0.0003  max mem: 3781
Epoch: [3]  [ 900/1412]  eta: 0:01:47  lr: 0.000001  loss: 0.2124 (0.2263)  labels_encoder: 0.0992 (0.1148)  labels_decoder: 0.1117 (0.1114)  labels_encoder_unscaled: 0.0992 (0.1148)  labels_decoder_unscaled: 0.2234 (0.2229)  time: 0.2182  data: 0.0003  max mem: 3781
Epoch: [3]  [ 950/1412]  eta: 0:01:37  lr: 0.000001  loss: 0.2190 (0.2262)  labels_encoder: 0.1138 (0.1147)  labels_decoder: 0.1037 (0.1115)  labels_encoder_unscaled: 0.1138 (0.1147)  labels_decoder_unscaled: 0.2075 (0.2230)  time: 0.2002  data: 0.0005  max mem: 3781
Epoch: [3]  [1000/1412]  eta: 0:01:26  lr: 0.000001  loss: 0.2308 (0.2268)  labels_encoder: 0.1180 (0.1152)  labels_decoder: 0.1082 (0.1116)  labels_encoder_unscaled: 0.1180 (0.1152)  labels_decoder_unscaled: 0.2164 (0.2232)  time: 0.2186  data: 0.0003  max mem: 3781
Epoch: [3]  [1050/1412]  eta: 0:01:16  lr: 0.000001  loss: 0.2498 (0.2268)  labels_encoder: 0.1271 (0.1152)  labels_decoder: 0.1204 (0.1115)  labels_encoder_unscaled: 0.1271 (0.1152)  labels_decoder_unscaled: 0.2407 (0.2231)  time: 0.2106  data: 0.0003  max mem: 3781
Epoch: [3]  [1100/1412]  eta: 0:01:05  lr: 0.000001  loss: 0.2048 (0.2267)  labels_encoder: 0.0989 (0.1152)  labels_decoder: 0.1086 (0.1115)  labels_encoder_unscaled: 0.0989 (0.1152)  labels_decoder_unscaled: 0.2172 (0.2230)  time: 0.2168  data: 0.0003  max mem: 3781
Epoch: [3]  [1150/1412]  eta: 0:00:55  lr: 0.000001  loss: 0.2042 (0.2265)  labels_encoder: 0.0974 (0.1150)  labels_decoder: 0.1078 (0.1114)  labels_encoder_unscaled: 0.0974 (0.1150)  labels_decoder_unscaled: 0.2156 (0.2229)  time: 0.2084  data: 0.0004  max mem: 3781
Epoch: [3]  [1200/1412]  eta: 0:00:44  lr: 0.000001  loss: 0.2098 (0.2267)  labels_encoder: 0.0999 (0.1153)  labels_decoder: 0.1099 (0.1114)  labels_encoder_unscaled: 0.0999 (0.1153)  labels_decoder_unscaled: 0.2199 (0.2229)  time: 0.2217  data: 0.0003  max mem: 3781
Epoch: [3]  [1250/1412]  eta: 0:00:34  lr: 0.000001  loss: 0.2060 (0.2266)  labels_encoder: 0.0921 (0.1151)  labels_decoder: 0.1101 (0.1115)  labels_encoder_unscaled: 0.0921 (0.1151)  labels_decoder_unscaled: 0.2203 (0.2230)  time: 0.2052  data: 0.0005  max mem: 3781
Epoch: [3]  [1300/1412]  eta: 0:00:23  lr: 0.000001  loss: 0.2022 (0.2263)  labels_encoder: 0.0976 (0.1149)  labels_decoder: 0.1101 (0.1114)  labels_encoder_unscaled: 0.0976 (0.1149)  labels_decoder_unscaled: 0.2202 (0.2227)  time: 0.2078  data: 0.0004  max mem: 3781
Epoch: [3]  [1350/1412]  eta: 0:00:13  lr: 0.000001  loss: 0.2024 (0.2263)  labels_encoder: 0.0918 (0.1149)  labels_decoder: 0.1043 (0.1114)  labels_encoder_unscaled: 0.0918 (0.1149)  labels_decoder_unscaled: 0.2087 (0.2229)  time: 0.2166  data: 0.0003  max mem: 3781
Epoch: [3]  [1400/1412]  eta: 0:00:02  lr: 0.000001  loss: 0.2162 (0.2264)  labels_encoder: 0.1101 (0.1150)  labels_decoder: 0.1043 (0.1114)  labels_encoder_unscaled: 0.1101 (0.1150)  labels_decoder_unscaled: 0.2085 (0.2228)  time: 0.2031  data: 0.0005  max mem: 3781
Epoch: [3]  [1411/1412]  eta: 0:00:00  lr: 0.000001  loss: 0.2430 (0.2265)  labels_encoder: 0.1212 (0.1150)  labels_decoder: 0.1164 (0.1114)  labels_encoder_unscaled: 0.1212 (0.1150)  labels_decoder_unscaled: 0.2328 (0.2228)  time: 0.1623  data: 0.0004  max mem: 3781
Epoch: [3] Total time: 0:04:57 (0.2108 s / it)
Averaged stats: lr: 0.000001  loss: 0.2430 (0.2265)  labels_encoder: 0.1212 (0.1150)  labels_decoder: 0.1164 (0.1114)  labels_encoder_unscaled: 0.1212 (0.1150)  labels_decoder_unscaled: 0.2328 (0.2228)
Test:  [   0/1613]  eta: 2:23:05  loss: 1.5391 (1.5391)  labels_encoder: 0.9458 (0.9458)  labels_decoder: 0.5933 (0.5933)  labels_encoder_unscaled: 0.9458 (0.9458)  labels_decoder_unscaled: 1.1866 (1.1866)  time: 5.3226  data: 5.2587  max mem: 3781
Test:  [  50/1613]  eta: 0:06:08  loss: 0.4235 (0.8449)  labels_encoder: 0.2582 (0.5258)  labels_decoder: 0.2056 (0.3192)  labels_encoder_unscaled: 0.2582 (0.5258)  labels_decoder_unscaled: 0.4112 (0.6383)  time: 0.1401  data: 0.0109  max mem: 3781
Test:  [ 100/1613]  eta: 0:04:47  loss: 0.5813 (0.7758)  labels_encoder: 0.3484 (0.5010)  labels_decoder: 0.1845 (0.2749)  labels_encoder_unscaled: 0.3484 (0.5010)  labels_decoder_unscaled: 0.3690 (0.5497)  time: 0.1504  data: 0.0337  max mem: 3781
Test:  [ 150/1613]  eta: 0:04:12  loss: 1.0119 (0.7747)  labels_encoder: 0.7054 (0.4966)  labels_decoder: 0.2305 (0.2781)  labels_encoder_unscaled: 0.7054 (0.4966)  labels_decoder_unscaled: 0.4610 (0.5561)  time: 0.1423  data: 0.0302  max mem: 3781
Test:  [ 200/1613]  eta: 0:03:53  loss: 0.8988 (0.9338)  labels_encoder: 0.5252 (0.6002)  labels_decoder: 0.3806 (0.3336)  labels_encoder_unscaled: 0.5252 (0.6002)  labels_decoder_unscaled: 0.7611 (0.6672)  time: 0.1399  data: 0.0334  max mem: 3781
Test:  [ 250/1613]  eta: 0:03:39  loss: 0.5741 (0.9659)  labels_encoder: 0.2581 (0.6166)  labels_decoder: 0.3422 (0.3493)  labels_encoder_unscaled: 0.2581 (0.6166)  labels_decoder_unscaled: 0.6843 (0.6987)  time: 0.1371  data: 0.0064  max mem: 3781
Test:  [ 300/1613]  eta: 0:03:27  loss: 1.1027 (0.9944)  labels_encoder: 0.6650 (0.6349)  labels_decoder: 0.4610 (0.3595)  labels_encoder_unscaled: 0.6650 (0.6349)  labels_decoder_unscaled: 0.9220 (0.7190)  time: 0.1431  data: 0.0060  max mem: 3781
Test:  [ 350/1613]  eta: 0:03:17  loss: 1.4119 (1.0263)  labels_encoder: 0.8072 (0.6558)  labels_decoder: 0.5568 (0.3705)  labels_encoder_unscaled: 0.8072 (0.6558)  labels_decoder_unscaled: 1.1136 (0.7411)  time: 0.1401  data: 0.0450  max mem: 3781
Test:  [ 400/1613]  eta: 0:03:08  loss: 0.7338 (1.0848)  labels_encoder: 0.4021 (0.7003)  labels_decoder: 0.3155 (0.3845)  labels_encoder_unscaled: 0.4021 (0.7003)  labels_decoder_unscaled: 0.6310 (0.7690)  time: 0.1449  data: 0.0221  max mem: 3781
Test:  [ 450/1613]  eta: 0:02:59  loss: 1.2527 (1.1755)  labels_encoder: 0.9079 (0.7641)  labels_decoder: 0.3439 (0.4114)  labels_encoder_unscaled: 0.9079 (0.7641)  labels_decoder_unscaled: 0.6878 (0.8228)  time: 0.1421  data: 0.0429  max mem: 3781
Test:  [ 500/1613]  eta: 0:02:49  loss: 0.4122 (1.1244)  labels_encoder: 0.2124 (0.7290)  labels_decoder: 0.1817 (0.3954)  labels_encoder_unscaled: 0.2124 (0.7290)  labels_decoder_unscaled: 0.3634 (0.7908)  time: 0.1404  data: 0.0639  max mem: 3781
Test:  [ 550/1613]  eta: 0:02:39  loss: 0.5104 (1.0976)  labels_encoder: 0.3308 (0.7106)  labels_decoder: 0.2049 (0.3870)  labels_encoder_unscaled: 0.3308 (0.7106)  labels_decoder_unscaled: 0.4098 (0.7741)  time: 0.1112  data: 0.0242  max mem: 3781
Test:  [ 600/1613]  eta: 0:02:29  loss: 0.9014 (1.1387)  labels_encoder: 0.5154 (0.7442)  labels_decoder: 0.3860 (0.3945)  labels_encoder_unscaled: 0.5154 (0.7442)  labels_decoder_unscaled: 0.7720 (0.7890)  time: 0.1265  data: 0.0413  max mem: 3781
Test:  [ 650/1613]  eta: 0:02:21  loss: 1.1858 (1.1381)  labels_encoder: 0.7004 (0.7405)  labels_decoder: 0.5093 (0.3976)  labels_encoder_unscaled: 0.7004 (0.7405)  labels_decoder_unscaled: 1.0185 (0.7951)  time: 0.1371  data: 0.0515  max mem: 3781
Test:  [ 700/1613]  eta: 0:02:13  loss: 0.4922 (1.1051)  labels_encoder: 0.3422 (0.7181)  labels_decoder: 0.2023 (0.3870)  labels_encoder_unscaled: 0.3422 (0.7181)  labels_decoder_unscaled: 0.4046 (0.7740)  time: 0.1337  data: 0.0706  max mem: 3781
Test:  [ 750/1613]  eta: 0:02:05  loss: 0.8319 (1.0760)  labels_encoder: 0.5047 (0.6976)  labels_decoder: 0.2430 (0.3784)  labels_encoder_unscaled: 0.5047 (0.6976)  labels_decoder_unscaled: 0.4860 (0.7568)  time: 0.1381  data: 0.0585  max mem: 3781
Test:  [ 800/1613]  eta: 0:01:57  loss: 0.5486 (1.0637)  labels_encoder: 0.3665 (0.6902)  labels_decoder: 0.2471 (0.3735)  labels_encoder_unscaled: 0.3665 (0.6902)  labels_decoder_unscaled: 0.4941 (0.7471)  time: 0.1239  data: 0.0462  max mem: 3781
Test:  [ 850/1613]  eta: 0:01:49  loss: 0.9594 (1.0627)  labels_encoder: 0.5055 (0.6860)  labels_decoder: 0.3989 (0.3767)  labels_encoder_unscaled: 0.5055 (0.6860)  labels_decoder_unscaled: 0.7978 (0.7533)  time: 0.1310  data: 0.0392  max mem: 3781
Test:  [ 900/1613]  eta: 0:01:42  loss: 0.5665 (1.0404)  labels_encoder: 0.2700 (0.6695)  labels_decoder: 0.2692 (0.3709)  labels_encoder_unscaled: 0.2700 (0.6695)  labels_decoder_unscaled: 0.5385 (0.7418)  time: 0.1412  data: 0.0532  max mem: 3781
Test:  [ 950/1613]  eta: 0:01:35  loss: 1.1713 (1.0384)  labels_encoder: 0.7911 (0.6676)  labels_decoder: 0.3725 (0.3707)  labels_encoder_unscaled: 0.7911 (0.6676)  labels_decoder_unscaled: 0.7449 (0.7415)  time: 0.1347  data: 0.0443  max mem: 3781
Test:  [1000/1613]  eta: 0:01:27  loss: 0.6801 (1.0247)  labels_encoder: 0.3956 (0.6580)  labels_decoder: 0.2452 (0.3667)  labels_encoder_unscaled: 0.3956 (0.6580)  labels_decoder_unscaled: 0.4904 (0.7334)  time: 0.1263  data: 0.0588  max mem: 3781
Test:  [1050/1613]  eta: 0:01:19  loss: 1.0118 (1.0274)  labels_encoder: 0.6762 (0.6610)  labels_decoder: 0.3488 (0.3665)  labels_encoder_unscaled: 0.6762 (0.6610)  labels_decoder_unscaled: 0.6977 (0.7330)  time: 0.1314  data: 0.0453  max mem: 3781
Test:  [1100/1613]  eta: 0:01:12  loss: 0.4374 (1.0353)  labels_encoder: 0.2636 (0.6674)  labels_decoder: 0.2256 (0.3679)  labels_encoder_unscaled: 0.2636 (0.6674)  labels_decoder_unscaled: 0.4513 (0.7358)  time: 0.1319  data: 0.0252  max mem: 3781
Test:  [1150/1613]  eta: 0:01:04  loss: 0.4985 (1.0300)  labels_encoder: 0.2786 (0.6634)  labels_decoder: 0.2200 (0.3666)  labels_encoder_unscaled: 0.2786 (0.6634)  labels_decoder_unscaled: 0.4399 (0.7331)  time: 0.1158  data: 0.0444  max mem: 3781
Test:  [1200/1613]  eta: 0:00:57  loss: 0.5026 (1.0347)  labels_encoder: 0.2487 (0.6666)  labels_decoder: 0.2309 (0.3681)  labels_encoder_unscaled: 0.2487 (0.6666)  labels_decoder_unscaled: 0.4617 (0.7361)  time: 0.1330  data: 0.0311  max mem: 3781
Test:  [1250/1613]  eta: 0:00:50  loss: 0.5512 (1.0367)  labels_encoder: 0.2799 (0.6683)  labels_decoder: 0.2553 (0.3685)  labels_encoder_unscaled: 0.2799 (0.6683)  labels_decoder_unscaled: 0.5106 (0.7370)  time: 0.1264  data: 0.0377  max mem: 3781
Test:  [1300/1613]  eta: 0:00:43  loss: 0.6370 (1.0333)  labels_encoder: 0.4215 (0.6653)  labels_decoder: 0.3045 (0.3680)  labels_encoder_unscaled: 0.4215 (0.6653)  labels_decoder_unscaled: 0.6091 (0.7361)  time: 0.1274  data: 0.0453  max mem: 3781
Test:  [1350/1613]  eta: 0:00:36  loss: 1.2258 (1.0354)  labels_encoder: 0.7953 (0.6676)  labels_decoder: 0.4037 (0.3678)  labels_encoder_unscaled: 0.7953 (0.6676)  labels_decoder_unscaled: 0.8074 (0.7356)  time: 0.1252  data: 0.0399  max mem: 3781
Test:  [1400/1613]  eta: 0:00:29  loss: 1.1300 (1.0419)  labels_encoder: 0.7017 (0.6718)  labels_decoder: 0.4372 (0.3700)  labels_encoder_unscaled: 0.7017 (0.6718)  labels_decoder_unscaled: 0.8744 (0.7401)  time: 0.1336  data: 0.0163  max mem: 3781
Test:  [1450/1613]  eta: 0:00:22  loss: 0.5829 (1.0461)  labels_encoder: 0.2714 (0.6747)  labels_decoder: 0.2295 (0.3714)  labels_encoder_unscaled: 0.2714 (0.6747)  labels_decoder_unscaled: 0.4590 (0.7428)  time: 0.1276  data: 0.0521  max mem: 3781
Test:  [1500/1613]  eta: 0:00:15  loss: 0.6438 (1.0440)  labels_encoder: 0.3936 (0.6731)  labels_decoder: 0.2531 (0.3709)  labels_encoder_unscaled: 0.3936 (0.6731)  labels_decoder_unscaled: 0.5062 (0.7418)  time: 0.1239  data: 0.0284  max mem: 3781
Test:  [1550/1613]  eta: 0:00:08  loss: 0.7376 (1.0450)  labels_encoder: 0.5240 (0.6743)  labels_decoder: 0.2999 (0.3706)  labels_encoder_unscaled: 0.5240 (0.6743)  labels_decoder_unscaled: 0.5997 (0.7413)  time: 0.1322  data: 0.0408  max mem: 3781
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9829 (1.0437)  labels_encoder: 0.5019 (0.6729)  labels_decoder: 0.4704 (0.3708)  labels_encoder_unscaled: 0.5019 (0.6729)  labels_decoder_unscaled: 0.9407 (0.7416)  time: 0.1275  data: 0.0138  max mem: 3781
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7785 (1.0413)  labels_encoder: 0.4482 (0.6713)  labels_decoder: 0.3303 (0.3700)  labels_encoder_unscaled: 0.4482 (0.6713)  labels_decoder_unscaled: 0.6607 (0.7399)  time: 0.1129  data: 0.0225  max mem: 3781
Test: Total time: 0:03:41 (0.1371 s / it)
Averaged stats: loss: 0.7785 (1.0413)  labels_encoder: 0.4482 (0.6713)  labels_decoder: 0.3303 (0.3700)  labels_encoder_unscaled: 0.4482 (0.6713)  labels_decoder_unscaled: 0.6607 (0.7399)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-kin_audio] mAP: 0.6365

dec_mAP all together: | 0.5083574887327094 |.
dec_mAP_pred | 0 : 0.5550687522263329 |.
dec_mAP_pred | 1 : 0.548028912305307 |.
dec_mAP_pred | 2 : 0.5354100197596223 |.
dec_mAP_pred | 3 : 0.5203882141687891 |.
dec_mAP_pred | 4 : 0.5036665438334724 |.
dec_mAP_pred | 5 : 0.48673369477489203 |.
dec_mAP_pred | 6 : 0.4705485137557653 |.
dec_mAP_pred | 7 : 0.4550350911832666 |.
all decoder map: | 0.5094 |.
BaseballPitch: 0.2634
BasketballDunk: 0.8125
Billiards: 0.3267
CleanAndJerk: 0.7541
CliffDiving: 0.8567
CricketBowling: 0.4825
CricketShot: 0.3020
Diving: 0.8743
FrisbeeCatch: 0.3401
GolfSwing: 0.7952
HammerThrow: 0.8337
HighJump: 0.8005
JavelinThrow: 0.7399
LongJump: 0.7749
PoleVault: 0.8698
Shotput: 0.7273
SoccerPenalty: 0.4341
TennisSwing: 0.6174
ThrowDiscus: 0.6577
VolleyballSpiking: 0.4666
Epoch: [4]  [   0/1412]  eta: 1:28:03  lr: 0.000000  loss: 0.1702 (0.1702)  labels_encoder: 0.0710 (0.0710)  labels_decoder: 0.0992 (0.0992)  labels_encoder_unscaled: 0.0710 (0.0710)  labels_decoder_unscaled: 0.1984 (0.1984)  time: 3.7418  data: 3.5132  max mem: 3781
Epoch: [4]  [  50/1412]  eta: 0:06:22  lr: 0.000000  loss: 0.2174 (0.2262)  labels_encoder: 0.1009 (0.1155)  labels_decoder: 0.1089 (0.1107)  labels_encoder_unscaled: 0.1009 (0.1155)  labels_decoder_unscaled: 0.2178 (0.2213)  time: 0.1968  data: 0.0003  max mem: 3781
Epoch: [4]  [ 100/1412]  eta: 0:05:18  lr: 0.000000  loss: 0.2218 (0.2322)  labels_encoder: 0.1137 (0.1203)  labels_decoder: 0.1099 (0.1119)  labels_encoder_unscaled: 0.1137 (0.1203)  labels_decoder_unscaled: 0.2198 (0.2238)  time: 0.1908  data: 0.0003  max mem: 3781
Epoch: [4]  [ 150/1412]  eta: 0:04:47  lr: 0.000000  loss: 0.2039 (0.2259)  labels_encoder: 0.0994 (0.1150)  labels_decoder: 0.1079 (0.1109)  labels_encoder_unscaled: 0.0994 (0.1150)  labels_decoder_unscaled: 0.2158 (0.2218)  time: 0.2033  data: 0.0003  max mem: 3781
Epoch: [4]  [ 200/1412]  eta: 0:04:29  lr: 0.000000  loss: 0.2011 (0.2241)  labels_encoder: 0.1101 (0.1142)  labels_decoder: 0.1053 (0.1099)  labels_encoder_unscaled: 0.1101 (0.1142)  labels_decoder_unscaled: 0.2105 (0.2198)  time: 0.2017  data: 0.0004  max mem: 3781
Epoch: [4]  [ 250/1412]  eta: 0:04:12  lr: 0.000000  loss: 0.2078 (0.2227)  labels_encoder: 0.1033 (0.1129)  labels_decoder: 0.1013 (0.1097)  labels_encoder_unscaled: 0.1033 (0.1129)  labels_decoder_unscaled: 0.2026 (0.2195)  time: 0.2002  data: 0.0003  max mem: 3781
Epoch: [4]  [ 300/1412]  eta: 0:03:58  lr: 0.000000  loss: 0.2122 (0.2218)  labels_encoder: 0.0925 (0.1122)  labels_decoder: 0.1134 (0.1097)  labels_encoder_unscaled: 0.0925 (0.1122)  labels_decoder_unscaled: 0.2269 (0.2194)  time: 0.1995  data: 0.0003  max mem: 3781
Epoch: [4]  [ 350/1412]  eta: 0:03:44  lr: 0.000000  loss: 0.2104 (0.2227)  labels_encoder: 0.1055 (0.1125)  labels_decoder: 0.1059 (0.1102)  labels_encoder_unscaled: 0.1055 (0.1125)  labels_decoder_unscaled: 0.2118 (0.2204)  time: 0.2017  data: 0.0003  max mem: 3781
Epoch: [4]  [ 400/1412]  eta: 0:03:33  lr: 0.000000  loss: 0.1853 (0.2215)  labels_encoder: 0.0855 (0.1120)  labels_decoder: 0.0993 (0.1095)  labels_encoder_unscaled: 0.0855 (0.1120)  labels_decoder_unscaled: 0.1987 (0.2190)  time: 0.2025  data: 0.0003  max mem: 3781
Epoch: [4]  [ 450/1412]  eta: 0:03:21  lr: 0.000000  loss: 0.2206 (0.2219)  labels_encoder: 0.1124 (0.1123)  labels_decoder: 0.1170 (0.1096)  labels_encoder_unscaled: 0.1124 (0.1123)  labels_decoder_unscaled: 0.2339 (0.2192)  time: 0.2091  data: 0.0003  max mem: 3781
Epoch: [4]  [ 500/1412]  eta: 0:03:10  lr: 0.000000  loss: 0.2060 (0.2214)  labels_encoder: 0.0949 (0.1117)  labels_decoder: 0.1022 (0.1097)  labels_encoder_unscaled: 0.0949 (0.1117)  labels_decoder_unscaled: 0.2044 (0.2194)  time: 0.1956  data: 0.0003  max mem: 3781
Epoch: [4]  [ 550/1412]  eta: 0:02:59  lr: 0.000000  loss: 0.2121 (0.2210)  labels_encoder: 0.1123 (0.1117)  labels_decoder: 0.1038 (0.1094)  labels_encoder_unscaled: 0.1123 (0.1117)  labels_decoder_unscaled: 0.2076 (0.2187)  time: 0.1990  data: 0.0003  max mem: 3781
Epoch: [4]  [ 600/1412]  eta: 0:02:47  lr: 0.000000  loss: 0.2029 (0.2208)  labels_encoder: 0.1031 (0.1113)  labels_decoder: 0.1051 (0.1095)  labels_encoder_unscaled: 0.1031 (0.1113)  labels_decoder_unscaled: 0.2101 (0.2190)  time: 0.2006  data: 0.0003  max mem: 3781
Epoch: [4]  [ 650/1412]  eta: 0:02:37  lr: 0.000000  loss: 0.2151 (0.2206)  labels_encoder: 0.1076 (0.1111)  labels_decoder: 0.1019 (0.1095)  labels_encoder_unscaled: 0.1076 (0.1111)  labels_decoder_unscaled: 0.2039 (0.2190)  time: 0.1978  data: 0.0003  max mem: 3781
Epoch: [4]  [ 700/1412]  eta: 0:02:26  lr: 0.000000  loss: 0.2124 (0.2206)  labels_encoder: 0.1155 (0.1110)  labels_decoder: 0.1138 (0.1095)  labels_encoder_unscaled: 0.1155 (0.1110)  labels_decoder_unscaled: 0.2277 (0.2190)  time: 0.2007  data: 0.0003  max mem: 3781
Epoch: [4]  [ 750/1412]  eta: 0:02:15  lr: 0.000000  loss: 0.2258 (0.2207)  labels_encoder: 0.1099 (0.1111)  labels_decoder: 0.1113 (0.1096)  labels_encoder_unscaled: 0.1099 (0.1111)  labels_decoder_unscaled: 0.2227 (0.2193)  time: 0.1998  data: 0.0003  max mem: 3781
Epoch: [4]  [ 800/1412]  eta: 0:02:05  lr: 0.000000  loss: 0.2156 (0.2211)  labels_encoder: 0.1109 (0.1113)  labels_decoder: 0.1058 (0.1097)  labels_encoder_unscaled: 0.1109 (0.1113)  labels_decoder_unscaled: 0.2116 (0.2194)  time: 0.2088  data: 0.0003  max mem: 3781
Epoch: [4]  [ 850/1412]  eta: 0:01:55  lr: 0.000000  loss: 0.2138 (0.2212)  labels_encoder: 0.1037 (0.1115)  labels_decoder: 0.1075 (0.1098)  labels_encoder_unscaled: 0.1037 (0.1115)  labels_decoder_unscaled: 0.2150 (0.2195)  time: 0.1893  data: 0.0003  max mem: 3781
Epoch: [4]  [ 900/1412]  eta: 0:01:44  lr: 0.000000  loss: 0.2101 (0.2212)  labels_encoder: 0.1000 (0.1114)  labels_decoder: 0.1011 (0.1097)  labels_encoder_unscaled: 0.1000 (0.1114)  labels_decoder_unscaled: 0.2021 (0.2195)  time: 0.1990  data: 0.0003  max mem: 3781
Epoch: [4]  [ 950/1412]  eta: 0:01:34  lr: 0.000000  loss: 0.2162 (0.2209)  labels_encoder: 0.1039 (0.1112)  labels_decoder: 0.1089 (0.1098)  labels_encoder_unscaled: 0.1039 (0.1112)  labels_decoder_unscaled: 0.2178 (0.2195)  time: 0.2020  data: 0.0003  max mem: 3781
Epoch: [4]  [1000/1412]  eta: 0:01:24  lr: 0.000000  loss: 0.2165 (0.2214)  labels_encoder: 0.1001 (0.1114)  labels_decoder: 0.1131 (0.1100)  labels_encoder_unscaled: 0.1001 (0.1114)  labels_decoder_unscaled: 0.2261 (0.2199)  time: 0.1971  data: 0.0003  max mem: 3781
Epoch: [4]  [1050/1412]  eta: 0:01:13  lr: 0.000000  loss: 0.2277 (0.2215)  labels_encoder: 0.1101 (0.1117)  labels_decoder: 0.1029 (0.1098)  labels_encoder_unscaled: 0.1101 (0.1117)  labels_decoder_unscaled: 0.2057 (0.2196)  time: 0.2095  data: 0.0003  max mem: 3781
Epoch: [4]  [1100/1412]  eta: 0:01:03  lr: 0.000000  loss: 0.2264 (0.2218)  labels_encoder: 0.1200 (0.1120)  labels_decoder: 0.1103 (0.1098)  labels_encoder_unscaled: 0.1200 (0.1120)  labels_decoder_unscaled: 0.2207 (0.2196)  time: 0.2031  data: 0.0003  max mem: 3781
Epoch: [4]  [1150/1412]  eta: 0:00:53  lr: 0.000000  loss: 0.2149 (0.2218)  labels_encoder: 0.1048 (0.1120)  labels_decoder: 0.1115 (0.1098)  labels_encoder_unscaled: 0.1048 (0.1120)  labels_decoder_unscaled: 0.2230 (0.2197)  time: 0.1924  data: 0.0003  max mem: 3781
Epoch: [4]  [1200/1412]  eta: 0:00:43  lr: 0.000000  loss: 0.2300 (0.2220)  labels_encoder: 0.1178 (0.1121)  labels_decoder: 0.1134 (0.1099)  labels_encoder_unscaled: 0.1178 (0.1121)  labels_decoder_unscaled: 0.2268 (0.2197)  time: 0.2180  data: 0.0003  max mem: 3781
Epoch: [4]  [1250/1412]  eta: 0:00:33  lr: 0.000000  loss: 0.2024 (0.2221)  labels_encoder: 0.0983 (0.1122)  labels_decoder: 0.1049 (0.1099)  labels_encoder_unscaled: 0.0983 (0.1122)  labels_decoder_unscaled: 0.2099 (0.2197)  time: 0.2116  data: 0.0003  max mem: 3781
Epoch: [4]  [1300/1412]  eta: 0:00:22  lr: 0.000000  loss: 0.2223 (0.2222)  labels_encoder: 0.1134 (0.1123)  labels_decoder: 0.1128 (0.1099)  labels_encoder_unscaled: 0.1134 (0.1123)  labels_decoder_unscaled: 0.2256 (0.2197)  time: 0.1959  data: 0.0003  max mem: 3781
Epoch: [4]  [1350/1412]  eta: 0:00:12  lr: 0.000000  loss: 0.2337 (0.2228)  labels_encoder: 0.1072 (0.1126)  labels_decoder: 0.1158 (0.1102)  labels_encoder_unscaled: 0.1072 (0.1126)  labels_decoder_unscaled: 0.2315 (0.2204)  time: 0.1992  data: 0.0003  max mem: 3781
Epoch: [4]  [1400/1412]  eta: 0:00:02  lr: 0.000000  loss: 0.2249 (0.2230)  labels_encoder: 0.1186 (0.1128)  labels_decoder: 0.1102 (0.1103)  labels_encoder_unscaled: 0.1186 (0.1128)  labels_decoder_unscaled: 0.2205 (0.2205)  time: 0.1930  data: 0.0007  max mem: 3781
Epoch: [4]  [1411/1412]  eta: 0:00:00  lr: 0.000000  loss: 0.2249 (0.2229)  labels_encoder: 0.1089 (0.1126)  labels_decoder: 0.1081 (0.1102)  labels_encoder_unscaled: 0.1089 (0.1126)  labels_decoder_unscaled: 0.2162 (0.2204)  time: 0.1631  data: 0.0006  max mem: 3781
Epoch: [4] Total time: 0:04:47 (0.2039 s / it)
Averaged stats: lr: 0.000000  loss: 0.2249 (0.2229)  labels_encoder: 0.1089 (0.1126)  labels_decoder: 0.1081 (0.1102)  labels_encoder_unscaled: 0.1089 (0.1126)  labels_decoder_unscaled: 0.2162 (0.2204)
Test:  [   0/1613]  eta: 1:57:20  loss: 1.5408 (1.5408)  labels_encoder: 0.9466 (0.9466)  labels_decoder: 0.5942 (0.5942)  labels_encoder_unscaled: 0.9466 (0.9466)  labels_decoder_unscaled: 1.1885 (1.1885)  time: 4.3649  data: 4.1819  max mem: 3781
Test:  [  50/1613]  eta: 0:05:13  loss: 0.4165 (0.8322)  labels_encoder: 0.2532 (0.5159)  labels_decoder: 0.2066 (0.3163)  labels_encoder_unscaled: 0.2532 (0.5159)  labels_decoder_unscaled: 0.4133 (0.6325)  time: 0.1105  data: 0.0002  max mem: 3781
Test:  [ 100/1613]  eta: 0:03:53  loss: 0.5792 (0.7704)  labels_encoder: 0.3528 (0.4967)  labels_decoder: 0.1833 (0.2737)  labels_encoder_unscaled: 0.3528 (0.4967)  labels_decoder_unscaled: 0.3666 (0.5474)  time: 0.1093  data: 0.0107  max mem: 3781
Test:  [ 150/1613]  eta: 0:03:29  loss: 1.0185 (0.7726)  labels_encoder: 0.7093 (0.4950)  labels_decoder: 0.2455 (0.2776)  labels_encoder_unscaled: 0.7093 (0.4950)  labels_decoder_unscaled: 0.4911 (0.5552)  time: 0.1207  data: 0.0440  max mem: 3781
Test:  [ 200/1613]  eta: 0:03:13  loss: 0.9075 (0.9309)  labels_encoder: 0.5208 (0.5976)  labels_decoder: 0.3803 (0.3333)  labels_encoder_unscaled: 0.5208 (0.5976)  labels_decoder_unscaled: 0.7606 (0.6666)  time: 0.1259  data: 0.0306  max mem: 3781
Test:  [ 250/1613]  eta: 0:03:02  loss: 0.5936 (0.9637)  labels_encoder: 0.2805 (0.6145)  labels_decoder: 0.3386 (0.3492)  labels_encoder_unscaled: 0.2805 (0.6145)  labels_decoder_unscaled: 0.6771 (0.6984)  time: 0.1263  data: 0.0002  max mem: 3781
Test:  [ 300/1613]  eta: 0:02:52  loss: 1.1046 (0.9912)  labels_encoder: 0.6659 (0.6321)  labels_decoder: 0.4626 (0.3591)  labels_encoder_unscaled: 0.6659 (0.6321)  labels_decoder_unscaled: 0.9252 (0.7181)  time: 0.1130  data: 0.0002  max mem: 3781
Test:  [ 350/1613]  eta: 0:02:42  loss: 1.4220 (1.0258)  labels_encoder: 0.8227 (0.6547)  labels_decoder: 0.5570 (0.3711)  labels_encoder_unscaled: 0.8227 (0.6547)  labels_decoder_unscaled: 1.1140 (0.7422)  time: 0.1129  data: 0.0002  max mem: 3781
Test:  [ 400/1613]  eta: 0:02:34  loss: 0.7316 (1.0832)  labels_encoder: 0.4017 (0.6983)  labels_decoder: 0.3196 (0.3849)  labels_encoder_unscaled: 0.4017 (0.6983)  labels_decoder_unscaled: 0.6393 (0.7699)  time: 0.1134  data: 0.0033  max mem: 3781
Test:  [ 450/1613]  eta: 0:02:26  loss: 1.2706 (1.1752)  labels_encoder: 0.9177 (0.7631)  labels_decoder: 0.3509 (0.4121)  labels_encoder_unscaled: 0.9177 (0.7631)  labels_decoder_unscaled: 0.7019 (0.8243)  time: 0.1144  data: 0.0068  max mem: 3781
Test:  [ 500/1613]  eta: 0:02:19  loss: 0.4062 (1.1238)  labels_encoder: 0.2142 (0.7278)  labels_decoder: 0.1795 (0.3960)  labels_encoder_unscaled: 0.2142 (0.7278)  labels_decoder_unscaled: 0.3591 (0.7920)  time: 0.1145  data: 0.0221  max mem: 3781
Test:  [ 550/1613]  eta: 0:02:12  loss: 0.5096 (1.0947)  labels_encoder: 0.3308 (0.7079)  labels_decoder: 0.1988 (0.3868)  labels_encoder_unscaled: 0.3308 (0.7079)  labels_decoder_unscaled: 0.3976 (0.7737)  time: 0.1095  data: 0.0042  max mem: 3781
Test:  [ 600/1613]  eta: 0:02:05  loss: 0.9127 (1.1363)  labels_encoder: 0.5204 (0.7421)  labels_decoder: 0.3922 (0.3942)  labels_encoder_unscaled: 0.5204 (0.7421)  labels_decoder_unscaled: 0.7845 (0.7884)  time: 0.1193  data: 0.0175  max mem: 3781
Test:  [ 650/1613]  eta: 0:01:58  loss: 1.2209 (1.1372)  labels_encoder: 0.7239 (0.7394)  labels_decoder: 0.5228 (0.3978)  labels_encoder_unscaled: 0.7239 (0.7394)  labels_decoder_unscaled: 1.0456 (0.7957)  time: 0.1141  data: 0.0098  max mem: 3781
Test:  [ 700/1613]  eta: 0:01:51  loss: 0.5222 (1.1039)  labels_encoder: 0.3387 (0.7168)  labels_decoder: 0.2014 (0.3871)  labels_encoder_unscaled: 0.3387 (0.7168)  labels_decoder_unscaled: 0.4027 (0.7742)  time: 0.1169  data: 0.0297  max mem: 3781
Test:  [ 750/1613]  eta: 0:01:45  loss: 0.8507 (1.0756)  labels_encoder: 0.5127 (0.6967)  labels_decoder: 0.2664 (0.3789)  labels_encoder_unscaled: 0.5127 (0.6967)  labels_decoder_unscaled: 0.5328 (0.7577)  time: 0.1159  data: 0.0116  max mem: 3781
Test:  [ 800/1613]  eta: 0:01:38  loss: 0.5440 (1.0637)  labels_encoder: 0.3578 (0.6895)  labels_decoder: 0.2475 (0.3741)  labels_encoder_unscaled: 0.3578 (0.6895)  labels_decoder_unscaled: 0.4949 (0.7482)  time: 0.1175  data: 0.0275  max mem: 3781
Test:  [ 850/1613]  eta: 0:01:32  loss: 0.9788 (1.0628)  labels_encoder: 0.5162 (0.6854)  labels_decoder: 0.4096 (0.3774)  labels_encoder_unscaled: 0.5162 (0.6854)  labels_decoder_unscaled: 0.8191 (0.7548)  time: 0.1137  data: 0.0155  max mem: 3781
Test:  [ 900/1613]  eta: 0:01:26  loss: 0.5825 (1.0403)  labels_encoder: 0.2832 (0.6687)  labels_decoder: 0.2716 (0.3716)  labels_encoder_unscaled: 0.2832 (0.6687)  labels_decoder_unscaled: 0.5432 (0.7433)  time: 0.1138  data: 0.0229  max mem: 3781
Test:  [ 950/1613]  eta: 0:01:20  loss: 1.1755 (1.0399)  labels_encoder: 0.8052 (0.6677)  labels_decoder: 0.3885 (0.3722)  labels_encoder_unscaled: 0.8052 (0.6677)  labels_decoder_unscaled: 0.7770 (0.7444)  time: 0.1088  data: 0.0235  max mem: 3781
Test:  [1000/1613]  eta: 0:01:13  loss: 0.6887 (1.0265)  labels_encoder: 0.3892 (0.6583)  labels_decoder: 0.2520 (0.3683)  labels_encoder_unscaled: 0.3892 (0.6583)  labels_decoder_unscaled: 0.5040 (0.7366)  time: 0.1136  data: 0.0244  max mem: 3781
Test:  [1050/1613]  eta: 0:01:07  loss: 1.0305 (1.0298)  labels_encoder: 0.6817 (0.6615)  labels_decoder: 0.3532 (0.3683)  labels_encoder_unscaled: 0.6817 (0.6615)  labels_decoder_unscaled: 0.7065 (0.7366)  time: 0.1108  data: 0.0002  max mem: 3781
Test:  [1100/1613]  eta: 0:01:01  loss: 0.4369 (1.0363)  labels_encoder: 0.2644 (0.6670)  labels_decoder: 0.2104 (0.3693)  labels_encoder_unscaled: 0.2644 (0.6670)  labels_decoder_unscaled: 0.4208 (0.7385)  time: 0.1131  data: 0.0002  max mem: 3781
Test:  [1150/1613]  eta: 0:00:55  loss: 0.4995 (1.0311)  labels_encoder: 0.2790 (0.6632)  labels_decoder: 0.2205 (0.3679)  labels_encoder_unscaled: 0.2790 (0.6632)  labels_decoder_unscaled: 0.4411 (0.7358)  time: 0.1110  data: 0.0192  max mem: 3781
Test:  [1200/1613]  eta: 0:00:49  loss: 0.4950 (1.0357)  labels_encoder: 0.2485 (0.6664)  labels_decoder: 0.2329 (0.3694)  labels_encoder_unscaled: 0.2485 (0.6664)  labels_decoder_unscaled: 0.4658 (0.7387)  time: 0.1136  data: 0.0249  max mem: 3781
Test:  [1250/1613]  eta: 0:00:43  loss: 0.5614 (1.0376)  labels_encoder: 0.2883 (0.6679)  labels_decoder: 0.2616 (0.3697)  labels_encoder_unscaled: 0.2883 (0.6679)  labels_decoder_unscaled: 0.5233 (0.7395)  time: 0.1166  data: 0.0093  max mem: 3781
Test:  [1300/1613]  eta: 0:00:37  loss: 0.6349 (1.0336)  labels_encoder: 0.4196 (0.6645)  labels_decoder: 0.3045 (0.3691)  labels_encoder_unscaled: 0.4196 (0.6645)  labels_decoder_unscaled: 0.6091 (0.7383)  time: 0.1194  data: 0.0165  max mem: 3781
Test:  [1350/1613]  eta: 0:00:31  loss: 1.1535 (1.0353)  labels_encoder: 0.7411 (0.6665)  labels_decoder: 0.3945 (0.3688)  labels_encoder_unscaled: 0.7411 (0.6665)  labels_decoder_unscaled: 0.7891 (0.7376)  time: 0.1135  data: 0.0490  max mem: 3781
Test:  [1400/1613]  eta: 0:00:25  loss: 1.0599 (1.0414)  labels_encoder: 0.6351 (0.6705)  labels_decoder: 0.4249 (0.3709)  labels_encoder_unscaled: 0.6351 (0.6705)  labels_decoder_unscaled: 0.8497 (0.7419)  time: 0.1158  data: 0.0002  max mem: 3781
Test:  [1450/1613]  eta: 0:00:19  loss: 0.5805 (1.0442)  labels_encoder: 0.3038 (0.6723)  labels_decoder: 0.2373 (0.3718)  labels_encoder_unscaled: 0.3038 (0.6723)  labels_decoder_unscaled: 0.4746 (0.7436)  time: 0.1153  data: 0.0094  max mem: 3781
Test:  [1500/1613]  eta: 0:00:13  loss: 0.6460 (1.0420)  labels_encoder: 0.3884 (0.6707)  labels_decoder: 0.2582 (0.3714)  labels_encoder_unscaled: 0.3884 (0.6707)  labels_decoder_unscaled: 0.5164 (0.7427)  time: 0.1114  data: 0.0060  max mem: 3781
Test:  [1550/1613]  eta: 0:00:07  loss: 0.7365 (1.0435)  labels_encoder: 0.5222 (0.6722)  labels_decoder: 0.3005 (0.3713)  labels_encoder_unscaled: 0.5222 (0.6722)  labels_decoder_unscaled: 0.6011 (0.7425)  time: 0.1103  data: 0.0026  max mem: 3781
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9647 (1.0418)  labels_encoder: 0.5019 (0.6705)  labels_decoder: 0.4655 (0.3713)  labels_encoder_unscaled: 0.5019 (0.6705)  labels_decoder_unscaled: 0.9309 (0.7426)  time: 0.1045  data: 0.0002  max mem: 3781
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7996 (1.0394)  labels_encoder: 0.4625 (0.6689)  labels_decoder: 0.3372 (0.3705)  labels_encoder_unscaled: 0.4625 (0.6689)  labels_decoder_unscaled: 0.6743 (0.7409)  time: 0.1000  data: 0.0001  max mem: 3781
Test: Total time: 0:03:12 (0.1192 s / it)
Averaged stats: loss: 0.7996 (1.0394)  labels_encoder: 0.4625 (0.6689)  labels_decoder: 0.3372 (0.3705)  labels_encoder_unscaled: 0.4625 (0.6689)  labels_decoder_unscaled: 0.6743 (0.7409)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-kin_audio] mAP: 0.6365

dec_mAP all together: | 0.5077301537683027 |.
dec_mAP_pred | 0 : 0.5540724130109865 |.
dec_mAP_pred | 1 : 0.5471421697513125 |.
dec_mAP_pred | 2 : 0.5346083034574398 |.
dec_mAP_pred | 3 : 0.5197191086150948 |.
dec_mAP_pred | 4 : 0.5030715787125473 |.
dec_mAP_pred | 5 : 0.48624927037579235 |.
dec_mAP_pred | 6 : 0.47012417087661423 |.
dec_mAP_pred | 7 : 0.4546675219982081 |.
all decoder map: | 0.5087 |.
BaseballPitch: 0.2635
BasketballDunk: 0.8134
Billiards: 0.3264
CleanAndJerk: 0.7534
CliffDiving: 0.8568
CricketBowling: 0.4834
CricketShot: 0.3043
Diving: 0.8737
FrisbeeCatch: 0.3393
GolfSwing: 0.7958
HammerThrow: 0.8334
HighJump: 0.8012
JavelinThrow: 0.7401
LongJump: 0.7730
PoleVault: 0.8697
Shotput: 0.7273
SoccerPenalty: 0.4326
TennisSwing: 0.6175
ThrowDiscus: 0.6574
VolleyballSpiking: 0.4677
Training time 0:38:16
