Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:kin_audio
dim_feature:8192
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:2
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:5
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  73.526 M, 99.828% Params, 2.372 GMac, 100.000% MACs, 
  (linear_encoding): Linear(8.39 M, 11.391% Params, 0.537 GMac, 22.630% MACs, in_features=8192, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    12.589 M, 17.092% Params, 0.818 GMac, 34.482% MACs, 
    (net): Sequential(
      12.589 M, 17.092% Params, 0.818 GMac, 34.482% MACs, 
      (0): Residual(
        4.195 M, 5.696% Params, 0.273 GMac, 11.492% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.696% Params, 0.273 GMac, 11.492% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.696% Params, 0.273 GMac, 11.492% MACs, 
            (qkv): Linear(3.146 M, 4.271% Params, 0.204 GMac, 8.619% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.850% Params, 0.136 GMac, 5.749% MACs, 
        (fn): PreNorm(
          2.099 M, 2.850% Params, 0.136 GMac, 5.749% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.850% Params, 0.136 GMac, 5.749% MACs, 
            (net): Sequential(
              2.099 M, 2.850% Params, 0.136 GMac, 5.749% MACs, 
              (0): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.696% Params, 0.273 GMac, 11.492% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.696% Params, 0.273 GMac, 11.492% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.696% Params, 0.273 GMac, 11.492% MACs, 
            (qkv): Linear(3.146 M, 4.271% Params, 0.204 GMac, 8.619% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.850% Params, 0.136 GMac, 5.749% MACs, 
        (fn): PreNorm(
          2.099 M, 2.850% Params, 0.136 GMac, 5.749% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.850% Params, 0.136 GMac, 5.749% MACs, 
            (net): Sequential(
              2.099 M, 2.850% Params, 0.136 GMac, 5.749% MACs, 
              (0): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.061% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 71.253% Params, 1.017 GMac, 42.879% MACs, 
    (layers): ModuleList(
      52.48 M, 71.253% Params, 1.017 GMac, 42.879% MACs, 
      (0): DecoderLayer(
        10.496 M, 14.251% Params, 0.203 GMac, 8.576% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.034 GMac, 1.415% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.153 GMac, 6.453% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 14.251% Params, 0.203 GMac, 8.576% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.034 GMac, 1.415% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.153 GMac, 6.453% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 14.251% Params, 0.203 GMac, 8.576% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.034 GMac, 1.415% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.153 GMac, 6.453% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 14.251% Params, 0.203 GMac, 8.576% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.034 GMac, 1.415% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.153 GMac, 6.453% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 14.251% Params, 0.203 GMac, 8.576% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.034 GMac, 1.415% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.700% Params, 0.153 GMac, 6.453% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.425% Params, 0.068 GMac, 2.873% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.425% Params, 0.008 GMac, 0.354% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.031% Params, 0.0 GMac, 0.008% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2372367404.0
Model params: 73653292
Loaded data/thumos_kin_plus_audio_val.pickle
Loaded data/thumos_kin_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1412]  eta: 1:53:34  lr: 0.000100  loss: 4.4324 (4.4324)  labels_encoder: 3.1138 (3.1138)  labels_decoder: 1.3186 (1.3186)  labels_encoder_unscaled: 3.1138 (3.1138)  labels_decoder_unscaled: 2.6371 (2.6371)  time: 4.8261  data: 4.1185  max mem: 2433
Epoch: [1]  [  50/1412]  eta: 0:06:05  lr: 0.000100  loss: 1.0731 (1.6030)  labels_encoder: 0.6756 (1.0488)  labels_decoder: 0.3815 (0.5543)  labels_encoder_unscaled: 0.6756 (1.0488)  labels_decoder_unscaled: 0.7631 (1.1085)  time: 0.1594  data: 0.0003  max mem: 3277
Epoch: [1]  [ 100/1412]  eta: 0:04:49  lr: 0.000100  loss: 0.7122 (1.1972)  labels_encoder: 0.4332 (0.7711)  labels_decoder: 0.2784 (0.4260)  labels_encoder_unscaled: 0.4332 (0.7711)  labels_decoder_unscaled: 0.5568 (0.8521)  time: 0.1765  data: 0.0003  max mem: 3277
Epoch: [1]  [ 150/1412]  eta: 0:04:19  lr: 0.000100  loss: 0.6737 (1.0241)  labels_encoder: 0.4294 (0.6542)  labels_decoder: 0.2468 (0.3698)  labels_encoder_unscaled: 0.4294 (0.6542)  labels_decoder_unscaled: 0.4937 (0.7396)  time: 0.1767  data: 0.0003  max mem: 3277
Epoch: [1]  [ 200/1412]  eta: 0:03:57  lr: 0.000100  loss: 0.6014 (0.9185)  labels_encoder: 0.3562 (0.5810)  labels_decoder: 0.2357 (0.3375)  labels_encoder_unscaled: 0.3562 (0.5810)  labels_decoder_unscaled: 0.4714 (0.6750)  time: 0.1718  data: 0.0003  max mem: 3277
Epoch: [1]  [ 250/1412]  eta: 0:03:42  lr: 0.000100  loss: 0.5509 (0.8491)  labels_encoder: 0.3229 (0.5338)  labels_decoder: 0.2201 (0.3153)  labels_encoder_unscaled: 0.3229 (0.5338)  labels_decoder_unscaled: 0.4403 (0.6306)  time: 0.1774  data: 0.0003  max mem: 3277
Epoch: [1]  [ 300/1412]  eta: 0:03:28  lr: 0.000100  loss: 0.5374 (0.7997)  labels_encoder: 0.3279 (0.5000)  labels_decoder: 0.2149 (0.2998)  labels_encoder_unscaled: 0.3279 (0.5000)  labels_decoder_unscaled: 0.4298 (0.5996)  time: 0.1645  data: 0.0003  max mem: 3277
Epoch: [1]  [ 350/1412]  eta: 0:03:16  lr: 0.000100  loss: 0.4584 (0.7576)  labels_encoder: 0.2708 (0.4712)  labels_decoder: 0.2027 (0.2864)  labels_encoder_unscaled: 0.2708 (0.4712)  labels_decoder_unscaled: 0.4054 (0.5727)  time: 0.1736  data: 0.0003  max mem: 3277
Epoch: [1]  [ 400/1412]  eta: 0:03:04  lr: 0.000100  loss: 0.4467 (0.7252)  labels_encoder: 0.2666 (0.4492)  labels_decoder: 0.1838 (0.2760)  labels_encoder_unscaled: 0.2666 (0.4492)  labels_decoder_unscaled: 0.3676 (0.5519)  time: 0.1652  data: 0.0006  max mem: 3277
Epoch: [1]  [ 450/1412]  eta: 0:02:54  lr: 0.000100  loss: 0.4984 (0.6989)  labels_encoder: 0.2971 (0.4318)  labels_decoder: 0.1965 (0.2671)  labels_encoder_unscaled: 0.2971 (0.4318)  labels_decoder_unscaled: 0.3930 (0.5342)  time: 0.1676  data: 0.0003  max mem: 3277
Epoch: [1]  [ 500/1412]  eta: 0:02:44  lr: 0.000100  loss: 0.4684 (0.6771)  labels_encoder: 0.2752 (0.4169)  labels_decoder: 0.1948 (0.2603)  labels_encoder_unscaled: 0.2752 (0.4169)  labels_decoder_unscaled: 0.3895 (0.5205)  time: 0.1719  data: 0.0003  max mem: 3277
Epoch: [1]  [ 550/1412]  eta: 0:02:35  lr: 0.000100  loss: 0.4341 (0.6583)  labels_encoder: 0.2380 (0.4040)  labels_decoder: 0.1960 (0.2542)  labels_encoder_unscaled: 0.2380 (0.4040)  labels_decoder_unscaled: 0.3921 (0.5085)  time: 0.1775  data: 0.0004  max mem: 3277
Epoch: [1]  [ 600/1412]  eta: 0:02:25  lr: 0.000100  loss: 0.4400 (0.6414)  labels_encoder: 0.2525 (0.3927)  labels_decoder: 0.1886 (0.2487)  labels_encoder_unscaled: 0.2525 (0.3927)  labels_decoder_unscaled: 0.3771 (0.4974)  time: 0.1641  data: 0.0003  max mem: 3277
Epoch: [1]  [ 650/1412]  eta: 0:02:16  lr: 0.000100  loss: 0.4511 (0.6281)  labels_encoder: 0.2718 (0.3834)  labels_decoder: 0.2004 (0.2448)  labels_encoder_unscaled: 0.2718 (0.3834)  labels_decoder_unscaled: 0.4007 (0.4895)  time: 0.1845  data: 0.0003  max mem: 3277
Epoch: [1]  [ 700/1412]  eta: 0:02:07  lr: 0.000100  loss: 0.4103 (0.6146)  labels_encoder: 0.2333 (0.3742)  labels_decoder: 0.1790 (0.2404)  labels_encoder_unscaled: 0.2333 (0.3742)  labels_decoder_unscaled: 0.3580 (0.4808)  time: 0.1698  data: 0.0003  max mem: 3277
Epoch: [1]  [ 750/1412]  eta: 0:01:57  lr: 0.000100  loss: 0.4445 (0.6021)  labels_encoder: 0.2549 (0.3659)  labels_decoder: 0.1748 (0.2362)  labels_encoder_unscaled: 0.2549 (0.3659)  labels_decoder_unscaled: 0.3497 (0.4724)  time: 0.1698  data: 0.0020  max mem: 3277
Epoch: [1]  [ 800/1412]  eta: 0:01:48  lr: 0.000100  loss: 0.4276 (0.5909)  labels_encoder: 0.2434 (0.3587)  labels_decoder: 0.1742 (0.2323)  labels_encoder_unscaled: 0.2434 (0.3587)  labels_decoder_unscaled: 0.3483 (0.4645)  time: 0.1734  data: 0.0003  max mem: 3277
Epoch: [1]  [ 850/1412]  eta: 0:01:39  lr: 0.000100  loss: 0.4151 (0.5802)  labels_encoder: 0.2515 (0.3517)  labels_decoder: 0.1674 (0.2285)  labels_encoder_unscaled: 0.2515 (0.3517)  labels_decoder_unscaled: 0.3348 (0.4570)  time: 0.1718  data: 0.0003  max mem: 3277
Epoch: [1]  [ 900/1412]  eta: 0:01:30  lr: 0.000100  loss: 0.4039 (0.5710)  labels_encoder: 0.2358 (0.3456)  labels_decoder: 0.1669 (0.2254)  labels_encoder_unscaled: 0.2358 (0.3456)  labels_decoder_unscaled: 0.3337 (0.4507)  time: 0.1803  data: 0.0003  max mem: 3277
Epoch: [1]  [ 950/1412]  eta: 0:01:21  lr: 0.000100  loss: 0.3734 (0.5613)  labels_encoder: 0.2148 (0.3392)  labels_decoder: 0.1621 (0.2221)  labels_encoder_unscaled: 0.2148 (0.3392)  labels_decoder_unscaled: 0.3242 (0.4441)  time: 0.1755  data: 0.0003  max mem: 3277
Epoch: [1]  [1000/1412]  eta: 0:01:12  lr: 0.000100  loss: 0.3855 (0.5528)  labels_encoder: 0.2178 (0.3337)  labels_decoder: 0.1632 (0.2191)  labels_encoder_unscaled: 0.2178 (0.3337)  labels_decoder_unscaled: 0.3264 (0.4382)  time: 0.1714  data: 0.0003  max mem: 3277
Epoch: [1]  [1050/1412]  eta: 0:01:03  lr: 0.000100  loss: 0.3926 (0.5451)  labels_encoder: 0.2089 (0.3285)  labels_decoder: 0.1650 (0.2167)  labels_encoder_unscaled: 0.2089 (0.3285)  labels_decoder_unscaled: 0.3300 (0.4333)  time: 0.1700  data: 0.0003  max mem: 3277
Epoch: [1]  [1100/1412]  eta: 0:00:55  lr: 0.000100  loss: 0.3818 (0.5375)  labels_encoder: 0.2012 (0.3231)  labels_decoder: 0.1803 (0.2144)  labels_encoder_unscaled: 0.2012 (0.3231)  labels_decoder_unscaled: 0.3607 (0.4287)  time: 0.1842  data: 0.0005  max mem: 3277
Epoch: [1]  [1150/1412]  eta: 0:00:46  lr: 0.000100  loss: 0.3944 (0.5306)  labels_encoder: 0.2089 (0.3184)  labels_decoder: 0.1770 (0.2123)  labels_encoder_unscaled: 0.2089 (0.3184)  labels_decoder_unscaled: 0.3540 (0.4245)  time: 0.1620  data: 0.0003  max mem: 3277
Epoch: [1]  [1200/1412]  eta: 0:00:37  lr: 0.000100  loss: 0.3504 (0.5241)  labels_encoder: 0.2008 (0.3142)  labels_decoder: 0.1437 (0.2099)  labels_encoder_unscaled: 0.2008 (0.3142)  labels_decoder_unscaled: 0.2874 (0.4199)  time: 0.1800  data: 0.0003  max mem: 3277
Epoch: [1]  [1250/1412]  eta: 0:00:28  lr: 0.000100  loss: 0.3545 (0.5173)  labels_encoder: 0.1890 (0.3094)  labels_decoder: 0.1656 (0.2079)  labels_encoder_unscaled: 0.1890 (0.3094)  labels_decoder_unscaled: 0.3312 (0.4157)  time: 0.1679  data: 0.0006  max mem: 3277
Epoch: [1]  [1300/1412]  eta: 0:00:19  lr: 0.000100  loss: 0.3532 (0.5111)  labels_encoder: 0.1869 (0.3052)  labels_decoder: 0.1540 (0.2060)  labels_encoder_unscaled: 0.1869 (0.3052)  labels_decoder_unscaled: 0.3080 (0.4119)  time: 0.1574  data: 0.0003  max mem: 3277
Epoch: [1]  [1350/1412]  eta: 0:00:10  lr: 0.000100  loss: 0.3435 (0.5057)  labels_encoder: 0.1859 (0.3015)  labels_decoder: 0.1638 (0.2042)  labels_encoder_unscaled: 0.1859 (0.3015)  labels_decoder_unscaled: 0.3276 (0.4083)  time: 0.1712  data: 0.0003  max mem: 3277
Epoch: [1]  [1400/1412]  eta: 0:00:02  lr: 0.000100  loss: 0.3401 (0.5006)  labels_encoder: 0.1839 (0.2980)  labels_decoder: 0.1594 (0.2027)  labels_encoder_unscaled: 0.1839 (0.2980)  labels_decoder_unscaled: 0.3188 (0.4053)  time: 0.1661  data: 0.0005  max mem: 3277
Epoch: [1]  [1411/1412]  eta: 0:00:00  lr: 0.000100  loss: 0.3769 (0.4995)  labels_encoder: 0.1961 (0.2971)  labels_decoder: 0.1643 (0.2024)  labels_encoder_unscaled: 0.1961 (0.2971)  labels_decoder_unscaled: 0.3286 (0.4048)  time: 0.1406  data: 0.0004  max mem: 3277
Epoch: [1] Total time: 0:04:08 (0.1757 s / it)
Averaged stats: lr: 0.000100  loss: 0.3769 (0.4995)  labels_encoder: 0.1961 (0.2971)  labels_decoder: 0.1643 (0.2024)  labels_encoder_unscaled: 0.1961 (0.2971)  labels_decoder_unscaled: 0.3286 (0.4048)
Test:  [   0/1613]  eta: 1:14:55  loss: 1.6688 (1.6688)  labels_encoder: 1.0208 (1.0208)  labels_decoder: 0.6480 (0.6480)  labels_encoder_unscaled: 1.0208 (1.0208)  labels_decoder_unscaled: 1.2960 (1.2960)  time: 2.7870  data: 2.7166  max mem: 3277
Test:  [  50/1613]  eta: 0:04:06  loss: 0.5070 (0.8993)  labels_encoder: 0.2476 (0.5506)  labels_decoder: 0.2458 (0.3486)  labels_encoder_unscaled: 0.2476 (0.5506)  labels_decoder_unscaled: 0.4915 (0.6973)  time: 0.0986  data: 0.0064  max mem: 3277
Test:  [ 100/1613]  eta: 0:03:22  loss: 0.7531 (0.7823)  labels_encoder: 0.3854 (0.5001)  labels_decoder: 0.2303 (0.2822)  labels_encoder_unscaled: 0.3854 (0.5001)  labels_decoder_unscaled: 0.4607 (0.5644)  time: 0.1167  data: 0.0474  max mem: 3277
Test:  [ 150/1613]  eta: 0:03:03  loss: 1.2577 (0.8183)  labels_encoder: 0.9217 (0.5273)  labels_decoder: 0.3439 (0.2911)  labels_encoder_unscaled: 0.9217 (0.5273)  labels_decoder_unscaled: 0.6878 (0.5821)  time: 0.1031  data: 0.0064  max mem: 3277
Test:  [ 200/1613]  eta: 0:02:49  loss: 0.9191 (0.9304)  labels_encoder: 0.5224 (0.6011)  labels_decoder: 0.3951 (0.3292)  labels_encoder_unscaled: 0.5224 (0.6011)  labels_decoder_unscaled: 0.7902 (0.6585)  time: 0.1093  data: 0.0368  max mem: 3277
Test:  [ 250/1613]  eta: 0:02:40  loss: 0.7100 (0.9372)  labels_encoder: 0.4009 (0.5974)  labels_decoder: 0.3061 (0.3398)  labels_encoder_unscaled: 0.4009 (0.5974)  labels_decoder_unscaled: 0.6121 (0.6797)  time: 0.1044  data: 0.0216  max mem: 3277
Test:  [ 300/1613]  eta: 0:02:34  loss: 1.5774 (1.0272)  labels_encoder: 0.9007 (0.6491)  labels_decoder: 0.6766 (0.3781)  labels_encoder_unscaled: 0.9007 (0.6491)  labels_decoder_unscaled: 1.3533 (0.7562)  time: 0.1183  data: 0.0507  max mem: 3277
Test:  [ 350/1613]  eta: 0:02:27  loss: 0.6947 (1.0219)  labels_encoder: 0.3484 (0.6490)  labels_decoder: 0.3264 (0.3729)  labels_encoder_unscaled: 0.3484 (0.6490)  labels_decoder_unscaled: 0.6529 (0.7458)  time: 0.1089  data: 0.0329  max mem: 3277
Test:  [ 400/1613]  eta: 0:02:20  loss: 0.8542 (1.0825)  labels_encoder: 0.4687 (0.6860)  labels_decoder: 0.3664 (0.3965)  labels_encoder_unscaled: 0.4687 (0.6860)  labels_decoder_unscaled: 0.7328 (0.7931)  time: 0.1069  data: 0.0210  max mem: 3277
Test:  [ 450/1613]  eta: 0:02:13  loss: 0.9800 (1.1857)  labels_encoder: 0.6392 (0.7546)  labels_decoder: 0.4049 (0.4310)  labels_encoder_unscaled: 0.6392 (0.7546)  labels_decoder_unscaled: 0.8097 (0.8620)  time: 0.1089  data: 0.0278  max mem: 3277
Test:  [ 500/1613]  eta: 0:02:06  loss: 0.2974 (1.1285)  labels_encoder: 0.1298 (0.7173)  labels_decoder: 0.1663 (0.4112)  labels_encoder_unscaled: 0.1298 (0.7173)  labels_decoder_unscaled: 0.3326 (0.8224)  time: 0.1095  data: 0.0228  max mem: 3277
Test:  [ 550/1613]  eta: 0:02:02  loss: 0.6266 (1.1361)  labels_encoder: 0.4371 (0.7239)  labels_decoder: 0.2353 (0.4122)  labels_encoder_unscaled: 0.4371 (0.7239)  labels_decoder_unscaled: 0.4705 (0.8244)  time: 0.1216  data: 0.0468  max mem: 3277
Test:  [ 600/1613]  eta: 0:01:56  loss: 0.8287 (1.1831)  labels_encoder: 0.4607 (0.7659)  labels_decoder: 0.3173 (0.4172)  labels_encoder_unscaled: 0.4607 (0.7659)  labels_decoder_unscaled: 0.6346 (0.8343)  time: 0.1118  data: 0.0203  max mem: 3277
Test:  [ 650/1613]  eta: 0:01:49  loss: 0.4723 (1.1503)  labels_encoder: 0.2548 (0.7420)  labels_decoder: 0.2392 (0.4083)  labels_encoder_unscaled: 0.2548 (0.7420)  labels_decoder_unscaled: 0.4785 (0.8165)  time: 0.1177  data: 0.0277  max mem: 3277
Test:  [ 700/1613]  eta: 0:01:43  loss: 0.5429 (1.1175)  labels_encoder: 0.3606 (0.7205)  labels_decoder: 0.1994 (0.3971)  labels_encoder_unscaled: 0.3606 (0.7205)  labels_decoder_unscaled: 0.3988 (0.7941)  time: 0.1128  data: 0.0372  max mem: 3277
Test:  [ 750/1613]  eta: 0:01:38  loss: 0.5021 (1.0818)  labels_encoder: 0.2975 (0.6962)  labels_decoder: 0.2056 (0.3856)  labels_encoder_unscaled: 0.2975 (0.6962)  labels_decoder_unscaled: 0.4112 (0.7713)  time: 0.1161  data: 0.0422  max mem: 3277
Test:  [ 800/1613]  eta: 0:01:32  loss: 0.8170 (1.0645)  labels_encoder: 0.4453 (0.6847)  labels_decoder: 0.3388 (0.3799)  labels_encoder_unscaled: 0.4453 (0.6847)  labels_decoder_unscaled: 0.6776 (0.7597)  time: 0.1176  data: 0.0446  max mem: 3277
Test:  [ 850/1613]  eta: 0:01:26  loss: 0.9115 (1.0559)  labels_encoder: 0.5892 (0.6762)  labels_decoder: 0.3223 (0.3797)  labels_encoder_unscaled: 0.5892 (0.6762)  labels_decoder_unscaled: 0.6447 (0.7593)  time: 0.1125  data: 0.0245  max mem: 3277
Test:  [ 900/1613]  eta: 0:01:21  loss: 0.5803 (1.0324)  labels_encoder: 0.2879 (0.6586)  labels_decoder: 0.2767 (0.3738)  labels_encoder_unscaled: 0.2879 (0.6586)  labels_decoder_unscaled: 0.5534 (0.7475)  time: 0.1145  data: 0.0434  max mem: 3277
Test:  [ 950/1613]  eta: 0:01:15  loss: 0.8331 (1.0154)  labels_encoder: 0.4903 (0.6458)  labels_decoder: 0.3253 (0.3696)  labels_encoder_unscaled: 0.4903 (0.6458)  labels_decoder_unscaled: 0.6505 (0.7393)  time: 0.1136  data: 0.0332  max mem: 3277
Test:  [1000/1613]  eta: 0:01:09  loss: 1.0191 (1.0103)  labels_encoder: 0.6458 (0.6419)  labels_decoder: 0.4254 (0.3685)  labels_encoder_unscaled: 0.6458 (0.6419)  labels_decoder_unscaled: 0.8507 (0.7369)  time: 0.1077  data: 0.0196  max mem: 3277
Test:  [1050/1613]  eta: 0:01:03  loss: 1.0380 (1.0067)  labels_encoder: 0.6683 (0.6388)  labels_decoder: 0.3875 (0.3679)  labels_encoder_unscaled: 0.6683 (0.6388)  labels_decoder_unscaled: 0.7750 (0.7358)  time: 0.1018  data: 0.0223  max mem: 3277
Test:  [1100/1613]  eta: 0:00:58  loss: 0.5128 (1.0015)  labels_encoder: 0.3666 (0.6366)  labels_decoder: 0.1992 (0.3650)  labels_encoder_unscaled: 0.3666 (0.6366)  labels_decoder_unscaled: 0.3984 (0.7299)  time: 0.1172  data: 0.0306  max mem: 3277
Test:  [1150/1613]  eta: 0:00:52  loss: 0.7222 (1.0064)  labels_encoder: 0.5831 (0.6411)  labels_decoder: 0.1882 (0.3653)  labels_encoder_unscaled: 0.5831 (0.6411)  labels_decoder_unscaled: 0.3764 (0.7306)  time: 0.1248  data: 0.0193  max mem: 3277
Test:  [1200/1613]  eta: 0:00:47  loss: 0.4896 (1.0145)  labels_encoder: 0.2413 (0.6472)  labels_decoder: 0.2113 (0.3673)  labels_encoder_unscaled: 0.2413 (0.6472)  labels_decoder_unscaled: 0.4226 (0.7345)  time: 0.1245  data: 0.0589  max mem: 3277
Test:  [1250/1613]  eta: 0:00:41  loss: 0.4431 (1.0134)  labels_encoder: 0.2956 (0.6466)  labels_decoder: 0.2078 (0.3668)  labels_encoder_unscaled: 0.2956 (0.6466)  labels_decoder_unscaled: 0.4155 (0.7335)  time: 0.1122  data: 0.0455  max mem: 3277
Test:  [1300/1613]  eta: 0:00:35  loss: 0.5685 (1.0087)  labels_encoder: 0.3096 (0.6426)  labels_decoder: 0.2931 (0.3661)  labels_encoder_unscaled: 0.3096 (0.6426)  labels_decoder_unscaled: 0.5863 (0.7322)  time: 0.1156  data: 0.0205  max mem: 3277
Test:  [1350/1613]  eta: 0:00:29  loss: 1.3529 (1.0121)  labels_encoder: 0.8949 (0.6457)  labels_decoder: 0.4688 (0.3665)  labels_encoder_unscaled: 0.8949 (0.6457)  labels_decoder_unscaled: 0.9376 (0.7329)  time: 0.1097  data: 0.0402  max mem: 3277
Test:  [1400/1613]  eta: 0:00:24  loss: 1.2137 (1.0198)  labels_encoder: 0.7503 (0.6495)  labels_decoder: 0.4649 (0.3703)  labels_encoder_unscaled: 0.7503 (0.6495)  labels_decoder_unscaled: 0.9298 (0.7407)  time: 0.1335  data: 0.0345  max mem: 3277
Test:  [1450/1613]  eta: 0:00:18  loss: 0.6048 (1.0350)  labels_encoder: 0.3002 (0.6591)  labels_decoder: 0.2456 (0.3760)  labels_encoder_unscaled: 0.3002 (0.6591)  labels_decoder_unscaled: 0.4913 (0.7519)  time: 0.1113  data: 0.0277  max mem: 3277
Test:  [1500/1613]  eta: 0:00:12  loss: 0.6936 (1.0279)  labels_encoder: 0.4519 (0.6542)  labels_decoder: 0.2505 (0.3737)  labels_encoder_unscaled: 0.4519 (0.6542)  labels_decoder_unscaled: 0.5011 (0.7474)  time: 0.1148  data: 0.0362  max mem: 3277
Test:  [1550/1613]  eta: 0:00:07  loss: 0.8378 (1.0230)  labels_encoder: 0.5895 (0.6508)  labels_decoder: 0.3526 (0.3722)  labels_encoder_unscaled: 0.5895 (0.6508)  labels_decoder_unscaled: 0.7052 (0.7444)  time: 0.1158  data: 0.0334  max mem: 3277
Test:  [1600/1613]  eta: 0:00:01  loss: 0.7499 (1.0223)  labels_encoder: 0.4206 (0.6497)  labels_decoder: 0.3404 (0.3726)  labels_encoder_unscaled: 0.4206 (0.6497)  labels_decoder_unscaled: 0.6808 (0.7453)  time: 0.1056  data: 0.0335  max mem: 3277
Test:  [1612/1613]  eta: 0:00:00  loss: 0.4503 (1.0192)  labels_encoder: 0.2538 (0.6478)  labels_decoder: 0.2115 (0.3714)  labels_encoder_unscaled: 0.2538 (0.6478)  labels_decoder_unscaled: 0.4230 (0.7428)  time: 0.1100  data: 0.0431  max mem: 3277
Test: Total time: 0:03:04 (0.1141 s / it)
Averaged stats: loss: 0.4503 (1.0192)  labels_encoder: 0.2538 (0.6478)  labels_decoder: 0.2115 (0.3714)  labels_encoder_unscaled: 0.2538 (0.6478)  labels_decoder_unscaled: 0.4230 (0.7428)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-kin_audio] mAP: 0.6383

dec_mAP all together: | 0.4998754784940365 |.
dec_mAP_pred | 0 : 0.547986138432698 |.
dec_mAP_pred | 1 : 0.5400625353767485 |.
dec_mAP_pred | 2 : 0.527510259984813 |.
dec_mAP_pred | 3 : 0.5124945255656914 |.
dec_mAP_pred | 4 : 0.49598936373173313 |.
dec_mAP_pred | 5 : 0.4789697218692058 |.
dec_mAP_pred | 6 : 0.4618778216356059 |.
dec_mAP_pred | 7 : 0.44527287260549153 |.
all decoder map: | 0.5013 |.
BaseballPitch: 0.4360
BasketballDunk: 0.7929
Billiards: 0.3087
CleanAndJerk: 0.7533
CliffDiving: 0.8575
CricketBowling: 0.5054
CricketShot: 0.2655
Diving: 0.8495
FrisbeeCatch: 0.3368
GolfSwing: 0.7328
HammerThrow: 0.8385
HighJump: 0.7673
JavelinThrow: 0.7623
LongJump: 0.8240
PoleVault: 0.8861
Shotput: 0.7183
SoccerPenalty: 0.4334
TennisSwing: 0.6068
ThrowDiscus: 0.6387
VolleyballSpiking: 0.4529
Epoch: [2]  [   0/1412]  eta: 1:24:51  lr: 0.000010  loss: 0.4450 (0.4450)  labels_encoder: 0.2228 (0.2228)  labels_decoder: 0.2222 (0.2222)  labels_encoder_unscaled: 0.2228 (0.2228)  labels_decoder_unscaled: 0.4444 (0.4444)  time: 3.6060  data: 3.4290  max mem: 3277
Epoch: [2]  [  50/1412]  eta: 0:05:41  lr: 0.000010  loss: 0.3058 (0.3027)  labels_encoder: 0.1614 (0.1623)  labels_decoder: 0.1362 (0.1405)  labels_encoder_unscaled: 0.1614 (0.1623)  labels_decoder_unscaled: 0.2725 (0.2809)  time: 0.1805  data: 0.0003  max mem: 3277
Epoch: [2]  [ 100/1412]  eta: 0:04:37  lr: 0.000010  loss: 0.2798 (0.2929)  labels_encoder: 0.1382 (0.1573)  labels_decoder: 0.1295 (0.1356)  labels_encoder_unscaled: 0.1382 (0.1573)  labels_decoder_unscaled: 0.2590 (0.2712)  time: 0.1767  data: 0.0003  max mem: 3277
Epoch: [2]  [ 150/1412]  eta: 0:04:12  lr: 0.000010  loss: 0.2691 (0.2840)  labels_encoder: 0.1345 (0.1509)  labels_decoder: 0.1319 (0.1331)  labels_encoder_unscaled: 0.1345 (0.1509)  labels_decoder_unscaled: 0.2638 (0.2662)  time: 0.1716  data: 0.0003  max mem: 3277
Epoch: [2]  [ 200/1412]  eta: 0:03:53  lr: 0.000010  loss: 0.2622 (0.2784)  labels_encoder: 0.1361 (0.1472)  labels_decoder: 0.1274 (0.1312)  labels_encoder_unscaled: 0.1361 (0.1472)  labels_decoder_unscaled: 0.2548 (0.2625)  time: 0.1650  data: 0.0003  max mem: 3277
Epoch: [2]  [ 250/1412]  eta: 0:03:40  lr: 0.000010  loss: 0.2359 (0.2757)  labels_encoder: 0.1160 (0.1452)  labels_decoder: 0.1252 (0.1306)  labels_encoder_unscaled: 0.1160 (0.1452)  labels_decoder_unscaled: 0.2505 (0.2611)  time: 0.1763  data: 0.0003  max mem: 3277
Epoch: [2]  [ 300/1412]  eta: 0:03:28  lr: 0.000010  loss: 0.2526 (0.2730)  labels_encoder: 0.1483 (0.1438)  labels_decoder: 0.1199 (0.1293)  labels_encoder_unscaled: 0.1483 (0.1438)  labels_decoder_unscaled: 0.2398 (0.2585)  time: 0.1745  data: 0.0003  max mem: 3277
Epoch: [2]  [ 350/1412]  eta: 0:03:17  lr: 0.000010  loss: 0.2712 (0.2738)  labels_encoder: 0.1395 (0.1449)  labels_decoder: 0.1267 (0.1289)  labels_encoder_unscaled: 0.1395 (0.1449)  labels_decoder_unscaled: 0.2534 (0.2579)  time: 0.1748  data: 0.0003  max mem: 3277
Epoch: [2]  [ 400/1412]  eta: 0:03:06  lr: 0.000010  loss: 0.2458 (0.2733)  labels_encoder: 0.1326 (0.1444)  labels_decoder: 0.1210 (0.1289)  labels_encoder_unscaled: 0.1326 (0.1444)  labels_decoder_unscaled: 0.2420 (0.2578)  time: 0.1795  data: 0.0003  max mem: 3277
Epoch: [2]  [ 450/1412]  eta: 0:02:57  lr: 0.000010  loss: 0.2536 (0.2718)  labels_encoder: 0.1324 (0.1436)  labels_decoder: 0.1204 (0.1282)  labels_encoder_unscaled: 0.1324 (0.1436)  labels_decoder_unscaled: 0.2407 (0.2563)  time: 0.1780  data: 0.0003  max mem: 3277
Epoch: [2]  [ 500/1412]  eta: 0:02:46  lr: 0.000010  loss: 0.2465 (0.2713)  labels_encoder: 0.1505 (0.1435)  labels_decoder: 0.1160 (0.1278)  labels_encoder_unscaled: 0.1505 (0.1435)  labels_decoder_unscaled: 0.2320 (0.2556)  time: 0.1768  data: 0.0003  max mem: 3277
Epoch: [2]  [ 550/1412]  eta: 0:02:37  lr: 0.000010  loss: 0.2718 (0.2704)  labels_encoder: 0.1332 (0.1430)  labels_decoder: 0.1271 (0.1274)  labels_encoder_unscaled: 0.1332 (0.1430)  labels_decoder_unscaled: 0.2543 (0.2549)  time: 0.1835  data: 0.0003  max mem: 3277
Epoch: [2]  [ 600/1412]  eta: 0:02:27  lr: 0.000010  loss: 0.2413 (0.2690)  labels_encoder: 0.1132 (0.1421)  labels_decoder: 0.1173 (0.1269)  labels_encoder_unscaled: 0.1132 (0.1421)  labels_decoder_unscaled: 0.2347 (0.2539)  time: 0.1636  data: 0.0003  max mem: 3277
Epoch: [2]  [ 650/1412]  eta: 0:02:18  lr: 0.000010  loss: 0.2528 (0.2682)  labels_encoder: 0.1241 (0.1416)  labels_decoder: 0.1202 (0.1266)  labels_encoder_unscaled: 0.1241 (0.1416)  labels_decoder_unscaled: 0.2403 (0.2532)  time: 0.1828  data: 0.0003  max mem: 3277
Epoch: [2]  [ 700/1412]  eta: 0:02:08  lr: 0.000010  loss: 0.2558 (0.2678)  labels_encoder: 0.1289 (0.1416)  labels_decoder: 0.1230 (0.1262)  labels_encoder_unscaled: 0.1289 (0.1416)  labels_decoder_unscaled: 0.2459 (0.2523)  time: 0.1781  data: 0.0003  max mem: 3277
Epoch: [2]  [ 750/1412]  eta: 0:01:59  lr: 0.000010  loss: 0.2608 (0.2679)  labels_encoder: 0.1271 (0.1418)  labels_decoder: 0.1243 (0.1261)  labels_encoder_unscaled: 0.1271 (0.1418)  labels_decoder_unscaled: 0.2487 (0.2522)  time: 0.1804  data: 0.0003  max mem: 3277
Epoch: [2]  [ 800/1412]  eta: 0:01:50  lr: 0.000010  loss: 0.2591 (0.2679)  labels_encoder: 0.1336 (0.1418)  labels_decoder: 0.1301 (0.1261)  labels_encoder_unscaled: 0.1336 (0.1418)  labels_decoder_unscaled: 0.2601 (0.2522)  time: 0.1720  data: 0.0003  max mem: 3277
Epoch: [2]  [ 850/1412]  eta: 0:01:40  lr: 0.000010  loss: 0.2396 (0.2664)  labels_encoder: 0.1275 (0.1407)  labels_decoder: 0.1109 (0.1257)  labels_encoder_unscaled: 0.1275 (0.1407)  labels_decoder_unscaled: 0.2218 (0.2514)  time: 0.1673  data: 0.0003  max mem: 3277
Epoch: [2]  [ 900/1412]  eta: 0:01:31  lr: 0.000010  loss: 0.2543 (0.2661)  labels_encoder: 0.1375 (0.1405)  labels_decoder: 0.1214 (0.1255)  labels_encoder_unscaled: 0.1375 (0.1405)  labels_decoder_unscaled: 0.2428 (0.2511)  time: 0.1763  data: 0.0003  max mem: 3277
Epoch: [2]  [ 950/1412]  eta: 0:01:22  lr: 0.000010  loss: 0.2466 (0.2656)  labels_encoder: 0.1260 (0.1403)  labels_decoder: 0.1090 (0.1253)  labels_encoder_unscaled: 0.1260 (0.1403)  labels_decoder_unscaled: 0.2181 (0.2506)  time: 0.1772  data: 0.0004  max mem: 3277
Epoch: [2]  [1000/1412]  eta: 0:01:13  lr: 0.000010  loss: 0.2376 (0.2648)  labels_encoder: 0.1196 (0.1397)  labels_decoder: 0.1203 (0.1250)  labels_encoder_unscaled: 0.1196 (0.1397)  labels_decoder_unscaled: 0.2406 (0.2500)  time: 0.1661  data: 0.0003  max mem: 3277
Epoch: [2]  [1050/1412]  eta: 0:01:04  lr: 0.000010  loss: 0.2541 (0.2639)  labels_encoder: 0.1382 (0.1392)  labels_decoder: 0.1166 (0.1247)  labels_encoder_unscaled: 0.1382 (0.1392)  labels_decoder_unscaled: 0.2331 (0.2494)  time: 0.1815  data: 0.0003  max mem: 3277
Epoch: [2]  [1100/1412]  eta: 0:00:55  lr: 0.000010  loss: 0.2447 (0.2634)  labels_encoder: 0.1327 (0.1390)  labels_decoder: 0.1118 (0.1244)  labels_encoder_unscaled: 0.1327 (0.1390)  labels_decoder_unscaled: 0.2237 (0.2488)  time: 0.1775  data: 0.0004  max mem: 3277
Epoch: [2]  [1150/1412]  eta: 0:00:46  lr: 0.000010  loss: 0.2358 (0.2631)  labels_encoder: 0.1223 (0.1389)  labels_decoder: 0.1162 (0.1243)  labels_encoder_unscaled: 0.1223 (0.1389)  labels_decoder_unscaled: 0.2323 (0.2485)  time: 0.1690  data: 0.0003  max mem: 3277
Epoch: [2]  [1200/1412]  eta: 0:00:37  lr: 0.000010  loss: 0.2223 (0.2618)  labels_encoder: 0.1073 (0.1379)  labels_decoder: 0.1126 (0.1239)  labels_encoder_unscaled: 0.1073 (0.1379)  labels_decoder_unscaled: 0.2251 (0.2478)  time: 0.1790  data: 0.0003  max mem: 3277
Epoch: [2]  [1250/1412]  eta: 0:00:28  lr: 0.000010  loss: 0.2258 (0.2614)  labels_encoder: 0.1198 (0.1377)  labels_decoder: 0.1133 (0.1237)  labels_encoder_unscaled: 0.1198 (0.1377)  labels_decoder_unscaled: 0.2265 (0.2474)  time: 0.1701  data: 0.0003  max mem: 3277
Epoch: [2]  [1300/1412]  eta: 0:00:19  lr: 0.000010  loss: 0.2533 (0.2608)  labels_encoder: 0.1380 (0.1373)  labels_decoder: 0.1183 (0.1235)  labels_encoder_unscaled: 0.1380 (0.1373)  labels_decoder_unscaled: 0.2365 (0.2470)  time: 0.1727  data: 0.0003  max mem: 3277
Epoch: [2]  [1350/1412]  eta: 0:00:11  lr: 0.000010  loss: 0.2318 (0.2601)  labels_encoder: 0.1154 (0.1369)  labels_decoder: 0.1096 (0.1232)  labels_encoder_unscaled: 0.1154 (0.1369)  labels_decoder_unscaled: 0.2193 (0.2464)  time: 0.1826  data: 0.0003  max mem: 3277
Epoch: [2]  [1400/1412]  eta: 0:00:02  lr: 0.000010  loss: 0.2257 (0.2596)  labels_encoder: 0.1160 (0.1366)  labels_decoder: 0.1112 (0.1230)  labels_encoder_unscaled: 0.1160 (0.1366)  labels_decoder_unscaled: 0.2224 (0.2459)  time: 0.1669  data: 0.0005  max mem: 3277
Epoch: [2]  [1411/1412]  eta: 0:00:00  lr: 0.000010  loss: 0.2269 (0.2595)  labels_encoder: 0.1207 (0.1366)  labels_decoder: 0.1152 (0.1229)  labels_encoder_unscaled: 0.1207 (0.1366)  labels_decoder_unscaled: 0.2304 (0.2458)  time: 0.1399  data: 0.0003  max mem: 3277
Epoch: [2] Total time: 0:04:10 (0.1775 s / it)
Averaged stats: lr: 0.000010  loss: 0.2269 (0.2595)  labels_encoder: 0.1207 (0.1366)  labels_decoder: 0.1152 (0.1229)  labels_encoder_unscaled: 0.1207 (0.1366)  labels_decoder_unscaled: 0.2304 (0.2458)
Test:  [   0/1613]  eta: 1:47:02  loss: 1.5890 (1.5890)  labels_encoder: 0.8501 (0.8501)  labels_decoder: 0.7390 (0.7390)  labels_encoder_unscaled: 0.8501 (0.8501)  labels_decoder_unscaled: 1.4779 (1.4779)  time: 3.9818  data: 3.9232  max mem: 3277
Test:  [  50/1613]  eta: 0:04:45  loss: 0.4740 (0.7627)  labels_encoder: 0.2025 (0.4511)  labels_decoder: 0.2128 (0.3117)  labels_encoder_unscaled: 0.2025 (0.4511)  labels_decoder_unscaled: 0.4257 (0.6233)  time: 0.1241  data: 0.0568  max mem: 3277
Test:  [ 100/1613]  eta: 0:03:55  loss: 0.4900 (0.7158)  labels_encoder: 0.3359 (0.4475)  labels_decoder: 0.1930 (0.2683)  labels_encoder_unscaled: 0.3359 (0.4475)  labels_decoder_unscaled: 0.3861 (0.5366)  time: 0.1332  data: 0.0663  max mem: 3277
Test:  [ 150/1613]  eta: 0:03:34  loss: 0.8113 (0.7301)  labels_encoder: 0.5852 (0.4591)  labels_decoder: 0.2602 (0.2711)  labels_encoder_unscaled: 0.5852 (0.4591)  labels_decoder_unscaled: 0.5204 (0.5421)  time: 0.1315  data: 0.0543  max mem: 3277
Test:  [ 200/1613]  eta: 0:03:22  loss: 0.8951 (0.8670)  labels_encoder: 0.5272 (0.5471)  labels_decoder: 0.3657 (0.3200)  labels_encoder_unscaled: 0.5272 (0.5471)  labels_decoder_unscaled: 0.7315 (0.6399)  time: 0.1313  data: 0.0706  max mem: 3277
Test:  [ 250/1613]  eta: 0:03:08  loss: 0.7258 (0.9162)  labels_encoder: 0.3790 (0.5750)  labels_decoder: 0.3317 (0.3412)  labels_encoder_unscaled: 0.3790 (0.5750)  labels_decoder_unscaled: 0.6634 (0.6823)  time: 0.1104  data: 0.0380  max mem: 3277
Test:  [ 300/1613]  eta: 0:02:58  loss: 0.8179 (0.9333)  labels_encoder: 0.5025 (0.5871)  labels_decoder: 0.3972 (0.3463)  labels_encoder_unscaled: 0.5025 (0.5871)  labels_decoder_unscaled: 0.7944 (0.6925)  time: 0.1277  data: 0.0613  max mem: 3277
Test:  [ 350/1613]  eta: 0:02:49  loss: 1.2240 (0.9621)  labels_encoder: 0.7203 (0.6076)  labels_decoder: 0.4693 (0.3545)  labels_encoder_unscaled: 0.7203 (0.6076)  labels_decoder_unscaled: 0.9385 (0.7091)  time: 0.1213  data: 0.0533  max mem: 3277
Test:  [ 400/1613]  eta: 0:02:42  loss: 0.7375 (1.0077)  labels_encoder: 0.4108 (0.6404)  labels_decoder: 0.3267 (0.3673)  labels_encoder_unscaled: 0.4108 (0.6404)  labels_decoder_unscaled: 0.6535 (0.7346)  time: 0.1233  data: 0.0401  max mem: 3277
Test:  [ 450/1613]  eta: 0:02:33  loss: 1.1174 (1.0971)  labels_encoder: 0.7851 (0.7023)  labels_decoder: 0.3526 (0.3948)  labels_encoder_unscaled: 0.7851 (0.7023)  labels_decoder_unscaled: 0.7051 (0.7896)  time: 0.1119  data: 0.0406  max mem: 3277
Test:  [ 500/1613]  eta: 0:02:24  loss: 0.2788 (1.0493)  labels_encoder: 0.1251 (0.6703)  labels_decoder: 0.1537 (0.3790)  labels_encoder_unscaled: 0.1251 (0.6703)  labels_decoder_unscaled: 0.3074 (0.7580)  time: 0.1103  data: 0.0346  max mem: 3277
Test:  [ 550/1613]  eta: 0:02:16  loss: 0.5726 (1.0298)  labels_encoder: 0.3515 (0.6573)  labels_decoder: 0.2461 (0.3725)  labels_encoder_unscaled: 0.3515 (0.6573)  labels_decoder_unscaled: 0.4922 (0.7450)  time: 0.1104  data: 0.0316  max mem: 3277
Test:  [ 600/1613]  eta: 0:02:08  loss: 0.9109 (1.0904)  labels_encoder: 0.5175 (0.7103)  labels_decoder: 0.3813 (0.3801)  labels_encoder_unscaled: 0.5175 (0.7103)  labels_decoder_unscaled: 0.7627 (0.7602)  time: 0.1121  data: 0.0347  max mem: 3277
Test:  [ 650/1613]  eta: 0:02:00  loss: 1.2473 (1.0985)  labels_encoder: 0.7766 (0.7137)  labels_decoder: 0.5489 (0.3848)  labels_encoder_unscaled: 0.7766 (0.7137)  labels_decoder_unscaled: 1.0978 (0.7696)  time: 0.1112  data: 0.0173  max mem: 3277
Test:  [ 700/1613]  eta: 0:01:53  loss: 0.4705 (1.0689)  labels_encoder: 0.3044 (0.6932)  labels_decoder: 0.1919 (0.3757)  labels_encoder_unscaled: 0.3044 (0.6932)  labels_decoder_unscaled: 0.3838 (0.7514)  time: 0.1101  data: 0.0166  max mem: 3277
Test:  [ 750/1613]  eta: 0:01:47  loss: 0.8631 (1.0454)  labels_encoder: 0.4866 (0.6765)  labels_decoder: 0.2768 (0.3689)  labels_encoder_unscaled: 0.4866 (0.6765)  labels_decoder_unscaled: 0.5536 (0.7379)  time: 0.1158  data: 0.0316  max mem: 3277
Test:  [ 800/1613]  eta: 0:01:40  loss: 0.5163 (1.0420)  labels_encoder: 0.2978 (0.6754)  labels_decoder: 0.2255 (0.3666)  labels_encoder_unscaled: 0.2978 (0.6754)  labels_decoder_unscaled: 0.4510 (0.7333)  time: 0.1201  data: 0.0176  max mem: 3277
Test:  [ 850/1613]  eta: 0:01:34  loss: 1.0193 (1.0474)  labels_encoder: 0.5496 (0.6765)  labels_decoder: 0.3628 (0.3709)  labels_encoder_unscaled: 0.5496 (0.6765)  labels_decoder_unscaled: 0.7257 (0.7418)  time: 0.1184  data: 0.0336  max mem: 3277
Test:  [ 900/1613]  eta: 0:01:27  loss: 0.5426 (1.0261)  labels_encoder: 0.3075 (0.6601)  labels_decoder: 0.2736 (0.3660)  labels_encoder_unscaled: 0.3075 (0.6601)  labels_decoder_unscaled: 0.5472 (0.7320)  time: 0.1207  data: 0.0351  max mem: 3277
Test:  [ 950/1613]  eta: 0:01:21  loss: 0.9960 (1.0300)  labels_encoder: 0.7084 (0.6606)  labels_decoder: 0.3858 (0.3694)  labels_encoder_unscaled: 0.7084 (0.6606)  labels_decoder_unscaled: 0.7716 (0.7388)  time: 0.1186  data: 0.0451  max mem: 3277
Test:  [1000/1613]  eta: 0:01:14  loss: 0.6897 (1.0160)  labels_encoder: 0.4028 (0.6505)  labels_decoder: 0.2869 (0.3655)  labels_encoder_unscaled: 0.4028 (0.6505)  labels_decoder_unscaled: 0.5739 (0.7309)  time: 0.1108  data: 0.0310  max mem: 3277
Test:  [1050/1613]  eta: 0:01:08  loss: 0.9914 (1.0204)  labels_encoder: 0.6338 (0.6542)  labels_decoder: 0.3362 (0.3661)  labels_encoder_unscaled: 0.6338 (0.6542)  labels_decoder_unscaled: 0.6724 (0.7323)  time: 0.1234  data: 0.0467  max mem: 3277
Test:  [1100/1613]  eta: 0:01:02  loss: 0.4191 (1.0232)  labels_encoder: 0.2216 (0.6577)  labels_decoder: 0.2074 (0.3655)  labels_encoder_unscaled: 0.2216 (0.6577)  labels_decoder_unscaled: 0.4148 (0.7310)  time: 0.1114  data: 0.0426  max mem: 3277
Test:  [1150/1613]  eta: 0:00:55  loss: 0.4016 (1.0142)  labels_encoder: 0.2674 (0.6511)  labels_decoder: 0.1903 (0.3631)  labels_encoder_unscaled: 0.2674 (0.6511)  labels_decoder_unscaled: 0.3806 (0.7261)  time: 0.1163  data: 0.0388  max mem: 3277
Test:  [1200/1613]  eta: 0:00:49  loss: 0.4592 (1.0214)  labels_encoder: 0.2327 (0.6557)  labels_decoder: 0.2216 (0.3657)  labels_encoder_unscaled: 0.2327 (0.6557)  labels_decoder_unscaled: 0.4432 (0.7313)  time: 0.1130  data: 0.0234  max mem: 3277
Test:  [1250/1613]  eta: 0:00:43  loss: 0.5585 (1.0228)  labels_encoder: 0.2894 (0.6567)  labels_decoder: 0.2677 (0.3660)  labels_encoder_unscaled: 0.2894 (0.6567)  labels_decoder_unscaled: 0.5354 (0.7321)  time: 0.1266  data: 0.0550  max mem: 3277
Test:  [1300/1613]  eta: 0:00:37  loss: 0.5025 (1.0143)  labels_encoder: 0.2967 (0.6507)  labels_decoder: 0.2524 (0.3637)  labels_encoder_unscaled: 0.2967 (0.6507)  labels_decoder_unscaled: 0.5048 (0.7273)  time: 0.1102  data: 0.0338  max mem: 3277
Test:  [1350/1613]  eta: 0:00:31  loss: 0.9436 (1.0177)  labels_encoder: 0.6387 (0.6535)  labels_decoder: 0.3459 (0.3642)  labels_encoder_unscaled: 0.6387 (0.6535)  labels_decoder_unscaled: 0.6918 (0.7285)  time: 0.1148  data: 0.0406  max mem: 3277
Test:  [1400/1613]  eta: 0:00:25  loss: 0.9021 (1.0209)  labels_encoder: 0.5915 (0.6551)  labels_decoder: 0.3430 (0.3659)  labels_encoder_unscaled: 0.5915 (0.6551)  labels_decoder_unscaled: 0.6860 (0.7317)  time: 0.1381  data: 0.0689  max mem: 3277
Test:  [1450/1613]  eta: 0:00:19  loss: 0.5325 (1.0217)  labels_encoder: 0.2735 (0.6557)  labels_decoder: 0.2419 (0.3660)  labels_encoder_unscaled: 0.2735 (0.6557)  labels_decoder_unscaled: 0.4839 (0.7321)  time: 0.1167  data: 0.0447  max mem: 3277
Test:  [1500/1613]  eta: 0:00:13  loss: 0.5991 (1.0166)  labels_encoder: 0.3554 (0.6529)  labels_decoder: 0.1882 (0.3637)  labels_encoder_unscaled: 0.3554 (0.6529)  labels_decoder_unscaled: 0.3764 (0.7274)  time: 0.1234  data: 0.0418  max mem: 3277
Test:  [1550/1613]  eta: 0:00:07  loss: 0.9166 (1.0167)  labels_encoder: 0.5554 (0.6533)  labels_decoder: 0.3023 (0.3634)  labels_encoder_unscaled: 0.5554 (0.6533)  labels_decoder_unscaled: 0.6045 (0.7269)  time: 0.1215  data: 0.0436  max mem: 3277
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9109 (1.0170)  labels_encoder: 0.4952 (0.6527)  labels_decoder: 0.4192 (0.3642)  labels_encoder_unscaled: 0.4952 (0.6527)  labels_decoder_unscaled: 0.8384 (0.7285)  time: 0.1272  data: 0.0392  max mem: 3277
Test:  [1612/1613]  eta: 0:00:00  loss: 0.7846 (1.0161)  labels_encoder: 0.4600 (0.6522)  labels_decoder: 0.3133 (0.3639)  labels_encoder_unscaled: 0.4600 (0.6522)  labels_decoder_unscaled: 0.6265 (0.7279)  time: 0.1104  data: 0.0439  max mem: 3277
Test: Total time: 0:03:15 (0.1210 s / it)
Averaged stats: loss: 0.7846 (1.0161)  labels_encoder: 0.4600 (0.6522)  labels_decoder: 0.3133 (0.3639)  labels_encoder_unscaled: 0.4600 (0.6522)  labels_decoder_unscaled: 0.6265 (0.7279)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-kin_audio] mAP: 0.6371

dec_mAP all together: | 0.5085947390109954 |.
dec_mAP_pred | 0 : 0.5560400423688403 |.
dec_mAP_pred | 1 : 0.5485138864625483 |.
dec_mAP_pred | 2 : 0.5359285097595146 |.
dec_mAP_pred | 3 : 0.5208620468312509 |.
dec_mAP_pred | 4 : 0.5046346514689486 |.
dec_mAP_pred | 5 : 0.4879428697479419 |.
dec_mAP_pred | 6 : 0.4713604683194027 |.
dec_mAP_pred | 7 : 0.45551548530738667 |.
all decoder map: | 0.5101 |.
BaseballPitch: 0.3417
BasketballDunk: 0.8139
Billiards: 0.3115
CleanAndJerk: 0.7237
CliffDiving: 0.8531
CricketBowling: 0.4963
CricketShot: 0.2991
Diving: 0.8585
FrisbeeCatch: 0.4024
GolfSwing: 0.7796
HammerThrow: 0.8497
HighJump: 0.7910
JavelinThrow: 0.7523
LongJump: 0.7757
PoleVault: 0.8776
Shotput: 0.7438
SoccerPenalty: 0.4101
TennisSwing: 0.6040
ThrowDiscus: 0.5961
VolleyballSpiking: 0.4614
Epoch: [3]  [   0/1412]  eta: 1:25:56  lr: 0.000001  loss: 0.2143 (0.2143)  labels_encoder: 0.0982 (0.0982)  labels_decoder: 0.1161 (0.1161)  labels_encoder_unscaled: 0.0982 (0.0982)  labels_decoder_unscaled: 0.2321 (0.2321)  time: 3.6518  data: 3.5058  max mem: 3277
Epoch: [3]  [  50/1412]  eta: 0:05:30  lr: 0.000001  loss: 0.2221 (0.2312)  labels_encoder: 0.1051 (0.1181)  labels_decoder: 0.1038 (0.1131)  labels_encoder_unscaled: 0.1051 (0.1181)  labels_decoder_unscaled: 0.2076 (0.2262)  time: 0.1771  data: 0.0004  max mem: 3277
Epoch: [3]  [ 100/1412]  eta: 0:04:37  lr: 0.000001  loss: 0.2319 (0.2268)  labels_encoder: 0.1171 (0.1145)  labels_decoder: 0.1049 (0.1123)  labels_encoder_unscaled: 0.1171 (0.1145)  labels_decoder_unscaled: 0.2098 (0.2246)  time: 0.1773  data: 0.0003  max mem: 3277
Epoch: [3]  [ 150/1412]  eta: 0:04:11  lr: 0.000001  loss: 0.2057 (0.2255)  labels_encoder: 0.0985 (0.1137)  labels_decoder: 0.0998 (0.1118)  labels_encoder_unscaled: 0.0985 (0.1137)  labels_decoder_unscaled: 0.1996 (0.2236)  time: 0.1706  data: 0.0003  max mem: 3277
Epoch: [3]  [ 200/1412]  eta: 0:03:53  lr: 0.000001  loss: 0.2134 (0.2233)  labels_encoder: 0.0997 (0.1125)  labels_decoder: 0.1077 (0.1108)  labels_encoder_unscaled: 0.0997 (0.1125)  labels_decoder_unscaled: 0.2154 (0.2215)  time: 0.1740  data: 0.0003  max mem: 3277
Epoch: [3]  [ 250/1412]  eta: 0:03:39  lr: 0.000001  loss: 0.2235 (0.2246)  labels_encoder: 0.1066 (0.1139)  labels_decoder: 0.1034 (0.1106)  labels_encoder_unscaled: 0.1066 (0.1139)  labels_decoder_unscaled: 0.2067 (0.2212)  time: 0.1737  data: 0.0003  max mem: 3277
Epoch: [3]  [ 300/1412]  eta: 0:03:24  lr: 0.000001  loss: 0.2050 (0.2257)  labels_encoder: 0.1076 (0.1153)  labels_decoder: 0.1050 (0.1104)  labels_encoder_unscaled: 0.1076 (0.1153)  labels_decoder_unscaled: 0.2100 (0.2207)  time: 0.1715  data: 0.0004  max mem: 3277
Epoch: [3]  [ 350/1412]  eta: 0:03:13  lr: 0.000001  loss: 0.2285 (0.2273)  labels_encoder: 0.1201 (0.1165)  labels_decoder: 0.1158 (0.1108)  labels_encoder_unscaled: 0.1201 (0.1165)  labels_decoder_unscaled: 0.2316 (0.2217)  time: 0.1822  data: 0.0003  max mem: 3277
Epoch: [3]  [ 400/1412]  eta: 0:03:03  lr: 0.000001  loss: 0.2282 (0.2275)  labels_encoder: 0.1168 (0.1167)  labels_decoder: 0.1087 (0.1109)  labels_encoder_unscaled: 0.1168 (0.1167)  labels_decoder_unscaled: 0.2174 (0.2217)  time: 0.1692  data: 0.0003  max mem: 3277
Epoch: [3]  [ 450/1412]  eta: 0:02:53  lr: 0.000001  loss: 0.2129 (0.2270)  labels_encoder: 0.0968 (0.1158)  labels_decoder: 0.1046 (0.1112)  labels_encoder_unscaled: 0.0968 (0.1158)  labels_decoder_unscaled: 0.2091 (0.2223)  time: 0.1740  data: 0.0003  max mem: 3277
Epoch: [3]  [ 500/1412]  eta: 0:02:43  lr: 0.000001  loss: 0.2328 (0.2268)  labels_encoder: 0.1096 (0.1154)  labels_decoder: 0.1147 (0.1113)  labels_encoder_unscaled: 0.1096 (0.1154)  labels_decoder_unscaled: 0.2294 (0.2227)  time: 0.1783  data: 0.0003  max mem: 3277
Epoch: [3]  [ 550/1412]  eta: 0:02:34  lr: 0.000001  loss: 0.2143 (0.2272)  labels_encoder: 0.1093 (0.1153)  labels_decoder: 0.1099 (0.1119)  labels_encoder_unscaled: 0.1093 (0.1153)  labels_decoder_unscaled: 0.2197 (0.2238)  time: 0.1587  data: 0.0003  max mem: 3277
Epoch: [3]  [ 600/1412]  eta: 0:02:24  lr: 0.000001  loss: 0.2348 (0.2270)  labels_encoder: 0.1285 (0.1154)  labels_decoder: 0.1129 (0.1116)  labels_encoder_unscaled: 0.1285 (0.1154)  labels_decoder_unscaled: 0.2258 (0.2232)  time: 0.1765  data: 0.0003  max mem: 3277
Epoch: [3]  [ 650/1412]  eta: 0:02:15  lr: 0.000001  loss: 0.1841 (0.2261)  labels_encoder: 0.0815 (0.1148)  labels_decoder: 0.1056 (0.1113)  labels_encoder_unscaled: 0.0815 (0.1148)  labels_decoder_unscaled: 0.2112 (0.2227)  time: 0.1713  data: 0.0003  max mem: 3277
Epoch: [3]  [ 700/1412]  eta: 0:02:06  lr: 0.000001  loss: 0.2200 (0.2269)  labels_encoder: 0.1185 (0.1156)  labels_decoder: 0.1100 (0.1113)  labels_encoder_unscaled: 0.1185 (0.1156)  labels_decoder_unscaled: 0.2200 (0.2226)  time: 0.1701  data: 0.0003  max mem: 3277
Epoch: [3]  [ 750/1412]  eta: 0:01:57  lr: 0.000001  loss: 0.2439 (0.2272)  labels_encoder: 0.1203 (0.1158)  labels_decoder: 0.1153 (0.1115)  labels_encoder_unscaled: 0.1203 (0.1158)  labels_decoder_unscaled: 0.2306 (0.2229)  time: 0.1762  data: 0.0003  max mem: 3277
Epoch: [3]  [ 800/1412]  eta: 0:01:48  lr: 0.000001  loss: 0.2391 (0.2271)  labels_encoder: 0.1049 (0.1155)  labels_decoder: 0.1161 (0.1116)  labels_encoder_unscaled: 0.1049 (0.1155)  labels_decoder_unscaled: 0.2321 (0.2232)  time: 0.1716  data: 0.0003  max mem: 3277
Epoch: [3]  [ 850/1412]  eta: 0:01:39  lr: 0.000001  loss: 0.2284 (0.2268)  labels_encoder: 0.1106 (0.1152)  labels_decoder: 0.1135 (0.1116)  labels_encoder_unscaled: 0.1106 (0.1152)  labels_decoder_unscaled: 0.2269 (0.2232)  time: 0.1756  data: 0.0003  max mem: 3277
Epoch: [3]  [ 900/1412]  eta: 0:01:30  lr: 0.000001  loss: 0.2273 (0.2267)  labels_encoder: 0.1093 (0.1151)  labels_decoder: 0.1119 (0.1116)  labels_encoder_unscaled: 0.1093 (0.1151)  labels_decoder_unscaled: 0.2238 (0.2233)  time: 0.1810  data: 0.0003  max mem: 3277
Epoch: [3]  [ 950/1412]  eta: 0:01:21  lr: 0.000001  loss: 0.2436 (0.2268)  labels_encoder: 0.1239 (0.1150)  labels_decoder: 0.1155 (0.1117)  labels_encoder_unscaled: 0.1239 (0.1150)  labels_decoder_unscaled: 0.2311 (0.2235)  time: 0.1646  data: 0.0003  max mem: 3277
Epoch: [3]  [1000/1412]  eta: 0:01:12  lr: 0.000001  loss: 0.2355 (0.2270)  labels_encoder: 0.1100 (0.1151)  labels_decoder: 0.1127 (0.1119)  labels_encoder_unscaled: 0.1100 (0.1151)  labels_decoder_unscaled: 0.2255 (0.2238)  time: 0.1761  data: 0.0004  max mem: 3277
Epoch: [3]  [1050/1412]  eta: 0:01:03  lr: 0.000001  loss: 0.2049 (0.2269)  labels_encoder: 0.1054 (0.1149)  labels_decoder: 0.1139 (0.1120)  labels_encoder_unscaled: 0.1054 (0.1149)  labels_decoder_unscaled: 0.2279 (0.2239)  time: 0.1777  data: 0.0003  max mem: 3277
Epoch: [3]  [1100/1412]  eta: 0:00:54  lr: 0.000001  loss: 0.2313 (0.2268)  labels_encoder: 0.1080 (0.1148)  labels_decoder: 0.1172 (0.1120)  labels_encoder_unscaled: 0.1080 (0.1148)  labels_decoder_unscaled: 0.2344 (0.2240)  time: 0.1705  data: 0.0003  max mem: 3277
Epoch: [3]  [1150/1412]  eta: 0:00:45  lr: 0.000001  loss: 0.2196 (0.2277)  labels_encoder: 0.1122 (0.1155)  labels_decoder: 0.1154 (0.1122)  labels_encoder_unscaled: 0.1122 (0.1155)  labels_decoder_unscaled: 0.2307 (0.2243)  time: 0.1697  data: 0.0003  max mem: 3277
Epoch: [3]  [1200/1412]  eta: 0:00:37  lr: 0.000001  loss: 0.2189 (0.2278)  labels_encoder: 0.1128 (0.1156)  labels_decoder: 0.1069 (0.1122)  labels_encoder_unscaled: 0.1128 (0.1156)  labels_decoder_unscaled: 0.2138 (0.2243)  time: 0.1672  data: 0.0003  max mem: 3277
Epoch: [3]  [1250/1412]  eta: 0:00:28  lr: 0.000001  loss: 0.2142 (0.2279)  labels_encoder: 0.1028 (0.1158)  labels_decoder: 0.1099 (0.1122)  labels_encoder_unscaled: 0.1028 (0.1158)  labels_decoder_unscaled: 0.2198 (0.2243)  time: 0.1765  data: 0.0003  max mem: 3277
Epoch: [3]  [1300/1412]  eta: 0:00:19  lr: 0.000001  loss: 0.2289 (0.2277)  labels_encoder: 0.1089 (0.1156)  labels_decoder: 0.1093 (0.1122)  labels_encoder_unscaled: 0.1089 (0.1156)  labels_decoder_unscaled: 0.2186 (0.2243)  time: 0.1792  data: 0.0003  max mem: 3277
Epoch: [3]  [1350/1412]  eta: 0:00:10  lr: 0.000001  loss: 0.2345 (0.2276)  labels_encoder: 0.1113 (0.1153)  labels_decoder: 0.1111 (0.1123)  labels_encoder_unscaled: 0.1113 (0.1153)  labels_decoder_unscaled: 0.2222 (0.2245)  time: 0.1633  data: 0.0003  max mem: 3277
Epoch: [3]  [1400/1412]  eta: 0:00:02  lr: 0.000001  loss: 0.2252 (0.2276)  labels_encoder: 0.1049 (0.1155)  labels_decoder: 0.1116 (0.1121)  labels_encoder_unscaled: 0.1049 (0.1155)  labels_decoder_unscaled: 0.2233 (0.2243)  time: 0.1689  data: 0.0006  max mem: 3277
Epoch: [3]  [1411/1412]  eta: 0:00:00  lr: 0.000001  loss: 0.1996 (0.2275)  labels_encoder: 0.0942 (0.1154)  labels_decoder: 0.1102 (0.1121)  labels_encoder_unscaled: 0.0942 (0.1154)  labels_decoder_unscaled: 0.2205 (0.2243)  time: 0.1375  data: 0.0004  max mem: 3277
Epoch: [3] Total time: 0:04:06 (0.1747 s / it)
Averaged stats: lr: 0.000001  loss: 0.1996 (0.2275)  labels_encoder: 0.0942 (0.1154)  labels_decoder: 0.1102 (0.1121)  labels_encoder_unscaled: 0.0942 (0.1154)  labels_decoder_unscaled: 0.2205 (0.2243)
Test:  [   0/1613]  eta: 1:18:05  loss: 1.2885 (1.2885)  labels_encoder: 0.7163 (0.7163)  labels_decoder: 0.5722 (0.5722)  labels_encoder_unscaled: 0.7163 (0.7163)  labels_decoder_unscaled: 1.1445 (1.1445)  time: 2.9050  data: 2.8160  max mem: 3277
Test:  [  50/1613]  eta: 0:04:13  loss: 0.4478 (0.7921)  labels_encoder: 0.2520 (0.4784)  labels_decoder: 0.2351 (0.3137)  labels_encoder_unscaled: 0.2520 (0.4784)  labels_decoder_unscaled: 0.4702 (0.6274)  time: 0.0865  data: 0.0036  max mem: 3277
Test:  [ 100/1613]  eta: 0:03:27  loss: 0.5599 (0.7404)  labels_encoder: 0.3225 (0.4705)  labels_decoder: 0.1868 (0.2699)  labels_encoder_unscaled: 0.3225 (0.4705)  labels_decoder_unscaled: 0.3736 (0.5398)  time: 0.1144  data: 0.0493  max mem: 3277
Test:  [ 150/1613]  eta: 0:03:14  loss: 0.7004 (0.7508)  labels_encoder: 0.5091 (0.4765)  labels_decoder: 0.2190 (0.2743)  labels_encoder_unscaled: 0.5091 (0.4765)  labels_decoder_unscaled: 0.4379 (0.5485)  time: 0.1247  data: 0.0585  max mem: 3277
Test:  [ 200/1613]  eta: 0:03:07  loss: 0.8793 (0.8941)  labels_encoder: 0.5064 (0.5675)  labels_decoder: 0.3658 (0.3266)  labels_encoder_unscaled: 0.5064 (0.5675)  labels_decoder_unscaled: 0.7316 (0.6532)  time: 0.1305  data: 0.0684  max mem: 3277
Test:  [ 250/1613]  eta: 0:02:58  loss: 0.8082 (0.9433)  labels_encoder: 0.4801 (0.5973)  labels_decoder: 0.3467 (0.3460)  labels_encoder_unscaled: 0.4801 (0.5973)  labels_decoder_unscaled: 0.6934 (0.6919)  time: 0.1298  data: 0.0672  max mem: 3277
Test:  [ 300/1613]  eta: 0:02:52  loss: 1.0772 (0.9878)  labels_encoder: 0.6173 (0.6264)  labels_decoder: 0.5187 (0.3614)  labels_encoder_unscaled: 0.6173 (0.6264)  labels_decoder_unscaled: 1.0374 (0.7228)  time: 0.1327  data: 0.0683  max mem: 3277
Test:  [ 350/1613]  eta: 0:02:45  loss: 1.2920 (1.0132)  labels_encoder: 0.7371 (0.6442)  labels_decoder: 0.4586 (0.3690)  labels_encoder_unscaled: 0.7371 (0.6442)  labels_decoder_unscaled: 0.9172 (0.7380)  time: 0.1312  data: 0.0680  max mem: 3277
Test:  [ 400/1613]  eta: 0:02:39  loss: 0.7364 (1.0584)  labels_encoder: 0.3876 (0.6767)  labels_decoder: 0.3395 (0.3818)  labels_encoder_unscaled: 0.3876 (0.6767)  labels_decoder_unscaled: 0.6789 (0.7636)  time: 0.1277  data: 0.0707  max mem: 3277
Test:  [ 450/1613]  eta: 0:02:32  loss: 1.0704 (1.1521)  labels_encoder: 0.6966 (0.7403)  labels_decoder: 0.3655 (0.4117)  labels_encoder_unscaled: 0.6966 (0.7403)  labels_decoder_unscaled: 0.7311 (0.8235)  time: 0.1355  data: 0.0659  max mem: 3277
Test:  [ 500/1613]  eta: 0:02:26  loss: 0.2960 (1.0997)  labels_encoder: 0.1507 (0.7048)  labels_decoder: 0.1596 (0.3948)  labels_encoder_unscaled: 0.1507 (0.7048)  labels_decoder_unscaled: 0.3193 (0.7897)  time: 0.1321  data: 0.0685  max mem: 3277
Test:  [ 550/1613]  eta: 0:02:20  loss: 0.6353 (1.0770)  labels_encoder: 0.3504 (0.6902)  labels_decoder: 0.2418 (0.3867)  labels_encoder_unscaled: 0.3504 (0.6902)  labels_decoder_unscaled: 0.4836 (0.7735)  time: 0.1348  data: 0.0695  max mem: 3277
Test:  [ 600/1613]  eta: 0:02:13  loss: 0.8651 (1.1375)  labels_encoder: 0.5002 (0.7422)  labels_decoder: 0.3650 (0.3953)  labels_encoder_unscaled: 0.5002 (0.7422)  labels_decoder_unscaled: 0.7300 (0.7906)  time: 0.1343  data: 0.0696  max mem: 3277
Test:  [ 650/1613]  eta: 0:02:07  loss: 1.0645 (1.1341)  labels_encoder: 0.5361 (0.7377)  labels_decoder: 0.4642 (0.3964)  labels_encoder_unscaled: 0.5361 (0.7377)  labels_decoder_unscaled: 0.9285 (0.7928)  time: 0.1409  data: 0.0705  max mem: 3277
Test:  [ 700/1613]  eta: 0:02:00  loss: 0.4653 (1.1025)  labels_encoder: 0.3175 (0.7160)  labels_decoder: 0.1903 (0.3865)  labels_encoder_unscaled: 0.3175 (0.7160)  labels_decoder_unscaled: 0.3807 (0.7731)  time: 0.1318  data: 0.0730  max mem: 3277
Test:  [ 750/1613]  eta: 0:01:54  loss: 0.7684 (1.0745)  labels_encoder: 0.4354 (0.6964)  labels_decoder: 0.2663 (0.3781)  labels_encoder_unscaled: 0.4354 (0.6964)  labels_decoder_unscaled: 0.5325 (0.7563)  time: 0.1348  data: 0.0717  max mem: 3277
Test:  [ 800/1613]  eta: 0:01:47  loss: 0.5393 (1.0693)  labels_encoder: 0.3421 (0.6937)  labels_decoder: 0.2413 (0.3756)  labels_encoder_unscaled: 0.3421 (0.6937)  labels_decoder_unscaled: 0.4825 (0.7513)  time: 0.1303  data: 0.0639  max mem: 3277
Test:  [ 850/1613]  eta: 0:01:41  loss: 0.9995 (1.0720)  labels_encoder: 0.5508 (0.6929)  labels_decoder: 0.3732 (0.3791)  labels_encoder_unscaled: 0.5508 (0.6929)  labels_decoder_unscaled: 0.7463 (0.7582)  time: 0.1264  data: 0.0660  max mem: 3277
Test:  [ 900/1613]  eta: 0:01:34  loss: 0.5288 (1.0495)  labels_encoder: 0.2905 (0.6754)  labels_decoder: 0.2881 (0.3740)  labels_encoder_unscaled: 0.2905 (0.6754)  labels_decoder_unscaled: 0.5762 (0.7481)  time: 0.1178  data: 0.0486  max mem: 3277
Test:  [ 950/1613]  eta: 0:01:27  loss: 1.1172 (1.0495)  labels_encoder: 0.7285 (0.6745)  labels_decoder: 0.4161 (0.3750)  labels_encoder_unscaled: 0.7285 (0.6745)  labels_decoder_unscaled: 0.8322 (0.7499)  time: 0.1211  data: 0.0573  max mem: 3277
Test:  [1000/1613]  eta: 0:01:20  loss: 0.8636 (1.0365)  labels_encoder: 0.4985 (0.6651)  labels_decoder: 0.3651 (0.3713)  labels_encoder_unscaled: 0.4985 (0.6651)  labels_decoder_unscaled: 0.7302 (0.7426)  time: 0.1156  data: 0.0466  max mem: 3277
Test:  [1050/1613]  eta: 0:01:13  loss: 0.9550 (1.0402)  labels_encoder: 0.6404 (0.6684)  labels_decoder: 0.3432 (0.3718)  labels_encoder_unscaled: 0.6404 (0.6684)  labels_decoder_unscaled: 0.6863 (0.7436)  time: 0.1218  data: 0.0505  max mem: 3277
Test:  [1100/1613]  eta: 0:01:06  loss: 0.4289 (1.0441)  labels_encoder: 0.2466 (0.6726)  labels_decoder: 0.2101 (0.3716)  labels_encoder_unscaled: 0.2466 (0.6726)  labels_decoder_unscaled: 0.4202 (0.7432)  time: 0.1178  data: 0.0587  max mem: 3277
Test:  [1150/1613]  eta: 0:01:00  loss: 0.4056 (1.0352)  labels_encoder: 0.2466 (0.6662)  labels_decoder: 0.1921 (0.3689)  labels_encoder_unscaled: 0.2466 (0.6662)  labels_decoder_unscaled: 0.3842 (0.7379)  time: 0.1209  data: 0.0524  max mem: 3277
Test:  [1200/1613]  eta: 0:00:53  loss: 0.4525 (1.0391)  labels_encoder: 0.2238 (0.6687)  labels_decoder: 0.1987 (0.3704)  labels_encoder_unscaled: 0.2238 (0.6687)  labels_decoder_unscaled: 0.3974 (0.7409)  time: 0.1228  data: 0.0509  max mem: 3277
Test:  [1250/1613]  eta: 0:00:46  loss: 0.5810 (1.0409)  labels_encoder: 0.2740 (0.6701)  labels_decoder: 0.2669 (0.3708)  labels_encoder_unscaled: 0.2740 (0.6701)  labels_decoder_unscaled: 0.5339 (0.7415)  time: 0.1092  data: 0.0475  max mem: 3277
Test:  [1300/1613]  eta: 0:00:40  loss: 0.6153 (1.0355)  labels_encoder: 0.3550 (0.6658)  labels_decoder: 0.2614 (0.3696)  labels_encoder_unscaled: 0.3550 (0.6658)  labels_decoder_unscaled: 0.5229 (0.7393)  time: 0.1076  data: 0.0491  max mem: 3277
Test:  [1350/1613]  eta: 0:00:33  loss: 1.0723 (1.0376)  labels_encoder: 0.7448 (0.6680)  labels_decoder: 0.3706 (0.3695)  labels_encoder_unscaled: 0.7448 (0.6680)  labels_decoder_unscaled: 0.7412 (0.7391)  time: 0.1147  data: 0.0344  max mem: 3277
Test:  [1400/1613]  eta: 0:00:27  loss: 1.0168 (1.0422)  labels_encoder: 0.6695 (0.6706)  labels_decoder: 0.4143 (0.3716)  labels_encoder_unscaled: 0.6695 (0.6706)  labels_decoder_unscaled: 0.8286 (0.7431)  time: 0.1165  data: 0.0455  max mem: 3277
Test:  [1450/1613]  eta: 0:00:20  loss: 0.5036 (1.0446)  labels_encoder: 0.1957 (0.6725)  labels_decoder: 0.2040 (0.3720)  labels_encoder_unscaled: 0.1957 (0.6725)  labels_decoder_unscaled: 0.4080 (0.7441)  time: 0.1082  data: 0.0463  max mem: 3277
Test:  [1500/1613]  eta: 0:00:14  loss: 0.5993 (1.0393)  labels_encoder: 0.3416 (0.6693)  labels_decoder: 0.1995 (0.3700)  labels_encoder_unscaled: 0.3416 (0.6693)  labels_decoder_unscaled: 0.3991 (0.7399)  time: 0.1066  data: 0.0384  max mem: 3277
Test:  [1550/1613]  eta: 0:00:07  loss: 1.0018 (1.0390)  labels_encoder: 0.6454 (0.6695)  labels_decoder: 0.3008 (0.3695)  labels_encoder_unscaled: 0.6454 (0.6695)  labels_decoder_unscaled: 0.6015 (0.7390)  time: 0.1074  data: 0.0360  max mem: 3277
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9182 (1.0395)  labels_encoder: 0.5579 (0.6689)  labels_decoder: 0.4072 (0.3706)  labels_encoder_unscaled: 0.5579 (0.6689)  labels_decoder_unscaled: 0.8144 (0.7412)  time: 0.1116  data: 0.0492  max mem: 3277
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8347 (1.0386)  labels_encoder: 0.4745 (0.6683)  labels_decoder: 0.3439 (0.3703)  labels_encoder_unscaled: 0.4745 (0.6683)  labels_decoder_unscaled: 0.6877 (0.7406)  time: 0.1023  data: 0.0448  max mem: 3277
Test: Total time: 0:03:22 (0.1258 s / it)
Averaged stats: loss: 0.8347 (1.0386)  labels_encoder: 0.4745 (0.6683)  labels_decoder: 0.3439 (0.3703)  labels_encoder_unscaled: 0.4745 (0.6683)  labels_decoder_unscaled: 0.6877 (0.7406)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-kin_audio] mAP: 0.6343

dec_mAP all together: | 0.5036389140110283 |.
dec_mAP_pred | 0 : 0.548969035351328 |.
dec_mAP_pred | 1 : 0.5420990022582377 |.
dec_mAP_pred | 2 : 0.5301035039529595 |.
dec_mAP_pred | 3 : 0.5156113063177242 |.
dec_mAP_pred | 4 : 0.4999341485701465 |.
dec_mAP_pred | 5 : 0.48377591240115647 |.
dec_mAP_pred | 6 : 0.4675920683090234 |.
dec_mAP_pred | 7 : 0.4521687237438107 |.
all decoder map: | 0.5050 |.
BaseballPitch: 0.3395
BasketballDunk: 0.8118
Billiards: 0.3077
CleanAndJerk: 0.7211
CliffDiving: 0.8500
CricketBowling: 0.4957
CricketShot: 0.2824
Diving: 0.8562
FrisbeeCatch: 0.4060
GolfSwing: 0.7653
HammerThrow: 0.8443
HighJump: 0.7963
JavelinThrow: 0.7508
LongJump: 0.7775
PoleVault: 0.8743
Shotput: 0.7368
SoccerPenalty: 0.4082
TennisSwing: 0.6067
ThrowDiscus: 0.5910
VolleyballSpiking: 0.4645
Epoch: [4]  [   0/1412]  eta: 1:32:16  lr: 0.000000  loss: 0.2216 (0.2216)  labels_encoder: 0.0963 (0.0963)  labels_decoder: 0.1254 (0.1254)  labels_encoder_unscaled: 0.0963 (0.0963)  labels_decoder_unscaled: 0.2507 (0.2507)  time: 3.9209  data: 3.7338  max mem: 3277
Epoch: [4]  [  50/1412]  eta: 0:05:43  lr: 0.000000  loss: 0.2362 (0.2263)  labels_encoder: 0.1235 (0.1138)  labels_decoder: 0.1098 (0.1125)  labels_encoder_unscaled: 0.1235 (0.1138)  labels_decoder_unscaled: 0.2196 (0.2250)  time: 0.1784  data: 0.0003  max mem: 3277
Epoch: [4]  [ 100/1412]  eta: 0:04:38  lr: 0.000000  loss: 0.2040 (0.2185)  labels_encoder: 0.0925 (0.1077)  labels_decoder: 0.1080 (0.1107)  labels_encoder_unscaled: 0.0925 (0.1077)  labels_decoder_unscaled: 0.2159 (0.2215)  time: 0.1752  data: 0.0003  max mem: 3277
Epoch: [4]  [ 150/1412]  eta: 0:04:14  lr: 0.000000  loss: 0.2324 (0.2246)  labels_encoder: 0.1168 (0.1133)  labels_decoder: 0.1122 (0.1112)  labels_encoder_unscaled: 0.1168 (0.1133)  labels_decoder_unscaled: 0.2243 (0.2224)  time: 0.1803  data: 0.0003  max mem: 3277
Epoch: [4]  [ 200/1412]  eta: 0:03:54  lr: 0.000000  loss: 0.2247 (0.2229)  labels_encoder: 0.1079 (0.1121)  labels_decoder: 0.1139 (0.1108)  labels_encoder_unscaled: 0.1079 (0.1121)  labels_decoder_unscaled: 0.2278 (0.2216)  time: 0.1652  data: 0.0003  max mem: 3277
Epoch: [4]  [ 250/1412]  eta: 0:03:41  lr: 0.000000  loss: 0.2010 (0.2214)  labels_encoder: 0.1032 (0.1114)  labels_decoder: 0.1049 (0.1100)  labels_encoder_unscaled: 0.1032 (0.1114)  labels_decoder_unscaled: 0.2097 (0.2200)  time: 0.1823  data: 0.0003  max mem: 3277
Epoch: [4]  [ 300/1412]  eta: 0:03:29  lr: 0.000000  loss: 0.2096 (0.2212)  labels_encoder: 0.0945 (0.1110)  labels_decoder: 0.1147 (0.1102)  labels_encoder_unscaled: 0.0945 (0.1110)  labels_decoder_unscaled: 0.2294 (0.2204)  time: 0.1789  data: 0.0003  max mem: 3277
Epoch: [4]  [ 350/1412]  eta: 0:03:18  lr: 0.000000  loss: 0.1860 (0.2205)  labels_encoder: 0.0943 (0.1105)  labels_decoder: 0.0991 (0.1100)  labels_encoder_unscaled: 0.0943 (0.1105)  labels_decoder_unscaled: 0.1981 (0.2201)  time: 0.1717  data: 0.0041  max mem: 3277
Epoch: [4]  [ 400/1412]  eta: 0:03:07  lr: 0.000000  loss: 0.2144 (0.2212)  labels_encoder: 0.0958 (0.1108)  labels_decoder: 0.1111 (0.1104)  labels_encoder_unscaled: 0.0958 (0.1108)  labels_decoder_unscaled: 0.2223 (0.2208)  time: 0.1768  data: 0.0003  max mem: 3277
Epoch: [4]  [ 450/1412]  eta: 0:02:57  lr: 0.000000  loss: 0.2274 (0.2218)  labels_encoder: 0.1086 (0.1113)  labels_decoder: 0.1068 (0.1104)  labels_encoder_unscaled: 0.1086 (0.1113)  labels_decoder_unscaled: 0.2136 (0.2209)  time: 0.1730  data: 0.0003  max mem: 3277
Epoch: [4]  [ 500/1412]  eta: 0:02:47  lr: 0.000000  loss: 0.1977 (0.2214)  labels_encoder: 0.1025 (0.1110)  labels_decoder: 0.1100 (0.1104)  labels_encoder_unscaled: 0.1025 (0.1110)  labels_decoder_unscaled: 0.2199 (0.2208)  time: 0.1843  data: 0.0003  max mem: 3277
Epoch: [4]  [ 550/1412]  eta: 0:02:38  lr: 0.000000  loss: 0.2305 (0.2224)  labels_encoder: 0.1202 (0.1118)  labels_decoder: 0.1065 (0.1106)  labels_encoder_unscaled: 0.1202 (0.1118)  labels_decoder_unscaled: 0.2130 (0.2212)  time: 0.1745  data: 0.0003  max mem: 3277
Epoch: [4]  [ 600/1412]  eta: 0:02:28  lr: 0.000000  loss: 0.2290 (0.2232)  labels_encoder: 0.1196 (0.1122)  labels_decoder: 0.1062 (0.1110)  labels_encoder_unscaled: 0.1196 (0.1122)  labels_decoder_unscaled: 0.2124 (0.2220)  time: 0.1725  data: 0.0003  max mem: 3277
Epoch: [4]  [ 650/1412]  eta: 0:02:18  lr: 0.000000  loss: 0.2169 (0.2234)  labels_encoder: 0.1101 (0.1122)  labels_decoder: 0.1121 (0.1112)  labels_encoder_unscaled: 0.1101 (0.1122)  labels_decoder_unscaled: 0.2241 (0.2224)  time: 0.1822  data: 0.0003  max mem: 3277
Epoch: [4]  [ 700/1412]  eta: 0:02:09  lr: 0.000000  loss: 0.2411 (0.2241)  labels_encoder: 0.1267 (0.1128)  labels_decoder: 0.1145 (0.1113)  labels_encoder_unscaled: 0.1267 (0.1128)  labels_decoder_unscaled: 0.2290 (0.2225)  time: 0.1765  data: 0.0003  max mem: 3277
Epoch: [4]  [ 750/1412]  eta: 0:01:59  lr: 0.000000  loss: 0.2150 (0.2239)  labels_encoder: 0.0964 (0.1126)  labels_decoder: 0.1111 (0.1113)  labels_encoder_unscaled: 0.0964 (0.1126)  labels_decoder_unscaled: 0.2222 (0.2225)  time: 0.1776  data: 0.0003  max mem: 3277
Epoch: [4]  [ 800/1412]  eta: 0:01:50  lr: 0.000000  loss: 0.2217 (0.2236)  labels_encoder: 0.1029 (0.1123)  labels_decoder: 0.1161 (0.1113)  labels_encoder_unscaled: 0.1029 (0.1123)  labels_decoder_unscaled: 0.2323 (0.2226)  time: 0.1682  data: 0.0003  max mem: 3277
Epoch: [4]  [ 850/1412]  eta: 0:01:41  lr: 0.000000  loss: 0.2275 (0.2235)  labels_encoder: 0.1153 (0.1123)  labels_decoder: 0.1081 (0.1112)  labels_encoder_unscaled: 0.1153 (0.1123)  labels_decoder_unscaled: 0.2162 (0.2225)  time: 0.1699  data: 0.0003  max mem: 3277
Epoch: [4]  [ 900/1412]  eta: 0:01:32  lr: 0.000000  loss: 0.2252 (0.2240)  labels_encoder: 0.1202 (0.1128)  labels_decoder: 0.1152 (0.1113)  labels_encoder_unscaled: 0.1202 (0.1128)  labels_decoder_unscaled: 0.2305 (0.2225)  time: 0.1805  data: 0.0003  max mem: 3277
Epoch: [4]  [ 950/1412]  eta: 0:01:23  lr: 0.000000  loss: 0.2185 (0.2242)  labels_encoder: 0.1109 (0.1128)  labels_decoder: 0.1111 (0.1114)  labels_encoder_unscaled: 0.1109 (0.1128)  labels_decoder_unscaled: 0.2221 (0.2228)  time: 0.1823  data: 0.0003  max mem: 3277
Epoch: [4]  [1000/1412]  eta: 0:01:14  lr: 0.000000  loss: 0.2318 (0.2244)  labels_encoder: 0.1241 (0.1131)  labels_decoder: 0.1079 (0.1113)  labels_encoder_unscaled: 0.1241 (0.1131)  labels_decoder_unscaled: 0.2158 (0.2226)  time: 0.1772  data: 0.0003  max mem: 3277
Epoch: [4]  [1050/1412]  eta: 0:01:05  lr: 0.000000  loss: 0.2013 (0.2243)  labels_encoder: 0.1014 (0.1130)  labels_decoder: 0.1107 (0.1113)  labels_encoder_unscaled: 0.1014 (0.1130)  labels_decoder_unscaled: 0.2215 (0.2226)  time: 0.1823  data: 0.0003  max mem: 3277
Epoch: [4]  [1100/1412]  eta: 0:00:56  lr: 0.000000  loss: 0.2359 (0.2245)  labels_encoder: 0.1167 (0.1131)  labels_decoder: 0.1169 (0.1114)  labels_encoder_unscaled: 0.1167 (0.1131)  labels_decoder_unscaled: 0.2337 (0.2227)  time: 0.1645  data: 0.0002  max mem: 3277
Epoch: [4]  [1150/1412]  eta: 0:00:47  lr: 0.000000  loss: 0.2197 (0.2245)  labels_encoder: 0.1060 (0.1132)  labels_decoder: 0.1120 (0.1113)  labels_encoder_unscaled: 0.1060 (0.1132)  labels_decoder_unscaled: 0.2239 (0.2226)  time: 0.1691  data: 0.0003  max mem: 3277
Epoch: [4]  [1200/1412]  eta: 0:00:38  lr: 0.000000  loss: 0.2369 (0.2246)  labels_encoder: 0.1131 (0.1133)  labels_decoder: 0.1116 (0.1113)  labels_encoder_unscaled: 0.1131 (0.1133)  labels_decoder_unscaled: 0.2232 (0.2226)  time: 0.1822  data: 0.0003  max mem: 3277
Epoch: [4]  [1250/1412]  eta: 0:00:28  lr: 0.000000  loss: 0.2212 (0.2246)  labels_encoder: 0.1192 (0.1133)  labels_decoder: 0.1131 (0.1113)  labels_encoder_unscaled: 0.1192 (0.1133)  labels_decoder_unscaled: 0.2263 (0.2226)  time: 0.1609  data: 0.0003  max mem: 3277
Epoch: [4]  [1300/1412]  eta: 0:00:20  lr: 0.000000  loss: 0.2020 (0.2241)  labels_encoder: 0.1024 (0.1130)  labels_decoder: 0.1038 (0.1111)  labels_encoder_unscaled: 0.1024 (0.1130)  labels_decoder_unscaled: 0.2076 (0.2222)  time: 0.1810  data: 0.0003  max mem: 3277
Epoch: [4]  [1350/1412]  eta: 0:00:11  lr: 0.000000  loss: 0.2179 (0.2243)  labels_encoder: 0.1107 (0.1132)  labels_decoder: 0.1080 (0.1110)  labels_encoder_unscaled: 0.1107 (0.1132)  labels_decoder_unscaled: 0.2159 (0.2221)  time: 0.1731  data: 0.0003  max mem: 3277
Epoch: [4]  [1400/1412]  eta: 0:00:02  lr: 0.000000  loss: 0.2097 (0.2241)  labels_encoder: 0.1070 (0.1130)  labels_decoder: 0.1064 (0.1110)  labels_encoder_unscaled: 0.1070 (0.1130)  labels_decoder_unscaled: 0.2128 (0.2221)  time: 0.1666  data: 0.0005  max mem: 3277
Epoch: [4]  [1411/1412]  eta: 0:00:00  lr: 0.000000  loss: 0.2340 (0.2243)  labels_encoder: 0.1070 (0.1131)  labels_decoder: 0.1133 (0.1111)  labels_encoder_unscaled: 0.1070 (0.1131)  labels_decoder_unscaled: 0.2267 (0.2223)  time: 0.1418  data: 0.0004  max mem: 3277
Epoch: [4] Total time: 0:04:12 (0.1787 s / it)
Averaged stats: lr: 0.000000  loss: 0.2340 (0.2243)  labels_encoder: 0.1070 (0.1131)  labels_decoder: 0.1133 (0.1111)  labels_encoder_unscaled: 0.1070 (0.1131)  labels_decoder_unscaled: 0.2267 (0.2223)
Test:  [   0/1613]  eta: 1:31:25  loss: 1.3096 (1.3096)  labels_encoder: 0.7298 (0.7298)  labels_decoder: 0.5798 (0.5798)  labels_encoder_unscaled: 0.7298 (0.7298)  labels_decoder_unscaled: 1.1596 (1.1596)  time: 3.4005  data: 3.2676  max mem: 3277
Test:  [  50/1613]  eta: 0:04:09  loss: 0.4500 (0.7885)  labels_encoder: 0.2512 (0.4755)  labels_decoder: 0.2363 (0.3130)  labels_encoder_unscaled: 0.2512 (0.4755)  labels_decoder_unscaled: 0.4727 (0.6260)  time: 0.0913  data: 0.0174  max mem: 3277
Test:  [ 100/1613]  eta: 0:03:17  loss: 0.5563 (0.7377)  labels_encoder: 0.3266 (0.4684)  labels_decoder: 0.1881 (0.2693)  labels_encoder_unscaled: 0.3266 (0.4684)  labels_decoder_unscaled: 0.3762 (0.5386)  time: 0.1020  data: 0.0408  max mem: 3277
Test:  [ 150/1613]  eta: 0:03:00  loss: 0.7344 (0.7494)  labels_encoder: 0.5228 (0.4752)  labels_decoder: 0.2137 (0.2742)  labels_encoder_unscaled: 0.5228 (0.4752)  labels_decoder_unscaled: 0.4273 (0.5483)  time: 0.1114  data: 0.0235  max mem: 3277
Test:  [ 200/1613]  eta: 0:02:48  loss: 0.8787 (0.8955)  labels_encoder: 0.5116 (0.5682)  labels_decoder: 0.3667 (0.3273)  labels_encoder_unscaled: 0.5116 (0.5682)  labels_decoder_unscaled: 0.7333 (0.6545)  time: 0.1026  data: 0.0086  max mem: 3277
Test:  [ 250/1613]  eta: 0:02:38  loss: 0.7616 (0.9432)  labels_encoder: 0.4177 (0.5969)  labels_decoder: 0.3433 (0.3463)  labels_encoder_unscaled: 0.4177 (0.5969)  labels_decoder_unscaled: 0.6866 (0.6925)  time: 0.0973  data: 0.0291  max mem: 3277
Test:  [ 300/1613]  eta: 0:02:29  loss: 1.0660 (0.9876)  labels_encoder: 0.6251 (0.6261)  labels_decoder: 0.5137 (0.3615)  labels_encoder_unscaled: 0.6251 (0.6261)  labels_decoder_unscaled: 1.0274 (0.7230)  time: 0.1045  data: 0.0416  max mem: 3277
Test:  [ 350/1613]  eta: 0:02:22  loss: 1.3003 (1.0129)  labels_encoder: 0.7554 (0.6437)  labels_decoder: 0.4633 (0.3691)  labels_encoder_unscaled: 0.7554 (0.6437)  labels_decoder_unscaled: 0.9266 (0.7383)  time: 0.1090  data: 0.0435  max mem: 3277
Test:  [ 400/1613]  eta: 0:02:15  loss: 0.7544 (1.0591)  labels_encoder: 0.3959 (0.6768)  labels_decoder: 0.3340 (0.3823)  labels_encoder_unscaled: 0.3959 (0.6768)  labels_decoder_unscaled: 0.6680 (0.7645)  time: 0.1079  data: 0.0113  max mem: 3277
Test:  [ 450/1613]  eta: 0:02:10  loss: 1.1413 (1.1532)  labels_encoder: 0.7505 (0.7409)  labels_decoder: 0.3687 (0.4123)  labels_encoder_unscaled: 0.7505 (0.7409)  labels_decoder_unscaled: 0.7375 (0.8246)  time: 0.1188  data: 0.0599  max mem: 3277
Test:  [ 500/1613]  eta: 0:02:04  loss: 0.2905 (1.1011)  labels_encoder: 0.1473 (0.7057)  labels_decoder: 0.1606 (0.3954)  labels_encoder_unscaled: 0.1473 (0.7057)  labels_decoder_unscaled: 0.3213 (0.7909)  time: 0.1043  data: 0.0411  max mem: 3277
Test:  [ 550/1613]  eta: 0:01:58  loss: 0.6348 (1.0783)  labels_encoder: 0.3460 (0.6910)  labels_decoder: 0.2459 (0.3873)  labels_encoder_unscaled: 0.3460 (0.6910)  labels_decoder_unscaled: 0.4918 (0.7746)  time: 0.1002  data: 0.0303  max mem: 3277
Test:  [ 600/1613]  eta: 0:01:52  loss: 0.8870 (1.1366)  labels_encoder: 0.5157 (0.7411)  labels_decoder: 0.3713 (0.3955)  labels_encoder_unscaled: 0.5157 (0.7411)  labels_decoder_unscaled: 0.7427 (0.7909)  time: 0.1092  data: 0.0085  max mem: 3277
Test:  [ 650/1613]  eta: 0:01:46  loss: 1.0817 (1.1338)  labels_encoder: 0.5587 (0.7370)  labels_decoder: 0.4703 (0.3968)  labels_encoder_unscaled: 0.5587 (0.7370)  labels_decoder_unscaled: 0.9406 (0.7935)  time: 0.1077  data: 0.0310  max mem: 3277
Test:  [ 700/1613]  eta: 0:01:40  loss: 0.4684 (1.1020)  labels_encoder: 0.3203 (0.7152)  labels_decoder: 0.1906 (0.3868)  labels_encoder_unscaled: 0.3203 (0.7152)  labels_decoder_unscaled: 0.3813 (0.7736)  time: 0.1027  data: 0.0143  max mem: 3277
Test:  [ 750/1613]  eta: 0:01:35  loss: 0.7780 (1.0746)  labels_encoder: 0.4432 (0.6960)  labels_decoder: 0.2738 (0.3786)  labels_encoder_unscaled: 0.4432 (0.6960)  labels_decoder_unscaled: 0.5476 (0.7571)  time: 0.1061  data: 0.0246  max mem: 3277
Test:  [ 800/1613]  eta: 0:01:29  loss: 0.5363 (1.0697)  labels_encoder: 0.3402 (0.6936)  labels_decoder: 0.2414 (0.3761)  labels_encoder_unscaled: 0.3402 (0.6936)  labels_decoder_unscaled: 0.4828 (0.7521)  time: 0.1157  data: 0.0318  max mem: 3277
Test:  [ 850/1613]  eta: 0:01:23  loss: 1.0093 (1.0728)  labels_encoder: 0.5529 (0.6932)  labels_decoder: 0.3770 (0.3796)  labels_encoder_unscaled: 0.5529 (0.6932)  labels_decoder_unscaled: 0.7541 (0.7592)  time: 0.1033  data: 0.0267  max mem: 3277
Test:  [ 900/1613]  eta: 0:01:18  loss: 0.5245 (1.0504)  labels_encoder: 0.3153 (0.6759)  labels_decoder: 0.2843 (0.3745)  labels_encoder_unscaled: 0.3153 (0.6759)  labels_decoder_unscaled: 0.5686 (0.7489)  time: 0.1041  data: 0.0226  max mem: 3277
Test:  [ 950/1613]  eta: 0:01:12  loss: 1.1070 (1.0512)  labels_encoder: 0.7380 (0.6756)  labels_decoder: 0.4129 (0.3756)  labels_encoder_unscaled: 0.7380 (0.6756)  labels_decoder_unscaled: 0.8258 (0.7512)  time: 0.1133  data: 0.0300  max mem: 3277
Test:  [1000/1613]  eta: 0:01:07  loss: 0.8522 (1.0383)  labels_encoder: 0.4869 (0.6662)  labels_decoder: 0.3652 (0.3720)  labels_encoder_unscaled: 0.4869 (0.6662)  labels_decoder_unscaled: 0.7305 (0.7440)  time: 0.1201  data: 0.0510  max mem: 3277
Test:  [1050/1613]  eta: 0:01:01  loss: 0.9430 (1.0422)  labels_encoder: 0.6415 (0.6697)  labels_decoder: 0.3387 (0.3725)  labels_encoder_unscaled: 0.6415 (0.6697)  labels_decoder_unscaled: 0.6773 (0.7449)  time: 0.1048  data: 0.0238  max mem: 3277
Test:  [1100/1613]  eta: 0:00:56  loss: 0.4253 (1.0461)  labels_encoder: 0.2467 (0.6739)  labels_decoder: 0.2109 (0.3722)  labels_encoder_unscaled: 0.2467 (0.6739)  labels_decoder_unscaled: 0.4217 (0.7444)  time: 0.1053  data: 0.0387  max mem: 3277
Test:  [1150/1613]  eta: 0:00:50  loss: 0.4041 (1.0369)  labels_encoder: 0.2407 (0.6674)  labels_decoder: 0.1917 (0.3695)  labels_encoder_unscaled: 0.2407 (0.6674)  labels_decoder_unscaled: 0.3834 (0.7390)  time: 0.1101  data: 0.0299  max mem: 3277
Test:  [1200/1613]  eta: 0:00:45  loss: 0.4678 (1.0407)  labels_encoder: 0.2294 (0.6698)  labels_decoder: 0.1986 (0.3709)  labels_encoder_unscaled: 0.2294 (0.6698)  labels_decoder_unscaled: 0.3972 (0.7418)  time: 0.1080  data: 0.0378  max mem: 3277
Test:  [1250/1613]  eta: 0:00:39  loss: 0.5807 (1.0428)  labels_encoder: 0.2746 (0.6714)  labels_decoder: 0.2681 (0.3713)  labels_encoder_unscaled: 0.2746 (0.6714)  labels_decoder_unscaled: 0.5363 (0.7426)  time: 0.1127  data: 0.0322  max mem: 3277
Test:  [1300/1613]  eta: 0:00:34  loss: 0.6158 (1.0375)  labels_encoder: 0.3566 (0.6673)  labels_decoder: 0.2628 (0.3702)  labels_encoder_unscaled: 0.3566 (0.6673)  labels_decoder_unscaled: 0.5255 (0.7404)  time: 0.1027  data: 0.0338  max mem: 3277
Test:  [1350/1613]  eta: 0:00:28  loss: 1.0605 (1.0396)  labels_encoder: 0.7003 (0.6695)  labels_decoder: 0.3602 (0.3701)  labels_encoder_unscaled: 0.7003 (0.6695)  labels_decoder_unscaled: 0.7204 (0.7402)  time: 0.1083  data: 0.0422  max mem: 3277
Test:  [1400/1613]  eta: 0:00:23  loss: 0.9977 (1.0445)  labels_encoder: 0.6649 (0.6723)  labels_decoder: 0.4036 (0.3722)  labels_encoder_unscaled: 0.6649 (0.6723)  labels_decoder_unscaled: 0.8072 (0.7443)  time: 0.1045  data: 0.0282  max mem: 3277
Test:  [1450/1613]  eta: 0:00:17  loss: 0.5183 (1.0470)  labels_encoder: 0.2037 (0.6743)  labels_decoder: 0.2112 (0.3727)  labels_encoder_unscaled: 0.2037 (0.6743)  labels_decoder_unscaled: 0.4224 (0.7453)  time: 0.1135  data: 0.0402  max mem: 3277
Test:  [1500/1613]  eta: 0:00:12  loss: 0.6064 (1.0417)  labels_encoder: 0.3443 (0.6711)  labels_decoder: 0.1994 (0.3706)  labels_encoder_unscaled: 0.3443 (0.6711)  labels_decoder_unscaled: 0.3987 (0.7412)  time: 0.0999  data: 0.0388  max mem: 3277
Test:  [1550/1613]  eta: 0:00:06  loss: 0.9930 (1.0415)  labels_encoder: 0.6390 (0.6714)  labels_decoder: 0.3010 (0.3701)  labels_encoder_unscaled: 0.6390 (0.6714)  labels_decoder_unscaled: 0.6019 (0.7403)  time: 0.0979  data: 0.0210  max mem: 3277
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9296 (1.0423)  labels_encoder: 0.5775 (0.6710)  labels_decoder: 0.4069 (0.3713)  labels_encoder_unscaled: 0.5775 (0.6710)  labels_decoder_unscaled: 0.8137 (0.7426)  time: 0.1037  data: 0.0220  max mem: 3277
Test:  [1612/1613]  eta: 0:00:00  loss: 0.8257 (1.0415)  labels_encoder: 0.4664 (0.6705)  labels_decoder: 0.3521 (0.3710)  labels_encoder_unscaled: 0.4664 (0.6705)  labels_decoder_unscaled: 0.7043 (0.7420)  time: 0.0941  data: 0.0166  max mem: 3277
Test: Total time: 0:02:56 (0.1095 s / it)
Averaged stats: loss: 0.8257 (1.0415)  labels_encoder: 0.4664 (0.6705)  labels_decoder: 0.3521 (0.3710)  labels_encoder_unscaled: 0.4664 (0.6705)  labels_decoder_unscaled: 0.7043 (0.7420)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-kin_audio] mAP: 0.6340

dec_mAP all together: | 0.5032532440144345 |.
dec_mAP_pred | 0 : 0.5488600774539133 |.
dec_mAP_pred | 1 : 0.5419194047401754 |.
dec_mAP_pred | 2 : 0.5298051514800084 |.
dec_mAP_pred | 3 : 0.5152642852007403 |.
dec_mAP_pred | 4 : 0.4995224356453455 |.
dec_mAP_pred | 5 : 0.483273726845156 |.
dec_mAP_pred | 6 : 0.4670728939682645 |.
dec_mAP_pred | 7 : 0.4516386333101334 |.
all decoder map: | 0.5047 |.
BaseballPitch: 0.3409
BasketballDunk: 0.8116
Billiards: 0.3077
CleanAndJerk: 0.7214
CliffDiving: 0.8493
CricketBowling: 0.4946
CricketShot: 0.2854
Diving: 0.8554
FrisbeeCatch: 0.4080
GolfSwing: 0.7665
HammerThrow: 0.8441
HighJump: 0.7957
JavelinThrow: 0.7495
LongJump: 0.7761
PoleVault: 0.8739
Shotput: 0.7350
SoccerPenalty: 0.4067
TennisSwing: 0.6061
ThrowDiscus: 0.5885
VolleyballSpiking: 0.4636
Training time 0:33:31
