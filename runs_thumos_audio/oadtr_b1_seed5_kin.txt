Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:kin_audio
dim_feature:8192
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:5
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  67.232 M, 99.818% Params, 1.963 GMac, 100.000% MACs, 
  (linear_encoding): Linear(8.39 M, 12.456% Params, 0.537 GMac, 27.345% MACs, in_features=8192, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    6.295 M, 9.345% Params, 0.409 GMac, 20.832% MACs, 
    (net): Sequential(
      6.295 M, 9.345% Params, 0.409 GMac, 20.832% MACs, 
      (0): Residual(
        4.195 M, 6.229% Params, 0.273 GMac, 13.886% MACs, 
        (fn): PreNormDrop(
          4.195 M, 6.229% Params, 0.273 GMac, 13.886% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 6.229% Params, 0.273 GMac, 13.886% MACs, 
            (qkv): Linear(3.146 M, 4.670% Params, 0.204 GMac, 10.414% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 3.117% Params, 0.136 GMac, 6.946% MACs, 
        (fn): PreNorm(
          2.099 M, 3.117% Params, 0.136 GMac, 6.946% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 3.117% Params, 0.136 GMac, 6.946% MACs, 
            (net): Sequential(
              2.099 M, 3.117% Params, 0.136 GMac, 6.946% MACs, 
              (0): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.067% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 77.916% Params, 1.017 GMac, 51.811% MACs, 
    (layers): ModuleList(
      52.48 M, 77.916% Params, 1.017 GMac, 51.811% MACs, 
      (0): DecoderLayer(
        10.496 M, 15.583% Params, 0.203 GMac, 10.362% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.034 GMac, 1.709% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.153 GMac, 7.798% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 15.583% Params, 0.203 GMac, 10.362% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.034 GMac, 1.709% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.153 GMac, 7.798% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 15.583% Params, 0.203 GMac, 10.362% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.034 GMac, 1.709% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.153 GMac, 7.798% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 15.583% Params, 0.203 GMac, 10.362% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.034 GMac, 1.709% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.153 GMac, 7.798% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 15.583% Params, 0.203 GMac, 10.362% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.034 GMac, 1.709% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 6.233% Params, 0.153 GMac, 7.798% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.558% Params, 0.068 GMac, 3.472% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.558% Params, 0.008 GMac, 0.427% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.558% Params, 0.008 GMac, 0.428% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.033% Params, 0.0 GMac, 0.009% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 1963353132.0
Model params: 67354668
Loaded data/thumos_kin_plus_audio_val.pickle
Loaded data/thumos_kin_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1412]  eta: 1:53:59  lr: 0.000100  loss: 4.5953 (4.5953)  labels_encoder: 3.3616 (3.3616)  labels_decoder: 1.2337 (1.2337)  labels_encoder_unscaled: 3.3616 (3.3616)  labels_decoder_unscaled: 2.4674 (2.4674)  time: 4.8438  data: 4.0229  max mem: 1997
Epoch: [1]  [  50/1412]  eta: 0:06:59  lr: 0.000100  loss: 0.9087 (1.4835)  labels_encoder: 0.5574 (0.9771)  labels_decoder: 0.3610 (0.5064)  labels_encoder_unscaled: 0.5574 (0.9771)  labels_decoder_unscaled: 0.7221 (1.0128)  time: 0.1833  data: 0.0004  max mem: 2769
Epoch: [1]  [ 100/1412]  eta: 0:05:12  lr: 0.000100  loss: 0.7534 (1.1252)  labels_encoder: 0.4617 (0.7252)  labels_decoder: 0.2870 (0.4001)  labels_encoder_unscaled: 0.4617 (0.7252)  labels_decoder_unscaled: 0.5740 (0.8001)  time: 0.1756  data: 0.0006  max mem: 2769
Epoch: [1]  [ 150/1412]  eta: 0:04:34  lr: 0.000100  loss: 0.6179 (0.9682)  labels_encoder: 0.3806 (0.6159)  labels_decoder: 0.2399 (0.3522)  labels_encoder_unscaled: 0.3806 (0.6159)  labels_decoder_unscaled: 0.4798 (0.7045)  time: 0.1613  data: 0.0004  max mem: 2769
Epoch: [1]  [ 200/1412]  eta: 0:04:10  lr: 0.000100  loss: 0.6054 (0.8728)  labels_encoder: 0.3673 (0.5498)  labels_decoder: 0.2452 (0.3229)  labels_encoder_unscaled: 0.3673 (0.5498)  labels_decoder_unscaled: 0.4905 (0.6459)  time: 0.1732  data: 0.0004  max mem: 2769
Epoch: [1]  [ 250/1412]  eta: 0:03:52  lr: 0.000100  loss: 0.5564 (0.8088)  labels_encoder: 0.3225 (0.5059)  labels_decoder: 0.2081 (0.3029)  labels_encoder_unscaled: 0.3225 (0.5059)  labels_decoder_unscaled: 0.4162 (0.6058)  time: 0.1651  data: 0.0003  max mem: 2769
Epoch: [1]  [ 300/1412]  eta: 0:03:36  lr: 0.000100  loss: 0.5115 (0.7666)  labels_encoder: 0.3271 (0.4783)  labels_decoder: 0.2047 (0.2884)  labels_encoder_unscaled: 0.3271 (0.4783)  labels_decoder_unscaled: 0.4095 (0.5767)  time: 0.1669  data: 0.0003  max mem: 2769
Epoch: [1]  [ 350/1412]  eta: 0:03:22  lr: 0.000100  loss: 0.5241 (0.7312)  labels_encoder: 0.3178 (0.4545)  labels_decoder: 0.2149 (0.2767)  labels_encoder_unscaled: 0.3178 (0.4545)  labels_decoder_unscaled: 0.4299 (0.5535)  time: 0.1665  data: 0.0005  max mem: 2769
Epoch: [1]  [ 400/1412]  eta: 0:03:10  lr: 0.000100  loss: 0.5107 (0.7056)  labels_encoder: 0.3006 (0.4373)  labels_decoder: 0.2101 (0.2683)  labels_encoder_unscaled: 0.3006 (0.4373)  labels_decoder_unscaled: 0.4202 (0.5367)  time: 0.1718  data: 0.0003  max mem: 2769
Epoch: [1]  [ 450/1412]  eta: 0:02:59  lr: 0.000100  loss: 0.4838 (0.6810)  labels_encoder: 0.2763 (0.4205)  labels_decoder: 0.1820 (0.2605)  labels_encoder_unscaled: 0.2763 (0.4205)  labels_decoder_unscaled: 0.3641 (0.5210)  time: 0.1813  data: 0.0003  max mem: 2769
Epoch: [1]  [ 500/1412]  eta: 0:02:47  lr: 0.000100  loss: 0.4467 (0.6591)  labels_encoder: 0.2409 (0.4053)  labels_decoder: 0.1887 (0.2538)  labels_encoder_unscaled: 0.2409 (0.4053)  labels_decoder_unscaled: 0.3774 (0.5076)  time: 0.1594  data: 0.0003  max mem: 2769
Epoch: [1]  [ 550/1412]  eta: 0:02:37  lr: 0.000100  loss: 0.4301 (0.6421)  labels_encoder: 0.2468 (0.3937)  labels_decoder: 0.1893 (0.2484)  labels_encoder_unscaled: 0.2468 (0.3937)  labels_decoder_unscaled: 0.3786 (0.4968)  time: 0.1703  data: 0.0003  max mem: 2769
Epoch: [1]  [ 600/1412]  eta: 0:02:27  lr: 0.000100  loss: 0.4313 (0.6263)  labels_encoder: 0.2383 (0.3830)  labels_decoder: 0.1797 (0.2434)  labels_encoder_unscaled: 0.2383 (0.3830)  labels_decoder_unscaled: 0.3594 (0.4868)  time: 0.1585  data: 0.0003  max mem: 2769
Epoch: [1]  [ 650/1412]  eta: 0:02:17  lr: 0.000100  loss: 0.4313 (0.6124)  labels_encoder: 0.2471 (0.3734)  labels_decoder: 0.1944 (0.2390)  labels_encoder_unscaled: 0.2471 (0.3734)  labels_decoder_unscaled: 0.3889 (0.4781)  time: 0.1672  data: 0.0003  max mem: 2769
Epoch: [1]  [ 700/1412]  eta: 0:02:08  lr: 0.000100  loss: 0.4014 (0.5991)  labels_encoder: 0.2302 (0.3647)  labels_decoder: 0.1664 (0.2344)  labels_encoder_unscaled: 0.2302 (0.3647)  labels_decoder_unscaled: 0.3328 (0.4688)  time: 0.1737  data: 0.0003  max mem: 2769
Epoch: [1]  [ 750/1412]  eta: 0:01:59  lr: 0.000100  loss: 0.4223 (0.5881)  labels_encoder: 0.2446 (0.3573)  labels_decoder: 0.1834 (0.2308)  labels_encoder_unscaled: 0.2446 (0.3573)  labels_decoder_unscaled: 0.3667 (0.4616)  time: 0.1830  data: 0.0003  max mem: 2769
Epoch: [1]  [ 800/1412]  eta: 0:01:49  lr: 0.000100  loss: 0.4054 (0.5772)  labels_encoder: 0.2234 (0.3500)  labels_decoder: 0.1772 (0.2273)  labels_encoder_unscaled: 0.2234 (0.3500)  labels_decoder_unscaled: 0.3544 (0.4546)  time: 0.1769  data: 0.0003  max mem: 2769
Epoch: [1]  [ 850/1412]  eta: 0:01:40  lr: 0.000100  loss: 0.4193 (0.5668)  labels_encoder: 0.2125 (0.3431)  labels_decoder: 0.1647 (0.2237)  labels_encoder_unscaled: 0.2125 (0.3431)  labels_decoder_unscaled: 0.3295 (0.4474)  time: 0.1735  data: 0.0003  max mem: 2769
Epoch: [1]  [ 900/1412]  eta: 0:01:31  lr: 0.000100  loss: 0.3715 (0.5584)  labels_encoder: 0.2093 (0.3372)  labels_decoder: 0.1728 (0.2212)  labels_encoder_unscaled: 0.2093 (0.3372)  labels_decoder_unscaled: 0.3456 (0.4423)  time: 0.1777  data: 0.0003  max mem: 2769
Epoch: [1]  [ 950/1412]  eta: 0:01:22  lr: 0.000100  loss: 0.3654 (0.5495)  labels_encoder: 0.2095 (0.3310)  labels_decoder: 0.1575 (0.2185)  labels_encoder_unscaled: 0.2095 (0.3310)  labels_decoder_unscaled: 0.3150 (0.4370)  time: 0.1700  data: 0.0003  max mem: 2769
Epoch: [1]  [1000/1412]  eta: 0:01:13  lr: 0.000100  loss: 0.3706 (0.5412)  labels_encoder: 0.1864 (0.3253)  labels_decoder: 0.1664 (0.2159)  labels_encoder_unscaled: 0.1864 (0.3253)  labels_decoder_unscaled: 0.3327 (0.4318)  time: 0.1788  data: 0.0003  max mem: 2769
Epoch: [1]  [1050/1412]  eta: 0:01:04  lr: 0.000100  loss: 0.3812 (0.5341)  labels_encoder: 0.2207 (0.3206)  labels_decoder: 0.1659 (0.2135)  labels_encoder_unscaled: 0.2207 (0.3206)  labels_decoder_unscaled: 0.3319 (0.4271)  time: 0.1757  data: 0.0004  max mem: 2769
Epoch: [1]  [1100/1412]  eta: 0:00:55  lr: 0.000100  loss: 0.3699 (0.5267)  labels_encoder: 0.2137 (0.3154)  labels_decoder: 0.1562 (0.2113)  labels_encoder_unscaled: 0.2137 (0.3154)  labels_decoder_unscaled: 0.3123 (0.4226)  time: 0.1771  data: 0.0003  max mem: 2769
Epoch: [1]  [1150/1412]  eta: 0:00:46  lr: 0.000100  loss: 0.3963 (0.5209)  labels_encoder: 0.2263 (0.3115)  labels_decoder: 0.1764 (0.2094)  labels_encoder_unscaled: 0.2263 (0.3115)  labels_decoder_unscaled: 0.3529 (0.4188)  time: 0.1775  data: 0.0003  max mem: 2769
Epoch: [1]  [1200/1412]  eta: 0:00:37  lr: 0.000100  loss: 0.3936 (0.5147)  labels_encoder: 0.2394 (0.3073)  labels_decoder: 0.1633 (0.2074)  labels_encoder_unscaled: 0.2394 (0.3073)  labels_decoder_unscaled: 0.3266 (0.4149)  time: 0.1586  data: 0.0003  max mem: 2769
Epoch: [1]  [1250/1412]  eta: 0:00:28  lr: 0.000100  loss: 0.3950 (0.5095)  labels_encoder: 0.2273 (0.3038)  labels_decoder: 0.1685 (0.2057)  labels_encoder_unscaled: 0.2273 (0.3038)  labels_decoder_unscaled: 0.3370 (0.4115)  time: 0.1636  data: 0.0003  max mem: 2769
Epoch: [1]  [1300/1412]  eta: 0:00:19  lr: 0.000100  loss: 0.3561 (0.5037)  labels_encoder: 0.1966 (0.2997)  labels_decoder: 0.1595 (0.2040)  labels_encoder_unscaled: 0.1966 (0.2997)  labels_decoder_unscaled: 0.3190 (0.4080)  time: 0.1718  data: 0.0003  max mem: 2769
Epoch: [1]  [1350/1412]  eta: 0:00:10  lr: 0.000100  loss: 0.3844 (0.4987)  labels_encoder: 0.2192 (0.2965)  labels_decoder: 0.1614 (0.2021)  labels_encoder_unscaled: 0.2192 (0.2965)  labels_decoder_unscaled: 0.3227 (0.4043)  time: 0.1708  data: 0.0003  max mem: 2769
Epoch: [1]  [1400/1412]  eta: 0:00:02  lr: 0.000100  loss: 0.3589 (0.4943)  labels_encoder: 0.1997 (0.2936)  labels_decoder: 0.1588 (0.2007)  labels_encoder_unscaled: 0.1997 (0.2936)  labels_decoder_unscaled: 0.3176 (0.4014)  time: 0.1639  data: 0.0005  max mem: 2769
Epoch: [1]  [1411/1412]  eta: 0:00:00  lr: 0.000100  loss: 0.3485 (0.4931)  labels_encoder: 0.1965 (0.2928)  labels_decoder: 0.1545 (0.2003)  labels_encoder_unscaled: 0.1965 (0.2928)  labels_decoder_unscaled: 0.3090 (0.4007)  time: 0.1361  data: 0.0004  max mem: 2769
Epoch: [1] Total time: 0:04:09 (0.1765 s / it)
Averaged stats: lr: 0.000100  loss: 0.3485 (0.4931)  labels_encoder: 0.1965 (0.2928)  labels_decoder: 0.1545 (0.2003)  labels_encoder_unscaled: 0.1965 (0.2928)  labels_decoder_unscaled: 0.3090 (0.4007)
Test:  [   0/1613]  eta: 1:42:16  loss: 0.2969 (0.2969)  labels_encoder: 0.1172 (0.1172)  labels_decoder: 0.1796 (0.1796)  labels_encoder_unscaled: 0.1172 (0.1172)  labels_decoder_unscaled: 0.3592 (0.3592)  time: 3.8042  data: 3.7431  max mem: 2769
Test:  [  50/1613]  eta: 0:05:06  loss: 0.6228 (0.8631)  labels_encoder: 0.3969 (0.5466)  labels_decoder: 0.2450 (0.3165)  labels_encoder_unscaled: 0.3969 (0.5466)  labels_decoder_unscaled: 0.4899 (0.6329)  time: 0.1201  data: 0.0146  max mem: 2769
Test:  [ 100/1613]  eta: 0:03:59  loss: 0.4428 (0.7268)  labels_encoder: 0.2149 (0.4536)  labels_decoder: 0.1876 (0.2732)  labels_encoder_unscaled: 0.2149 (0.4536)  labels_decoder_unscaled: 0.3752 (0.5465)  time: 0.1198  data: 0.0002  max mem: 2769
Test:  [ 150/1613]  eta: 0:03:31  loss: 0.5949 (0.7003)  labels_encoder: 0.4669 (0.4364)  labels_decoder: 0.2148 (0.2639)  labels_encoder_unscaled: 0.4669 (0.4364)  labels_decoder_unscaled: 0.4297 (0.5278)  time: 0.1151  data: 0.0003  max mem: 2769
Test:  [ 200/1613]  eta: 0:03:17  loss: 0.9485 (0.8353)  labels_encoder: 0.5980 (0.5246)  labels_decoder: 0.3730 (0.3106)  labels_encoder_unscaled: 0.5980 (0.5246)  labels_decoder_unscaled: 0.7460 (0.6213)  time: 0.1165  data: 0.0006  max mem: 2769
Test:  [ 250/1613]  eta: 0:03:06  loss: 0.3965 (0.8463)  labels_encoder: 0.2532 (0.5274)  labels_decoder: 0.2448 (0.3189)  labels_encoder_unscaled: 0.2532 (0.5274)  labels_decoder_unscaled: 0.4897 (0.6378)  time: 0.1298  data: 0.0003  max mem: 2769
Test:  [ 300/1613]  eta: 0:02:55  loss: 1.0316 (0.8997)  labels_encoder: 0.5469 (0.5537)  labels_decoder: 0.5522 (0.3459)  labels_encoder_unscaled: 0.5469 (0.5537)  labels_decoder_unscaled: 1.1044 (0.6919)  time: 0.1064  data: 0.0025  max mem: 2769
Test:  [ 350/1613]  eta: 0:02:45  loss: 0.9385 (0.9356)  labels_encoder: 0.5730 (0.5800)  labels_decoder: 0.3742 (0.3556)  labels_encoder_unscaled: 0.5730 (0.5800)  labels_decoder_unscaled: 0.7484 (0.7112)  time: 0.1165  data: 0.0036  max mem: 2769
Test:  [ 400/1613]  eta: 0:02:36  loss: 0.7316 (0.9705)  labels_encoder: 0.3736 (0.6040)  labels_decoder: 0.3101 (0.3666)  labels_encoder_unscaled: 0.3736 (0.6040)  labels_decoder_unscaled: 0.6202 (0.7331)  time: 0.1298  data: 0.0604  max mem: 2769
Test:  [ 450/1613]  eta: 0:02:28  loss: 0.9624 (1.0811)  labels_encoder: 0.6218 (0.6804)  labels_decoder: 0.4003 (0.4007)  labels_encoder_unscaled: 0.6218 (0.6804)  labels_decoder_unscaled: 0.8005 (0.8015)  time: 0.1099  data: 0.0231  max mem: 2769
Test:  [ 500/1613]  eta: 0:02:20  loss: 0.6354 (1.0428)  labels_encoder: 0.3133 (0.6561)  labels_decoder: 0.2188 (0.3867)  labels_encoder_unscaled: 0.3133 (0.6561)  labels_decoder_unscaled: 0.4375 (0.7735)  time: 0.1148  data: 0.0374  max mem: 2769
Test:  [ 550/1613]  eta: 0:02:13  loss: 0.5939 (1.0237)  labels_encoder: 0.3335 (0.6454)  labels_decoder: 0.2022 (0.3783)  labels_encoder_unscaled: 0.3335 (0.6454)  labels_decoder_unscaled: 0.4045 (0.7565)  time: 0.1153  data: 0.0393  max mem: 2769
Test:  [ 600/1613]  eta: 0:02:05  loss: 0.5226 (1.0628)  labels_encoder: 0.2811 (0.6735)  labels_decoder: 0.2476 (0.3893)  labels_encoder_unscaled: 0.2811 (0.6735)  labels_decoder_unscaled: 0.4952 (0.7787)  time: 0.1126  data: 0.0296  max mem: 2769
Test:  [ 650/1613]  eta: 0:01:59  loss: 1.0402 (1.0578)  labels_encoder: 0.6193 (0.6711)  labels_decoder: 0.4062 (0.3866)  labels_encoder_unscaled: 0.6193 (0.6711)  labels_decoder_unscaled: 0.8123 (0.7732)  time: 0.1243  data: 0.0521  max mem: 2769
Test:  [ 700/1613]  eta: 0:01:52  loss: 0.4095 (1.0369)  labels_encoder: 0.2850 (0.6584)  labels_decoder: 0.1716 (0.3785)  labels_encoder_unscaled: 0.2850 (0.6584)  labels_decoder_unscaled: 0.3432 (0.7571)  time: 0.1225  data: 0.0403  max mem: 2769
Test:  [ 750/1613]  eta: 0:01:45  loss: 0.5768 (1.0099)  labels_encoder: 0.3386 (0.6408)  labels_decoder: 0.2046 (0.3692)  labels_encoder_unscaled: 0.3386 (0.6408)  labels_decoder_unscaled: 0.4091 (0.7383)  time: 0.1038  data: 0.0186  max mem: 2769
Test:  [ 800/1613]  eta: 0:01:38  loss: 0.6211 (1.0140)  labels_encoder: 0.3205 (0.6423)  labels_decoder: 0.3223 (0.3717)  labels_encoder_unscaled: 0.3205 (0.6423)  labels_decoder_unscaled: 0.6446 (0.7434)  time: 0.1131  data: 0.0363  max mem: 2769
Test:  [ 850/1613]  eta: 0:01:32  loss: 1.1376 (1.0142)  labels_encoder: 0.5344 (0.6409)  labels_decoder: 0.4275 (0.3734)  labels_encoder_unscaled: 0.5344 (0.6409)  labels_decoder_unscaled: 0.8551 (0.7467)  time: 0.1112  data: 0.0109  max mem: 2769
Test:  [ 900/1613]  eta: 0:01:26  loss: 0.5426 (0.9984)  labels_encoder: 0.2730 (0.6292)  labels_decoder: 0.3202 (0.3692)  labels_encoder_unscaled: 0.2730 (0.6292)  labels_decoder_unscaled: 0.6403 (0.7384)  time: 0.1279  data: 0.0272  max mem: 2769
Test:  [ 950/1613]  eta: 0:01:19  loss: 1.0608 (1.0035)  labels_encoder: 0.7030 (0.6328)  labels_decoder: 0.3508 (0.3706)  labels_encoder_unscaled: 0.7030 (0.6328)  labels_decoder_unscaled: 0.7015 (0.7413)  time: 0.1104  data: 0.0052  max mem: 2769
Test:  [1000/1613]  eta: 0:01:13  loss: 0.8142 (0.9913)  labels_encoder: 0.5069 (0.6245)  labels_decoder: 0.4031 (0.3669)  labels_encoder_unscaled: 0.5069 (0.6245)  labels_decoder_unscaled: 0.8062 (0.7337)  time: 0.1025  data: 0.0002  max mem: 2769
Test:  [1050/1613]  eta: 0:01:07  loss: 1.0337 (0.9969)  labels_encoder: 0.7280 (0.6299)  labels_decoder: 0.3449 (0.3670)  labels_encoder_unscaled: 0.7280 (0.6299)  labels_decoder_unscaled: 0.6898 (0.7340)  time: 0.1113  data: 0.0114  max mem: 2769
Test:  [1100/1613]  eta: 0:01:01  loss: 0.8030 (1.0160)  labels_encoder: 0.4409 (0.6438)  labels_decoder: 0.3879 (0.3722)  labels_encoder_unscaled: 0.4409 (0.6438)  labels_decoder_unscaled: 0.7759 (0.7444)  time: 0.1129  data: 0.0187  max mem: 2769
Test:  [1150/1613]  eta: 0:00:55  loss: 0.5288 (1.0059)  labels_encoder: 0.3289 (0.6349)  labels_decoder: 0.2051 (0.3709)  labels_encoder_unscaled: 0.3289 (0.6349)  labels_decoder_unscaled: 0.4102 (0.7419)  time: 0.1201  data: 0.0023  max mem: 2769
Test:  [1200/1613]  eta: 0:00:49  loss: 0.4554 (1.0150)  labels_encoder: 0.2653 (0.6419)  labels_decoder: 0.2004 (0.3731)  labels_encoder_unscaled: 0.2653 (0.6419)  labels_decoder_unscaled: 0.4007 (0.7461)  time: 0.1224  data: 0.0238  max mem: 2769
Test:  [1250/1613]  eta: 0:00:43  loss: 0.6315 (1.0153)  labels_encoder: 0.3274 (0.6419)  labels_decoder: 0.2671 (0.3734)  labels_encoder_unscaled: 0.3274 (0.6419)  labels_decoder_unscaled: 0.5341 (0.7469)  time: 0.1198  data: 0.0111  max mem: 2769
Test:  [1300/1613]  eta: 0:00:37  loss: 0.8118 (1.0123)  labels_encoder: 0.4760 (0.6385)  labels_decoder: 0.3480 (0.3738)  labels_encoder_unscaled: 0.4760 (0.6385)  labels_decoder_unscaled: 0.6960 (0.7476)  time: 0.1105  data: 0.0103  max mem: 2769
Test:  [1350/1613]  eta: 0:00:31  loss: 1.2592 (1.0245)  labels_encoder: 0.8160 (0.6483)  labels_decoder: 0.4948 (0.3762)  labels_encoder_unscaled: 0.8160 (0.6483)  labels_decoder_unscaled: 0.9896 (0.7523)  time: 0.1351  data: 0.0075  max mem: 2769
Test:  [1400/1613]  eta: 0:00:25  loss: 0.7262 (1.0220)  labels_encoder: 0.5718 (0.6472)  labels_decoder: 0.2848 (0.3749)  labels_encoder_unscaled: 0.5718 (0.6472)  labels_decoder_unscaled: 0.5696 (0.7497)  time: 0.1009  data: 0.0166  max mem: 2769
Test:  [1450/1613]  eta: 0:00:19  loss: 0.5597 (1.0190)  labels_encoder: 0.2652 (0.6463)  labels_decoder: 0.2944 (0.3727)  labels_encoder_unscaled: 0.2652 (0.6463)  labels_decoder_unscaled: 0.5889 (0.7454)  time: 0.1170  data: 0.0331  max mem: 2769
Test:  [1500/1613]  eta: 0:00:13  loss: 0.6317 (1.0178)  labels_encoder: 0.3769 (0.6477)  labels_decoder: 0.2299 (0.3701)  labels_encoder_unscaled: 0.3769 (0.6477)  labels_decoder_unscaled: 0.4598 (0.7403)  time: 0.1139  data: 0.0037  max mem: 2769
Test:  [1550/1613]  eta: 0:00:07  loss: 0.9988 (1.0235)  labels_encoder: 0.6925 (0.6527)  labels_decoder: 0.3303 (0.3708)  labels_encoder_unscaled: 0.6925 (0.6527)  labels_decoder_unscaled: 0.6607 (0.7415)  time: 0.1087  data: 0.0235  max mem: 2769
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9419 (1.0238)  labels_encoder: 0.4568 (0.6526)  labels_decoder: 0.3723 (0.3711)  labels_encoder_unscaled: 0.4568 (0.6526)  labels_decoder_unscaled: 0.7445 (0.7423)  time: 0.1111  data: 0.0116  max mem: 2769
Test:  [1612/1613]  eta: 0:00:00  loss: 0.6626 (1.0219)  labels_encoder: 0.3957 (0.6516)  labels_decoder: 0.2227 (0.3703)  labels_encoder_unscaled: 0.3957 (0.6516)  labels_decoder_unscaled: 0.4455 (0.7407)  time: 0.1045  data: 0.0228  max mem: 2769
Test: Total time: 0:03:11 (0.1187 s / it)
Averaged stats: loss: 0.6626 (1.0219)  labels_encoder: 0.3957 (0.6516)  labels_decoder: 0.2227 (0.3703)  labels_encoder_unscaled: 0.3957 (0.6516)  labels_decoder_unscaled: 0.4455 (0.7407)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-kin_audio] mAP: 0.6391

dec_mAP all together: | 0.5251346899403213 |.
dec_mAP_pred | 0 : 0.5848428894859575 |.
dec_mAP_pred | 1 : 0.5734872749284328 |.
dec_mAP_pred | 2 : 0.557280920766089 |.
dec_mAP_pred | 3 : 0.5386549218455811 |.
dec_mAP_pred | 4 : 0.518712957826731 |.
dec_mAP_pred | 5 : 0.4994300157175938 |.
dec_mAP_pred | 6 : 0.4811950658929517 |.
dec_mAP_pred | 7 : 0.4635829318036616 |.
all decoder map: | 0.5271 |.
BaseballPitch: 0.4337
BasketballDunk: 0.8057
Billiards: 0.3252
CleanAndJerk: 0.7731
CliffDiving: 0.8718
CricketBowling: 0.4849
CricketShot: 0.3051
Diving: 0.8676
FrisbeeCatch: 0.2498
GolfSwing: 0.7705
HammerThrow: 0.8665
HighJump: 0.7000
JavelinThrow: 0.7355
LongJump: 0.8048
PoleVault: 0.8699
Shotput: 0.7431
SoccerPenalty: 0.4209
TennisSwing: 0.5902
ThrowDiscus: 0.6887
VolleyballSpiking: 0.4743
Epoch: [2]  [   0/1412]  eta: 1:37:14  lr: 0.000010  loss: 0.2697 (0.2697)  labels_encoder: 0.1549 (0.1549)  labels_decoder: 0.1148 (0.1148)  labels_encoder_unscaled: 0.1549 (0.1549)  labels_decoder_unscaled: 0.2296 (0.2296)  time: 4.1322  data: 3.9351  max mem: 2769
Epoch: [2]  [  50/1412]  eta: 0:05:54  lr: 0.000010  loss: 0.2870 (0.2965)  labels_encoder: 0.1504 (0.1599)  labels_decoder: 0.1234 (0.1366)  labels_encoder_unscaled: 0.1504 (0.1599)  labels_decoder_unscaled: 0.2468 (0.2732)  time: 0.1769  data: 0.0003  max mem: 2769
Epoch: [2]  [ 100/1412]  eta: 0:04:43  lr: 0.000010  loss: 0.2719 (0.2900)  labels_encoder: 0.1401 (0.1560)  labels_decoder: 0.1265 (0.1340)  labels_encoder_unscaled: 0.1401 (0.1560)  labels_decoder_unscaled: 0.2530 (0.2680)  time: 0.1691  data: 0.0003  max mem: 2769
Epoch: [2]  [ 150/1412]  eta: 0:04:14  lr: 0.000010  loss: 0.2642 (0.2841)  labels_encoder: 0.1470 (0.1527)  labels_decoder: 0.1232 (0.1314)  labels_encoder_unscaled: 0.1470 (0.1527)  labels_decoder_unscaled: 0.2464 (0.2628)  time: 0.1826  data: 0.0003  max mem: 2769
Epoch: [2]  [ 200/1412]  eta: 0:03:56  lr: 0.000010  loss: 0.2400 (0.2814)  labels_encoder: 0.1291 (0.1516)  labels_decoder: 0.1202 (0.1298)  labels_encoder_unscaled: 0.1291 (0.1516)  labels_decoder_unscaled: 0.2404 (0.2597)  time: 0.1800  data: 0.0002  max mem: 2769
Epoch: [2]  [ 250/1412]  eta: 0:03:39  lr: 0.000010  loss: 0.2779 (0.2817)  labels_encoder: 0.1401 (0.1519)  labels_decoder: 0.1314 (0.1299)  labels_encoder_unscaled: 0.1401 (0.1519)  labels_decoder_unscaled: 0.2628 (0.2597)  time: 0.1631  data: 0.0003  max mem: 2769
Epoch: [2]  [ 300/1412]  eta: 0:03:25  lr: 0.000010  loss: 0.2725 (0.2792)  labels_encoder: 0.1358 (0.1498)  labels_decoder: 0.1249 (0.1294)  labels_encoder_unscaled: 0.1358 (0.1498)  labels_decoder_unscaled: 0.2499 (0.2588)  time: 0.1674  data: 0.0003  max mem: 2769
Epoch: [2]  [ 350/1412]  eta: 0:03:16  lr: 0.000010  loss: 0.2525 (0.2783)  labels_encoder: 0.1294 (0.1494)  labels_decoder: 0.1280 (0.1289)  labels_encoder_unscaled: 0.1294 (0.1494)  labels_decoder_unscaled: 0.2560 (0.2578)  time: 0.1818  data: 0.0003  max mem: 2769
Epoch: [2]  [ 400/1412]  eta: 0:03:05  lr: 0.000010  loss: 0.2790 (0.2765)  labels_encoder: 0.1376 (0.1483)  labels_decoder: 0.1274 (0.1283)  labels_encoder_unscaled: 0.1376 (0.1483)  labels_decoder_unscaled: 0.2548 (0.2566)  time: 0.1710  data: 0.0003  max mem: 2769
Epoch: [2]  [ 450/1412]  eta: 0:02:55  lr: 0.000010  loss: 0.2754 (0.2755)  labels_encoder: 0.1499 (0.1473)  labels_decoder: 0.1299 (0.1282)  labels_encoder_unscaled: 0.1499 (0.1473)  labels_decoder_unscaled: 0.2598 (0.2564)  time: 0.1744  data: 0.0003  max mem: 2769
Epoch: [2]  [ 500/1412]  eta: 0:02:45  lr: 0.000010  loss: 0.2376 (0.2737)  labels_encoder: 0.1266 (0.1461)  labels_decoder: 0.1214 (0.1276)  labels_encoder_unscaled: 0.1266 (0.1461)  labels_decoder_unscaled: 0.2427 (0.2552)  time: 0.1657  data: 0.0002  max mem: 2769
Epoch: [2]  [ 550/1412]  eta: 0:02:35  lr: 0.000010  loss: 0.2449 (0.2720)  labels_encoder: 0.1260 (0.1453)  labels_decoder: 0.1203 (0.1268)  labels_encoder_unscaled: 0.1260 (0.1453)  labels_decoder_unscaled: 0.2407 (0.2536)  time: 0.1634  data: 0.0003  max mem: 2769
Epoch: [2]  [ 600/1412]  eta: 0:02:25  lr: 0.000010  loss: 0.2612 (0.2709)  labels_encoder: 0.1384 (0.1442)  labels_decoder: 0.1189 (0.1267)  labels_encoder_unscaled: 0.1384 (0.1442)  labels_decoder_unscaled: 0.2378 (0.2533)  time: 0.1762  data: 0.0003  max mem: 2769
Epoch: [2]  [ 650/1412]  eta: 0:02:16  lr: 0.000010  loss: 0.2636 (0.2688)  labels_encoder: 0.1358 (0.1429)  labels_decoder: 0.1173 (0.1259)  labels_encoder_unscaled: 0.1358 (0.1429)  labels_decoder_unscaled: 0.2345 (0.2518)  time: 0.1756  data: 0.0003  max mem: 2769
Epoch: [2]  [ 700/1412]  eta: 0:02:07  lr: 0.000010  loss: 0.2447 (0.2678)  labels_encoder: 0.1249 (0.1423)  labels_decoder: 0.1208 (0.1255)  labels_encoder_unscaled: 0.1249 (0.1423)  labels_decoder_unscaled: 0.2416 (0.2511)  time: 0.1755  data: 0.0003  max mem: 2769
Epoch: [2]  [ 750/1412]  eta: 0:01:58  lr: 0.000010  loss: 0.2475 (0.2670)  labels_encoder: 0.1216 (0.1418)  labels_decoder: 0.1146 (0.1252)  labels_encoder_unscaled: 0.1216 (0.1418)  labels_decoder_unscaled: 0.2293 (0.2504)  time: 0.1735  data: 0.0003  max mem: 2769
Epoch: [2]  [ 800/1412]  eta: 0:01:49  lr: 0.000010  loss: 0.2238 (0.2660)  labels_encoder: 0.1119 (0.1412)  labels_decoder: 0.1176 (0.1249)  labels_encoder_unscaled: 0.1119 (0.1412)  labels_decoder_unscaled: 0.2352 (0.2497)  time: 0.1833  data: 0.0003  max mem: 2769
Epoch: [2]  [ 850/1412]  eta: 0:01:40  lr: 0.000010  loss: 0.2576 (0.2648)  labels_encoder: 0.1362 (0.1402)  labels_decoder: 0.1163 (0.1245)  labels_encoder_unscaled: 0.1362 (0.1402)  labels_decoder_unscaled: 0.2326 (0.2491)  time: 0.1741  data: 0.0003  max mem: 2769
Epoch: [2]  [ 900/1412]  eta: 0:01:31  lr: 0.000010  loss: 0.2510 (0.2641)  labels_encoder: 0.1170 (0.1397)  labels_decoder: 0.1135 (0.1244)  labels_encoder_unscaled: 0.1170 (0.1397)  labels_decoder_unscaled: 0.2271 (0.2488)  time: 0.1756  data: 0.0003  max mem: 2769
Epoch: [2]  [ 950/1412]  eta: 0:01:22  lr: 0.000010  loss: 0.2616 (0.2635)  labels_encoder: 0.1468 (0.1394)  labels_decoder: 0.1192 (0.1241)  labels_encoder_unscaled: 0.1468 (0.1394)  labels_decoder_unscaled: 0.2385 (0.2483)  time: 0.1786  data: 0.0003  max mem: 2769
Epoch: [2]  [1000/1412]  eta: 0:01:13  lr: 0.000010  loss: 0.2413 (0.2623)  labels_encoder: 0.1260 (0.1386)  labels_decoder: 0.1095 (0.1237)  labels_encoder_unscaled: 0.1260 (0.1386)  labels_decoder_unscaled: 0.2189 (0.2473)  time: 0.1681  data: 0.0003  max mem: 2769
Epoch: [2]  [1050/1412]  eta: 0:01:04  lr: 0.000010  loss: 0.2422 (0.2617)  labels_encoder: 0.1195 (0.1383)  labels_decoder: 0.1183 (0.1234)  labels_encoder_unscaled: 0.1195 (0.1383)  labels_decoder_unscaled: 0.2366 (0.2469)  time: 0.1726  data: 0.0003  max mem: 2769
Epoch: [2]  [1100/1412]  eta: 0:00:55  lr: 0.000010  loss: 0.2468 (0.2613)  labels_encoder: 0.1336 (0.1381)  labels_decoder: 0.1185 (0.1232)  labels_encoder_unscaled: 0.1336 (0.1381)  labels_decoder_unscaled: 0.2371 (0.2464)  time: 0.1701  data: 0.0003  max mem: 2769
Epoch: [2]  [1150/1412]  eta: 0:00:46  lr: 0.000010  loss: 0.2531 (0.2607)  labels_encoder: 0.1249 (0.1379)  labels_decoder: 0.1167 (0.1229)  labels_encoder_unscaled: 0.1249 (0.1379)  labels_decoder_unscaled: 0.2333 (0.2457)  time: 0.1712  data: 0.0003  max mem: 2769
Epoch: [2]  [1200/1412]  eta: 0:00:37  lr: 0.000010  loss: 0.2385 (0.2602)  labels_encoder: 0.1238 (0.1376)  labels_decoder: 0.1099 (0.1227)  labels_encoder_unscaled: 0.1238 (0.1376)  labels_decoder_unscaled: 0.2197 (0.2453)  time: 0.1782  data: 0.0007  max mem: 2769
Epoch: [2]  [1250/1412]  eta: 0:00:28  lr: 0.000010  loss: 0.2306 (0.2595)  labels_encoder: 0.1179 (0.1371)  labels_decoder: 0.1033 (0.1223)  labels_encoder_unscaled: 0.1179 (0.1371)  labels_decoder_unscaled: 0.2066 (0.2447)  time: 0.1817  data: 0.0003  max mem: 2769
Epoch: [2]  [1300/1412]  eta: 0:00:19  lr: 0.000010  loss: 0.2378 (0.2587)  labels_encoder: 0.1196 (0.1366)  labels_decoder: 0.1217 (0.1221)  labels_encoder_unscaled: 0.1196 (0.1366)  labels_decoder_unscaled: 0.2434 (0.2442)  time: 0.1654  data: 0.0006  max mem: 2769
Epoch: [2]  [1350/1412]  eta: 0:00:10  lr: 0.000010  loss: 0.2558 (0.2584)  labels_encoder: 0.1417 (0.1364)  labels_decoder: 0.1143 (0.1220)  labels_encoder_unscaled: 0.1417 (0.1364)  labels_decoder_unscaled: 0.2287 (0.2439)  time: 0.1749  data: 0.0003  max mem: 2769
Epoch: [2]  [1400/1412]  eta: 0:00:02  lr: 0.000010  loss: 0.2209 (0.2580)  labels_encoder: 0.1174 (0.1363)  labels_decoder: 0.1092 (0.1217)  labels_encoder_unscaled: 0.1174 (0.1363)  labels_decoder_unscaled: 0.2185 (0.2434)  time: 0.1633  data: 0.0004  max mem: 2769
Epoch: [2]  [1411/1412]  eta: 0:00:00  lr: 0.000010  loss: 0.2213 (0.2578)  labels_encoder: 0.1112 (0.1361)  labels_decoder: 0.1106 (0.1217)  labels_encoder_unscaled: 0.1112 (0.1361)  labels_decoder_unscaled: 0.2212 (0.2434)  time: 0.1302  data: 0.0003  max mem: 2769
Epoch: [2] Total time: 0:04:09 (0.1769 s / it)
Averaged stats: lr: 0.000010  loss: 0.2213 (0.2578)  labels_encoder: 0.1112 (0.1361)  labels_decoder: 0.1106 (0.1217)  labels_encoder_unscaled: 0.1112 (0.1361)  labels_decoder_unscaled: 0.2212 (0.2434)
Test:  [   0/1613]  eta: 1:36:39  loss: 0.5486 (0.5486)  labels_encoder: 0.2995 (0.2995)  labels_decoder: 0.2491 (0.2491)  labels_encoder_unscaled: 0.2995 (0.2995)  labels_decoder_unscaled: 0.4983 (0.4983)  time: 3.5952  data: 3.4487  max mem: 2769
Test:  [  50/1613]  eta: 0:04:37  loss: 0.4450 (0.7854)  labels_encoder: 0.2568 (0.4897)  labels_decoder: 0.1913 (0.2956)  labels_encoder_unscaled: 0.2568 (0.4897)  labels_decoder_unscaled: 0.3827 (0.5913)  time: 0.1110  data: 0.0350  max mem: 2769
Test:  [ 100/1613]  eta: 0:03:39  loss: 0.3751 (0.7105)  labels_encoder: 0.2502 (0.4513)  labels_decoder: 0.1776 (0.2591)  labels_encoder_unscaled: 0.2502 (0.4513)  labels_decoder_unscaled: 0.3553 (0.5183)  time: 0.1192  data: 0.0511  max mem: 2769
Test:  [ 150/1613]  eta: 0:03:15  loss: 0.7324 (0.7187)  labels_encoder: 0.5184 (0.4560)  labels_decoder: 0.2224 (0.2627)  labels_encoder_unscaled: 0.5184 (0.4560)  labels_decoder_unscaled: 0.4449 (0.5254)  time: 0.1029  data: 0.0418  max mem: 2769
Test:  [ 200/1613]  eta: 0:03:01  loss: 1.0889 (0.8999)  labels_encoder: 0.6470 (0.5740)  labels_decoder: 0.4179 (0.3258)  labels_encoder_unscaled: 0.6470 (0.5740)  labels_decoder_unscaled: 0.8358 (0.6517)  time: 0.1045  data: 0.0303  max mem: 2769
Test:  [ 250/1613]  eta: 0:02:49  loss: 0.6501 (0.9233)  labels_encoder: 0.2874 (0.5835)  labels_decoder: 0.3455 (0.3398)  labels_encoder_unscaled: 0.2874 (0.5835)  labels_decoder_unscaled: 0.6911 (0.6797)  time: 0.1092  data: 0.0510  max mem: 2769
Test:  [ 300/1613]  eta: 0:02:40  loss: 1.1272 (0.9403)  labels_encoder: 0.6289 (0.5924)  labels_decoder: 0.4266 (0.3479)  labels_encoder_unscaled: 0.6289 (0.5924)  labels_decoder_unscaled: 0.8532 (0.6958)  time: 0.1185  data: 0.0609  max mem: 2769
Test:  [ 350/1613]  eta: 0:02:32  loss: 1.4040 (0.9688)  labels_encoder: 0.7884 (0.6102)  labels_decoder: 0.4872 (0.3586)  labels_encoder_unscaled: 0.7884 (0.6102)  labels_decoder_unscaled: 0.9745 (0.7172)  time: 0.1130  data: 0.0461  max mem: 2769
Test:  [ 400/1613]  eta: 0:02:27  loss: 0.7421 (1.0153)  labels_encoder: 0.4154 (0.6441)  labels_decoder: 0.2891 (0.3712)  labels_encoder_unscaled: 0.4154 (0.6441)  labels_decoder_unscaled: 0.5781 (0.7425)  time: 0.1177  data: 0.0351  max mem: 2769
Test:  [ 450/1613]  eta: 0:02:21  loss: 0.9042 (1.1004)  labels_encoder: 0.5535 (0.7040)  labels_decoder: 0.3269 (0.3963)  labels_encoder_unscaled: 0.5535 (0.7040)  labels_decoder_unscaled: 0.6539 (0.7927)  time: 0.1148  data: 0.0505  max mem: 2769
Test:  [ 500/1613]  eta: 0:02:14  loss: 0.5144 (1.0537)  labels_encoder: 0.2185 (0.6728)  labels_decoder: 0.2320 (0.3809)  labels_encoder_unscaled: 0.2185 (0.6728)  labels_decoder_unscaled: 0.4639 (0.7619)  time: 0.1127  data: 0.0506  max mem: 2769
Test:  [ 550/1613]  eta: 0:02:08  loss: 0.6573 (1.0331)  labels_encoder: 0.4233 (0.6582)  labels_decoder: 0.2125 (0.3749)  labels_encoder_unscaled: 0.4233 (0.6582)  labels_decoder_unscaled: 0.4251 (0.7499)  time: 0.1104  data: 0.0259  max mem: 2769
Test:  [ 600/1613]  eta: 0:02:01  loss: 0.5907 (1.0767)  labels_encoder: 0.2533 (0.6938)  labels_decoder: 0.2924 (0.3829)  labels_encoder_unscaled: 0.2533 (0.6938)  labels_decoder_unscaled: 0.5847 (0.7658)  time: 0.1161  data: 0.0616  max mem: 2769
Test:  [ 650/1613]  eta: 0:01:55  loss: 0.8393 (1.0751)  labels_encoder: 0.4595 (0.6918)  labels_decoder: 0.3822 (0.3832)  labels_encoder_unscaled: 0.4595 (0.6918)  labels_decoder_unscaled: 0.7645 (0.7665)  time: 0.1143  data: 0.0516  max mem: 2769
Test:  [ 700/1613]  eta: 0:01:49  loss: 0.5334 (1.0518)  labels_encoder: 0.3175 (0.6763)  labels_decoder: 0.1828 (0.3755)  labels_encoder_unscaled: 0.3175 (0.6763)  labels_decoder_unscaled: 0.3656 (0.7510)  time: 0.1155  data: 0.0173  max mem: 2769
Test:  [ 750/1613]  eta: 0:01:42  loss: 0.7782 (1.0294)  labels_encoder: 0.3827 (0.6604)  labels_decoder: 0.2636 (0.3690)  labels_encoder_unscaled: 0.3827 (0.6604)  labels_decoder_unscaled: 0.5272 (0.7380)  time: 0.1165  data: 0.0368  max mem: 2769
Test:  [ 800/1613]  eta: 0:01:36  loss: 0.7167 (1.0259)  labels_encoder: 0.3567 (0.6580)  labels_decoder: 0.2706 (0.3679)  labels_encoder_unscaled: 0.3567 (0.6580)  labels_decoder_unscaled: 0.5413 (0.7358)  time: 0.1055  data: 0.0309  max mem: 2769
Test:  [ 850/1613]  eta: 0:01:30  loss: 1.0542 (1.0271)  labels_encoder: 0.6348 (0.6557)  labels_decoder: 0.4194 (0.3714)  labels_encoder_unscaled: 0.6348 (0.6557)  labels_decoder_unscaled: 0.8389 (0.7429)  time: 0.1063  data: 0.0341  max mem: 2769
Test:  [ 900/1613]  eta: 0:01:24  loss: 0.5267 (1.0053)  labels_encoder: 0.2570 (0.6392)  labels_decoder: 0.2697 (0.3660)  labels_encoder_unscaled: 0.2570 (0.6392)  labels_decoder_unscaled: 0.5394 (0.7320)  time: 0.1084  data: 0.0358  max mem: 2769
Test:  [ 950/1613]  eta: 0:01:17  loss: 1.0656 (1.0085)  labels_encoder: 0.6739 (0.6392)  labels_decoder: 0.3428 (0.3692)  labels_encoder_unscaled: 0.6739 (0.6392)  labels_decoder_unscaled: 0.6857 (0.7385)  time: 0.1121  data: 0.0072  max mem: 2769
Test:  [1000/1613]  eta: 0:01:11  loss: 0.9270 (0.9978)  labels_encoder: 0.5536 (0.6312)  labels_decoder: 0.3162 (0.3666)  labels_encoder_unscaled: 0.5536 (0.6312)  labels_decoder_unscaled: 0.6324 (0.7332)  time: 0.1085  data: 0.0167  max mem: 2769
Test:  [1050/1613]  eta: 0:01:05  loss: 0.9991 (1.0063)  labels_encoder: 0.6315 (0.6383)  labels_decoder: 0.3698 (0.3681)  labels_encoder_unscaled: 0.6315 (0.6383)  labels_decoder_unscaled: 0.7396 (0.7361)  time: 0.1221  data: 0.0291  max mem: 2769
Test:  [1100/1613]  eta: 0:00:59  loss: 0.5394 (1.0065)  labels_encoder: 0.2551 (0.6392)  labels_decoder: 0.2818 (0.3673)  labels_encoder_unscaled: 0.2551 (0.6392)  labels_decoder_unscaled: 0.5636 (0.7346)  time: 0.1186  data: 0.0353  max mem: 2769
Test:  [1150/1613]  eta: 0:00:54  loss: 0.4262 (1.0007)  labels_encoder: 0.2580 (0.6349)  labels_decoder: 0.2362 (0.3658)  labels_encoder_unscaled: 0.2580 (0.6349)  labels_decoder_unscaled: 0.4725 (0.7316)  time: 0.1198  data: 0.0150  max mem: 2769
Test:  [1200/1613]  eta: 0:00:48  loss: 0.4703 (1.0066)  labels_encoder: 0.2687 (0.6389)  labels_decoder: 0.2025 (0.3677)  labels_encoder_unscaled: 0.2687 (0.6389)  labels_decoder_unscaled: 0.4051 (0.7354)  time: 0.1112  data: 0.0286  max mem: 2769
Test:  [1250/1613]  eta: 0:00:42  loss: 0.5687 (1.0063)  labels_encoder: 0.2948 (0.6386)  labels_decoder: 0.2643 (0.3677)  labels_encoder_unscaled: 0.2948 (0.6386)  labels_decoder_unscaled: 0.5286 (0.7354)  time: 0.1081  data: 0.0166  max mem: 2769
Test:  [1300/1613]  eta: 0:00:36  loss: 0.5820 (1.0015)  labels_encoder: 0.3376 (0.6350)  labels_decoder: 0.2543 (0.3665)  labels_encoder_unscaled: 0.3376 (0.6350)  labels_decoder_unscaled: 0.5086 (0.7331)  time: 0.1213  data: 0.0555  max mem: 2769
Test:  [1350/1613]  eta: 0:00:30  loss: 1.1143 (1.0064)  labels_encoder: 0.7238 (0.6397)  labels_decoder: 0.3746 (0.3666)  labels_encoder_unscaled: 0.7238 (0.6397)  labels_decoder_unscaled: 0.7492 (0.7332)  time: 0.1065  data: 0.0002  max mem: 2769
Test:  [1400/1613]  eta: 0:00:24  loss: 0.8294 (1.0105)  labels_encoder: 0.5393 (0.6429)  labels_decoder: 0.3050 (0.3676)  labels_encoder_unscaled: 0.5393 (0.6429)  labels_decoder_unscaled: 0.6101 (0.7353)  time: 0.1090  data: 0.0092  max mem: 2769
Test:  [1450/1613]  eta: 0:00:18  loss: 0.5992 (1.0127)  labels_encoder: 0.3479 (0.6440)  labels_decoder: 0.2951 (0.3687)  labels_encoder_unscaled: 0.3479 (0.6440)  labels_decoder_unscaled: 0.5902 (0.7374)  time: 0.1159  data: 0.0242  max mem: 2769
Test:  [1500/1613]  eta: 0:00:13  loss: 0.5741 (1.0114)  labels_encoder: 0.3587 (0.6438)  labels_decoder: 0.2221 (0.3676)  labels_encoder_unscaled: 0.3587 (0.6438)  labels_decoder_unscaled: 0.4443 (0.7352)  time: 0.1024  data: 0.0222  max mem: 2769
Test:  [1550/1613]  eta: 0:00:07  loss: 0.8832 (1.0110)  labels_encoder: 0.5670 (0.6440)  labels_decoder: 0.3252 (0.3670)  labels_encoder_unscaled: 0.5670 (0.6440)  labels_decoder_unscaled: 0.6504 (0.7340)  time: 0.1161  data: 0.0429  max mem: 2769
Test:  [1600/1613]  eta: 0:00:01  loss: 0.7260 (1.0114)  labels_encoder: 0.4425 (0.6436)  labels_decoder: 0.3321 (0.3678)  labels_encoder_unscaled: 0.4425 (0.6436)  labels_decoder_unscaled: 0.6643 (0.7356)  time: 0.1236  data: 0.0387  max mem: 2769
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5284 (1.0092)  labels_encoder: 0.2752 (0.6424)  labels_decoder: 0.2166 (0.3669)  labels_encoder_unscaled: 0.2752 (0.6424)  labels_decoder_unscaled: 0.4331 (0.7337)  time: 0.0988  data: 0.0199  max mem: 2769
Test: Total time: 0:03:07 (0.1163 s / it)
Averaged stats: loss: 0.5284 (1.0092)  labels_encoder: 0.2752 (0.6424)  labels_decoder: 0.2166 (0.3669)  labels_encoder_unscaled: 0.2752 (0.6424)  labels_decoder_unscaled: 0.4331 (0.7337)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-kin_audio] mAP: 0.6428

dec_mAP all together: | 0.5085171625010381 |.
dec_mAP_pred | 0 : 0.5585449610923364 |.
dec_mAP_pred | 1 : 0.5500392622806463 |.
dec_mAP_pred | 2 : 0.5362773990185119 |.
dec_mAP_pred | 3 : 0.5201935390475526 |.
dec_mAP_pred | 4 : 0.5028951451084476 |.
dec_mAP_pred | 5 : 0.48618811523159866 |.
dec_mAP_pred | 6 : 0.4699348230504894 |.
dec_mAP_pred | 7 : 0.4541998403372546 |.
all decoder map: | 0.5098 |.
BaseballPitch: 0.3516
BasketballDunk: 0.8045
Billiards: 0.3447
CleanAndJerk: 0.7473
CliffDiving: 0.8649
CricketBowling: 0.4918
CricketShot: 0.2990
Diving: 0.8692
FrisbeeCatch: 0.3128
GolfSwing: 0.7640
HammerThrow: 0.8576
HighJump: 0.7946
JavelinThrow: 0.7355
LongJump: 0.7926
PoleVault: 0.8783
Shotput: 0.7576
SoccerPenalty: 0.4047
TennisSwing: 0.5925
ThrowDiscus: 0.7037
VolleyballSpiking: 0.4900
Epoch: [3]  [   0/1412]  eta: 1:43:38  lr: 0.000001  loss: 0.2143 (0.2143)  labels_encoder: 0.0935 (0.0935)  labels_decoder: 0.1208 (0.1208)  labels_encoder_unscaled: 0.0935 (0.0935)  labels_decoder_unscaled: 0.2416 (0.2416)  time: 4.4043  data: 4.1964  max mem: 2769
Epoch: [3]  [  50/1412]  eta: 0:05:48  lr: 0.000001  loss: 0.2364 (0.2265)  labels_encoder: 0.1165 (0.1158)  labels_decoder: 0.1138 (0.1107)  labels_encoder_unscaled: 0.1165 (0.1158)  labels_decoder_unscaled: 0.2277 (0.2214)  time: 0.1724  data: 0.0003  max mem: 2769
Epoch: [3]  [ 100/1412]  eta: 0:04:37  lr: 0.000001  loss: 0.2060 (0.2278)  labels_encoder: 0.0993 (0.1152)  labels_decoder: 0.1145 (0.1126)  labels_encoder_unscaled: 0.0993 (0.1152)  labels_decoder_unscaled: 0.2291 (0.2251)  time: 0.1717  data: 0.0003  max mem: 2769
Epoch: [3]  [ 150/1412]  eta: 0:04:09  lr: 0.000001  loss: 0.2067 (0.2268)  labels_encoder: 0.0972 (0.1142)  labels_decoder: 0.1126 (0.1126)  labels_encoder_unscaled: 0.0972 (0.1142)  labels_decoder_unscaled: 0.2252 (0.2252)  time: 0.1665  data: 0.0004  max mem: 2769
Epoch: [3]  [ 200/1412]  eta: 0:03:49  lr: 0.000001  loss: 0.2244 (0.2277)  labels_encoder: 0.0950 (0.1147)  labels_decoder: 0.1114 (0.1131)  labels_encoder_unscaled: 0.0950 (0.1147)  labels_decoder_unscaled: 0.2228 (0.2261)  time: 0.1639  data: 0.0005  max mem: 2769
Epoch: [3]  [ 250/1412]  eta: 0:03:35  lr: 0.000001  loss: 0.2172 (0.2263)  labels_encoder: 0.1092 (0.1138)  labels_decoder: 0.1125 (0.1125)  labels_encoder_unscaled: 0.1092 (0.1138)  labels_decoder_unscaled: 0.2251 (0.2251)  time: 0.1764  data: 0.0043  max mem: 2769
Epoch: [3]  [ 300/1412]  eta: 0:03:22  lr: 0.000001  loss: 0.1965 (0.2261)  labels_encoder: 0.0995 (0.1138)  labels_decoder: 0.1002 (0.1123)  labels_encoder_unscaled: 0.0995 (0.1138)  labels_decoder_unscaled: 0.2004 (0.2246)  time: 0.1642  data: 0.0003  max mem: 2769
Epoch: [3]  [ 350/1412]  eta: 0:03:11  lr: 0.000001  loss: 0.2171 (0.2256)  labels_encoder: 0.1041 (0.1140)  labels_decoder: 0.0975 (0.1116)  labels_encoder_unscaled: 0.1041 (0.1140)  labels_decoder_unscaled: 0.1950 (0.2233)  time: 0.1754  data: 0.0003  max mem: 2769
Epoch: [3]  [ 400/1412]  eta: 0:03:01  lr: 0.000001  loss: 0.2137 (0.2263)  labels_encoder: 0.1089 (0.1149)  labels_decoder: 0.1124 (0.1113)  labels_encoder_unscaled: 0.1089 (0.1149)  labels_decoder_unscaled: 0.2248 (0.2227)  time: 0.1693  data: 0.0003  max mem: 2769
Epoch: [3]  [ 450/1412]  eta: 0:02:52  lr: 0.000001  loss: 0.2242 (0.2257)  labels_encoder: 0.1182 (0.1146)  labels_decoder: 0.1131 (0.1110)  labels_encoder_unscaled: 0.1182 (0.1146)  labels_decoder_unscaled: 0.2261 (0.2221)  time: 0.1772  data: 0.0003  max mem: 2769
Epoch: [3]  [ 500/1412]  eta: 0:02:42  lr: 0.000001  loss: 0.2153 (0.2264)  labels_encoder: 0.1042 (0.1155)  labels_decoder: 0.0997 (0.1109)  labels_encoder_unscaled: 0.1042 (0.1155)  labels_decoder_unscaled: 0.1994 (0.2218)  time: 0.1664  data: 0.0003  max mem: 2769
Epoch: [3]  [ 550/1412]  eta: 0:02:33  lr: 0.000001  loss: 0.2375 (0.2278)  labels_encoder: 0.1178 (0.1165)  labels_decoder: 0.1077 (0.1113)  labels_encoder_unscaled: 0.1178 (0.1165)  labels_decoder_unscaled: 0.2154 (0.2226)  time: 0.1673  data: 0.0003  max mem: 2769
Epoch: [3]  [ 600/1412]  eta: 0:02:23  lr: 0.000001  loss: 0.2130 (0.2278)  labels_encoder: 0.0975 (0.1164)  labels_decoder: 0.1187 (0.1114)  labels_encoder_unscaled: 0.0975 (0.1164)  labels_decoder_unscaled: 0.2373 (0.2228)  time: 0.1654  data: 0.0003  max mem: 2769
Epoch: [3]  [ 650/1412]  eta: 0:02:14  lr: 0.000001  loss: 0.2322 (0.2278)  labels_encoder: 0.1066 (0.1162)  labels_decoder: 0.1125 (0.1115)  labels_encoder_unscaled: 0.1066 (0.1162)  labels_decoder_unscaled: 0.2249 (0.2231)  time: 0.1581  data: 0.0002  max mem: 2769
Epoch: [3]  [ 700/1412]  eta: 0:02:04  lr: 0.000001  loss: 0.2394 (0.2277)  labels_encoder: 0.1136 (0.1162)  labels_decoder: 0.1101 (0.1115)  labels_encoder_unscaled: 0.1136 (0.1162)  labels_decoder_unscaled: 0.2202 (0.2230)  time: 0.1677  data: 0.0004  max mem: 2769
Epoch: [3]  [ 750/1412]  eta: 0:01:55  lr: 0.000001  loss: 0.2255 (0.2278)  labels_encoder: 0.1030 (0.1161)  labels_decoder: 0.1048 (0.1117)  labels_encoder_unscaled: 0.1030 (0.1161)  labels_decoder_unscaled: 0.2096 (0.2234)  time: 0.1708  data: 0.0003  max mem: 2769
Epoch: [3]  [ 800/1412]  eta: 0:01:47  lr: 0.000001  loss: 0.2195 (0.2278)  labels_encoder: 0.1123 (0.1161)  labels_decoder: 0.1038 (0.1117)  labels_encoder_unscaled: 0.1123 (0.1161)  labels_decoder_unscaled: 0.2076 (0.2233)  time: 0.1776  data: 0.0003  max mem: 2769
Epoch: [3]  [ 850/1412]  eta: 0:01:38  lr: 0.000001  loss: 0.1981 (0.2272)  labels_encoder: 0.0972 (0.1158)  labels_decoder: 0.1066 (0.1114)  labels_encoder_unscaled: 0.0972 (0.1158)  labels_decoder_unscaled: 0.2132 (0.2227)  time: 0.1741  data: 0.0003  max mem: 2769
Epoch: [3]  [ 900/1412]  eta: 0:01:29  lr: 0.000001  loss: 0.2190 (0.2273)  labels_encoder: 0.0988 (0.1158)  labels_decoder: 0.1156 (0.1115)  labels_encoder_unscaled: 0.0988 (0.1158)  labels_decoder_unscaled: 0.2313 (0.2231)  time: 0.1605  data: 0.0003  max mem: 2769
Epoch: [3]  [ 950/1412]  eta: 0:01:20  lr: 0.000001  loss: 0.2222 (0.2271)  labels_encoder: 0.1101 (0.1157)  labels_decoder: 0.1073 (0.1115)  labels_encoder_unscaled: 0.1101 (0.1157)  labels_decoder_unscaled: 0.2146 (0.2230)  time: 0.1704  data: 0.0003  max mem: 2769
Epoch: [3]  [1000/1412]  eta: 0:01:12  lr: 0.000001  loss: 0.2080 (0.2273)  labels_encoder: 0.1077 (0.1159)  labels_decoder: 0.1059 (0.1115)  labels_encoder_unscaled: 0.1077 (0.1159)  labels_decoder_unscaled: 0.2119 (0.2229)  time: 0.1842  data: 0.0003  max mem: 2769
Epoch: [3]  [1050/1412]  eta: 0:01:03  lr: 0.000001  loss: 0.2349 (0.2273)  labels_encoder: 0.1203 (0.1158)  labels_decoder: 0.1159 (0.1115)  labels_encoder_unscaled: 0.1203 (0.1158)  labels_decoder_unscaled: 0.2319 (0.2230)  time: 0.1681  data: 0.0003  max mem: 2769
Epoch: [3]  [1100/1412]  eta: 0:00:54  lr: 0.000001  loss: 0.2394 (0.2279)  labels_encoder: 0.1163 (0.1162)  labels_decoder: 0.1142 (0.1117)  labels_encoder_unscaled: 0.1163 (0.1162)  labels_decoder_unscaled: 0.2285 (0.2234)  time: 0.1694  data: 0.0003  max mem: 2769
Epoch: [3]  [1150/1412]  eta: 0:00:45  lr: 0.000001  loss: 0.2244 (0.2278)  labels_encoder: 0.1026 (0.1161)  labels_decoder: 0.1081 (0.1117)  labels_encoder_unscaled: 0.1026 (0.1161)  labels_decoder_unscaled: 0.2161 (0.2234)  time: 0.1776  data: 0.0003  max mem: 2769
Epoch: [3]  [1200/1412]  eta: 0:00:37  lr: 0.000001  loss: 0.2168 (0.2276)  labels_encoder: 0.1133 (0.1160)  labels_decoder: 0.1087 (0.1116)  labels_encoder_unscaled: 0.1133 (0.1160)  labels_decoder_unscaled: 0.2174 (0.2231)  time: 0.1678  data: 0.0024  max mem: 2769
Epoch: [3]  [1250/1412]  eta: 0:00:28  lr: 0.000001  loss: 0.2252 (0.2275)  labels_encoder: 0.1149 (0.1160)  labels_decoder: 0.1080 (0.1115)  labels_encoder_unscaled: 0.1149 (0.1160)  labels_decoder_unscaled: 0.2160 (0.2230)  time: 0.1790  data: 0.0003  max mem: 2769
Epoch: [3]  [1300/1412]  eta: 0:00:19  lr: 0.000001  loss: 0.2429 (0.2274)  labels_encoder: 0.1155 (0.1159)  labels_decoder: 0.1122 (0.1115)  labels_encoder_unscaled: 0.1155 (0.1159)  labels_decoder_unscaled: 0.2243 (0.2231)  time: 0.1726  data: 0.0003  max mem: 2769
Epoch: [3]  [1350/1412]  eta: 0:00:10  lr: 0.000001  loss: 0.2190 (0.2275)  labels_encoder: 0.1067 (0.1161)  labels_decoder: 0.1065 (0.1115)  labels_encoder_unscaled: 0.1067 (0.1161)  labels_decoder_unscaled: 0.2131 (0.2229)  time: 0.1843  data: 0.0003  max mem: 2769
Epoch: [3]  [1400/1412]  eta: 0:00:02  lr: 0.000001  loss: 0.2182 (0.2274)  labels_encoder: 0.1072 (0.1161)  labels_decoder: 0.1071 (0.1114)  labels_encoder_unscaled: 0.1072 (0.1161)  labels_decoder_unscaled: 0.2141 (0.2227)  time: 0.1643  data: 0.0005  max mem: 2769
Epoch: [3]  [1411/1412]  eta: 0:00:00  lr: 0.000001  loss: 0.1999 (0.2274)  labels_encoder: 0.1027 (0.1161)  labels_decoder: 0.0968 (0.1113)  labels_encoder_unscaled: 0.1027 (0.1161)  labels_decoder_unscaled: 0.1936 (0.2226)  time: 0.1408  data: 0.0004  max mem: 2769
Epoch: [3] Total time: 0:04:06 (0.1749 s / it)
Averaged stats: lr: 0.000001  loss: 0.1999 (0.2274)  labels_encoder: 0.1027 (0.1161)  labels_decoder: 0.0968 (0.1113)  labels_encoder_unscaled: 0.1027 (0.1161)  labels_decoder_unscaled: 0.1936 (0.2226)
Test:  [   0/1613]  eta: 1:40:58  loss: 0.4907 (0.4907)  labels_encoder: 0.2660 (0.2660)  labels_decoder: 0.2247 (0.2247)  labels_encoder_unscaled: 0.2660 (0.2660)  labels_decoder_unscaled: 0.4494 (0.4494)  time: 3.7562  data: 3.6060  max mem: 2769
Test:  [  50/1613]  eta: 0:04:41  loss: 0.4519 (0.8052)  labels_encoder: 0.3007 (0.5119)  labels_decoder: 0.1950 (0.2933)  labels_encoder_unscaled: 0.3007 (0.5119)  labels_decoder_unscaled: 0.3900 (0.5867)  time: 0.1104  data: 0.0398  max mem: 2769
Test:  [ 100/1613]  eta: 0:03:47  loss: 0.3951 (0.7270)  labels_encoder: 0.2335 (0.4670)  labels_decoder: 0.1602 (0.2600)  labels_encoder_unscaled: 0.2335 (0.4670)  labels_decoder_unscaled: 0.3204 (0.5201)  time: 0.1220  data: 0.0550  max mem: 2769
Test:  [ 150/1613]  eta: 0:03:25  loss: 0.8691 (0.7282)  labels_encoder: 0.4736 (0.4619)  labels_decoder: 0.2120 (0.2662)  labels_encoder_unscaled: 0.4736 (0.4619)  labels_decoder_unscaled: 0.4239 (0.5325)  time: 0.1181  data: 0.0563  max mem: 2769
Test:  [ 200/1613]  eta: 0:03:12  loss: 0.9929 (0.9005)  labels_encoder: 0.5894 (0.5719)  labels_decoder: 0.3892 (0.3286)  labels_encoder_unscaled: 0.5894 (0.5719)  labels_decoder_unscaled: 0.7783 (0.6571)  time: 0.1154  data: 0.0363  max mem: 2769
Test:  [ 250/1613]  eta: 0:03:01  loss: 0.8211 (0.9281)  labels_encoder: 0.3429 (0.5834)  labels_decoder: 0.3427 (0.3447)  labels_encoder_unscaled: 0.3429 (0.5834)  labels_decoder_unscaled: 0.6854 (0.6894)  time: 0.1184  data: 0.0426  max mem: 2769
Test:  [ 300/1613]  eta: 0:02:51  loss: 1.2863 (0.9626)  labels_encoder: 0.7034 (0.6067)  labels_decoder: 0.4637 (0.3559)  labels_encoder_unscaled: 0.7034 (0.6067)  labels_decoder_unscaled: 0.9273 (0.7118)  time: 0.1184  data: 0.0537  max mem: 2769
Test:  [ 350/1613]  eta: 0:02:45  loss: 1.3381 (0.9908)  labels_encoder: 0.7695 (0.6250)  labels_decoder: 0.4875 (0.3657)  labels_encoder_unscaled: 0.7695 (0.6250)  labels_decoder_unscaled: 0.9751 (0.7315)  time: 0.1317  data: 0.0605  max mem: 2769
Test:  [ 400/1613]  eta: 0:02:38  loss: 0.7408 (1.0362)  labels_encoder: 0.3900 (0.6585)  labels_decoder: 0.3160 (0.3777)  labels_encoder_unscaled: 0.3900 (0.6585)  labels_decoder_unscaled: 0.6320 (0.7555)  time: 0.1359  data: 0.0523  max mem: 2769
Test:  [ 450/1613]  eta: 0:02:29  loss: 1.0390 (1.1238)  labels_encoder: 0.6680 (0.7214)  labels_decoder: 0.3419 (0.4024)  labels_encoder_unscaled: 0.6680 (0.7214)  labels_decoder_unscaled: 0.6838 (0.8048)  time: 0.1091  data: 0.0072  max mem: 2769
Test:  [ 500/1613]  eta: 0:02:21  loss: 0.5174 (1.0773)  labels_encoder: 0.2301 (0.6898)  labels_decoder: 0.2636 (0.3875)  labels_encoder_unscaled: 0.2301 (0.6898)  labels_decoder_unscaled: 0.5273 (0.7750)  time: 0.1205  data: 0.0377  max mem: 2769
Test:  [ 550/1613]  eta: 0:02:14  loss: 0.6706 (1.0594)  labels_encoder: 0.3837 (0.6779)  labels_decoder: 0.2417 (0.3814)  labels_encoder_unscaled: 0.3837 (0.6779)  labels_decoder_unscaled: 0.4834 (0.7629)  time: 0.1190  data: 0.0408  max mem: 2769
Test:  [ 600/1613]  eta: 0:02:07  loss: 0.6419 (1.1113)  labels_encoder: 0.3280 (0.7188)  labels_decoder: 0.3185 (0.3925)  labels_encoder_unscaled: 0.3280 (0.7188)  labels_decoder_unscaled: 0.6371 (0.7851)  time: 0.1151  data: 0.0385  max mem: 2769
Test:  [ 650/1613]  eta: 0:02:00  loss: 0.8440 (1.1092)  labels_encoder: 0.4780 (0.7164)  labels_decoder: 0.3764 (0.3928)  labels_encoder_unscaled: 0.4780 (0.7164)  labels_decoder_unscaled: 0.7528 (0.7856)  time: 0.1123  data: 0.0233  max mem: 2769
Test:  [ 700/1613]  eta: 0:01:53  loss: 0.5395 (1.0848)  labels_encoder: 0.3285 (0.7001)  labels_decoder: 0.1876 (0.3847)  labels_encoder_unscaled: 0.3285 (0.7001)  labels_decoder_unscaled: 0.3753 (0.7693)  time: 0.1206  data: 0.0256  max mem: 2769
Test:  [ 750/1613]  eta: 0:01:47  loss: 0.7866 (1.0588)  labels_encoder: 0.4075 (0.6821)  labels_decoder: 0.2600 (0.3768)  labels_encoder_unscaled: 0.4075 (0.6821)  labels_decoder_unscaled: 0.5201 (0.7535)  time: 0.1135  data: 0.0280  max mem: 2769
Test:  [ 800/1613]  eta: 0:01:40  loss: 0.6273 (1.0518)  labels_encoder: 0.2995 (0.6770)  labels_decoder: 0.2492 (0.3747)  labels_encoder_unscaled: 0.2995 (0.6770)  labels_decoder_unscaled: 0.4984 (0.7495)  time: 0.1238  data: 0.0488  max mem: 2769
Test:  [ 850/1613]  eta: 0:01:34  loss: 0.9871 (1.0507)  labels_encoder: 0.5689 (0.6735)  labels_decoder: 0.4128 (0.3772)  labels_encoder_unscaled: 0.5689 (0.6735)  labels_decoder_unscaled: 0.8255 (0.7544)  time: 0.1153  data: 0.0406  max mem: 2769
Test:  [ 900/1613]  eta: 0:01:27  loss: 0.5671 (1.0272)  labels_encoder: 0.2589 (0.6560)  labels_decoder: 0.2642 (0.3712)  labels_encoder_unscaled: 0.2589 (0.6560)  labels_decoder_unscaled: 0.5285 (0.7424)  time: 0.1104  data: 0.0175  max mem: 2769
Test:  [ 950/1613]  eta: 0:01:21  loss: 1.1384 (1.0263)  labels_encoder: 0.7274 (0.6542)  labels_decoder: 0.3154 (0.3721)  labels_encoder_unscaled: 0.7274 (0.6542)  labels_decoder_unscaled: 0.6309 (0.7442)  time: 0.1140  data: 0.0306  max mem: 2769
Test:  [1000/1613]  eta: 0:01:15  loss: 0.8563 (1.0148)  labels_encoder: 0.4888 (0.6457)  labels_decoder: 0.3325 (0.3691)  labels_encoder_unscaled: 0.4888 (0.6457)  labels_decoder_unscaled: 0.6651 (0.7382)  time: 0.1210  data: 0.0333  max mem: 2769
Test:  [1050/1613]  eta: 0:01:08  loss: 0.9843 (1.0194)  labels_encoder: 0.6251 (0.6501)  labels_decoder: 0.3507 (0.3693)  labels_encoder_unscaled: 0.6251 (0.6501)  labels_decoder_unscaled: 0.7014 (0.7386)  time: 0.1129  data: 0.0190  max mem: 2769
Test:  [1100/1613]  eta: 0:01:02  loss: 0.5875 (1.0249)  labels_encoder: 0.2809 (0.6547)  labels_decoder: 0.3039 (0.3702)  labels_encoder_unscaled: 0.2809 (0.6547)  labels_decoder_unscaled: 0.6078 (0.7405)  time: 0.1196  data: 0.0002  max mem: 2769
Test:  [1150/1613]  eta: 0:00:56  loss: 0.4431 (1.0198)  labels_encoder: 0.2747 (0.6505)  labels_decoder: 0.2407 (0.3693)  labels_encoder_unscaled: 0.2747 (0.6505)  labels_decoder_unscaled: 0.4814 (0.7386)  time: 0.1140  data: 0.0406  max mem: 2769
Test:  [1200/1613]  eta: 0:00:50  loss: 0.4718 (1.0237)  labels_encoder: 0.2580 (0.6531)  labels_decoder: 0.2033 (0.3705)  labels_encoder_unscaled: 0.2580 (0.6531)  labels_decoder_unscaled: 0.4066 (0.7410)  time: 0.1262  data: 0.0597  max mem: 2769
Test:  [1250/1613]  eta: 0:00:44  loss: 0.5809 (1.0249)  labels_encoder: 0.2729 (0.6540)  labels_decoder: 0.2656 (0.3709)  labels_encoder_unscaled: 0.2729 (0.6540)  labels_decoder_unscaled: 0.5313 (0.7417)  time: 0.1221  data: 0.0289  max mem: 2769
Test:  [1300/1613]  eta: 0:00:38  loss: 0.6814 (1.0214)  labels_encoder: 0.4152 (0.6513)  labels_decoder: 0.2677 (0.3700)  labels_encoder_unscaled: 0.4152 (0.6513)  labels_decoder_unscaled: 0.5353 (0.7400)  time: 0.1234  data: 0.0492  max mem: 2769
Test:  [1350/1613]  eta: 0:00:32  loss: 1.0815 (1.0264)  labels_encoder: 0.7089 (0.6561)  labels_decoder: 0.3886 (0.3703)  labels_encoder_unscaled: 0.7089 (0.6561)  labels_decoder_unscaled: 0.7773 (0.7406)  time: 0.1314  data: 0.0472  max mem: 2769
Test:  [1400/1613]  eta: 0:00:25  loss: 0.9567 (1.0310)  labels_encoder: 0.6116 (0.6595)  labels_decoder: 0.3377 (0.3715)  labels_encoder_unscaled: 0.6116 (0.6595)  labels_decoder_unscaled: 0.6754 (0.7429)  time: 0.1184  data: 0.0166  max mem: 2769
Test:  [1450/1613]  eta: 0:00:19  loss: 0.6350 (1.0365)  labels_encoder: 0.3761 (0.6634)  labels_decoder: 0.3039 (0.3731)  labels_encoder_unscaled: 0.3761 (0.6634)  labels_decoder_unscaled: 0.6078 (0.7463)  time: 0.1019  data: 0.0193  max mem: 2769
Test:  [1500/1613]  eta: 0:00:13  loss: 0.5742 (1.0354)  labels_encoder: 0.3604 (0.6631)  labels_decoder: 0.2252 (0.3723)  labels_encoder_unscaled: 0.3604 (0.6631)  labels_decoder_unscaled: 0.4504 (0.7446)  time: 0.1121  data: 0.0237  max mem: 2769
Test:  [1550/1613]  eta: 0:00:07  loss: 0.8779 (1.0340)  labels_encoder: 0.5516 (0.6627)  labels_decoder: 0.2833 (0.3713)  labels_encoder_unscaled: 0.5516 (0.6627)  labels_decoder_unscaled: 0.5667 (0.7426)  time: 0.1137  data: 0.0068  max mem: 2769
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9362 (1.0338)  labels_encoder: 0.5622 (0.6620)  labels_decoder: 0.3952 (0.3718)  labels_encoder_unscaled: 0.5622 (0.6620)  labels_decoder_unscaled: 0.7904 (0.7435)  time: 0.1144  data: 0.0335  max mem: 2769
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5204 (1.0319)  labels_encoder: 0.2939 (0.6610)  labels_decoder: 0.2140 (0.3709)  labels_encoder_unscaled: 0.2939 (0.6610)  labels_decoder_unscaled: 0.4279 (0.7418)  time: 0.1041  data: 0.0180  max mem: 2769
Test: Total time: 0:03:14 (0.1209 s / it)
Averaged stats: loss: 0.5204 (1.0319)  labels_encoder: 0.2939 (0.6610)  labels_decoder: 0.2140 (0.3709)  labels_encoder_unscaled: 0.2939 (0.6610)  labels_decoder_unscaled: 0.4279 (0.7418)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-kin_audio] mAP: 0.6379

dec_mAP all together: | 0.5018750603783102 |.
dec_mAP_pred | 0 : 0.5490003129370843 |.
dec_mAP_pred | 1 : 0.5411262750650285 |.
dec_mAP_pred | 2 : 0.5282269433130586 |.
dec_mAP_pred | 3 : 0.5129675068707046 |.
dec_mAP_pred | 4 : 0.4965685141336163 |.
dec_mAP_pred | 5 : 0.4806318372829173 |.
dec_mAP_pred | 6 : 0.46512801114054386 |.
dec_mAP_pred | 7 : 0.45000757525295265 |.
all decoder map: | 0.5030 |.
BaseballPitch: 0.3249
BasketballDunk: 0.8057
Billiards: 0.3404
CleanAndJerk: 0.7446
CliffDiving: 0.8614
CricketBowling: 0.4897
CricketShot: 0.2945
Diving: 0.8665
FrisbeeCatch: 0.3197
GolfSwing: 0.7617
HammerThrow: 0.8550
HighJump: 0.7861
JavelinThrow: 0.7292
LongJump: 0.7857
PoleVault: 0.8721
Shotput: 0.7543
SoccerPenalty: 0.3922
TennisSwing: 0.5966
ThrowDiscus: 0.6920
VolleyballSpiking: 0.4854
Epoch: [4]  [   0/1412]  eta: 1:48:57  lr: 0.000000  loss: 0.2069 (0.2069)  labels_encoder: 0.0971 (0.0971)  labels_decoder: 0.1098 (0.1098)  labels_encoder_unscaled: 0.0971 (0.0971)  labels_decoder_unscaled: 0.2197 (0.2197)  time: 4.6303  data: 4.4517  max mem: 2769
Epoch: [4]  [  50/1412]  eta: 0:06:16  lr: 0.000000  loss: 0.2401 (0.2312)  labels_encoder: 0.1261 (0.1189)  labels_decoder: 0.1104 (0.1124)  labels_encoder_unscaled: 0.1261 (0.1189)  labels_decoder_unscaled: 0.2209 (0.2247)  time: 0.1773  data: 0.0004  max mem: 2769
Epoch: [4]  [ 100/1412]  eta: 0:04:47  lr: 0.000000  loss: 0.2226 (0.2316)  labels_encoder: 0.1166 (0.1190)  labels_decoder: 0.1148 (0.1126)  labels_encoder_unscaled: 0.1166 (0.1190)  labels_decoder_unscaled: 0.2296 (0.2252)  time: 0.1540  data: 0.0003  max mem: 2769
Epoch: [4]  [ 150/1412]  eta: 0:04:18  lr: 0.000000  loss: 0.2231 (0.2271)  labels_encoder: 0.1183 (0.1164)  labels_decoder: 0.1097 (0.1108)  labels_encoder_unscaled: 0.1183 (0.1164)  labels_decoder_unscaled: 0.2194 (0.2215)  time: 0.1915  data: 0.0003  max mem: 2769
Epoch: [4]  [ 200/1412]  eta: 0:04:00  lr: 0.000000  loss: 0.2165 (0.2251)  labels_encoder: 0.1112 (0.1154)  labels_decoder: 0.1029 (0.1097)  labels_encoder_unscaled: 0.1112 (0.1154)  labels_decoder_unscaled: 0.2058 (0.2193)  time: 0.1925  data: 0.0004  max mem: 2769
Epoch: [4]  [ 250/1412]  eta: 0:03:48  lr: 0.000000  loss: 0.2173 (0.2257)  labels_encoder: 0.1064 (0.1156)  labels_decoder: 0.1093 (0.1101)  labels_encoder_unscaled: 0.1064 (0.1156)  labels_decoder_unscaled: 0.2186 (0.2203)  time: 0.1967  data: 0.0004  max mem: 2769
Epoch: [4]  [ 300/1412]  eta: 0:03:34  lr: 0.000000  loss: 0.2219 (0.2253)  labels_encoder: 0.1133 (0.1152)  labels_decoder: 0.1064 (0.1101)  labels_encoder_unscaled: 0.1133 (0.1152)  labels_decoder_unscaled: 0.2128 (0.2202)  time: 0.1773  data: 0.0004  max mem: 2769
Epoch: [4]  [ 350/1412]  eta: 0:03:22  lr: 0.000000  loss: 0.2074 (0.2236)  labels_encoder: 0.1106 (0.1139)  labels_decoder: 0.1041 (0.1097)  labels_encoder_unscaled: 0.1106 (0.1139)  labels_decoder_unscaled: 0.2082 (0.2195)  time: 0.1840  data: 0.0004  max mem: 2769
Epoch: [4]  [ 400/1412]  eta: 0:03:11  lr: 0.000000  loss: 0.2338 (0.2235)  labels_encoder: 0.1131 (0.1134)  labels_decoder: 0.1137 (0.1101)  labels_encoder_unscaled: 0.1131 (0.1134)  labels_decoder_unscaled: 0.2274 (0.2202)  time: 0.1768  data: 0.0003  max mem: 2769
Epoch: [4]  [ 450/1412]  eta: 0:03:01  lr: 0.000000  loss: 0.2262 (0.2239)  labels_encoder: 0.1137 (0.1134)  labels_decoder: 0.1125 (0.1105)  labels_encoder_unscaled: 0.1137 (0.1134)  labels_decoder_unscaled: 0.2250 (0.2209)  time: 0.1795  data: 0.0003  max mem: 2769
Epoch: [4]  [ 500/1412]  eta: 0:02:51  lr: 0.000000  loss: 0.2233 (0.2240)  labels_encoder: 0.1100 (0.1137)  labels_decoder: 0.1123 (0.1103)  labels_encoder_unscaled: 0.1100 (0.1137)  labels_decoder_unscaled: 0.2245 (0.2206)  time: 0.1776  data: 0.0003  max mem: 2769
Epoch: [4]  [ 550/1412]  eta: 0:02:40  lr: 0.000000  loss: 0.2297 (0.2243)  labels_encoder: 0.1166 (0.1136)  labels_decoder: 0.1179 (0.1107)  labels_encoder_unscaled: 0.1166 (0.1136)  labels_decoder_unscaled: 0.2358 (0.2214)  time: 0.1701  data: 0.0003  max mem: 2769
Epoch: [4]  [ 600/1412]  eta: 0:02:30  lr: 0.000000  loss: 0.2223 (0.2240)  labels_encoder: 0.1099 (0.1134)  labels_decoder: 0.1022 (0.1106)  labels_encoder_unscaled: 0.1099 (0.1134)  labels_decoder_unscaled: 0.2043 (0.2212)  time: 0.1604  data: 0.0003  max mem: 2769
Epoch: [4]  [ 650/1412]  eta: 0:02:20  lr: 0.000000  loss: 0.2178 (0.2241)  labels_encoder: 0.1107 (0.1135)  labels_decoder: 0.1070 (0.1106)  labels_encoder_unscaled: 0.1107 (0.1135)  labels_decoder_unscaled: 0.2140 (0.2213)  time: 0.1657  data: 0.0004  max mem: 2769
Epoch: [4]  [ 700/1412]  eta: 0:02:10  lr: 0.000000  loss: 0.2331 (0.2246)  labels_encoder: 0.1152 (0.1137)  labels_decoder: 0.1131 (0.1109)  labels_encoder_unscaled: 0.1152 (0.1137)  labels_decoder_unscaled: 0.2263 (0.2218)  time: 0.1694  data: 0.0005  max mem: 2769
Epoch: [4]  [ 750/1412]  eta: 0:02:01  lr: 0.000000  loss: 0.2143 (0.2244)  labels_encoder: 0.1030 (0.1136)  labels_decoder: 0.1006 (0.1108)  labels_encoder_unscaled: 0.1030 (0.1136)  labels_decoder_unscaled: 0.2012 (0.2215)  time: 0.1783  data: 0.0003  max mem: 2769
Epoch: [4]  [ 800/1412]  eta: 0:01:51  lr: 0.000000  loss: 0.2151 (0.2246)  labels_encoder: 0.1114 (0.1139)  labels_decoder: 0.1037 (0.1107)  labels_encoder_unscaled: 0.1114 (0.1139)  labels_decoder_unscaled: 0.2073 (0.2214)  time: 0.1758  data: 0.0003  max mem: 2769
Epoch: [4]  [ 850/1412]  eta: 0:01:41  lr: 0.000000  loss: 0.2304 (0.2246)  labels_encoder: 0.1255 (0.1140)  labels_decoder: 0.1130 (0.1106)  labels_encoder_unscaled: 0.1255 (0.1140)  labels_decoder_unscaled: 0.2260 (0.2212)  time: 0.1648  data: 0.0003  max mem: 2769
Epoch: [4]  [ 900/1412]  eta: 0:01:32  lr: 0.000000  loss: 0.2299 (0.2249)  labels_encoder: 0.1284 (0.1142)  labels_decoder: 0.1087 (0.1107)  labels_encoder_unscaled: 0.1284 (0.1142)  labels_decoder_unscaled: 0.2175 (0.2213)  time: 0.1699  data: 0.0003  max mem: 2769
Epoch: [4]  [ 950/1412]  eta: 0:01:23  lr: 0.000000  loss: 0.2252 (0.2246)  labels_encoder: 0.1095 (0.1139)  labels_decoder: 0.1169 (0.1106)  labels_encoder_unscaled: 0.1095 (0.1139)  labels_decoder_unscaled: 0.2338 (0.2213)  time: 0.1748  data: 0.0003  max mem: 2769
Epoch: [4]  [1000/1412]  eta: 0:01:13  lr: 0.000000  loss: 0.2088 (0.2245)  labels_encoder: 0.1034 (0.1139)  labels_decoder: 0.1087 (0.1106)  labels_encoder_unscaled: 0.1034 (0.1139)  labels_decoder_unscaled: 0.2173 (0.2213)  time: 0.1621  data: 0.0003  max mem: 2769
Epoch: [4]  [1050/1412]  eta: 0:01:04  lr: 0.000000  loss: 0.2033 (0.2245)  labels_encoder: 0.1041 (0.1138)  labels_decoder: 0.1095 (0.1107)  labels_encoder_unscaled: 0.1041 (0.1138)  labels_decoder_unscaled: 0.2191 (0.2214)  time: 0.1688  data: 0.0003  max mem: 2769
Epoch: [4]  [1100/1412]  eta: 0:00:55  lr: 0.000000  loss: 0.2039 (0.2242)  labels_encoder: 0.1064 (0.1137)  labels_decoder: 0.1025 (0.1105)  labels_encoder_unscaled: 0.1064 (0.1137)  labels_decoder_unscaled: 0.2049 (0.2210)  time: 0.1555  data: 0.0003  max mem: 2769
Epoch: [4]  [1150/1412]  eta: 0:00:46  lr: 0.000000  loss: 0.2342 (0.2240)  labels_encoder: 0.1242 (0.1137)  labels_decoder: 0.1075 (0.1103)  labels_encoder_unscaled: 0.1242 (0.1137)  labels_decoder_unscaled: 0.2150 (0.2206)  time: 0.1586  data: 0.0003  max mem: 2769
Epoch: [4]  [1200/1412]  eta: 0:00:37  lr: 0.000000  loss: 0.2172 (0.2238)  labels_encoder: 0.0988 (0.1136)  labels_decoder: 0.1066 (0.1102)  labels_encoder_unscaled: 0.0988 (0.1136)  labels_decoder_unscaled: 0.2133 (0.2204)  time: 0.1745  data: 0.0003  max mem: 2769
Epoch: [4]  [1250/1412]  eta: 0:00:28  lr: 0.000000  loss: 0.2072 (0.2234)  labels_encoder: 0.1044 (0.1134)  labels_decoder: 0.1093 (0.1101)  labels_encoder_unscaled: 0.1044 (0.1134)  labels_decoder_unscaled: 0.2186 (0.2201)  time: 0.1588  data: 0.0003  max mem: 2769
Epoch: [4]  [1300/1412]  eta: 0:00:19  lr: 0.000000  loss: 0.2196 (0.2236)  labels_encoder: 0.1025 (0.1135)  labels_decoder: 0.1164 (0.1101)  labels_encoder_unscaled: 0.1025 (0.1135)  labels_decoder_unscaled: 0.2328 (0.2202)  time: 0.1714  data: 0.0004  max mem: 2769
Epoch: [4]  [1350/1412]  eta: 0:00:10  lr: 0.000000  loss: 0.2060 (0.2236)  labels_encoder: 0.1113 (0.1135)  labels_decoder: 0.1087 (0.1101)  labels_encoder_unscaled: 0.1113 (0.1135)  labels_decoder_unscaled: 0.2174 (0.2202)  time: 0.1753  data: 0.0003  max mem: 2769
Epoch: [4]  [1400/1412]  eta: 0:00:02  lr: 0.000000  loss: 0.2343 (0.2238)  labels_encoder: 0.1245 (0.1136)  labels_decoder: 0.1199 (0.1102)  labels_encoder_unscaled: 0.1245 (0.1136)  labels_decoder_unscaled: 0.2397 (0.2205)  time: 0.1564  data: 0.0007  max mem: 2769
Epoch: [4]  [1411/1412]  eta: 0:00:00  lr: 0.000000  loss: 0.2279 (0.2238)  labels_encoder: 0.1167 (0.1136)  labels_decoder: 0.1054 (0.1102)  labels_encoder_unscaled: 0.1167 (0.1136)  labels_decoder_unscaled: 0.2108 (0.2203)  time: 0.1285  data: 0.0006  max mem: 2769
Epoch: [4] Total time: 0:04:07 (0.1754 s / it)
Averaged stats: lr: 0.000000  loss: 0.2279 (0.2238)  labels_encoder: 0.1167 (0.1136)  labels_decoder: 0.1054 (0.1102)  labels_encoder_unscaled: 0.1167 (0.1136)  labels_decoder_unscaled: 0.2108 (0.2203)
Test:  [   0/1613]  eta: 1:38:09  loss: 0.4775 (0.4775)  labels_encoder: 0.2596 (0.2596)  labels_decoder: 0.2179 (0.2179)  labels_encoder_unscaled: 0.2596 (0.2596)  labels_decoder_unscaled: 0.4358 (0.4358)  time: 3.6510  data: 3.4724  max mem: 2769
Test:  [  50/1613]  eta: 0:04:53  loss: 0.4625 (0.7916)  labels_encoder: 0.2820 (0.4988)  labels_decoder: 0.1899 (0.2928)  labels_encoder_unscaled: 0.2820 (0.4988)  labels_decoder_unscaled: 0.3797 (0.5855)  time: 0.0917  data: 0.0002  max mem: 2769
Test:  [ 100/1613]  eta: 0:03:40  loss: 0.3695 (0.7127)  labels_encoder: 0.2442 (0.4553)  labels_decoder: 0.1712 (0.2573)  labels_encoder_unscaled: 0.2442 (0.4553)  labels_decoder_unscaled: 0.3423 (0.5146)  time: 0.0884  data: 0.0080  max mem: 2769
Test:  [ 150/1613]  eta: 0:03:14  loss: 0.8435 (0.7168)  labels_encoder: 0.4801 (0.4538)  labels_decoder: 0.2137 (0.2630)  labels_encoder_unscaled: 0.4801 (0.4538)  labels_decoder_unscaled: 0.4275 (0.5260)  time: 0.1099  data: 0.0119  max mem: 2769
Test:  [ 200/1613]  eta: 0:02:57  loss: 0.9945 (0.8866)  labels_encoder: 0.5889 (0.5625)  labels_decoder: 0.3901 (0.3242)  labels_encoder_unscaled: 0.5889 (0.5625)  labels_decoder_unscaled: 0.7802 (0.6484)  time: 0.1078  data: 0.0120  max mem: 2769
Test:  [ 250/1613]  eta: 0:02:46  loss: 0.7916 (0.9168)  labels_encoder: 0.3186 (0.5760)  labels_decoder: 0.3479 (0.3408)  labels_encoder_unscaled: 0.3186 (0.5760)  labels_decoder_unscaled: 0.6958 (0.6815)  time: 0.1143  data: 0.0185  max mem: 2769
Test:  [ 300/1613]  eta: 0:02:38  loss: 1.2014 (0.9437)  labels_encoder: 0.6519 (0.5938)  labels_decoder: 0.4280 (0.3499)  labels_encoder_unscaled: 0.6519 (0.5938)  labels_decoder_unscaled: 0.8560 (0.6999)  time: 0.1152  data: 0.0124  max mem: 2769
Test:  [ 350/1613]  eta: 0:02:30  loss: 1.3349 (0.9752)  labels_encoder: 0.7807 (0.6145)  labels_decoder: 0.4891 (0.3607)  labels_encoder_unscaled: 0.7807 (0.6145)  labels_decoder_unscaled: 0.9782 (0.7214)  time: 0.1137  data: 0.0202  max mem: 2769
Test:  [ 400/1613]  eta: 0:02:22  loss: 0.7470 (1.0237)  labels_encoder: 0.4011 (0.6499)  labels_decoder: 0.3143 (0.3737)  labels_encoder_unscaled: 0.4011 (0.6499)  labels_decoder_unscaled: 0.6285 (0.7475)  time: 0.0993  data: 0.0057  max mem: 2769
Test:  [ 450/1613]  eta: 0:02:16  loss: 1.0485 (1.1085)  labels_encoder: 0.6812 (0.7107)  labels_decoder: 0.3368 (0.3978)  labels_encoder_unscaled: 0.6812 (0.7107)  labels_decoder_unscaled: 0.6736 (0.7956)  time: 0.1161  data: 0.0466  max mem: 2769
Test:  [ 500/1613]  eta: 0:02:09  loss: 0.5159 (1.0620)  labels_encoder: 0.2251 (0.6794)  labels_decoder: 0.2300 (0.3825)  labels_encoder_unscaled: 0.2251 (0.6794)  labels_decoder_unscaled: 0.4600 (0.7651)  time: 0.0965  data: 0.0024  max mem: 2769
Test:  [ 550/1613]  eta: 0:02:02  loss: 0.6747 (1.0449)  labels_encoder: 0.3840 (0.6682)  labels_decoder: 0.2399 (0.3767)  labels_encoder_unscaled: 0.3840 (0.6682)  labels_decoder_unscaled: 0.4799 (0.7534)  time: 0.1117  data: 0.0360  max mem: 2769
Test:  [ 600/1613]  eta: 0:01:56  loss: 0.6421 (1.0980)  labels_encoder: 0.3325 (0.7102)  labels_decoder: 0.3159 (0.3878)  labels_encoder_unscaled: 0.3325 (0.7102)  labels_decoder_unscaled: 0.6318 (0.7757)  time: 0.1129  data: 0.0324  max mem: 2769
Test:  [ 650/1613]  eta: 0:01:50  loss: 0.9215 (1.0998)  labels_encoder: 0.5080 (0.7103)  labels_decoder: 0.4018 (0.3895)  labels_encoder_unscaled: 0.5080 (0.7103)  labels_decoder_unscaled: 0.8036 (0.7789)  time: 0.1109  data: 0.0216  max mem: 2769
Test:  [ 700/1613]  eta: 0:01:45  loss: 0.5479 (1.0763)  labels_encoder: 0.3349 (0.6946)  labels_decoder: 0.1853 (0.3817)  labels_encoder_unscaled: 0.3349 (0.6946)  labels_decoder_unscaled: 0.3706 (0.7634)  time: 0.1230  data: 0.0292  max mem: 2769
Test:  [ 750/1613]  eta: 0:01:39  loss: 0.8491 (1.0524)  labels_encoder: 0.4445 (0.6778)  labels_decoder: 0.2836 (0.3746)  labels_encoder_unscaled: 0.4445 (0.6778)  labels_decoder_unscaled: 0.5673 (0.7492)  time: 0.1185  data: 0.0187  max mem: 2769
Test:  [ 800/1613]  eta: 0:01:33  loss: 0.6131 (1.0451)  labels_encoder: 0.2980 (0.6727)  labels_decoder: 0.2447 (0.3724)  labels_encoder_unscaled: 0.2980 (0.6727)  labels_decoder_unscaled: 0.4894 (0.7448)  time: 0.1144  data: 0.0178  max mem: 2769
Test:  [ 850/1613]  eta: 0:01:27  loss: 0.9985 (1.0451)  labels_encoder: 0.5578 (0.6699)  labels_decoder: 0.4079 (0.3752)  labels_encoder_unscaled: 0.5578 (0.6699)  labels_decoder_unscaled: 0.8157 (0.7504)  time: 0.1052  data: 0.0255  max mem: 2769
Test:  [ 900/1613]  eta: 0:01:21  loss: 0.5476 (1.0222)  labels_encoder: 0.2461 (0.6528)  labels_decoder: 0.2642 (0.3693)  labels_encoder_unscaled: 0.2461 (0.6528)  labels_decoder_unscaled: 0.5284 (0.7386)  time: 0.1193  data: 0.0247  max mem: 2769
Test:  [ 950/1613]  eta: 0:01:16  loss: 1.1337 (1.0222)  labels_encoder: 0.7217 (0.6517)  labels_decoder: 0.3177 (0.3705)  labels_encoder_unscaled: 0.7217 (0.6517)  labels_decoder_unscaled: 0.6354 (0.7409)  time: 0.1117  data: 0.0376  max mem: 2769
Test:  [1000/1613]  eta: 0:01:10  loss: 0.7813 (1.0104)  labels_encoder: 0.4429 (0.6430)  labels_decoder: 0.3289 (0.3674)  labels_encoder_unscaled: 0.4429 (0.6430)  labels_decoder_unscaled: 0.6577 (0.7348)  time: 0.1065  data: 0.0372  max mem: 2769
Test:  [1050/1613]  eta: 0:01:04  loss: 0.9780 (1.0152)  labels_encoder: 0.6262 (0.6475)  labels_decoder: 0.3501 (0.3677)  labels_encoder_unscaled: 0.6262 (0.6475)  labels_decoder_unscaled: 0.7001 (0.7354)  time: 0.1230  data: 0.0029  max mem: 2769
Test:  [1100/1613]  eta: 0:00:58  loss: 0.5780 (1.0200)  labels_encoder: 0.2745 (0.6515)  labels_decoder: 0.2991 (0.3685)  labels_encoder_unscaled: 0.2745 (0.6515)  labels_decoder_unscaled: 0.5982 (0.7370)  time: 0.1136  data: 0.0298  max mem: 2769
Test:  [1150/1613]  eta: 0:00:52  loss: 0.4479 (1.0148)  labels_encoder: 0.2791 (0.6473)  labels_decoder: 0.2254 (0.3675)  labels_encoder_unscaled: 0.2791 (0.6473)  labels_decoder_unscaled: 0.4507 (0.7349)  time: 0.1108  data: 0.0339  max mem: 2769
Test:  [1200/1613]  eta: 0:00:47  loss: 0.4812 (1.0194)  labels_encoder: 0.2544 (0.6504)  labels_decoder: 0.2133 (0.3690)  labels_encoder_unscaled: 0.2544 (0.6504)  labels_decoder_unscaled: 0.4265 (0.7380)  time: 0.1146  data: 0.0409  max mem: 2769
Test:  [1250/1613]  eta: 0:00:41  loss: 0.5733 (1.0206)  labels_encoder: 0.2751 (0.6512)  labels_decoder: 0.2559 (0.3693)  labels_encoder_unscaled: 0.2751 (0.6512)  labels_decoder_unscaled: 0.5119 (0.7387)  time: 0.1190  data: 0.0027  max mem: 2769
Test:  [1300/1613]  eta: 0:00:35  loss: 0.6295 (1.0159)  labels_encoder: 0.3820 (0.6478)  labels_decoder: 0.2643 (0.3681)  labels_encoder_unscaled: 0.3820 (0.6478)  labels_decoder_unscaled: 0.5285 (0.7362)  time: 0.1075  data: 0.0419  max mem: 2769
Test:  [1350/1613]  eta: 0:00:29  loss: 1.1205 (1.0209)  labels_encoder: 0.7156 (0.6525)  labels_decoder: 0.3826 (0.3684)  labels_encoder_unscaled: 0.7156 (0.6525)  labels_decoder_unscaled: 0.7652 (0.7369)  time: 0.1172  data: 0.0213  max mem: 2769
Test:  [1400/1613]  eta: 0:00:24  loss: 0.9298 (1.0258)  labels_encoder: 0.6228 (0.6560)  labels_decoder: 0.3234 (0.3698)  labels_encoder_unscaled: 0.6228 (0.6560)  labels_decoder_unscaled: 0.6467 (0.7395)  time: 0.1079  data: 0.0075  max mem: 2769
Test:  [1450/1613]  eta: 0:00:18  loss: 0.6433 (1.0315)  labels_encoder: 0.3603 (0.6600)  labels_decoder: 0.3081 (0.3715)  labels_encoder_unscaled: 0.3603 (0.6600)  labels_decoder_unscaled: 0.6163 (0.7430)  time: 0.0927  data: 0.0207  max mem: 2769
Test:  [1500/1613]  eta: 0:00:12  loss: 0.5921 (1.0305)  labels_encoder: 0.3618 (0.6598)  labels_decoder: 0.2323 (0.3707)  labels_encoder_unscaled: 0.3618 (0.6598)  labels_decoder_unscaled: 0.4647 (0.7414)  time: 0.1126  data: 0.0304  max mem: 2769
Test:  [1550/1613]  eta: 0:00:07  loss: 0.8720 (1.0295)  labels_encoder: 0.5651 (0.6597)  labels_decoder: 0.2846 (0.3698)  labels_encoder_unscaled: 0.5651 (0.6597)  labels_decoder_unscaled: 0.5692 (0.7396)  time: 0.1107  data: 0.0519  max mem: 2769
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9270 (1.0298)  labels_encoder: 0.5817 (0.6593)  labels_decoder: 0.4231 (0.3705)  labels_encoder_unscaled: 0.5817 (0.6593)  labels_decoder_unscaled: 0.8462 (0.7410)  time: 0.1161  data: 0.0153  max mem: 2769
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5119 (1.0280)  labels_encoder: 0.3142 (0.6583)  labels_decoder: 0.2117 (0.3697)  labels_encoder_unscaled: 0.3142 (0.6583)  labels_decoder_unscaled: 0.4233 (0.7393)  time: 0.1090  data: 0.0208  max mem: 2769
Test: Total time: 0:03:03 (0.1140 s / it)
Averaged stats: loss: 0.5119 (1.0280)  labels_encoder: 0.3142 (0.6583)  labels_decoder: 0.2117 (0.3697)  labels_encoder_unscaled: 0.3142 (0.6583)  labels_decoder_unscaled: 0.4233 (0.7393)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-kin_audio] mAP: 0.6374

dec_mAP all together: | 0.5017839299312937 |.
dec_mAP_pred | 0 : 0.5489541584422094 |.
dec_mAP_pred | 1 : 0.5410501351391808 |.
dec_mAP_pred | 2 : 0.5281462834500209 |.
dec_mAP_pred | 3 : 0.5129179045197357 |.
dec_mAP_pred | 4 : 0.4964954138797868 |.
dec_mAP_pred | 5 : 0.48051324553109076 |.
dec_mAP_pred | 6 : 0.4649804570634897 |.
dec_mAP_pred | 7 : 0.449841513318131 |.
all decoder map: | 0.5029 |.
BaseballPitch: 0.3177
BasketballDunk: 0.8055
Billiards: 0.3410
CleanAndJerk: 0.7443
CliffDiving: 0.8609
CricketBowling: 0.4899
CricketShot: 0.2939
Diving: 0.8661
FrisbeeCatch: 0.3222
GolfSwing: 0.7646
HammerThrow: 0.8560
HighJump: 0.7839
JavelinThrow: 0.7290
LongJump: 0.7837
PoleVault: 0.8723
Shotput: 0.7522
SoccerPenalty: 0.3911
TennisSwing: 0.5968
ThrowDiscus: 0.6916
VolleyballSpiking: 0.4854
Training time 0:34:04
