Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:anet_audio
dim_feature:7168
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:2
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  78.772 M, 99.834% Params, 2.714 GMac, 100.000% MACs, 
  (linear_encoding): Linear(7.341 M, 9.304% Params, 0.47 GMac, 17.307% MACs, in_features=7168, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 23.933% Params, 1.227 GMac, 45.207% MACs, 
    (net): Sequential(
      18.884 M, 23.933% Params, 1.227 GMac, 45.207% MACs, 
      (0): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.317% Params, 0.273 GMac, 10.044% MACs, 
            (qkv): Linear(3.146 M, 3.987% Params, 0.204 GMac, 7.533% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
        (fn): PreNorm(
          2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
            (net): Sequential(
              2.099 M, 2.660% Params, 0.136 GMac, 5.025% MACs, 
              (0): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.057% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 66.512% Params, 1.017 GMac, 37.478% MACs, 
    (layers): ModuleList(
      52.48 M, 66.512% Params, 1.017 GMac, 37.478% MACs, 
      (0): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 13.302% Params, 0.203 GMac, 7.496% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.034 GMac, 1.236% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.321% Params, 0.153 GMac, 5.640% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.330% Params, 0.068 GMac, 2.511% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.330% Params, 0.008 GMac, 0.309% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.029% Params, 0.0 GMac, 0.007% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2714272812.0
Model params: 78903340
Loaded data/thumos_anet_plus_audio_val.pickle
Loaded data/thumos_anet_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1405]  eta: 1:44:37  lr: 0.000100  loss: 4.6603 (4.6603)  labels_encoder: 3.0234 (3.0234)  labels_decoder: 1.6369 (1.6369)  labels_encoder_unscaled: 3.0234 (3.0234)  labels_decoder_unscaled: 3.2738 (3.2738)  time: 4.4683  data: 3.7870  max mem: 2800
Epoch: [1]  [  50/1405]  eta: 0:07:01  lr: 0.000100  loss: 1.1130 (1.6826)  labels_encoder: 0.7098 (1.0735)  labels_decoder: 0.4077 (0.6092)  labels_encoder_unscaled: 0.7098 (1.0735)  labels_decoder_unscaled: 0.8153 (1.2184)  time: 0.1910  data: 0.0003  max mem: 3702
Epoch: [1]  [ 100/1405]  eta: 0:05:29  lr: 0.000100  loss: 0.7957 (1.2726)  labels_encoder: 0.4756 (0.8027)  labels_decoder: 0.3116 (0.4699)  labels_encoder_unscaled: 0.4756 (0.8027)  labels_decoder_unscaled: 0.6231 (0.9398)  time: 0.1985  data: 0.0003  max mem: 3702
Epoch: [1]  [ 150/1405]  eta: 0:04:50  lr: 0.000100  loss: 0.7149 (1.0997)  labels_encoder: 0.4287 (0.6913)  labels_decoder: 0.2640 (0.4084)  labels_encoder_unscaled: 0.4287 (0.6913)  labels_decoder_unscaled: 0.5280 (0.8168)  time: 0.1881  data: 0.0039  max mem: 3702
Epoch: [1]  [ 200/1405]  eta: 0:04:28  lr: 0.000100  loss: 0.6605 (0.9965)  labels_encoder: 0.4093 (0.6251)  labels_decoder: 0.2549 (0.3714)  labels_encoder_unscaled: 0.4093 (0.6251)  labels_decoder_unscaled: 0.5098 (0.7428)  time: 0.1979  data: 0.0003  max mem: 3702
Epoch: [1]  [ 250/1405]  eta: 0:04:10  lr: 0.000100  loss: 0.5558 (0.9230)  labels_encoder: 0.3313 (0.5780)  labels_decoder: 0.2230 (0.3450)  labels_encoder_unscaled: 0.3313 (0.5780)  labels_decoder_unscaled: 0.4460 (0.6900)  time: 0.1869  data: 0.0003  max mem: 3702
Epoch: [1]  [ 300/1405]  eta: 0:03:56  lr: 0.000100  loss: 0.6067 (0.8725)  labels_encoder: 0.3828 (0.5456)  labels_decoder: 0.2295 (0.3269)  labels_encoder_unscaled: 0.3828 (0.5456)  labels_decoder_unscaled: 0.4589 (0.6538)  time: 0.2104  data: 0.0004  max mem: 3702
Epoch: [1]  [ 350/1405]  eta: 0:03:40  lr: 0.000100  loss: 0.5793 (0.8324)  labels_encoder: 0.3453 (0.5185)  labels_decoder: 0.2161 (0.3139)  labels_encoder_unscaled: 0.3453 (0.5185)  labels_decoder_unscaled: 0.4322 (0.6279)  time: 0.1674  data: 0.0003  max mem: 3702
Epoch: [1]  [ 400/1405]  eta: 0:03:26  lr: 0.000100  loss: 0.5003 (0.7943)  labels_encoder: 0.3087 (0.4932)  labels_decoder: 0.2011 (0.3011)  labels_encoder_unscaled: 0.3087 (0.4932)  labels_decoder_unscaled: 0.4021 (0.6023)  time: 0.1815  data: 0.0003  max mem: 3702
Epoch: [1]  [ 450/1405]  eta: 0:03:12  lr: 0.000100  loss: 0.4832 (0.7647)  labels_encoder: 0.2799 (0.4734)  labels_decoder: 0.1938 (0.2913)  labels_encoder_unscaled: 0.2799 (0.4734)  labels_decoder_unscaled: 0.3875 (0.5825)  time: 0.1714  data: 0.0003  max mem: 3702
Epoch: [1]  [ 500/1405]  eta: 0:02:59  lr: 0.000100  loss: 0.4896 (0.7390)  labels_encoder: 0.2877 (0.4562)  labels_decoder: 0.2062 (0.2828)  labels_encoder_unscaled: 0.2877 (0.4562)  labels_decoder_unscaled: 0.4123 (0.5655)  time: 0.1636  data: 0.0003  max mem: 3702
Epoch: [1]  [ 550/1405]  eta: 0:02:47  lr: 0.000100  loss: 0.4815 (0.7187)  labels_encoder: 0.2822 (0.4427)  labels_decoder: 0.1960 (0.2760)  labels_encoder_unscaled: 0.2822 (0.4427)  labels_decoder_unscaled: 0.3921 (0.5520)  time: 0.1679  data: 0.0003  max mem: 3702
Epoch: [1]  [ 600/1405]  eta: 0:02:35  lr: 0.000100  loss: 0.4548 (0.6993)  labels_encoder: 0.2714 (0.4296)  labels_decoder: 0.1782 (0.2697)  labels_encoder_unscaled: 0.2714 (0.4296)  labels_decoder_unscaled: 0.3564 (0.5393)  time: 0.1703  data: 0.0003  max mem: 3702
Epoch: [1]  [ 650/1405]  eta: 0:02:25  lr: 0.000100  loss: 0.4777 (0.6828)  labels_encoder: 0.2788 (0.4184)  labels_decoder: 0.1977 (0.2644)  labels_encoder_unscaled: 0.2788 (0.4184)  labels_decoder_unscaled: 0.3953 (0.5289)  time: 0.1845  data: 0.0003  max mem: 3702
Epoch: [1]  [ 700/1405]  eta: 0:02:14  lr: 0.000100  loss: 0.4385 (0.6666)  labels_encoder: 0.2591 (0.4075)  labels_decoder: 0.1793 (0.2591)  labels_encoder_unscaled: 0.2591 (0.4075)  labels_decoder_unscaled: 0.3586 (0.5181)  time: 0.1803  data: 0.0003  max mem: 3702
Epoch: [1]  [ 750/1405]  eta: 0:02:04  lr: 0.000100  loss: 0.4647 (0.6534)  labels_encoder: 0.2665 (0.3987)  labels_decoder: 0.2002 (0.2548)  labels_encoder_unscaled: 0.2665 (0.3987)  labels_decoder_unscaled: 0.4004 (0.5095)  time: 0.1739  data: 0.0003  max mem: 3702
Epoch: [1]  [ 800/1405]  eta: 0:01:54  lr: 0.000100  loss: 0.4699 (0.6415)  labels_encoder: 0.2753 (0.3908)  labels_decoder: 0.1869 (0.2506)  labels_encoder_unscaled: 0.2753 (0.3908)  labels_decoder_unscaled: 0.3738 (0.5013)  time: 0.1658  data: 0.0003  max mem: 3702
Epoch: [1]  [ 850/1405]  eta: 0:01:44  lr: 0.000100  loss: 0.4462 (0.6308)  labels_encoder: 0.2524 (0.3839)  labels_decoder: 0.1806 (0.2470)  labels_encoder_unscaled: 0.2524 (0.3839)  labels_decoder_unscaled: 0.3611 (0.4939)  time: 0.1708  data: 0.0003  max mem: 3702
Epoch: [1]  [ 900/1405]  eta: 0:01:34  lr: 0.000100  loss: 0.4368 (0.6210)  labels_encoder: 0.2345 (0.3775)  labels_decoder: 0.1882 (0.2435)  labels_encoder_unscaled: 0.2345 (0.3775)  labels_decoder_unscaled: 0.3764 (0.4871)  time: 0.1808  data: 0.0003  max mem: 3702
Epoch: [1]  [ 950/1405]  eta: 0:01:25  lr: 0.000100  loss: 0.4386 (0.6112)  labels_encoder: 0.2677 (0.3711)  labels_decoder: 0.1714 (0.2401)  labels_encoder_unscaled: 0.2677 (0.3711)  labels_decoder_unscaled: 0.3429 (0.4802)  time: 0.1896  data: 0.0003  max mem: 3702
Epoch: [1]  [1000/1405]  eta: 0:01:15  lr: 0.000100  loss: 0.4474 (0.6026)  labels_encoder: 0.2615 (0.3654)  labels_decoder: 0.1838 (0.2372)  labels_encoder_unscaled: 0.2615 (0.3654)  labels_decoder_unscaled: 0.3677 (0.4744)  time: 0.1865  data: 0.0004  max mem: 3702
Epoch: [1]  [1050/1405]  eta: 0:01:06  lr: 0.000100  loss: 0.4228 (0.5947)  labels_encoder: 0.2439 (0.3602)  labels_decoder: 0.1748 (0.2345)  labels_encoder_unscaled: 0.2439 (0.3602)  labels_decoder_unscaled: 0.3496 (0.4690)  time: 0.1931  data: 0.0004  max mem: 3702
Epoch: [1]  [1100/1405]  eta: 0:00:57  lr: 0.000100  loss: 0.4300 (0.5867)  labels_encoder: 0.2494 (0.3550)  labels_decoder: 0.1708 (0.2317)  labels_encoder_unscaled: 0.2494 (0.3550)  labels_decoder_unscaled: 0.3415 (0.4634)  time: 0.1837  data: 0.0003  max mem: 3702
Epoch: [1]  [1150/1405]  eta: 0:00:47  lr: 0.000100  loss: 0.3992 (0.5794)  labels_encoder: 0.2162 (0.3501)  labels_decoder: 0.1607 (0.2292)  labels_encoder_unscaled: 0.2162 (0.3501)  labels_decoder_unscaled: 0.3214 (0.4585)  time: 0.1824  data: 0.0003  max mem: 3702
Epoch: [1]  [1200/1405]  eta: 0:00:38  lr: 0.000100  loss: 0.4130 (0.5727)  labels_encoder: 0.2292 (0.3456)  labels_decoder: 0.1769 (0.2270)  labels_encoder_unscaled: 0.2292 (0.3456)  labels_decoder_unscaled: 0.3538 (0.4541)  time: 0.1734  data: 0.0003  max mem: 3702
Epoch: [1]  [1250/1405]  eta: 0:00:28  lr: 0.000100  loss: 0.3675 (0.5656)  labels_encoder: 0.2005 (0.3409)  labels_decoder: 0.1614 (0.2247)  labels_encoder_unscaled: 0.2005 (0.3409)  labels_decoder_unscaled: 0.3228 (0.4494)  time: 0.1779  data: 0.0003  max mem: 3702
Epoch: [1]  [1300/1405]  eta: 0:00:19  lr: 0.000100  loss: 0.4068 (0.5598)  labels_encoder: 0.2551 (0.3371)  labels_decoder: 0.1711 (0.2227)  labels_encoder_unscaled: 0.2551 (0.3371)  labels_decoder_unscaled: 0.3421 (0.4454)  time: 0.1811  data: 0.0003  max mem: 3702
Epoch: [1]  [1350/1405]  eta: 0:00:10  lr: 0.000100  loss: 0.3986 (0.5541)  labels_encoder: 0.2167 (0.3333)  labels_decoder: 0.1621 (0.2208)  labels_encoder_unscaled: 0.2167 (0.3333)  labels_decoder_unscaled: 0.3243 (0.4417)  time: 0.1833  data: 0.0003  max mem: 3702
Epoch: [1]  [1400/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3866 (0.5484)  labels_encoder: 0.2040 (0.3294)  labels_decoder: 0.1702 (0.2190)  labels_encoder_unscaled: 0.2040 (0.3294)  labels_decoder_unscaled: 0.3405 (0.4380)  time: 0.1584  data: 0.0003  max mem: 3702
Epoch: [1]  [1404/1405]  eta: 0:00:00  lr: 0.000100  loss: 0.3901 (0.5481)  labels_encoder: 0.2213 (0.3292)  labels_decoder: 0.1687 (0.2189)  labels_encoder_unscaled: 0.2213 (0.3292)  labels_decoder_unscaled: 0.3375 (0.4378)  time: 0.1571  data: 0.0003  max mem: 3702
Epoch: [1] Total time: 0:04:20 (0.1856 s / it)
Averaged stats: lr: 0.000100  loss: 0.3901 (0.5481)  labels_encoder: 0.2213 (0.3292)  labels_decoder: 0.1687 (0.2189)  labels_encoder_unscaled: 0.2213 (0.3292)  labels_decoder_unscaled: 0.3375 (0.4378)
Test:  [   0/1613]  eta: 1:22:51  loss: 4.9603 (4.9603)  labels_encoder: 3.4382 (3.4382)  labels_decoder: 1.5222 (1.5222)  labels_encoder_unscaled: 3.4382 (3.4382)  labels_decoder_unscaled: 3.0443 (3.0443)  time: 3.0821  data: 2.9410  max mem: 3702
Test:  [  50/1613]  eta: 0:04:25  loss: 0.4596 (1.1200)  labels_encoder: 0.2717 (0.7179)  labels_decoder: 0.2036 (0.4020)  labels_encoder_unscaled: 0.2717 (0.7179)  labels_decoder_unscaled: 0.4073 (0.8041)  time: 0.1221  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:34  loss: 0.2278 (0.8190)  labels_encoder: 0.1483 (0.5180)  labels_decoder: 0.0796 (0.3010)  labels_encoder_unscaled: 0.1483 (0.5180)  labels_decoder_unscaled: 0.1591 (0.6020)  time: 0.1220  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:13  loss: 0.5276 (0.7525)  labels_encoder: 0.3419 (0.4748)  labels_decoder: 0.1856 (0.2776)  labels_encoder_unscaled: 0.3419 (0.4748)  labels_decoder_unscaled: 0.3713 (0.5552)  time: 0.1192  data: 0.0068  max mem: 3702
Test:  [ 200/1613]  eta: 0:03:02  loss: 0.9789 (0.8639)  labels_encoder: 0.5669 (0.5557)  labels_decoder: 0.3868 (0.3082)  labels_encoder_unscaled: 0.5669 (0.5557)  labels_decoder_unscaled: 0.7736 (0.6164)  time: 0.1244  data: 0.0197  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:53  loss: 0.4493 (0.8981)  labels_encoder: 0.3013 (0.5716)  labels_decoder: 0.2217 (0.3265)  labels_encoder_unscaled: 0.3013 (0.5716)  labels_decoder_unscaled: 0.4434 (0.6530)  time: 0.1116  data: 0.0110  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:45  loss: 0.4518 (0.9157)  labels_encoder: 0.2969 (0.5793)  labels_decoder: 0.2191 (0.3364)  labels_encoder_unscaled: 0.2969 (0.5793)  labels_decoder_unscaled: 0.4381 (0.6729)  time: 0.1220  data: 0.0230  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:37  loss: 0.7083 (0.8827)  labels_encoder: 0.3699 (0.5550)  labels_decoder: 0.3304 (0.3277)  labels_encoder_unscaled: 0.3699 (0.5550)  labels_decoder_unscaled: 0.6608 (0.6554)  time: 0.0980  data: 0.0296  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:30  loss: 0.9603 (0.9893)  labels_encoder: 0.5731 (0.6313)  labels_decoder: 0.3983 (0.3580)  labels_encoder_unscaled: 0.5731 (0.6313)  labels_decoder_unscaled: 0.7966 (0.7160)  time: 0.1172  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:23  loss: 0.6459 (1.0496)  labels_encoder: 0.3763 (0.6719)  labels_decoder: 0.2506 (0.3777)  labels_encoder_unscaled: 0.3763 (0.6719)  labels_decoder_unscaled: 0.5012 (0.7554)  time: 0.1118  data: 0.0144  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:16  loss: 0.2830 (1.0117)  labels_encoder: 0.1118 (0.6483)  labels_decoder: 0.1670 (0.3634)  labels_encoder_unscaled: 0.1118 (0.6483)  labels_decoder_unscaled: 0.3341 (0.7268)  time: 0.1226  data: 0.0193  max mem: 3702
Test:  [ 550/1613]  eta: 0:02:09  loss: 0.7069 (1.0260)  labels_encoder: 0.4105 (0.6565)  labels_decoder: 0.2710 (0.3695)  labels_encoder_unscaled: 0.4105 (0.6565)  labels_decoder_unscaled: 0.5421 (0.7389)  time: 0.1142  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:02:03  loss: 1.1539 (1.0358)  labels_encoder: 0.8216 (0.6677)  labels_decoder: 0.3323 (0.3681)  labels_encoder_unscaled: 0.8216 (0.6677)  labels_decoder_unscaled: 0.6646 (0.7361)  time: 0.1096  data: 0.0089  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:56  loss: 1.4072 (1.0342)  labels_encoder: 0.9939 (0.6658)  labels_decoder: 0.4699 (0.3684)  labels_encoder_unscaled: 0.9939 (0.6658)  labels_decoder_unscaled: 0.9399 (0.7368)  time: 0.1190  data: 0.0209  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:50  loss: 0.5545 (1.0202)  labels_encoder: 0.2967 (0.6559)  labels_decoder: 0.2192 (0.3642)  labels_encoder_unscaled: 0.2967 (0.6559)  labels_decoder_unscaled: 0.4385 (0.7284)  time: 0.1170  data: 0.0196  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:44  loss: 0.7890 (1.0094)  labels_encoder: 0.4709 (0.6486)  labels_decoder: 0.3181 (0.3608)  labels_encoder_unscaled: 0.4709 (0.6486)  labels_decoder_unscaled: 0.6362 (0.7216)  time: 0.1215  data: 0.0186  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:38  loss: 0.5351 (1.0071)  labels_encoder: 0.3645 (0.6468)  labels_decoder: 0.2047 (0.3603)  labels_encoder_unscaled: 0.3645 (0.6468)  labels_decoder_unscaled: 0.4093 (0.7205)  time: 0.1218  data: 0.0224  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:32  loss: 1.1953 (1.0125)  labels_encoder: 0.7551 (0.6490)  labels_decoder: 0.4632 (0.3635)  labels_encoder_unscaled: 0.7551 (0.6490)  labels_decoder_unscaled: 0.9264 (0.7270)  time: 0.1241  data: 0.0368  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:26  loss: 0.6942 (1.0309)  labels_encoder: 0.4445 (0.6590)  labels_decoder: 0.2743 (0.3719)  labels_encoder_unscaled: 0.4445 (0.6590)  labels_decoder_unscaled: 0.5486 (0.7438)  time: 0.1196  data: 0.0265  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:20  loss: 0.9263 (1.0159)  labels_encoder: 0.5402 (0.6478)  labels_decoder: 0.3830 (0.3681)  labels_encoder_unscaled: 0.5402 (0.6478)  labels_decoder_unscaled: 0.7660 (0.7362)  time: 0.1199  data: 0.0361  max mem: 3702
Test:  [1000/1613]  eta: 0:01:14  loss: 0.5816 (1.0072)  labels_encoder: 0.3400 (0.6419)  labels_decoder: 0.2253 (0.3653)  labels_encoder_unscaled: 0.3400 (0.6419)  labels_decoder_unscaled: 0.4507 (0.7306)  time: 0.1180  data: 0.0219  max mem: 3702
Test:  [1050/1613]  eta: 0:01:07  loss: 0.9571 (1.0085)  labels_encoder: 0.5595 (0.6426)  labels_decoder: 0.3574 (0.3660)  labels_encoder_unscaled: 0.5595 (0.6426)  labels_decoder_unscaled: 0.7148 (0.7319)  time: 0.1076  data: 0.0191  max mem: 3702
Test:  [1100/1613]  eta: 0:01:01  loss: 0.6886 (1.0156)  labels_encoder: 0.3790 (0.6497)  labels_decoder: 0.2886 (0.3659)  labels_encoder_unscaled: 0.3790 (0.6497)  labels_decoder_unscaled: 0.5773 (0.7319)  time: 0.1199  data: 0.0334  max mem: 3702
Test:  [1150/1613]  eta: 0:00:55  loss: 0.4760 (1.0053)  labels_encoder: 0.2940 (0.6422)  labels_decoder: 0.1820 (0.3630)  labels_encoder_unscaled: 0.2940 (0.6422)  labels_decoder_unscaled: 0.3640 (0.7260)  time: 0.1158  data: 0.0162  max mem: 3702
Test:  [1200/1613]  eta: 0:00:49  loss: 0.5901 (1.0223)  labels_encoder: 0.3185 (0.6521)  labels_decoder: 0.2538 (0.3702)  labels_encoder_unscaled: 0.3185 (0.6521)  labels_decoder_unscaled: 0.5075 (0.7403)  time: 0.1233  data: 0.0124  max mem: 3702
Test:  [1250/1613]  eta: 0:00:43  loss: 0.3072 (1.0235)  labels_encoder: 0.1802 (0.6529)  labels_decoder: 0.1531 (0.3706)  labels_encoder_unscaled: 0.1802 (0.6529)  labels_decoder_unscaled: 0.3062 (0.7411)  time: 0.1201  data: 0.0546  max mem: 3702
Test:  [1300/1613]  eta: 0:00:37  loss: 0.5323 (1.0156)  labels_encoder: 0.3585 (0.6483)  labels_decoder: 0.2364 (0.3673)  labels_encoder_unscaled: 0.3585 (0.6483)  labels_decoder_unscaled: 0.4728 (0.7345)  time: 0.1251  data: 0.0087  max mem: 3702
Test:  [1350/1613]  eta: 0:00:31  loss: 1.3346 (1.0344)  labels_encoder: 0.7860 (0.6620)  labels_decoder: 0.5227 (0.3725)  labels_encoder_unscaled: 0.7860 (0.6620)  labels_decoder_unscaled: 1.0455 (0.7449)  time: 0.1232  data: 0.0434  max mem: 3702
Test:  [1400/1613]  eta: 0:00:25  loss: 1.0385 (1.0370)  labels_encoder: 0.7268 (0.6634)  labels_decoder: 0.3995 (0.3736)  labels_encoder_unscaled: 0.7268 (0.6634)  labels_decoder_unscaled: 0.7990 (0.7473)  time: 0.1131  data: 0.0200  max mem: 3702
Test:  [1450/1613]  eta: 0:00:19  loss: 0.7456 (1.0627)  labels_encoder: 0.4301 (0.6782)  labels_decoder: 0.4176 (0.3845)  labels_encoder_unscaled: 0.4301 (0.6782)  labels_decoder_unscaled: 0.8351 (0.7690)  time: 0.1193  data: 0.0198  max mem: 3702
Test:  [1500/1613]  eta: 0:00:13  loss: 0.7394 (1.0798)  labels_encoder: 0.4500 (0.6923)  labels_decoder: 0.2648 (0.3875)  labels_encoder_unscaled: 0.4500 (0.6923)  labels_decoder_unscaled: 0.5296 (0.7750)  time: 0.1050  data: 0.0004  max mem: 3702
Test:  [1550/1613]  eta: 0:00:07  loss: 0.7145 (1.0747)  labels_encoder: 0.4215 (0.6888)  labels_decoder: 0.3047 (0.3858)  labels_encoder_unscaled: 0.4215 (0.6888)  labels_decoder_unscaled: 0.6094 (0.7717)  time: 0.1235  data: 0.0464  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 1.5009 (1.0735)  labels_encoder: 1.0341 (0.6883)  labels_decoder: 0.4522 (0.3853)  labels_encoder_unscaled: 1.0341 (0.6883)  labels_decoder_unscaled: 0.9044 (0.7706)  time: 0.1338  data: 0.0247  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.9243 (1.0716)  labels_encoder: 0.6161 (0.6874)  labels_decoder: 0.3074 (0.3842)  labels_encoder_unscaled: 0.6161 (0.6874)  labels_decoder_unscaled: 0.6147 (0.7684)  time: 0.1173  data: 0.0098  max mem: 3702
Test: Total time: 0:03:14 (0.1207 s / it)
Averaged stats: loss: 0.9243 (1.0716)  labels_encoder: 0.6161 (0.6874)  labels_decoder: 0.3074 (0.3842)  labels_encoder_unscaled: 0.6161 (0.6874)  labels_decoder_unscaled: 0.6147 (0.7684)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-anet_audio] mAP: 0.5850

dec_mAP all together: | 0.48501013100578777 |.
dec_mAP_pred | 0 : 0.546716738889958 |.
dec_mAP_pred | 1 : 0.5338352927847821 |.
dec_mAP_pred | 2 : 0.5161227456346198 |.
dec_mAP_pred | 3 : 0.4971974212177905 |.
dec_mAP_pred | 4 : 0.47756998022097247 |.
dec_mAP_pred | 5 : 0.45893311183423957 |.
dec_mAP_pred | 6 : 0.4413195393905089 |.
dec_mAP_pred | 7 : 0.4254014198207541 |.
all decoder map: | 0.4871 |.
BaseballPitch: 0.1905
BasketballDunk: 0.7791
Billiards: 0.4682
CleanAndJerk: 0.7744
CliffDiving: 0.8207
CricketBowling: 0.4186
CricketShot: 0.2440
Diving: 0.7074
FrisbeeCatch: 0.2852
GolfSwing: 0.5931
HammerThrow: 0.8575
HighJump: 0.6659
JavelinThrow: 0.7191
LongJump: 0.7476
PoleVault: 0.8933
Shotput: 0.6712
SoccerPenalty: 0.2845
TennisSwing: 0.5713
ThrowDiscus: 0.6972
VolleyballSpiking: 0.3105
Epoch: [2]  [   0/1405]  eta: 1:33:47  lr: 0.000010  loss: 0.3470 (0.3470)  labels_encoder: 0.1884 (0.1884)  labels_decoder: 0.1586 (0.1586)  labels_encoder_unscaled: 0.1884 (0.1884)  labels_decoder_unscaled: 0.3173 (0.3173)  time: 4.0056  data: 3.7261  max mem: 3702
Epoch: [2]  [  50/1405]  eta: 0:06:31  lr: 0.000010  loss: 0.3102 (0.3388)  labels_encoder: 0.1741 (0.1874)  labels_decoder: 0.1313 (0.1514)  labels_encoder_unscaled: 0.1741 (0.1874)  labels_decoder_unscaled: 0.2627 (0.3029)  time: 0.2092  data: 0.0003  max mem: 3702
Epoch: [2]  [ 100/1405]  eta: 0:05:11  lr: 0.000010  loss: 0.2920 (0.3198)  labels_encoder: 0.1595 (0.1747)  labels_decoder: 0.1292 (0.1452)  labels_encoder_unscaled: 0.1595 (0.1747)  labels_decoder_unscaled: 0.2584 (0.2904)  time: 0.1827  data: 0.0003  max mem: 3702
Epoch: [2]  [ 150/1405]  eta: 0:04:41  lr: 0.000010  loss: 0.2848 (0.3115)  labels_encoder: 0.1492 (0.1689)  labels_decoder: 0.1376 (0.1426)  labels_encoder_unscaled: 0.1492 (0.1689)  labels_decoder_unscaled: 0.2752 (0.2852)  time: 0.1968  data: 0.0003  max mem: 3702
Epoch: [2]  [ 200/1405]  eta: 0:04:21  lr: 0.000010  loss: 0.3015 (0.3092)  labels_encoder: 0.1613 (0.1685)  labels_decoder: 0.1307 (0.1406)  labels_encoder_unscaled: 0.1613 (0.1685)  labels_decoder_unscaled: 0.2614 (0.2813)  time: 0.1921  data: 0.0003  max mem: 3702
Epoch: [2]  [ 250/1405]  eta: 0:04:04  lr: 0.000010  loss: 0.2794 (0.3059)  labels_encoder: 0.1416 (0.1664)  labels_decoder: 0.1396 (0.1395)  labels_encoder_unscaled: 0.1416 (0.1664)  labels_decoder_unscaled: 0.2791 (0.2790)  time: 0.1883  data: 0.0004  max mem: 3702
Epoch: [2]  [ 300/1405]  eta: 0:03:51  lr: 0.000010  loss: 0.2744 (0.3021)  labels_encoder: 0.1454 (0.1635)  labels_decoder: 0.1303 (0.1386)  labels_encoder_unscaled: 0.1454 (0.1635)  labels_decoder_unscaled: 0.2606 (0.2772)  time: 0.1951  data: 0.0003  max mem: 3702
Epoch: [2]  [ 350/1405]  eta: 0:03:39  lr: 0.000010  loss: 0.2676 (0.3004)  labels_encoder: 0.1434 (0.1621)  labels_decoder: 0.1262 (0.1384)  labels_encoder_unscaled: 0.1434 (0.1621)  labels_decoder_unscaled: 0.2524 (0.2767)  time: 0.2004  data: 0.0003  max mem: 3702
Epoch: [2]  [ 400/1405]  eta: 0:03:28  lr: 0.000010  loss: 0.2783 (0.2987)  labels_encoder: 0.1517 (0.1611)  labels_decoder: 0.1320 (0.1376)  labels_encoder_unscaled: 0.1517 (0.1611)  labels_decoder_unscaled: 0.2640 (0.2752)  time: 0.2033  data: 0.0004  max mem: 3702
Epoch: [2]  [ 450/1405]  eta: 0:03:17  lr: 0.000010  loss: 0.3146 (0.2990)  labels_encoder: 0.1821 (0.1615)  labels_decoder: 0.1387 (0.1375)  labels_encoder_unscaled: 0.1821 (0.1615)  labels_decoder_unscaled: 0.2773 (0.2751)  time: 0.2073  data: 0.0005  max mem: 3702
Epoch: [2]  [ 500/1405]  eta: 0:03:07  lr: 0.000010  loss: 0.2716 (0.2982)  labels_encoder: 0.1524 (0.1614)  labels_decoder: 0.1249 (0.1368)  labels_encoder_unscaled: 0.1524 (0.1614)  labels_decoder_unscaled: 0.2498 (0.2736)  time: 0.2098  data: 0.0005  max mem: 3702
Epoch: [2]  [ 550/1405]  eta: 0:02:56  lr: 0.000010  loss: 0.2605 (0.2971)  labels_encoder: 0.1343 (0.1606)  labels_decoder: 0.1232 (0.1365)  labels_encoder_unscaled: 0.1343 (0.1606)  labels_decoder_unscaled: 0.2463 (0.2729)  time: 0.2106  data: 0.0004  max mem: 3702
Epoch: [2]  [ 600/1405]  eta: 0:02:46  lr: 0.000010  loss: 0.3051 (0.2959)  labels_encoder: 0.1613 (0.1600)  labels_decoder: 0.1289 (0.1359)  labels_encoder_unscaled: 0.1613 (0.1600)  labels_decoder_unscaled: 0.2578 (0.2718)  time: 0.1998  data: 0.0003  max mem: 3702
Epoch: [2]  [ 650/1405]  eta: 0:02:35  lr: 0.000010  loss: 0.2782 (0.2948)  labels_encoder: 0.1407 (0.1594)  labels_decoder: 0.1286 (0.1355)  labels_encoder_unscaled: 0.1407 (0.1594)  labels_decoder_unscaled: 0.2572 (0.2710)  time: 0.1992  data: 0.0003  max mem: 3702
Epoch: [2]  [ 700/1405]  eta: 0:02:25  lr: 0.000010  loss: 0.2828 (0.2938)  labels_encoder: 0.1484 (0.1588)  labels_decoder: 0.1280 (0.1351)  labels_encoder_unscaled: 0.1484 (0.1588)  labels_decoder_unscaled: 0.2561 (0.2701)  time: 0.1907  data: 0.0003  max mem: 3702
Epoch: [2]  [ 750/1405]  eta: 0:02:14  lr: 0.000010  loss: 0.2621 (0.2922)  labels_encoder: 0.1399 (0.1576)  labels_decoder: 0.1219 (0.1346)  labels_encoder_unscaled: 0.1399 (0.1576)  labels_decoder_unscaled: 0.2439 (0.2692)  time: 0.1955  data: 0.0003  max mem: 3702
Epoch: [2]  [ 800/1405]  eta: 0:02:03  lr: 0.000010  loss: 0.2599 (0.2908)  labels_encoder: 0.1367 (0.1569)  labels_decoder: 0.1243 (0.1339)  labels_encoder_unscaled: 0.1367 (0.1569)  labels_decoder_unscaled: 0.2486 (0.2679)  time: 0.1862  data: 0.0003  max mem: 3702
Epoch: [2]  [ 850/1405]  eta: 0:01:53  lr: 0.000010  loss: 0.2826 (0.2894)  labels_encoder: 0.1431 (0.1557)  labels_decoder: 0.1314 (0.1337)  labels_encoder_unscaled: 0.1431 (0.1557)  labels_decoder_unscaled: 0.2628 (0.2674)  time: 0.2082  data: 0.0004  max mem: 3702
Epoch: [2]  [ 900/1405]  eta: 0:01:42  lr: 0.000010  loss: 0.2818 (0.2886)  labels_encoder: 0.1475 (0.1552)  labels_decoder: 0.1343 (0.1335)  labels_encoder_unscaled: 0.1475 (0.1552)  labels_decoder_unscaled: 0.2685 (0.2669)  time: 0.1710  data: 0.0003  max mem: 3702
Epoch: [2]  [ 950/1405]  eta: 0:01:32  lr: 0.000010  loss: 0.2935 (0.2884)  labels_encoder: 0.1607 (0.1553)  labels_decoder: 0.1319 (0.1330)  labels_encoder_unscaled: 0.1607 (0.1553)  labels_decoder_unscaled: 0.2637 (0.2661)  time: 0.1836  data: 0.0003  max mem: 3702
Epoch: [2]  [1000/1405]  eta: 0:01:21  lr: 0.000010  loss: 0.2962 (0.2876)  labels_encoder: 0.1601 (0.1551)  labels_decoder: 0.1241 (0.1325)  labels_encoder_unscaled: 0.1601 (0.1551)  labels_decoder_unscaled: 0.2482 (0.2650)  time: 0.1815  data: 0.0003  max mem: 3702
Epoch: [2]  [1050/1405]  eta: 0:01:11  lr: 0.000010  loss: 0.2813 (0.2866)  labels_encoder: 0.1406 (0.1544)  labels_decoder: 0.1285 (0.1322)  labels_encoder_unscaled: 0.1406 (0.1544)  labels_decoder_unscaled: 0.2571 (0.2644)  time: 0.1830  data: 0.0003  max mem: 3702
Epoch: [2]  [1100/1405]  eta: 0:01:01  lr: 0.000010  loss: 0.2472 (0.2857)  labels_encoder: 0.1328 (0.1538)  labels_decoder: 0.1202 (0.1319)  labels_encoder_unscaled: 0.1328 (0.1538)  labels_decoder_unscaled: 0.2405 (0.2637)  time: 0.1913  data: 0.0004  max mem: 3702
Epoch: [2]  [1150/1405]  eta: 0:00:50  lr: 0.000010  loss: 0.2681 (0.2851)  labels_encoder: 0.1246 (0.1534)  labels_decoder: 0.1296 (0.1316)  labels_encoder_unscaled: 0.1246 (0.1534)  labels_decoder_unscaled: 0.2592 (0.2632)  time: 0.1779  data: 0.0003  max mem: 3702
Epoch: [2]  [1200/1405]  eta: 0:00:40  lr: 0.000010  loss: 0.2581 (0.2842)  labels_encoder: 0.1439 (0.1529)  labels_decoder: 0.1239 (0.1313)  labels_encoder_unscaled: 0.1439 (0.1529)  labels_decoder_unscaled: 0.2478 (0.2626)  time: 0.1868  data: 0.0003  max mem: 3702
Epoch: [2]  [1250/1405]  eta: 0:00:30  lr: 0.000010  loss: 0.2331 (0.2836)  labels_encoder: 0.1213 (0.1525)  labels_decoder: 0.1142 (0.1311)  labels_encoder_unscaled: 0.1213 (0.1525)  labels_decoder_unscaled: 0.2284 (0.2622)  time: 0.2011  data: 0.0003  max mem: 3702
Epoch: [2]  [1300/1405]  eta: 0:00:20  lr: 0.000010  loss: 0.2650 (0.2834)  labels_encoder: 0.1459 (0.1524)  labels_decoder: 0.1263 (0.1310)  labels_encoder_unscaled: 0.1459 (0.1524)  labels_decoder_unscaled: 0.2526 (0.2620)  time: 0.1923  data: 0.0003  max mem: 3702
Epoch: [2]  [1350/1405]  eta: 0:00:10  lr: 0.000010  loss: 0.2560 (0.2825)  labels_encoder: 0.1368 (0.1517)  labels_decoder: 0.1252 (0.1308)  labels_encoder_unscaled: 0.1368 (0.1517)  labels_decoder_unscaled: 0.2503 (0.2615)  time: 0.2002  data: 0.0003  max mem: 3702
Epoch: [2]  [1400/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2252 (0.2817)  labels_encoder: 0.1218 (0.1513)  labels_decoder: 0.1108 (0.1304)  labels_encoder_unscaled: 0.1218 (0.1513)  labels_decoder_unscaled: 0.2215 (0.2607)  time: 0.1719  data: 0.0006  max mem: 3702
Epoch: [2]  [1404/1405]  eta: 0:00:00  lr: 0.000010  loss: 0.2275 (0.2816)  labels_encoder: 0.1170 (0.1513)  labels_decoder: 0.1108 (0.1304)  labels_encoder_unscaled: 0.1170 (0.1513)  labels_decoder_unscaled: 0.2215 (0.2607)  time: 0.1555  data: 0.0004  max mem: 3702
Epoch: [2] Total time: 0:04:38 (0.1985 s / it)
Averaged stats: lr: 0.000010  loss: 0.2275 (0.2816)  labels_encoder: 0.1170 (0.1513)  labels_decoder: 0.1108 (0.1304)  labels_encoder_unscaled: 0.1170 (0.1513)  labels_decoder_unscaled: 0.2215 (0.2607)
Test:  [   0/1613]  eta: 1:39:47  loss: 2.6657 (2.6657)  labels_encoder: 1.9414 (1.9414)  labels_decoder: 0.7243 (0.7243)  labels_encoder_unscaled: 1.9414 (1.9414)  labels_decoder_unscaled: 1.4486 (1.4486)  time: 3.7119  data: 3.4999  max mem: 3702
Test:  [  50/1613]  eta: 0:04:40  loss: 0.4749 (1.0221)  labels_encoder: 0.2906 (0.6420)  labels_decoder: 0.1840 (0.3802)  labels_encoder_unscaled: 0.2906 (0.6420)  labels_decoder_unscaled: 0.3680 (0.7604)  time: 0.1011  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:36  loss: 0.2725 (0.8071)  labels_encoder: 0.1800 (0.5177)  labels_decoder: 0.0724 (0.2894)  labels_encoder_unscaled: 0.1800 (0.5177)  labels_decoder_unscaled: 0.1449 (0.5788)  time: 0.1074  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:11  loss: 0.9276 (0.7858)  labels_encoder: 0.5846 (0.5097)  labels_decoder: 0.2609 (0.2761)  labels_encoder_unscaled: 0.5846 (0.5097)  labels_decoder_unscaled: 0.5218 (0.5521)  time: 0.1111  data: 0.0005  max mem: 3702
Test:  [ 200/1613]  eta: 0:02:54  loss: 1.0583 (0.9428)  labels_encoder: 0.6409 (0.6148)  labels_decoder: 0.4272 (0.3280)  labels_encoder_unscaled: 0.6409 (0.6148)  labels_decoder_unscaled: 0.8544 (0.6560)  time: 0.0978  data: 0.0021  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:44  loss: 0.6381 (0.9961)  labels_encoder: 0.3484 (0.6465)  labels_decoder: 0.2710 (0.3497)  labels_encoder_unscaled: 0.3484 (0.6465)  labels_decoder_unscaled: 0.5420 (0.6993)  time: 0.1018  data: 0.0002  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:35  loss: 0.5914 (0.9987)  labels_encoder: 0.3742 (0.6462)  labels_decoder: 0.2501 (0.3525)  labels_encoder_unscaled: 0.3742 (0.6462)  labels_decoder_unscaled: 0.5002 (0.7050)  time: 0.1127  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:27  loss: 1.0405 (0.9877)  labels_encoder: 0.5511 (0.6330)  labels_decoder: 0.4559 (0.3547)  labels_encoder_unscaled: 0.5511 (0.6330)  labels_decoder_unscaled: 0.9119 (0.7094)  time: 0.1085  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:20  loss: 0.8390 (1.1119)  labels_encoder: 0.4970 (0.7185)  labels_decoder: 0.3779 (0.3934)  labels_encoder_unscaled: 0.4970 (0.7185)  labels_decoder_unscaled: 0.7558 (0.7867)  time: 0.1096  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:13  loss: 0.9833 (1.1912)  labels_encoder: 0.6552 (0.7730)  labels_decoder: 0.3281 (0.4182)  labels_encoder_unscaled: 0.6552 (0.7730)  labels_decoder_unscaled: 0.6562 (0.8364)  time: 0.1130  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:07  loss: 0.3851 (1.1406)  labels_encoder: 0.2032 (0.7386)  labels_decoder: 0.1873 (0.4020)  labels_encoder_unscaled: 0.2032 (0.7386)  labels_decoder_unscaled: 0.3746 (0.8040)  time: 0.1124  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:02:00  loss: 0.5686 (1.1350)  labels_encoder: 0.3769 (0.7332)  labels_decoder: 0.2581 (0.4019)  labels_encoder_unscaled: 0.3769 (0.7332)  labels_decoder_unscaled: 0.5162 (0.8037)  time: 0.1067  data: 0.0009  max mem: 3702
Test:  [ 600/1613]  eta: 0:01:54  loss: 1.6096 (1.1800)  labels_encoder: 0.8813 (0.7727)  labels_decoder: 0.4680 (0.4073)  labels_encoder_unscaled: 0.8813 (0.7727)  labels_decoder_unscaled: 0.9361 (0.8147)  time: 0.1056  data: 0.0002  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:48  loss: 0.7667 (1.1634)  labels_encoder: 0.4441 (0.7577)  labels_decoder: 0.4089 (0.4058)  labels_encoder_unscaled: 0.4441 (0.7577)  labels_decoder_unscaled: 0.8178 (0.8116)  time: 0.1121  data: 0.0002  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:42  loss: 0.5559 (1.1331)  labels_encoder: 0.3081 (0.7363)  labels_decoder: 0.2458 (0.3968)  labels_encoder_unscaled: 0.3081 (0.7363)  labels_decoder_unscaled: 0.4915 (0.7936)  time: 0.1070  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:36  loss: 0.7406 (1.1114)  labels_encoder: 0.4396 (0.7207)  labels_decoder: 0.3147 (0.3907)  labels_encoder_unscaled: 0.4396 (0.7207)  labels_decoder_unscaled: 0.6294 (0.7814)  time: 0.1029  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:30  loss: 0.7744 (1.1092)  labels_encoder: 0.5041 (0.7205)  labels_decoder: 0.3157 (0.3887)  labels_encoder_unscaled: 0.5041 (0.7205)  labels_decoder_unscaled: 0.6315 (0.7774)  time: 0.1002  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:24  loss: 1.5356 (1.1086)  labels_encoder: 0.9848 (0.7175)  labels_decoder: 0.5915 (0.3911)  labels_encoder_unscaled: 0.9848 (0.7175)  labels_decoder_unscaled: 1.1830 (0.7822)  time: 0.1068  data: 0.0002  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:18  loss: 0.7400 (1.1281)  labels_encoder: 0.4896 (0.7300)  labels_decoder: 0.2949 (0.3980)  labels_encoder_unscaled: 0.4896 (0.7300)  labels_decoder_unscaled: 0.5897 (0.7961)  time: 0.1085  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:12  loss: 0.9607 (1.1158)  labels_encoder: 0.6246 (0.7222)  labels_decoder: 0.2949 (0.3936)  labels_encoder_unscaled: 0.6246 (0.7222)  labels_decoder_unscaled: 0.5898 (0.7873)  time: 0.0995  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:07  loss: 0.5551 (1.1033)  labels_encoder: 0.3318 (0.7133)  labels_decoder: 0.2310 (0.3900)  labels_encoder_unscaled: 0.3318 (0.7133)  labels_decoder_unscaled: 0.4620 (0.7799)  time: 0.1063  data: 0.0002  max mem: 3702
Test:  [1050/1613]  eta: 0:01:01  loss: 0.9287 (1.1000)  labels_encoder: 0.5396 (0.7113)  labels_decoder: 0.3327 (0.3887)  labels_encoder_unscaled: 0.5396 (0.7113)  labels_decoder_unscaled: 0.6654 (0.7774)  time: 0.1042  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:00:55  loss: 0.5333 (1.1023)  labels_encoder: 0.3729 (0.7143)  labels_decoder: 0.2935 (0.3880)  labels_encoder_unscaled: 0.3729 (0.7143)  labels_decoder_unscaled: 0.5870 (0.7760)  time: 0.1032  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:50  loss: 0.6842 (1.0888)  labels_encoder: 0.3573 (0.7050)  labels_decoder: 0.2722 (0.3838)  labels_encoder_unscaled: 0.3573 (0.7050)  labels_decoder_unscaled: 0.5444 (0.7676)  time: 0.1140  data: 0.0002  max mem: 3702
Test:  [1200/1613]  eta: 0:00:44  loss: 0.5247 (1.0934)  labels_encoder: 0.3834 (0.7081)  labels_decoder: 0.2195 (0.3853)  labels_encoder_unscaled: 0.3834 (0.7081)  labels_decoder_unscaled: 0.4389 (0.7707)  time: 0.1079  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:39  loss: 0.3838 (1.0908)  labels_encoder: 0.2023 (0.7056)  labels_decoder: 0.2010 (0.3852)  labels_encoder_unscaled: 0.2023 (0.7056)  labels_decoder_unscaled: 0.4020 (0.7704)  time: 0.1052  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:33  loss: 0.8880 (1.0833)  labels_encoder: 0.5449 (0.7003)  labels_decoder: 0.3342 (0.3831)  labels_encoder_unscaled: 0.5449 (0.7003)  labels_decoder_unscaled: 0.6684 (0.7661)  time: 0.1047  data: 0.0026  max mem: 3702
Test:  [1350/1613]  eta: 0:00:28  loss: 0.8905 (1.1008)  labels_encoder: 0.5704 (0.7125)  labels_decoder: 0.3653 (0.3883)  labels_encoder_unscaled: 0.5704 (0.7125)  labels_decoder_unscaled: 0.7306 (0.7765)  time: 0.0934  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:22  loss: 1.0153 (1.0938)  labels_encoder: 0.6535 (0.7075)  labels_decoder: 0.4191 (0.3863)  labels_encoder_unscaled: 0.6535 (0.7075)  labels_decoder_unscaled: 0.8383 (0.7727)  time: 0.1120  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:17  loss: 0.5877 (1.1043)  labels_encoder: 0.3538 (0.7128)  labels_decoder: 0.3418 (0.3914)  labels_encoder_unscaled: 0.3538 (0.7128)  labels_decoder_unscaled: 0.6836 (0.7829)  time: 0.1009  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:12  loss: 0.6760 (1.1139)  labels_encoder: 0.4135 (0.7203)  labels_decoder: 0.2254 (0.3935)  labels_encoder_unscaled: 0.4135 (0.7203)  labels_decoder_unscaled: 0.4508 (0.7871)  time: 0.0972  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:06  loss: 0.6747 (1.1071)  labels_encoder: 0.4396 (0.7162)  labels_decoder: 0.2351 (0.3909)  labels_encoder_unscaled: 0.4396 (0.7162)  labels_decoder_unscaled: 0.4701 (0.7819)  time: 0.1040  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8598 (1.1008)  labels_encoder: 0.5473 (0.7116)  labels_decoder: 0.3124 (0.3892)  labels_encoder_unscaled: 0.5473 (0.7116)  labels_decoder_unscaled: 0.6247 (0.7785)  time: 0.1054  data: 0.0002  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.4351 (1.0993)  labels_encoder: 0.2847 (0.7109)  labels_decoder: 0.2021 (0.3884)  labels_encoder_unscaled: 0.2847 (0.7109)  labels_decoder_unscaled: 0.4042 (0.7768)  time: 0.0821  data: 0.0001  max mem: 3702
Test: Total time: 0:02:53 (0.1077 s / it)
Averaged stats: loss: 0.4351 (1.0993)  labels_encoder: 0.2847 (0.7109)  labels_decoder: 0.2021 (0.3884)  labels_encoder_unscaled: 0.2847 (0.7109)  labels_decoder_unscaled: 0.4042 (0.7768)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-anet_audio] mAP: 0.5840

dec_mAP all together: | 0.4714892989683189 |.
dec_mAP_pred | 0 : 0.5196901817029101 |.
dec_mAP_pred | 1 : 0.5105134410418348 |.
dec_mAP_pred | 2 : 0.49703170310770844 |.
dec_mAP_pred | 3 : 0.48212933181353373 |.
dec_mAP_pred | 4 : 0.46632545306213685 |.
dec_mAP_pred | 5 : 0.4510131735063002 |.
dec_mAP_pred | 6 : 0.4359078291431624 |.
dec_mAP_pred | 7 : 0.4217755040183273 |.
all decoder map: | 0.4730 |.
BaseballPitch: 0.1554
BasketballDunk: 0.7718
Billiards: 0.4528
CleanAndJerk: 0.7479
CliffDiving: 0.8143
CricketBowling: 0.4494
CricketShot: 0.2464
Diving: 0.6898
FrisbeeCatch: 0.3600
GolfSwing: 0.6080
HammerThrow: 0.8570
HighJump: 0.6466
JavelinThrow: 0.6841
LongJump: 0.7861
PoleVault: 0.8732
Shotput: 0.6875
SoccerPenalty: 0.3058
TennisSwing: 0.5783
ThrowDiscus: 0.6542
VolleyballSpiking: 0.3118
Epoch: [3]  [   0/1405]  eta: 1:21:44  lr: 0.000001  loss: 0.2414 (0.2414)  labels_encoder: 0.1014 (0.1014)  labels_decoder: 0.1401 (0.1401)  labels_encoder_unscaled: 0.1014 (0.1014)  labels_decoder_unscaled: 0.2801 (0.2801)  time: 3.4910  data: 3.2384  max mem: 3702
Epoch: [3]  [  50/1405]  eta: 0:06:03  lr: 0.000001  loss: 0.2362 (0.2390)  labels_encoder: 0.1240 (0.1231)  labels_decoder: 0.1110 (0.1158)  labels_encoder_unscaled: 0.1240 (0.1231)  labels_decoder_unscaled: 0.2220 (0.2317)  time: 0.1916  data: 0.0003  max mem: 3702
Epoch: [3]  [ 100/1405]  eta: 0:05:00  lr: 0.000001  loss: 0.2370 (0.2399)  labels_encoder: 0.1135 (0.1230)  labels_decoder: 0.1195 (0.1169)  labels_encoder_unscaled: 0.1135 (0.1230)  labels_decoder_unscaled: 0.2389 (0.2338)  time: 0.1939  data: 0.0003  max mem: 3702
Epoch: [3]  [ 150/1405]  eta: 0:04:39  lr: 0.000001  loss: 0.2373 (0.2436)  labels_encoder: 0.1141 (0.1254)  labels_decoder: 0.1246 (0.1182)  labels_encoder_unscaled: 0.1141 (0.1254)  labels_decoder_unscaled: 0.2492 (0.2364)  time: 0.2094  data: 0.0003  max mem: 3702
Epoch: [3]  [ 200/1405]  eta: 0:04:23  lr: 0.000001  loss: 0.2361 (0.2442)  labels_encoder: 0.1238 (0.1258)  labels_decoder: 0.1191 (0.1184)  labels_encoder_unscaled: 0.1238 (0.1258)  labels_decoder_unscaled: 0.2381 (0.2368)  time: 0.2145  data: 0.0003  max mem: 3702
Epoch: [3]  [ 250/1405]  eta: 0:04:13  lr: 0.000001  loss: 0.2546 (0.2466)  labels_encoder: 0.1260 (0.1275)  labels_decoder: 0.1215 (0.1191)  labels_encoder_unscaled: 0.1260 (0.1275)  labels_decoder_unscaled: 0.2431 (0.2383)  time: 0.2205  data: 0.0004  max mem: 3702
Epoch: [3]  [ 300/1405]  eta: 0:04:00  lr: 0.000001  loss: 0.2525 (0.2477)  labels_encoder: 0.1296 (0.1286)  labels_decoder: 0.1206 (0.1191)  labels_encoder_unscaled: 0.1296 (0.1286)  labels_decoder_unscaled: 0.2412 (0.2382)  time: 0.1996  data: 0.0003  max mem: 3702
Epoch: [3]  [ 350/1405]  eta: 0:03:46  lr: 0.000001  loss: 0.2435 (0.2481)  labels_encoder: 0.1278 (0.1292)  labels_decoder: 0.1147 (0.1190)  labels_encoder_unscaled: 0.1278 (0.1292)  labels_decoder_unscaled: 0.2294 (0.2379)  time: 0.2105  data: 0.0003  max mem: 3702
Epoch: [3]  [ 400/1405]  eta: 0:03:34  lr: 0.000001  loss: 0.2407 (0.2464)  labels_encoder: 0.1192 (0.1280)  labels_decoder: 0.1170 (0.1184)  labels_encoder_unscaled: 0.1192 (0.1280)  labels_decoder_unscaled: 0.2339 (0.2368)  time: 0.2069  data: 0.0003  max mem: 3702
Epoch: [3]  [ 450/1405]  eta: 0:03:23  lr: 0.000001  loss: 0.2327 (0.2465)  labels_encoder: 0.1168 (0.1277)  labels_decoder: 0.1168 (0.1188)  labels_encoder_unscaled: 0.1168 (0.1277)  labels_decoder_unscaled: 0.2337 (0.2375)  time: 0.2185  data: 0.0004  max mem: 3702
Epoch: [3]  [ 500/1405]  eta: 0:03:12  lr: 0.000001  loss: 0.2549 (0.2473)  labels_encoder: 0.1332 (0.1283)  labels_decoder: 0.1166 (0.1190)  labels_encoder_unscaled: 0.1332 (0.1283)  labels_decoder_unscaled: 0.2331 (0.2380)  time: 0.2150  data: 0.0004  max mem: 3702
Epoch: [3]  [ 550/1405]  eta: 0:03:01  lr: 0.000001  loss: 0.2493 (0.2479)  labels_encoder: 0.1315 (0.1288)  labels_decoder: 0.1158 (0.1191)  labels_encoder_unscaled: 0.1315 (0.1288)  labels_decoder_unscaled: 0.2317 (0.2383)  time: 0.2043  data: 0.0004  max mem: 3702
Epoch: [3]  [ 600/1405]  eta: 0:02:49  lr: 0.000001  loss: 0.2394 (0.2476)  labels_encoder: 0.1234 (0.1285)  labels_decoder: 0.1188 (0.1192)  labels_encoder_unscaled: 0.1234 (0.1285)  labels_decoder_unscaled: 0.2377 (0.2383)  time: 0.1993  data: 0.0003  max mem: 3702
Epoch: [3]  [ 650/1405]  eta: 0:02:40  lr: 0.000001  loss: 0.2269 (0.2474)  labels_encoder: 0.1124 (0.1283)  labels_decoder: 0.1175 (0.1191)  labels_encoder_unscaled: 0.1124 (0.1283)  labels_decoder_unscaled: 0.2349 (0.2382)  time: 0.2405  data: 0.0004  max mem: 3702
Epoch: [3]  [ 700/1405]  eta: 0:02:30  lr: 0.000001  loss: 0.2348 (0.2468)  labels_encoder: 0.1162 (0.1279)  labels_decoder: 0.1192 (0.1189)  labels_encoder_unscaled: 0.1162 (0.1279)  labels_decoder_unscaled: 0.2384 (0.2378)  time: 0.2284  data: 0.0004  max mem: 3702
Epoch: [3]  [ 750/1405]  eta: 0:02:21  lr: 0.000001  loss: 0.2241 (0.2468)  labels_encoder: 0.1061 (0.1279)  labels_decoder: 0.1142 (0.1189)  labels_encoder_unscaled: 0.1061 (0.1279)  labels_decoder_unscaled: 0.2284 (0.2378)  time: 0.2389  data: 0.0043  max mem: 3702
Epoch: [3]  [ 800/1405]  eta: 0:02:12  lr: 0.000001  loss: 0.2369 (0.2473)  labels_encoder: 0.1166 (0.1284)  labels_decoder: 0.1145 (0.1188)  labels_encoder_unscaled: 0.1166 (0.1284)  labels_decoder_unscaled: 0.2290 (0.2376)  time: 0.2839  data: 0.0005  max mem: 3702
Epoch: [3]  [ 850/1405]  eta: 0:02:02  lr: 0.000001  loss: 0.2336 (0.2475)  labels_encoder: 0.1157 (0.1285)  labels_decoder: 0.1216 (0.1190)  labels_encoder_unscaled: 0.1157 (0.1285)  labels_decoder_unscaled: 0.2432 (0.2380)  time: 0.2154  data: 0.0004  max mem: 3702
Epoch: [3]  [ 900/1405]  eta: 0:01:50  lr: 0.000001  loss: 0.2358 (0.2473)  labels_encoder: 0.1194 (0.1283)  labels_decoder: 0.1164 (0.1190)  labels_encoder_unscaled: 0.1194 (0.1283)  labels_decoder_unscaled: 0.2327 (0.2380)  time: 0.2145  data: 0.0004  max mem: 3702
Epoch: [3]  [ 950/1405]  eta: 0:01:39  lr: 0.000001  loss: 0.2524 (0.2470)  labels_encoder: 0.1280 (0.1281)  labels_decoder: 0.1175 (0.1190)  labels_encoder_unscaled: 0.1280 (0.1281)  labels_decoder_unscaled: 0.2350 (0.2379)  time: 0.2000  data: 0.0004  max mem: 3702
Epoch: [3]  [1000/1405]  eta: 0:01:27  lr: 0.000001  loss: 0.2300 (0.2472)  labels_encoder: 0.1137 (0.1281)  labels_decoder: 0.1125 (0.1190)  labels_encoder_unscaled: 0.1137 (0.1281)  labels_decoder_unscaled: 0.2249 (0.2381)  time: 0.1794  data: 0.0003  max mem: 3702
Epoch: [3]  [1050/1405]  eta: 0:01:16  lr: 0.000001  loss: 0.2495 (0.2475)  labels_encoder: 0.1348 (0.1283)  labels_decoder: 0.1199 (0.1192)  labels_encoder_unscaled: 0.1348 (0.1283)  labels_decoder_unscaled: 0.2398 (0.2384)  time: 0.1835  data: 0.0003  max mem: 3702
Epoch: [3]  [1100/1405]  eta: 0:01:05  lr: 0.000001  loss: 0.2429 (0.2475)  labels_encoder: 0.1259 (0.1284)  labels_decoder: 0.1110 (0.1191)  labels_encoder_unscaled: 0.1259 (0.1284)  labels_decoder_unscaled: 0.2220 (0.2382)  time: 0.1865  data: 0.0004  max mem: 3702
Epoch: [3]  [1150/1405]  eta: 0:00:54  lr: 0.000001  loss: 0.2617 (0.2476)  labels_encoder: 0.1285 (0.1284)  labels_decoder: 0.1168 (0.1192)  labels_encoder_unscaled: 0.1285 (0.1284)  labels_decoder_unscaled: 0.2335 (0.2384)  time: 0.2028  data: 0.0003  max mem: 3702
Epoch: [3]  [1200/1405]  eta: 0:00:43  lr: 0.000001  loss: 0.2376 (0.2470)  labels_encoder: 0.1235 (0.1280)  labels_decoder: 0.1157 (0.1191)  labels_encoder_unscaled: 0.1235 (0.1280)  labels_decoder_unscaled: 0.2314 (0.2381)  time: 0.1965  data: 0.0003  max mem: 3702
Epoch: [3]  [1250/1405]  eta: 0:00:32  lr: 0.000001  loss: 0.2408 (0.2475)  labels_encoder: 0.1227 (0.1282)  labels_decoder: 0.1219 (0.1193)  labels_encoder_unscaled: 0.1227 (0.1282)  labels_decoder_unscaled: 0.2438 (0.2386)  time: 0.1947  data: 0.0003  max mem: 3702
Epoch: [3]  [1300/1405]  eta: 0:00:22  lr: 0.000001  loss: 0.2387 (0.2475)  labels_encoder: 0.1184 (0.1283)  labels_decoder: 0.1197 (0.1192)  labels_encoder_unscaled: 0.1184 (0.1283)  labels_decoder_unscaled: 0.2393 (0.2384)  time: 0.1861  data: 0.0003  max mem: 3702
Epoch: [3]  [1350/1405]  eta: 0:00:11  lr: 0.000001  loss: 0.2660 (0.2478)  labels_encoder: 0.1373 (0.1286)  labels_decoder: 0.1138 (0.1192)  labels_encoder_unscaled: 0.1373 (0.1286)  labels_decoder_unscaled: 0.2275 (0.2384)  time: 0.1929  data: 0.0003  max mem: 3702
Epoch: [3]  [1400/1405]  eta: 0:00:01  lr: 0.000001  loss: 0.2554 (0.2481)  labels_encoder: 0.1415 (0.1288)  labels_decoder: 0.1193 (0.1193)  labels_encoder_unscaled: 0.1415 (0.1288)  labels_decoder_unscaled: 0.2385 (0.2386)  time: 0.1660  data: 0.0004  max mem: 3702
Epoch: [3]  [1404/1405]  eta: 0:00:00  lr: 0.000001  loss: 0.2554 (0.2481)  labels_encoder: 0.1415 (0.1288)  labels_decoder: 0.1193 (0.1193)  labels_encoder_unscaled: 0.1415 (0.1288)  labels_decoder_unscaled: 0.2385 (0.2386)  time: 0.1599  data: 0.0003  max mem: 3702
Epoch: [3] Total time: 0:04:54 (0.2095 s / it)
Averaged stats: lr: 0.000001  loss: 0.2554 (0.2481)  labels_encoder: 0.1415 (0.1288)  labels_decoder: 0.1193 (0.1193)  labels_encoder_unscaled: 0.1415 (0.1288)  labels_decoder_unscaled: 0.2385 (0.2386)
Test:  [   0/1613]  eta: 1:38:59  loss: 2.0246 (2.0246)  labels_encoder: 1.3630 (1.3630)  labels_decoder: 0.6616 (0.6616)  labels_encoder_unscaled: 1.3630 (1.3630)  labels_decoder_unscaled: 1.3232 (1.3232)  time: 3.6822  data: 3.6204  max mem: 3702
Test:  [  50/1613]  eta: 0:04:42  loss: 0.4567 (1.0204)  labels_encoder: 0.2880 (0.6435)  labels_decoder: 0.1851 (0.3768)  labels_encoder_unscaled: 0.2880 (0.6435)  labels_decoder_unscaled: 0.3702 (0.7537)  time: 0.1111  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:35  loss: 0.2848 (0.7874)  labels_encoder: 0.1822 (0.5041)  labels_decoder: 0.0682 (0.2834)  labels_encoder_unscaled: 0.1822 (0.5041)  labels_decoder_unscaled: 0.1364 (0.5667)  time: 0.1129  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:03:08  loss: 0.8825 (0.7694)  labels_encoder: 0.5836 (0.4963)  labels_decoder: 0.2720 (0.2731)  labels_encoder_unscaled: 0.5836 (0.4963)  labels_decoder_unscaled: 0.5440 (0.5462)  time: 0.1046  data: 0.0085  max mem: 3702
Test:  [ 200/1613]  eta: 0:02:53  loss: 1.0097 (0.9250)  labels_encoder: 0.6091 (0.6016)  labels_decoder: 0.3857 (0.3234)  labels_encoder_unscaled: 0.6091 (0.6016)  labels_decoder_unscaled: 0.7714 (0.6468)  time: 0.1043  data: 0.0002  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:44  loss: 0.5813 (0.9828)  labels_encoder: 0.3307 (0.6381)  labels_decoder: 0.2488 (0.3447)  labels_encoder_unscaled: 0.3307 (0.6381)  labels_decoder_unscaled: 0.4977 (0.6895)  time: 0.1064  data: 0.0002  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:34  loss: 0.5696 (0.9954)  labels_encoder: 0.3517 (0.6451)  labels_decoder: 0.2662 (0.3503)  labels_encoder_unscaled: 0.3517 (0.6451)  labels_decoder_unscaled: 0.5323 (0.7006)  time: 0.1045  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:26  loss: 1.1043 (0.9913)  labels_encoder: 0.6460 (0.6361)  labels_decoder: 0.4748 (0.3552)  labels_encoder_unscaled: 0.6460 (0.6361)  labels_decoder_unscaled: 0.9496 (0.7104)  time: 0.1020  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:18  loss: 0.8368 (1.1376)  labels_encoder: 0.4556 (0.7362)  labels_decoder: 0.3762 (0.4014)  labels_encoder_unscaled: 0.4556 (0.7362)  labels_decoder_unscaled: 0.7523 (0.8027)  time: 0.1046  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:11  loss: 0.9057 (1.2168)  labels_encoder: 0.5962 (0.7911)  labels_decoder: 0.3095 (0.4258)  labels_encoder_unscaled: 0.5962 (0.7911)  labels_decoder_unscaled: 0.6190 (0.8516)  time: 0.1154  data: 0.0050  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:04  loss: 0.3507 (1.1647)  labels_encoder: 0.1991 (0.7556)  labels_decoder: 0.1930 (0.4091)  labels_encoder_unscaled: 0.1991 (0.7556)  labels_decoder_unscaled: 0.3861 (0.8182)  time: 0.1058  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:01:58  loss: 0.5193 (1.1562)  labels_encoder: 0.2908 (0.7484)  labels_decoder: 0.2738 (0.4078)  labels_encoder_unscaled: 0.2908 (0.7484)  labels_decoder_unscaled: 0.5476 (0.8157)  time: 0.1172  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:01:52  loss: 1.6185 (1.1946)  labels_encoder: 0.9770 (0.7824)  labels_decoder: 0.4767 (0.4122)  labels_encoder_unscaled: 0.9770 (0.7824)  labels_decoder_unscaled: 0.9535 (0.8244)  time: 0.1201  data: 0.0002  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:46  loss: 0.9045 (1.1795)  labels_encoder: 0.5339 (0.7687)  labels_decoder: 0.4455 (0.4108)  labels_encoder_unscaled: 0.5339 (0.7687)  labels_decoder_unscaled: 0.8910 (0.8215)  time: 0.1116  data: 0.0002  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:41  loss: 0.5588 (1.1495)  labels_encoder: 0.3124 (0.7478)  labels_decoder: 0.2208 (0.4017)  labels_encoder_unscaled: 0.3124 (0.7478)  labels_decoder_unscaled: 0.4416 (0.8034)  time: 0.1120  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:35  loss: 0.8512 (1.1310)  labels_encoder: 0.5103 (0.7349)  labels_decoder: 0.3409 (0.3961)  labels_encoder_unscaled: 0.5103 (0.7349)  labels_decoder_unscaled: 0.6819 (0.7923)  time: 0.1004  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:30  loss: 0.8609 (1.1290)  labels_encoder: 0.4857 (0.7345)  labels_decoder: 0.3164 (0.3945)  labels_encoder_unscaled: 0.4857 (0.7345)  labels_decoder_unscaled: 0.6329 (0.7889)  time: 0.1092  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:24  loss: 1.6242 (1.1291)  labels_encoder: 1.0247 (0.7322)  labels_decoder: 0.5994 (0.3969)  labels_encoder_unscaled: 1.0247 (0.7322)  labels_decoder_unscaled: 1.1989 (0.7938)  time: 0.1130  data: 0.0027  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:18  loss: 0.7793 (1.1486)  labels_encoder: 0.4988 (0.7452)  labels_decoder: 0.2948 (0.4033)  labels_encoder_unscaled: 0.4988 (0.7452)  labels_decoder_unscaled: 0.5896 (0.8066)  time: 0.1011  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:12  loss: 0.9909 (1.1393)  labels_encoder: 0.6656 (0.7395)  labels_decoder: 0.3392 (0.3998)  labels_encoder_unscaled: 0.6656 (0.7395)  labels_decoder_unscaled: 0.6784 (0.7996)  time: 0.1074  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:07  loss: 0.6167 (1.1286)  labels_encoder: 0.3554 (0.7318)  labels_decoder: 0.2784 (0.3968)  labels_encoder_unscaled: 0.3554 (0.7318)  labels_decoder_unscaled: 0.5568 (0.7936)  time: 0.1063  data: 0.0002  max mem: 3702
Test:  [1050/1613]  eta: 0:01:01  loss: 0.8711 (1.1253)  labels_encoder: 0.5153 (0.7300)  labels_decoder: 0.3021 (0.3953)  labels_encoder_unscaled: 0.5153 (0.7300)  labels_decoder_unscaled: 0.6043 (0.7907)  time: 0.1057  data: 0.0023  max mem: 3702
Test:  [1100/1613]  eta: 0:00:56  loss: 0.6847 (1.1302)  labels_encoder: 0.4601 (0.7350)  labels_decoder: 0.3221 (0.3952)  labels_encoder_unscaled: 0.4601 (0.7350)  labels_decoder_unscaled: 0.6443 (0.7903)  time: 0.1060  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:50  loss: 0.6546 (1.1162)  labels_encoder: 0.3764 (0.7254)  labels_decoder: 0.2782 (0.3908)  labels_encoder_unscaled: 0.3764 (0.7254)  labels_decoder_unscaled: 0.5564 (0.7815)  time: 0.1028  data: 0.0030  max mem: 3702
Test:  [1200/1613]  eta: 0:00:44  loss: 0.4708 (1.1199)  labels_encoder: 0.2915 (0.7276)  labels_decoder: 0.2079 (0.3924)  labels_encoder_unscaled: 0.2915 (0.7276)  labels_decoder_unscaled: 0.4158 (0.7847)  time: 0.1092  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:39  loss: 0.4100 (1.1184)  labels_encoder: 0.2047 (0.7261)  labels_decoder: 0.1960 (0.3923)  labels_encoder_unscaled: 0.2047 (0.7261)  labels_decoder_unscaled: 0.3920 (0.7845)  time: 0.0962  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:33  loss: 0.9033 (1.1117)  labels_encoder: 0.5626 (0.7214)  labels_decoder: 0.3060 (0.3903)  labels_encoder_unscaled: 0.5626 (0.7214)  labels_decoder_unscaled: 0.6120 (0.7806)  time: 0.0999  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:28  loss: 0.9377 (1.1301)  labels_encoder: 0.5571 (0.7346)  labels_decoder: 0.3806 (0.3955)  labels_encoder_unscaled: 0.5571 (0.7346)  labels_decoder_unscaled: 0.7612 (0.7911)  time: 0.0931  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:22  loss: 0.9526 (1.1235)  labels_encoder: 0.6580 (0.7300)  labels_decoder: 0.3960 (0.3935)  labels_encoder_unscaled: 0.6580 (0.7300)  labels_decoder_unscaled: 0.7920 (0.7871)  time: 0.0961  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:17  loss: 0.6904 (1.1315)  labels_encoder: 0.3800 (0.7344)  labels_decoder: 0.3537 (0.3971)  labels_encoder_unscaled: 0.3800 (0.7344)  labels_decoder_unscaled: 0.7074 (0.7942)  time: 0.0954  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:12  loss: 0.7722 (1.1428)  labels_encoder: 0.4874 (0.7429)  labels_decoder: 0.2503 (0.3998)  labels_encoder_unscaled: 0.4874 (0.7429)  labels_decoder_unscaled: 0.5007 (0.7997)  time: 0.0926  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:06  loss: 0.7151 (1.1375)  labels_encoder: 0.4800 (0.7399)  labels_decoder: 0.2606 (0.3976)  labels_encoder_unscaled: 0.4800 (0.7399)  labels_decoder_unscaled: 0.5213 (0.7953)  time: 0.0981  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9295 (1.1320)  labels_encoder: 0.5848 (0.7357)  labels_decoder: 0.3446 (0.3963)  labels_encoder_unscaled: 0.5848 (0.7357)  labels_decoder_unscaled: 0.6893 (0.7925)  time: 0.0984  data: 0.0002  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5075 (1.1304)  labels_encoder: 0.3277 (0.7350)  labels_decoder: 0.2175 (0.3954)  labels_encoder_unscaled: 0.3277 (0.7350)  labels_decoder_unscaled: 0.4349 (0.7909)  time: 0.0860  data: 0.0001  max mem: 3702
Test: Total time: 0:02:51 (0.1065 s / it)
Averaged stats: loss: 0.5075 (1.1304)  labels_encoder: 0.3277 (0.7350)  labels_decoder: 0.2175 (0.3954)  labels_encoder_unscaled: 0.3277 (0.7350)  labels_decoder_unscaled: 0.4349 (0.7909)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-anet_audio] mAP: 0.5799

dec_mAP all together: | 0.4669286974865722 |.
dec_mAP_pred | 0 : 0.5123687791964016 |.
dec_mAP_pred | 1 : 0.503917306515195 |.
dec_mAP_pred | 2 : 0.4913097438454047 |.
dec_mAP_pred | 3 : 0.47725781946474843 |.
dec_mAP_pred | 4 : 0.46223005932161493 |.
dec_mAP_pred | 5 : 0.4475792875562841 |.
dec_mAP_pred | 6 : 0.43302041242114153 |.
dec_mAP_pred | 7 : 0.4194327757756837 |.
all decoder map: | 0.4684 |.
BaseballPitch: 0.1395
BasketballDunk: 0.7696
Billiards: 0.4576
CleanAndJerk: 0.7474
CliffDiving: 0.8070
CricketBowling: 0.4465
CricketShot: 0.2461
Diving: 0.6911
FrisbeeCatch: 0.3507
GolfSwing: 0.6013
HammerThrow: 0.8539
HighJump: 0.6430
JavelinThrow: 0.6769
LongJump: 0.7752
PoleVault: 0.8676
Shotput: 0.6778
SoccerPenalty: 0.3204
TennisSwing: 0.5791
ThrowDiscus: 0.6404
VolleyballSpiking: 0.3071
Epoch: [4]  [   0/1405]  eta: 1:13:31  lr: 0.000000  loss: 0.2582 (0.2582)  labels_encoder: 0.1358 (0.1358)  labels_decoder: 0.1224 (0.1224)  labels_encoder_unscaled: 0.1358 (0.1358)  labels_decoder_unscaled: 0.2447 (0.2447)  time: 3.1396  data: 2.9099  max mem: 3702
Epoch: [4]  [  50/1405]  eta: 0:05:42  lr: 0.000000  loss: 0.2367 (0.2456)  labels_encoder: 0.1225 (0.1283)  labels_decoder: 0.1142 (0.1172)  labels_encoder_unscaled: 0.1225 (0.1283)  labels_decoder_unscaled: 0.2284 (0.2345)  time: 0.1803  data: 0.0003  max mem: 3702
Epoch: [4]  [ 100/1405]  eta: 0:04:44  lr: 0.000000  loss: 0.2431 (0.2471)  labels_encoder: 0.1240 (0.1296)  labels_decoder: 0.1116 (0.1175)  labels_encoder_unscaled: 0.1240 (0.1296)  labels_decoder_unscaled: 0.2233 (0.2350)  time: 0.1821  data: 0.0003  max mem: 3702
Epoch: [4]  [ 150/1405]  eta: 0:04:23  lr: 0.000000  loss: 0.2303 (0.2438)  labels_encoder: 0.1133 (0.1263)  labels_decoder: 0.1138 (0.1174)  labels_encoder_unscaled: 0.1133 (0.1263)  labels_decoder_unscaled: 0.2275 (0.2349)  time: 0.1936  data: 0.0003  max mem: 3702
Epoch: [4]  [ 200/1405]  eta: 0:04:05  lr: 0.000000  loss: 0.2424 (0.2440)  labels_encoder: 0.1318 (0.1263)  labels_decoder: 0.1243 (0.1177)  labels_encoder_unscaled: 0.1318 (0.1263)  labels_decoder_unscaled: 0.2485 (0.2354)  time: 0.1882  data: 0.0003  max mem: 3702
Epoch: [4]  [ 250/1405]  eta: 0:03:50  lr: 0.000000  loss: 0.2409 (0.2453)  labels_encoder: 0.1275 (0.1279)  labels_decoder: 0.1100 (0.1175)  labels_encoder_unscaled: 0.1275 (0.1279)  labels_decoder_unscaled: 0.2200 (0.2349)  time: 0.1825  data: 0.0003  max mem: 3702
Epoch: [4]  [ 300/1405]  eta: 0:03:38  lr: 0.000000  loss: 0.2360 (0.2440)  labels_encoder: 0.1138 (0.1262)  labels_decoder: 0.1201 (0.1177)  labels_encoder_unscaled: 0.1138 (0.1262)  labels_decoder_unscaled: 0.2402 (0.2355)  time: 0.1906  data: 0.0003  max mem: 3702
Epoch: [4]  [ 350/1405]  eta: 0:03:27  lr: 0.000000  loss: 0.2624 (0.2453)  labels_encoder: 0.1291 (0.1267)  labels_decoder: 0.1215 (0.1187)  labels_encoder_unscaled: 0.1291 (0.1267)  labels_decoder_unscaled: 0.2430 (0.2373)  time: 0.1847  data: 0.0003  max mem: 3702
Epoch: [4]  [ 400/1405]  eta: 0:03:16  lr: 0.000000  loss: 0.2384 (0.2465)  labels_encoder: 0.1246 (0.1277)  labels_decoder: 0.1134 (0.1188)  labels_encoder_unscaled: 0.1246 (0.1277)  labels_decoder_unscaled: 0.2268 (0.2376)  time: 0.1849  data: 0.0003  max mem: 3702
Epoch: [4]  [ 450/1405]  eta: 0:03:06  lr: 0.000000  loss: 0.2581 (0.2465)  labels_encoder: 0.1207 (0.1280)  labels_decoder: 0.1106 (0.1184)  labels_encoder_unscaled: 0.1207 (0.1280)  labels_decoder_unscaled: 0.2213 (0.2369)  time: 0.1864  data: 0.0003  max mem: 3702
Epoch: [4]  [ 500/1405]  eta: 0:02:55  lr: 0.000000  loss: 0.2274 (0.2459)  labels_encoder: 0.1136 (0.1278)  labels_decoder: 0.1141 (0.1182)  labels_encoder_unscaled: 0.1136 (0.1278)  labels_decoder_unscaled: 0.2282 (0.2363)  time: 0.1865  data: 0.0003  max mem: 3702
Epoch: [4]  [ 550/1405]  eta: 0:02:45  lr: 0.000000  loss: 0.2478 (0.2461)  labels_encoder: 0.1389 (0.1279)  labels_decoder: 0.1196 (0.1182)  labels_encoder_unscaled: 0.1389 (0.1279)  labels_decoder_unscaled: 0.2391 (0.2364)  time: 0.1828  data: 0.0003  max mem: 3702
Epoch: [4]  [ 600/1405]  eta: 0:02:35  lr: 0.000000  loss: 0.2511 (0.2457)  labels_encoder: 0.1213 (0.1275)  labels_decoder: 0.1126 (0.1182)  labels_encoder_unscaled: 0.1213 (0.1275)  labels_decoder_unscaled: 0.2252 (0.2364)  time: 0.1893  data: 0.0003  max mem: 3702
Epoch: [4]  [ 650/1405]  eta: 0:02:25  lr: 0.000000  loss: 0.2404 (0.2460)  labels_encoder: 0.1397 (0.1276)  labels_decoder: 0.1075 (0.1183)  labels_encoder_unscaled: 0.1397 (0.1276)  labels_decoder_unscaled: 0.2150 (0.2367)  time: 0.1907  data: 0.0003  max mem: 3702
Epoch: [4]  [ 700/1405]  eta: 0:02:16  lr: 0.000000  loss: 0.2363 (0.2453)  labels_encoder: 0.1255 (0.1273)  labels_decoder: 0.1031 (0.1181)  labels_encoder_unscaled: 0.1255 (0.1273)  labels_decoder_unscaled: 0.2062 (0.2361)  time: 0.1908  data: 0.0003  max mem: 3702
Epoch: [4]  [ 750/1405]  eta: 0:02:06  lr: 0.000000  loss: 0.2380 (0.2454)  labels_encoder: 0.1227 (0.1273)  labels_decoder: 0.1146 (0.1181)  labels_encoder_unscaled: 0.1227 (0.1273)  labels_decoder_unscaled: 0.2291 (0.2362)  time: 0.1961  data: 0.0003  max mem: 3702
Epoch: [4]  [ 800/1405]  eta: 0:01:56  lr: 0.000000  loss: 0.2379 (0.2450)  labels_encoder: 0.1241 (0.1268)  labels_decoder: 0.1174 (0.1182)  labels_encoder_unscaled: 0.1241 (0.1268)  labels_decoder_unscaled: 0.2347 (0.2364)  time: 0.1888  data: 0.0003  max mem: 3702
Epoch: [4]  [ 850/1405]  eta: 0:01:47  lr: 0.000000  loss: 0.2362 (0.2444)  labels_encoder: 0.1243 (0.1264)  labels_decoder: 0.1113 (0.1180)  labels_encoder_unscaled: 0.1243 (0.1264)  labels_decoder_unscaled: 0.2226 (0.2360)  time: 0.1905  data: 0.0003  max mem: 3702
Epoch: [4]  [ 900/1405]  eta: 0:01:37  lr: 0.000000  loss: 0.2183 (0.2444)  labels_encoder: 0.0991 (0.1265)  labels_decoder: 0.1143 (0.1180)  labels_encoder_unscaled: 0.0991 (0.1265)  labels_decoder_unscaled: 0.2285 (0.2360)  time: 0.1894  data: 0.0003  max mem: 3702
Epoch: [4]  [ 950/1405]  eta: 0:01:27  lr: 0.000000  loss: 0.2391 (0.2441)  labels_encoder: 0.1141 (0.1258)  labels_decoder: 0.1321 (0.1182)  labels_encoder_unscaled: 0.1141 (0.1258)  labels_decoder_unscaled: 0.2642 (0.2365)  time: 0.1894  data: 0.0003  max mem: 3702
Epoch: [4]  [1000/1405]  eta: 0:01:17  lr: 0.000000  loss: 0.2355 (0.2440)  labels_encoder: 0.1265 (0.1260)  labels_decoder: 0.1140 (0.1180)  labels_encoder_unscaled: 0.1265 (0.1260)  labels_decoder_unscaled: 0.2281 (0.2361)  time: 0.1713  data: 0.0002  max mem: 3702
Epoch: [4]  [1050/1405]  eta: 0:01:07  lr: 0.000000  loss: 0.2317 (0.2439)  labels_encoder: 0.1084 (0.1259)  labels_decoder: 0.1099 (0.1179)  labels_encoder_unscaled: 0.1084 (0.1259)  labels_decoder_unscaled: 0.2197 (0.2358)  time: 0.1778  data: 0.0003  max mem: 3702
Epoch: [4]  [1100/1405]  eta: 0:00:58  lr: 0.000000  loss: 0.2442 (0.2439)  labels_encoder: 0.1220 (0.1261)  labels_decoder: 0.1097 (0.1179)  labels_encoder_unscaled: 0.1220 (0.1261)  labels_decoder_unscaled: 0.2193 (0.2358)  time: 0.1750  data: 0.0003  max mem: 3702
Epoch: [4]  [1150/1405]  eta: 0:00:48  lr: 0.000000  loss: 0.2266 (0.2445)  labels_encoder: 0.1138 (0.1264)  labels_decoder: 0.1064 (0.1181)  labels_encoder_unscaled: 0.1138 (0.1264)  labels_decoder_unscaled: 0.2127 (0.2361)  time: 0.1854  data: 0.0003  max mem: 3702
Epoch: [4]  [1200/1405]  eta: 0:00:38  lr: 0.000000  loss: 0.2372 (0.2449)  labels_encoder: 0.1274 (0.1267)  labels_decoder: 0.1217 (0.1182)  labels_encoder_unscaled: 0.1274 (0.1267)  labels_decoder_unscaled: 0.2433 (0.2364)  time: 0.1810  data: 0.0003  max mem: 3702
Epoch: [4]  [1250/1405]  eta: 0:00:29  lr: 0.000000  loss: 0.2509 (0.2450)  labels_encoder: 0.1341 (0.1268)  labels_decoder: 0.1108 (0.1181)  labels_encoder_unscaled: 0.1341 (0.1268)  labels_decoder_unscaled: 0.2217 (0.2363)  time: 0.1784  data: 0.0003  max mem: 3702
Epoch: [4]  [1300/1405]  eta: 0:00:19  lr: 0.000000  loss: 0.2235 (0.2449)  labels_encoder: 0.1160 (0.1267)  labels_decoder: 0.1149 (0.1182)  labels_encoder_unscaled: 0.1160 (0.1267)  labels_decoder_unscaled: 0.2298 (0.2363)  time: 0.1849  data: 0.0003  max mem: 3702
Epoch: [4]  [1350/1405]  eta: 0:00:10  lr: 0.000000  loss: 0.2307 (0.2445)  labels_encoder: 0.1159 (0.1265)  labels_decoder: 0.1067 (0.1180)  labels_encoder_unscaled: 0.1159 (0.1265)  labels_decoder_unscaled: 0.2134 (0.2360)  time: 0.1895  data: 0.0003  max mem: 3702
Epoch: [4]  [1400/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2337 (0.2442)  labels_encoder: 0.1135 (0.1263)  labels_decoder: 0.1141 (0.1179)  labels_encoder_unscaled: 0.1135 (0.1263)  labels_decoder_unscaled: 0.2281 (0.2357)  time: 0.1545  data: 0.0003  max mem: 3702
Epoch: [4]  [1404/1405]  eta: 0:00:00  lr: 0.000000  loss: 0.2337 (0.2441)  labels_encoder: 0.1135 (0.1263)  labels_decoder: 0.1113 (0.1178)  labels_encoder_unscaled: 0.1135 (0.1263)  labels_decoder_unscaled: 0.2226 (0.2357)  time: 0.1482  data: 0.0003  max mem: 3702
Epoch: [4] Total time: 0:04:26 (0.1894 s / it)
Averaged stats: lr: 0.000000  loss: 0.2337 (0.2441)  labels_encoder: 0.1135 (0.1263)  labels_decoder: 0.1113 (0.1178)  labels_encoder_unscaled: 0.1135 (0.1263)  labels_decoder_unscaled: 0.2226 (0.2357)
Test:  [   0/1613]  eta: 1:22:04  loss: 2.0935 (2.0935)  labels_encoder: 1.4236 (1.4236)  labels_decoder: 0.6699 (0.6699)  labels_encoder_unscaled: 1.4236 (1.4236)  labels_decoder_unscaled: 1.3399 (1.3399)  time: 3.0533  data: 2.9108  max mem: 3702
Test:  [  50/1613]  eta: 0:04:21  loss: 0.4574 (1.0113)  labels_encoder: 0.2900 (0.6374)  labels_decoder: 0.1864 (0.3739)  labels_encoder_unscaled: 0.2900 (0.6374)  labels_decoder_unscaled: 0.3729 (0.7478)  time: 0.0981  data: 0.0002  max mem: 3702
Test:  [ 100/1613]  eta: 0:03:19  loss: 0.2986 (0.7836)  labels_encoder: 0.1891 (0.5021)  labels_decoder: 0.0667 (0.2815)  labels_encoder_unscaled: 0.1891 (0.5021)  labels_decoder_unscaled: 0.1335 (0.5631)  time: 0.0919  data: 0.0002  max mem: 3702
Test:  [ 150/1613]  eta: 0:02:58  loss: 0.8988 (0.7692)  labels_encoder: 0.5842 (0.4967)  labels_decoder: 0.2632 (0.2724)  labels_encoder_unscaled: 0.5842 (0.4967)  labels_decoder_unscaled: 0.5263 (0.5449)  time: 0.1004  data: 0.0002  max mem: 3702
Test:  [ 200/1613]  eta: 0:02:46  loss: 1.0120 (0.9250)  labels_encoder: 0.6084 (0.6021)  labels_decoder: 0.3864 (0.3230)  labels_encoder_unscaled: 0.6084 (0.6021)  labels_decoder_unscaled: 0.7728 (0.6459)  time: 0.1129  data: 0.0002  max mem: 3702
Test:  [ 250/1613]  eta: 0:02:38  loss: 0.5947 (0.9814)  labels_encoder: 0.3427 (0.6371)  labels_decoder: 0.2497 (0.3443)  labels_encoder_unscaled: 0.3427 (0.6371)  labels_decoder_unscaled: 0.4993 (0.6887)  time: 0.1013  data: 0.0002  max mem: 3702
Test:  [ 300/1613]  eta: 0:02:30  loss: 0.5705 (0.9946)  labels_encoder: 0.3520 (0.6440)  labels_decoder: 0.2675 (0.3506)  labels_encoder_unscaled: 0.3520 (0.6440)  labels_decoder_unscaled: 0.5349 (0.7012)  time: 0.1016  data: 0.0002  max mem: 3702
Test:  [ 350/1613]  eta: 0:02:21  loss: 1.1241 (0.9912)  labels_encoder: 0.6168 (0.6355)  labels_decoder: 0.4670 (0.3557)  labels_encoder_unscaled: 0.6168 (0.6355)  labels_decoder_unscaled: 0.9341 (0.7114)  time: 0.0979  data: 0.0002  max mem: 3702
Test:  [ 400/1613]  eta: 0:02:16  loss: 0.8508 (1.1387)  labels_encoder: 0.4558 (0.7361)  labels_decoder: 0.3719 (0.4026)  labels_encoder_unscaled: 0.4558 (0.7361)  labels_decoder_unscaled: 0.7438 (0.8052)  time: 0.1134  data: 0.0002  max mem: 3702
Test:  [ 450/1613]  eta: 0:02:09  loss: 0.9174 (1.2182)  labels_encoder: 0.6068 (0.7912)  labels_decoder: 0.3106 (0.4270)  labels_encoder_unscaled: 0.6068 (0.7912)  labels_decoder_unscaled: 0.6212 (0.8540)  time: 0.1025  data: 0.0002  max mem: 3702
Test:  [ 500/1613]  eta: 0:02:02  loss: 0.3442 (1.1667)  labels_encoder: 0.2053 (0.7563)  labels_decoder: 0.1889 (0.4104)  labels_encoder_unscaled: 0.2053 (0.7563)  labels_decoder_unscaled: 0.3779 (0.8208)  time: 0.0978  data: 0.0002  max mem: 3702
Test:  [ 550/1613]  eta: 0:01:56  loss: 0.5157 (1.1574)  labels_encoder: 0.3060 (0.7485)  labels_decoder: 0.2740 (0.4089)  labels_encoder_unscaled: 0.3060 (0.7485)  labels_decoder_unscaled: 0.5480 (0.8177)  time: 0.1075  data: 0.0002  max mem: 3702
Test:  [ 600/1613]  eta: 0:01:50  loss: 1.5651 (1.1968)  labels_encoder: 0.9377 (0.7838)  labels_decoder: 0.4857 (0.4130)  labels_encoder_unscaled: 0.9377 (0.7838)  labels_decoder_unscaled: 0.9714 (0.8261)  time: 0.1098  data: 0.0002  max mem: 3702
Test:  [ 650/1613]  eta: 0:01:44  loss: 0.9117 (1.1821)  labels_encoder: 0.5343 (0.7703)  labels_decoder: 0.4518 (0.4118)  labels_encoder_unscaled: 0.5343 (0.7703)  labels_decoder_unscaled: 0.9035 (0.8235)  time: 0.1060  data: 0.0002  max mem: 3702
Test:  [ 700/1613]  eta: 0:01:38  loss: 0.5595 (1.1519)  labels_encoder: 0.3167 (0.7492)  labels_decoder: 0.2165 (0.4027)  labels_encoder_unscaled: 0.3167 (0.7492)  labels_decoder_unscaled: 0.4330 (0.8054)  time: 0.0990  data: 0.0002  max mem: 3702
Test:  [ 750/1613]  eta: 0:01:33  loss: 0.8681 (1.1332)  labels_encoder: 0.5159 (0.7359)  labels_decoder: 0.3521 (0.3973)  labels_encoder_unscaled: 0.5159 (0.7359)  labels_decoder_unscaled: 0.7043 (0.7945)  time: 0.1094  data: 0.0002  max mem: 3702
Test:  [ 800/1613]  eta: 0:01:27  loss: 0.8498 (1.1313)  labels_encoder: 0.5074 (0.7357)  labels_decoder: 0.3141 (0.3956)  labels_encoder_unscaled: 0.5074 (0.7357)  labels_decoder_unscaled: 0.6282 (0.7913)  time: 0.0971  data: 0.0002  max mem: 3702
Test:  [ 850/1613]  eta: 0:01:21  loss: 1.6186 (1.1312)  labels_encoder: 1.0173 (0.7333)  labels_decoder: 0.5969 (0.3980)  labels_encoder_unscaled: 1.0173 (0.7333)  labels_decoder_unscaled: 1.1937 (0.7959)  time: 0.1004  data: 0.0002  max mem: 3702
Test:  [ 900/1613]  eta: 0:01:16  loss: 0.7741 (1.1503)  labels_encoder: 0.4998 (0.7460)  labels_decoder: 0.2932 (0.4043)  labels_encoder_unscaled: 0.4998 (0.7460)  labels_decoder_unscaled: 0.5864 (0.8086)  time: 0.0955  data: 0.0002  max mem: 3702
Test:  [ 950/1613]  eta: 0:01:10  loss: 0.9964 (1.1397)  labels_encoder: 0.6715 (0.7393)  labels_decoder: 0.3396 (0.4005)  labels_encoder_unscaled: 0.6715 (0.7393)  labels_decoder_unscaled: 0.6791 (0.8010)  time: 0.1060  data: 0.0002  max mem: 3702
Test:  [1000/1613]  eta: 0:01:05  loss: 0.6121 (1.1290)  labels_encoder: 0.3619 (0.7315)  labels_decoder: 0.2795 (0.3976)  labels_encoder_unscaled: 0.3619 (0.7315)  labels_decoder_unscaled: 0.5591 (0.7951)  time: 0.1126  data: 0.0002  max mem: 3702
Test:  [1050/1613]  eta: 0:01:00  loss: 0.8731 (1.1251)  labels_encoder: 0.5166 (0.7292)  labels_decoder: 0.3022 (0.3960)  labels_encoder_unscaled: 0.5166 (0.7292)  labels_decoder_unscaled: 0.6044 (0.7919)  time: 0.1063  data: 0.0002  max mem: 3702
Test:  [1100/1613]  eta: 0:00:54  loss: 0.6995 (1.1311)  labels_encoder: 0.4795 (0.7349)  labels_decoder: 0.3348 (0.3962)  labels_encoder_unscaled: 0.4795 (0.7349)  labels_decoder_unscaled: 0.6696 (0.7925)  time: 0.0974  data: 0.0002  max mem: 3702
Test:  [1150/1613]  eta: 0:00:49  loss: 0.6469 (1.1170)  labels_encoder: 0.3682 (0.7253)  labels_decoder: 0.2733 (0.3918)  labels_encoder_unscaled: 0.3682 (0.7253)  labels_decoder_unscaled: 0.5466 (0.7835)  time: 0.1057  data: 0.0002  max mem: 3702
Test:  [1200/1613]  eta: 0:00:43  loss: 0.4676 (1.1206)  labels_encoder: 0.3039 (0.7274)  labels_decoder: 0.2059 (0.3933)  labels_encoder_unscaled: 0.3039 (0.7274)  labels_decoder_unscaled: 0.4118 (0.7865)  time: 0.1014  data: 0.0002  max mem: 3702
Test:  [1250/1613]  eta: 0:00:38  loss: 0.4092 (1.1190)  labels_encoder: 0.2053 (0.7259)  labels_decoder: 0.2016 (0.3932)  labels_encoder_unscaled: 0.2053 (0.7259)  labels_decoder_unscaled: 0.4032 (0.7863)  time: 0.1110  data: 0.0002  max mem: 3702
Test:  [1300/1613]  eta: 0:00:33  loss: 0.9374 (1.1124)  labels_encoder: 0.5835 (0.7211)  labels_decoder: 0.3119 (0.3913)  labels_encoder_unscaled: 0.5835 (0.7211)  labels_decoder_unscaled: 0.6238 (0.7826)  time: 0.0979  data: 0.0002  max mem: 3702
Test:  [1350/1613]  eta: 0:00:27  loss: 0.9306 (1.1312)  labels_encoder: 0.5501 (0.7345)  labels_decoder: 0.3805 (0.3968)  labels_encoder_unscaled: 0.5501 (0.7345)  labels_decoder_unscaled: 0.7610 (0.7935)  time: 0.1004  data: 0.0002  max mem: 3702
Test:  [1400/1613]  eta: 0:00:22  loss: 0.9534 (1.1244)  labels_encoder: 0.6463 (0.7296)  labels_decoder: 0.3915 (0.3947)  labels_encoder_unscaled: 0.6463 (0.7296)  labels_decoder_unscaled: 0.7830 (0.7895)  time: 0.1085  data: 0.0002  max mem: 3702
Test:  [1450/1613]  eta: 0:00:17  loss: 0.7132 (1.1321)  labels_encoder: 0.3819 (0.7338)  labels_decoder: 0.3562 (0.3982)  labels_encoder_unscaled: 0.3819 (0.7338)  labels_decoder_unscaled: 0.7124 (0.7964)  time: 0.1139  data: 0.0002  max mem: 3702
Test:  [1500/1613]  eta: 0:00:11  loss: 0.7832 (1.1436)  labels_encoder: 0.4948 (0.7426)  labels_decoder: 0.2550 (0.4011)  labels_encoder_unscaled: 0.4948 (0.7426)  labels_decoder_unscaled: 0.5100 (0.8021)  time: 0.0929  data: 0.0002  max mem: 3702
Test:  [1550/1613]  eta: 0:00:06  loss: 0.7215 (1.1380)  labels_encoder: 0.4822 (0.7393)  labels_decoder: 0.2626 (0.3988)  labels_encoder_unscaled: 0.4822 (0.7393)  labels_decoder_unscaled: 0.5252 (0.7975)  time: 0.0987  data: 0.0002  max mem: 3702
Test:  [1600/1613]  eta: 0:00:01  loss: 0.9458 (1.1323)  labels_encoder: 0.5917 (0.7350)  labels_decoder: 0.3517 (0.3974)  labels_encoder_unscaled: 0.5917 (0.7350)  labels_decoder_unscaled: 0.7034 (0.7947)  time: 0.1007  data: 0.0024  max mem: 3702
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5207 (1.1308)  labels_encoder: 0.3317 (0.7342)  labels_decoder: 0.2167 (0.3965)  labels_encoder_unscaled: 0.3317 (0.7342)  labels_decoder_unscaled: 0.4333 (0.7931)  time: 0.0695  data: 0.0023  max mem: 3702
Test: Total time: 0:02:50 (0.1057 s / it)
Averaged stats: loss: 0.5207 (1.1308)  labels_encoder: 0.3317 (0.7342)  labels_decoder: 0.2167 (0.3965)  labels_encoder_unscaled: 0.3317 (0.7342)  labels_decoder_unscaled: 0.4333 (0.7931)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-anet_audio] mAP: 0.5797

dec_mAP all together: | 0.46650603589758977 |.
dec_mAP_pred | 0 : 0.5117077950220039 |.
dec_mAP_pred | 1 : 0.5033287917755878 |.
dec_mAP_pred | 2 : 0.4908048141262964 |.
dec_mAP_pred | 3 : 0.47685466585858355 |.
dec_mAP_pred | 4 : 0.46185145532197336 |.
dec_mAP_pred | 5 : 0.4472255517422008 |.
dec_mAP_pred | 6 : 0.4327210866238035 |.
dec_mAP_pred | 7 : 0.41918006642352734 |.
all decoder map: | 0.4680 |.
BaseballPitch: 0.1407
BasketballDunk: 0.7702
Billiards: 0.4579
CleanAndJerk: 0.7476
CliffDiving: 0.8066
CricketBowling: 0.4464
CricketShot: 0.2459
Diving: 0.6907
FrisbeeCatch: 0.3513
GolfSwing: 0.6028
HammerThrow: 0.8539
HighJump: 0.6421
JavelinThrow: 0.6765
LongJump: 0.7734
PoleVault: 0.8666
Shotput: 0.6790
SoccerPenalty: 0.3178
TennisSwing: 0.5794
ThrowDiscus: 0.6387
VolleyballSpiking: 0.3069
Training time 0:34:37
