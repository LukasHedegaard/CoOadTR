Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:kin_audio
dim_feature:8192
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:3
attn_dropout_rate:0.1
positional_encoding_type:learned
hidden_dim:1024
dropout_rate:0.1
numclass:22
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:1
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['video_validation_0000690', 'video_validation_0000288', 'video_validation_0000289', 'video_validation_0000416', 'video_validation_0000282', 'video_validation_0000283', 'video_validation_0000281', 'video_validation_0000286', 'video_validation_0000287', 'video_validation_0000284', 'video_validation_0000285', 'video_validation_0000202', 'video_validation_0000203', 'video_validation_0000201', 'video_validation_0000206', 'video_validation_0000207', 'video_validation_0000204', 'video_validation_0000205', 'video_validation_0000790', 'video_validation_0000208', 'video_validation_0000209', 'video_validation_0000420', 'video_validation_0000364', 'video_validation_0000853', 'video_validation_0000950', 'video_validation_0000937', 'video_validation_0000367', 'video_validation_0000290', 'video_validation_0000210', 'video_validation_0000059', 'video_validation_0000058', 'video_validation_0000057', 'video_validation_0000056', 'video_validation_0000055', 'video_validation_0000054', 'video_validation_0000053', 'video_validation_0000052', 'video_validation_0000051', 'video_validation_0000933', 'video_validation_0000949', 'video_validation_0000948', 'video_validation_0000945', 'video_validation_0000944', 'video_validation_0000947', 'video_validation_0000946', 'video_validation_0000941', 'video_validation_0000940', 'video_validation_0000190', 'video_validation_0000942', 'video_validation_0000261', 'video_validation_0000262', 'video_validation_0000263', 'video_validation_0000264', 'video_validation_0000265', 'video_validation_0000266', 'video_validation_0000267', 'video_validation_0000268', 'video_validation_0000269', 'video_validation_0000989', 'video_validation_0000060', 'video_validation_0000370', 'video_validation_0000938', 'video_validation_0000935', 'video_validation_0000668', 'video_validation_0000669', 'video_validation_0000664', 'video_validation_0000665', 'video_validation_0000932', 'video_validation_0000667', 'video_validation_0000934', 'video_validation_0000661', 'video_validation_0000662', 'video_validation_0000663', 'video_validation_0000181', 'video_validation_0000180', 'video_validation_0000183', 'video_validation_0000182', 'video_validation_0000185', 'video_validation_0000184', 'video_validation_0000187', 'video_validation_0000186', 'video_validation_0000189', 'video_validation_0000188', 'video_validation_0000936', 'video_validation_0000270', 'video_validation_0000854', 'video_validation_0000178', 'video_validation_0000179', 'video_validation_0000174', 'video_validation_0000175', 'video_validation_0000176', 'video_validation_0000177', 'video_validation_0000170', 'video_validation_0000171', 'video_validation_0000172', 'video_validation_0000173', 'video_validation_0000670', 'video_validation_0000419', 'video_validation_0000943', 'video_validation_0000485', 'video_validation_0000369', 'video_validation_0000368', 'video_validation_0000318', 'video_validation_0000319', 'video_validation_0000415', 'video_validation_0000414', 'video_validation_0000413', 'video_validation_0000412', 'video_validation_0000411', 'video_validation_0000311', 'video_validation_0000312', 'video_validation_0000313', 'video_validation_0000314', 'video_validation_0000315', 'video_validation_0000316', 'video_validation_0000317', 'video_validation_0000418', 'video_validation_0000365', 'video_validation_0000482', 'video_validation_0000169', 'video_validation_0000168', 'video_validation_0000167', 'video_validation_0000166', 'video_validation_0000165', 'video_validation_0000164', 'video_validation_0000163', 'video_validation_0000162', 'video_validation_0000161', 'video_validation_0000160', 'video_validation_0000857', 'video_validation_0000856', 'video_validation_0000855', 'video_validation_0000366', 'video_validation_0000488', 'video_validation_0000489', 'video_validation_0000851', 'video_validation_0000484', 'video_validation_0000361', 'video_validation_0000486', 'video_validation_0000487', 'video_validation_0000481', 'video_validation_0000910', 'video_validation_0000483', 'video_validation_0000363', 'video_validation_0000990', 'video_validation_0000939', 'video_validation_0000362', 'video_validation_0000987', 'video_validation_0000859', 'video_validation_0000787', 'video_validation_0000786', 'video_validation_0000785', 'video_validation_0000784', 'video_validation_0000783', 'video_validation_0000782', 'video_validation_0000781', 'video_validation_0000981', 'video_validation_0000983', 'video_validation_0000982', 'video_validation_0000985', 'video_validation_0000984', 'video_validation_0000417', 'video_validation_0000788', 'video_validation_0000152', 'video_validation_0000153', 'video_validation_0000151', 'video_validation_0000156', 'video_validation_0000157', 'video_validation_0000154', 'video_validation_0000155', 'video_validation_0000158', 'video_validation_0000159', 'video_validation_0000901', 'video_validation_0000903', 'video_validation_0000902', 'video_validation_0000905', 'video_validation_0000904', 'video_validation_0000907', 'video_validation_0000906', 'video_validation_0000909', 'video_validation_0000908', 'video_validation_0000490', 'video_validation_0000860', 'video_validation_0000858', 'video_validation_0000988', 'video_validation_0000320', 'video_validation_0000688', 'video_validation_0000689', 'video_validation_0000686', 'video_validation_0000687', 'video_validation_0000684', 'video_validation_0000685', 'video_validation_0000682', 'video_validation_0000683', 'video_validation_0000681', 'video_validation_0000789', 'video_validation_0000986', 'video_validation_0000931', 'video_validation_0000852', 'video_validation_0000666']
test_session_set:['video_test_0000292', 'video_test_0001078', 'video_test_0000896', 'video_test_0000897', 'video_test_0000950', 'video_test_0001159', 'video_test_0001079', 'video_test_0000807', 'video_test_0000179', 'video_test_0000173', 'video_test_0001072', 'video_test_0001075', 'video_test_0000767', 'video_test_0001076', 'video_test_0000007', 'video_test_0000006', 'video_test_0000556', 'video_test_0001307', 'video_test_0001153', 'video_test_0000718', 'video_test_0000716', 'video_test_0001309', 'video_test_0000714', 'video_test_0000558', 'video_test_0001267', 'video_test_0000367', 'video_test_0001324', 'video_test_0000085', 'video_test_0000887', 'video_test_0001281', 'video_test_0000882', 'video_test_0000671', 'video_test_0000964', 'video_test_0001164', 'video_test_0001114', 'video_test_0000771', 'video_test_0001163', 'video_test_0001118', 'video_test_0001201', 'video_test_0001040', 'video_test_0001207', 'video_test_0000723', 'video_test_0000569', 'video_test_0000672', 'video_test_0000673', 'video_test_0000278', 'video_test_0001162', 'video_test_0000405', 'video_test_0000073', 'video_test_0000560', 'video_test_0001276', 'video_test_0000270', 'video_test_0000273', 'video_test_0000374', 'video_test_0000372', 'video_test_0001168', 'video_test_0000379', 'video_test_0001446', 'video_test_0001447', 'video_test_0001098', 'video_test_0000873', 'video_test_0000039', 'video_test_0000442', 'video_test_0001219', 'video_test_0000762', 'video_test_0000611', 'video_test_0000617', 'video_test_0000615', 'video_test_0001270', 'video_test_0000740', 'video_test_0000293', 'video_test_0000504', 'video_test_0000505', 'video_test_0000665', 'video_test_0000664', 'video_test_0000577', 'video_test_0000814', 'video_test_0001369', 'video_test_0001194', 'video_test_0001195', 'video_test_0001512', 'video_test_0001235', 'video_test_0001459', 'video_test_0000691', 'video_test_0000765', 'video_test_0001452', 'video_test_0000188', 'video_test_0000591', 'video_test_0001268', 'video_test_0000593', 'video_test_0000864', 'video_test_0000601', 'video_test_0001135', 'video_test_0000004', 'video_test_0000903', 'video_test_0000285', 'video_test_0001174', 'video_test_0000046', 'video_test_0000045', 'video_test_0001223', 'video_test_0001358', 'video_test_0001134', 'video_test_0000698', 'video_test_0000461', 'video_test_0001182', 'video_test_0000450', 'video_test_0000602', 'video_test_0001229', 'video_test_0000989', 'video_test_0000357', 'video_test_0001039', 'video_test_0000355', 'video_test_0000353', 'video_test_0001508', 'video_test_0000981', 'video_test_0000242', 'video_test_0000854', 'video_test_0001484', 'video_test_0000635', 'video_test_0001129', 'video_test_0001339', 'video_test_0001483', 'video_test_0001123', 'video_test_0001127', 'video_test_0000689', 'video_test_0000756', 'video_test_0001431', 'video_test_0000129', 'video_test_0001433', 'video_test_0001343', 'video_test_0000324', 'video_test_0001064', 'video_test_0001531', 'video_test_0001532', 'video_test_0000413', 'video_test_0000991', 'video_test_0001255', 'video_test_0000464', 'video_test_0001202', 'video_test_0001080', 'video_test_0001081', 'video_test_0000847', 'video_test_0000028', 'video_test_0000844', 'video_test_0000622', 'video_test_0000026', 'video_test_0001325', 'video_test_0001496', 'video_test_0001495', 'video_test_0000624', 'video_test_0000724', 'video_test_0001409', 'video_test_0000131', 'video_test_0000448', 'video_test_0000444', 'video_test_0000443', 'video_test_0001038', 'video_test_0000238', 'video_test_0001527', 'video_test_0001522', 'video_test_0000051', 'video_test_0001058', 'video_test_0001391', 'video_test_0000429', 'video_test_0000426', 'video_test_0000785', 'video_test_0000786', 'video_test_0001314', 'video_test_0000392', 'video_test_0000423', 'video_test_0001146', 'video_test_0001313', 'video_test_0001008', 'video_test_0001247', 'video_test_0000737', 'video_test_0001319', 'video_test_0000308', 'video_test_0000730', 'video_test_0000058', 'video_test_0000538', 'video_test_0001556', 'video_test_0000113', 'video_test_0000626', 'video_test_0000839', 'video_test_0000220', 'video_test_0001389', 'video_test_0000437', 'video_test_0000940', 'video_test_0000211', 'video_test_0000946', 'video_test_0001558', 'video_test_0000796', 'video_test_0000062', 'video_test_0000793', 'video_test_0000987', 'video_test_0001066', 'video_test_0000412', 'video_test_0000798', 'video_test_0001549', 'video_test_0000011', 'video_test_0001257', 'video_test_0000541', 'video_test_0000701', 'video_test_0000250', 'video_test_0000254', 'video_test_0000549', 'video_test_0001209', 'video_test_0001463', 'video_test_0001460', 'video_test_0000319', 'video_test_0001468', 'video_test_0000846', 'video_test_0001292']
class_index:['Background', 'BaseballPitch', 'BasketballDunk', 'Billiards', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'Diving', 'FrisbeeCatch', 'GolfSwing', 'HammerThrow', 'HighJump', 'JavelinThrow', 'LongJump', 'PoleVault', 'Shotput', 'SoccerPenalty', 'TennisSwing', 'ThrowDiscus', 'VolleyballSpiking', 'Ambiguous']
distributed:False
position encoding : learned
position decoding : learned
Warning! No positional inputs found for a module, assuming batch size is 1.
VisionTransformer_v3(
  79.821 M, 99.836% Params, 2.781 GMac, 100.000% MACs, 
  (linear_encoding): Linear(8.39 M, 10.493% Params, 0.537 GMac, 19.302% MACs, in_features=8192, out_features=1024, bias=True)
  (position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 65, 1024)
  )
  (pe_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (encoder): TransformerModel(
    18.884 M, 23.619% Params, 1.227 GMac, 44.116% MACs, 
    (net): Sequential(
      18.884 M, 23.619% Params, 1.227 GMac, 44.116% MACs, 
      (0): Residual(
        4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
            (qkv): Linear(3.146 M, 3.935% Params, 0.204 GMac, 7.351% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (1): Residual(
        2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
        (fn): PreNorm(
          2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
            (net): Sequential(
              2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
              (0): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (2): Residual(
        4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
            (qkv): Linear(3.146 M, 3.935% Params, 0.204 GMac, 7.351% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (3): Residual(
        2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
        (fn): PreNorm(
          2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
            (net): Sequential(
              2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
              (0): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
      (4): Residual(
        4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
        (fn): PreNormDrop(
          4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (fn): SelfAttention(
            4.195 M, 5.247% Params, 0.273 GMac, 9.802% MACs, 
            (qkv): Linear(3.146 M, 3.935% Params, 0.204 GMac, 7.351% MACs, in_features=1024, out_features=3072, bias=False)
            (attn_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (proj): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
      )
      (5): Residual(
        2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
        (fn): PreNorm(
          2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
          (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
          (fn): FeedForward(
            2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
            (net): Sequential(
              2.099 M, 2.626% Params, 0.136 GMac, 4.903% MACs, 
              (0): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, )
              (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
              (3): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
              (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
  (pre_head_ln): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  (mlp_head): Linear(0.045 M, 0.056% Params, 0.0 GMac, 0.002% MACs, in_features=2048, out_features=22, bias=True)
  (to_cls_token): Identity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  (decoder): Decoder(
    52.48 M, 65.639% Params, 1.017 GMac, 36.573% MACs, 
    (layers): ModuleList(
      52.48 M, 65.639% Params, 1.017 GMac, 36.573% MACs, 
      (0): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        10.496 M, 13.128% Params, 0.203 GMac, 7.315% MACs, 
        (self_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.034 GMac, 1.207% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (cross_attention): AttentionLayer(
          4.198 M, 5.251% Params, 0.153 GMac, 5.504% MACs, 
          (inner_attention): FullAttention(
            0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
            (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
          (query_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
          (key_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (value_projection): Linear(1.05 M, 1.313% Params, 0.068 GMac, 2.451% MACs, in_features=1024, out_features=1024, bias=True)
          (out_projection): Linear(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, in_features=1024, out_features=1024, bias=True)
        )
        (conv1): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(1.05 M, 1.313% Params, 0.008 GMac, 0.302% MACs, 1024, 1024, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder_position_encoding): LearnedPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): Embedding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 8, 1024)
  )
  (classifier): Linear(0.023 M, 0.028% Params, 0.0 GMac, 0.006% MACs, in_features=1024, out_features=22, bias=True)
  (after_dropout): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
)
Model FLOPs: 2781381676.0
Model params: 79951916
Loaded data/thumos_kin_plus_audio_val.pickle
Loaded data/thumos_kin_plus_audio_test.pickle
Start training
Epoch: [1]  [   0/1415]  eta: 1:49:37  lr: 0.000100  loss: 4.7279 (4.7279)  labels_encoder: 3.4211 (3.4211)  labels_decoder: 1.3068 (1.3068)  labels_encoder_unscaled: 3.4211 (3.4211)  labels_decoder_unscaled: 2.6136 (2.6136)  time: 4.6482  data: 3.8736  max mem: 2868
Epoch: [1]  [  50/1415]  eta: 0:06:47  lr: 0.000100  loss: 1.0231 (1.5858)  labels_encoder: 0.6438 (1.0323)  labels_decoder: 0.3581 (0.5535)  labels_encoder_unscaled: 0.6438 (1.0323)  labels_decoder_unscaled: 0.7162 (1.1071)  time: 0.1946  data: 0.0003  max mem: 3781
Epoch: [1]  [ 100/1415]  eta: 0:05:23  lr: 0.000100  loss: 0.7165 (1.1886)  labels_encoder: 0.4506 (0.7633)  labels_decoder: 0.2685 (0.4253)  labels_encoder_unscaled: 0.4506 (0.7633)  labels_decoder_unscaled: 0.5369 (0.8507)  time: 0.2002  data: 0.0003  max mem: 3781
Epoch: [1]  [ 150/1415]  eta: 0:04:47  lr: 0.000100  loss: 0.6448 (1.0109)  labels_encoder: 0.3752 (0.6405)  labels_decoder: 0.2584 (0.3703)  labels_encoder_unscaled: 0.3752 (0.6405)  labels_decoder_unscaled: 0.5168 (0.7407)  time: 0.1965  data: 0.0003  max mem: 3781
Epoch: [1]  [ 200/1415]  eta: 0:04:25  lr: 0.000100  loss: 0.5756 (0.9108)  labels_encoder: 0.3358 (0.5714)  labels_decoder: 0.2350 (0.3393)  labels_encoder_unscaled: 0.3358 (0.5714)  labels_decoder_unscaled: 0.4700 (0.6786)  time: 0.1981  data: 0.0003  max mem: 3781
Epoch: [1]  [ 250/1415]  eta: 0:04:06  lr: 0.000100  loss: 0.5512 (0.8450)  labels_encoder: 0.3360 (0.5275)  labels_decoder: 0.2199 (0.3175)  labels_encoder_unscaled: 0.3360 (0.5275)  labels_decoder_unscaled: 0.4399 (0.6350)  time: 0.1900  data: 0.0003  max mem: 3781
Epoch: [1]  [ 300/1415]  eta: 0:03:52  lr: 0.000100  loss: 0.5380 (0.7935)  labels_encoder: 0.3205 (0.4931)  labels_decoder: 0.2159 (0.3004)  labels_encoder_unscaled: 0.3205 (0.4931)  labels_decoder_unscaled: 0.4317 (0.6008)  time: 0.1934  data: 0.0003  max mem: 3781
Epoch: [1]  [ 350/1415]  eta: 0:03:39  lr: 0.000100  loss: 0.5287 (0.7567)  labels_encoder: 0.2974 (0.4683)  labels_decoder: 0.2231 (0.2884)  labels_encoder_unscaled: 0.2974 (0.4683)  labels_decoder_unscaled: 0.4463 (0.5768)  time: 0.1955  data: 0.0003  max mem: 3781
Epoch: [1]  [ 400/1415]  eta: 0:03:27  lr: 0.000100  loss: 0.4946 (0.7249)  labels_encoder: 0.2825 (0.4465)  labels_decoder: 0.1971 (0.2784)  labels_encoder_unscaled: 0.2825 (0.4465)  labels_decoder_unscaled: 0.3942 (0.5568)  time: 0.1921  data: 0.0003  max mem: 3781
Epoch: [1]  [ 450/1415]  eta: 0:03:16  lr: 0.000100  loss: 0.4712 (0.6977)  labels_encoder: 0.2709 (0.4282)  labels_decoder: 0.1947 (0.2695)  labels_encoder_unscaled: 0.2709 (0.4282)  labels_decoder_unscaled: 0.3894 (0.5390)  time: 0.1915  data: 0.0003  max mem: 3781
Epoch: [1]  [ 500/1415]  eta: 0:03:04  lr: 0.000100  loss: 0.4908 (0.6760)  labels_encoder: 0.2862 (0.4141)  labels_decoder: 0.2082 (0.2619)  labels_encoder_unscaled: 0.2862 (0.4141)  labels_decoder_unscaled: 0.4164 (0.5239)  time: 0.1825  data: 0.0003  max mem: 3781
Epoch: [1]  [ 550/1415]  eta: 0:02:53  lr: 0.000100  loss: 0.4369 (0.6587)  labels_encoder: 0.2738 (0.4028)  labels_decoder: 0.1754 (0.2559)  labels_encoder_unscaled: 0.2738 (0.4028)  labels_decoder_unscaled: 0.3507 (0.5117)  time: 0.2016  data: 0.0003  max mem: 3781
Epoch: [1]  [ 600/1415]  eta: 0:02:43  lr: 0.000100  loss: 0.4752 (0.6421)  labels_encoder: 0.3025 (0.3920)  labels_decoder: 0.1809 (0.2501)  labels_encoder_unscaled: 0.3025 (0.3920)  labels_decoder_unscaled: 0.3617 (0.5003)  time: 0.1975  data: 0.0003  max mem: 3781
Epoch: [1]  [ 650/1415]  eta: 0:02:32  lr: 0.000100  loss: 0.4355 (0.6282)  labels_encoder: 0.2602 (0.3831)  labels_decoder: 0.1713 (0.2450)  labels_encoder_unscaled: 0.2602 (0.3831)  labels_decoder_unscaled: 0.3427 (0.4901)  time: 0.1946  data: 0.0003  max mem: 3781
Epoch: [1]  [ 700/1415]  eta: 0:02:22  lr: 0.000100  loss: 0.4204 (0.6152)  labels_encoder: 0.2469 (0.3745)  labels_decoder: 0.1793 (0.2407)  labels_encoder_unscaled: 0.2469 (0.3745)  labels_decoder_unscaled: 0.3587 (0.4815)  time: 0.2045  data: 0.0003  max mem: 3781
Epoch: [1]  [ 750/1415]  eta: 0:02:12  lr: 0.000100  loss: 0.4186 (0.6027)  labels_encoder: 0.2268 (0.3660)  labels_decoder: 0.1808 (0.2366)  labels_encoder_unscaled: 0.2268 (0.3660)  labels_decoder_unscaled: 0.3616 (0.4733)  time: 0.1992  data: 0.0003  max mem: 3781
Epoch: [1]  [ 800/1415]  eta: 0:02:02  lr: 0.000100  loss: 0.4236 (0.5914)  labels_encoder: 0.2482 (0.3585)  labels_decoder: 0.1756 (0.2329)  labels_encoder_unscaled: 0.2482 (0.3585)  labels_decoder_unscaled: 0.3512 (0.4657)  time: 0.1976  data: 0.0003  max mem: 3781
Epoch: [1]  [ 850/1415]  eta: 0:01:52  lr: 0.000100  loss: 0.3969 (0.5815)  labels_encoder: 0.2236 (0.3520)  labels_decoder: 0.1736 (0.2295)  labels_encoder_unscaled: 0.2236 (0.3520)  labels_decoder_unscaled: 0.3473 (0.4591)  time: 0.1995  data: 0.0003  max mem: 3781
Epoch: [1]  [ 900/1415]  eta: 0:01:42  lr: 0.000100  loss: 0.3895 (0.5727)  labels_encoder: 0.2309 (0.3461)  labels_decoder: 0.1653 (0.2266)  labels_encoder_unscaled: 0.2309 (0.3461)  labels_decoder_unscaled: 0.3306 (0.4531)  time: 0.1890  data: 0.0003  max mem: 3781
Epoch: [1]  [ 950/1415]  eta: 0:01:32  lr: 0.000100  loss: 0.3851 (0.5629)  labels_encoder: 0.2263 (0.3393)  labels_decoder: 0.1646 (0.2236)  labels_encoder_unscaled: 0.2263 (0.3393)  labels_decoder_unscaled: 0.3292 (0.4473)  time: 0.1925  data: 0.0003  max mem: 3781
Epoch: [1]  [1000/1415]  eta: 0:01:22  lr: 0.000100  loss: 0.4157 (0.5555)  labels_encoder: 0.2302 (0.3343)  labels_decoder: 0.1730 (0.2212)  labels_encoder_unscaled: 0.2302 (0.3343)  labels_decoder_unscaled: 0.3460 (0.4424)  time: 0.1974  data: 0.0003  max mem: 3781
Epoch: [1]  [1050/1415]  eta: 0:01:12  lr: 0.000100  loss: 0.4094 (0.5476)  labels_encoder: 0.2207 (0.3289)  labels_decoder: 0.1860 (0.2186)  labels_encoder_unscaled: 0.2207 (0.3289)  labels_decoder_unscaled: 0.3720 (0.4373)  time: 0.1889  data: 0.0003  max mem: 3781
Epoch: [1]  [1100/1415]  eta: 0:01:02  lr: 0.000100  loss: 0.3494 (0.5403)  labels_encoder: 0.1966 (0.3241)  labels_decoder: 0.1576 (0.2163)  labels_encoder_unscaled: 0.1966 (0.3241)  labels_decoder_unscaled: 0.3152 (0.4325)  time: 0.1978  data: 0.0004  max mem: 3781
Epoch: [1]  [1150/1415]  eta: 0:00:52  lr: 0.000100  loss: 0.3831 (0.5331)  labels_encoder: 0.2245 (0.3191)  labels_decoder: 0.1611 (0.2140)  labels_encoder_unscaled: 0.2245 (0.3191)  labels_decoder_unscaled: 0.3222 (0.4280)  time: 0.1895  data: 0.0003  max mem: 3781
Epoch: [1]  [1200/1415]  eta: 0:00:42  lr: 0.000100  loss: 0.3500 (0.5264)  labels_encoder: 0.1946 (0.3147)  labels_decoder: 0.1525 (0.2117)  labels_encoder_unscaled: 0.1946 (0.3147)  labels_decoder_unscaled: 0.3050 (0.4234)  time: 0.1922  data: 0.0024  max mem: 3781
Epoch: [1]  [1250/1415]  eta: 0:00:32  lr: 0.000100  loss: 0.3793 (0.5200)  labels_encoder: 0.2067 (0.3104)  labels_decoder: 0.1654 (0.2096)  labels_encoder_unscaled: 0.2067 (0.3104)  labels_decoder_unscaled: 0.3309 (0.4191)  time: 0.1922  data: 0.0003  max mem: 3781
Epoch: [1]  [1300/1415]  eta: 0:00:22  lr: 0.000100  loss: 0.3443 (0.5149)  labels_encoder: 0.1982 (0.3070)  labels_decoder: 0.1577 (0.2079)  labels_encoder_unscaled: 0.1982 (0.3070)  labels_decoder_unscaled: 0.3155 (0.4158)  time: 0.1957  data: 0.0003  max mem: 3781
Epoch: [1]  [1350/1415]  eta: 0:00:12  lr: 0.000100  loss: 0.3870 (0.5098)  labels_encoder: 0.2245 (0.3036)  labels_decoder: 0.1702 (0.2062)  labels_encoder_unscaled: 0.2245 (0.3036)  labels_decoder_unscaled: 0.3404 (0.4124)  time: 0.1873  data: 0.0003  max mem: 3781
Epoch: [1]  [1400/1415]  eta: 0:00:02  lr: 0.000100  loss: 0.3454 (0.5039)  labels_encoder: 0.2048 (0.2997)  labels_decoder: 0.1461 (0.2041)  labels_encoder_unscaled: 0.2048 (0.2997)  labels_decoder_unscaled: 0.2921 (0.4083)  time: 0.1789  data: 0.0005  max mem: 3781
Epoch: [1]  [1414/1415]  eta: 0:00:00  lr: 0.000100  loss: 0.3454 (0.5024)  labels_encoder: 0.1873 (0.2988)  labels_decoder: 0.1416 (0.2036)  labels_encoder_unscaled: 0.1873 (0.2988)  labels_decoder_unscaled: 0.2833 (0.4072)  time: 0.1482  data: 0.0003  max mem: 3781
Epoch: [1] Total time: 0:04:37 (0.1963 s / it)
Averaged stats: lr: 0.000100  loss: 0.3454 (0.5024)  labels_encoder: 0.1873 (0.2988)  labels_decoder: 0.1416 (0.2036)  labels_encoder_unscaled: 0.1873 (0.2988)  labels_decoder_unscaled: 0.2833 (0.4072)
Test:  [   0/1613]  eta: 1:35:58  loss: 0.4744 (0.4744)  labels_encoder: 0.2906 (0.2906)  labels_decoder: 0.1838 (0.1838)  labels_encoder_unscaled: 0.2906 (0.2906)  labels_decoder_unscaled: 0.3676 (0.3676)  time: 3.5699  data: 3.3578  max mem: 3781
Test:  [  50/1613]  eta: 0:05:09  loss: 0.4132 (0.7035)  labels_encoder: 0.2246 (0.4211)  labels_decoder: 0.2041 (0.2824)  labels_encoder_unscaled: 0.2246 (0.4211)  labels_decoder_unscaled: 0.4081 (0.5648)  time: 0.1274  data: 0.0004  max mem: 3781
Test:  [ 100/1613]  eta: 0:04:03  loss: 0.5558 (0.7294)  labels_encoder: 0.3867 (0.4630)  labels_decoder: 0.1692 (0.2665)  labels_encoder_unscaled: 0.3867 (0.4630)  labels_decoder_unscaled: 0.3384 (0.5329)  time: 0.1256  data: 0.0002  max mem: 3781
Test:  [ 150/1613]  eta: 0:03:44  loss: 0.9776 (0.7201)  labels_encoder: 0.7122 (0.4621)  labels_decoder: 0.2471 (0.2580)  labels_encoder_unscaled: 0.7122 (0.4621)  labels_decoder_unscaled: 0.4942 (0.5159)  time: 0.1507  data: 0.0003  max mem: 3781
Test:  [ 200/1613]  eta: 0:03:23  loss: 0.9800 (0.8965)  labels_encoder: 0.6146 (0.5699)  labels_decoder: 0.3930 (0.3266)  labels_encoder_unscaled: 0.6146 (0.5699)  labels_decoder_unscaled: 0.7859 (0.6532)  time: 0.1263  data: 0.0002  max mem: 3781
Test:  [ 250/1613]  eta: 0:03:09  loss: 0.4456 (0.9283)  labels_encoder: 0.2281 (0.5898)  labels_decoder: 0.1461 (0.3384)  labels_encoder_unscaled: 0.2281 (0.5898)  labels_decoder_unscaled: 0.2921 (0.6769)  time: 0.1225  data: 0.0002  max mem: 3781
Test:  [ 300/1613]  eta: 0:02:57  loss: 0.6524 (0.9330)  labels_encoder: 0.3587 (0.5979)  labels_decoder: 0.2142 (0.3351)  labels_encoder_unscaled: 0.3587 (0.5979)  labels_decoder_unscaled: 0.4284 (0.6702)  time: 0.1170  data: 0.0003  max mem: 3781
Test:  [ 350/1613]  eta: 0:02:48  loss: 0.8734 (0.9551)  labels_encoder: 0.5794 (0.6108)  labels_decoder: 0.3401 (0.3443)  labels_encoder_unscaled: 0.5794 (0.6108)  labels_decoder_unscaled: 0.6801 (0.6887)  time: 0.1243  data: 0.0002  max mem: 3781
Test:  [ 400/1613]  eta: 0:02:39  loss: 0.7247 (0.9990)  labels_encoder: 0.4079 (0.6397)  labels_decoder: 0.3115 (0.3593)  labels_encoder_unscaled: 0.4079 (0.6397)  labels_decoder_unscaled: 0.6230 (0.7185)  time: 0.1385  data: 0.0007  max mem: 3781
Test:  [ 450/1613]  eta: 0:02:32  loss: 0.9550 (1.0621)  labels_encoder: 0.6699 (0.6863)  labels_decoder: 0.2851 (0.3759)  labels_encoder_unscaled: 0.6699 (0.6863)  labels_decoder_unscaled: 0.5703 (0.7517)  time: 0.1314  data: 0.0002  max mem: 3781
Test:  [ 500/1613]  eta: 0:02:26  loss: 0.2940 (1.0220)  labels_encoder: 0.1190 (0.6573)  labels_decoder: 0.1775 (0.3647)  labels_encoder_unscaled: 0.1190 (0.6573)  labels_decoder_unscaled: 0.3549 (0.7295)  time: 0.1172  data: 0.0002  max mem: 3781
Test:  [ 550/1613]  eta: 0:02:17  loss: 0.7268 (0.9976)  labels_encoder: 0.4693 (0.6392)  labels_decoder: 0.2752 (0.3584)  labels_encoder_unscaled: 0.4693 (0.6392)  labels_decoder_unscaled: 0.5505 (0.7168)  time: 0.1155  data: 0.0002  max mem: 3781
Test:  [ 600/1613]  eta: 0:02:10  loss: 0.6860 (1.0134)  labels_encoder: 0.3862 (0.6557)  labels_decoder: 0.2997 (0.3577)  labels_encoder_unscaled: 0.3862 (0.6557)  labels_decoder_unscaled: 0.5995 (0.7154)  time: 0.1295  data: 0.0002  max mem: 3781
Test:  [ 650/1613]  eta: 0:02:03  loss: 1.0893 (1.0064)  labels_encoder: 0.6590 (0.6493)  labels_decoder: 0.3881 (0.3571)  labels_encoder_unscaled: 0.6590 (0.6493)  labels_decoder_unscaled: 0.7762 (0.7142)  time: 0.1392  data: 0.0002  max mem: 3781
Test:  [ 700/1613]  eta: 0:01:56  loss: 0.4738 (0.9843)  labels_encoder: 0.2968 (0.6328)  labels_decoder: 0.1821 (0.3516)  labels_encoder_unscaled: 0.2968 (0.6328)  labels_decoder_unscaled: 0.3642 (0.7032)  time: 0.1350  data: 0.0047  max mem: 3781
Test:  [ 750/1613]  eta: 0:01:49  loss: 0.6547 (0.9747)  labels_encoder: 0.3759 (0.6259)  labels_decoder: 0.2788 (0.3488)  labels_encoder_unscaled: 0.3759 (0.6259)  labels_decoder_unscaled: 0.5577 (0.6976)  time: 0.1160  data: 0.0002  max mem: 3781
Test:  [ 800/1613]  eta: 0:01:43  loss: 0.6078 (0.9894)  labels_encoder: 0.2453 (0.6353)  labels_decoder: 0.3077 (0.3540)  labels_encoder_unscaled: 0.2453 (0.6353)  labels_decoder_unscaled: 0.6155 (0.7081)  time: 0.1249  data: 0.0003  max mem: 3781
Test:  [ 850/1613]  eta: 0:01:36  loss: 1.3703 (1.0156)  labels_encoder: 0.8422 (0.6514)  labels_decoder: 0.5554 (0.3642)  labels_encoder_unscaled: 0.8422 (0.6514)  labels_decoder_unscaled: 1.1108 (0.7283)  time: 0.1157  data: 0.0043  max mem: 3781
Test:  [ 900/1613]  eta: 0:01:30  loss: 0.6142 (0.9985)  labels_encoder: 0.3168 (0.6368)  labels_decoder: 0.2705 (0.3617)  labels_encoder_unscaled: 0.3168 (0.6368)  labels_decoder_unscaled: 0.5410 (0.7235)  time: 0.1208  data: 0.0002  max mem: 3781
Test:  [ 950/1613]  eta: 0:01:24  loss: 1.0072 (1.0188)  labels_encoder: 0.6463 (0.6506)  labels_decoder: 0.3340 (0.3683)  labels_encoder_unscaled: 0.6463 (0.6506)  labels_decoder_unscaled: 0.6680 (0.7365)  time: 0.1432  data: 0.0295  max mem: 3781
Test:  [1000/1613]  eta: 0:01:17  loss: 0.4898 (1.0071)  labels_encoder: 0.3272 (0.6425)  labels_decoder: 0.2120 (0.3646)  labels_encoder_unscaled: 0.3272 (0.6425)  labels_decoder_unscaled: 0.4240 (0.7292)  time: 0.1167  data: 0.0002  max mem: 3781
Test:  [1050/1613]  eta: 0:01:11  loss: 1.0549 (1.0282)  labels_encoder: 0.7125 (0.6591)  labels_decoder: 0.3755 (0.3691)  labels_encoder_unscaled: 0.7125 (0.6591)  labels_decoder_unscaled: 0.7510 (0.7382)  time: 0.1299  data: 0.0092  max mem: 3781
Test:  [1100/1613]  eta: 0:01:05  loss: 0.7138 (1.0528)  labels_encoder: 0.3623 (0.6764)  labels_decoder: 0.3769 (0.3764)  labels_encoder_unscaled: 0.3623 (0.6764)  labels_decoder_unscaled: 0.7538 (0.7529)  time: 0.1491  data: 0.0097  max mem: 3781
Test:  [1150/1613]  eta: 0:00:58  loss: 0.7000 (1.0452)  labels_encoder: 0.4460 (0.6703)  labels_decoder: 0.2540 (0.3750)  labels_encoder_unscaled: 0.4460 (0.6703)  labels_decoder_unscaled: 0.5081 (0.7499)  time: 0.1245  data: 0.0002  max mem: 3781
Test:  [1200/1613]  eta: 0:00:52  loss: 0.5082 (1.0452)  labels_encoder: 0.2562 (0.6696)  labels_decoder: 0.2273 (0.3756)  labels_encoder_unscaled: 0.2562 (0.6696)  labels_decoder_unscaled: 0.4547 (0.7512)  time: 0.1191  data: 0.0031  max mem: 3781
Test:  [1250/1613]  eta: 0:00:46  loss: 0.5317 (1.0428)  labels_encoder: 0.2884 (0.6680)  labels_decoder: 0.2616 (0.3748)  labels_encoder_unscaled: 0.2884 (0.6680)  labels_decoder_unscaled: 0.5231 (0.7497)  time: 0.1273  data: 0.0002  max mem: 3781
Test:  [1300/1613]  eta: 0:00:39  loss: 0.6330 (1.0368)  labels_encoder: 0.3636 (0.6637)  labels_decoder: 0.2695 (0.3731)  labels_encoder_unscaled: 0.3636 (0.6637)  labels_decoder_unscaled: 0.5389 (0.7462)  time: 0.1268  data: 0.0037  max mem: 3781
Test:  [1350/1613]  eta: 0:00:33  loss: 1.0708 (1.0485)  labels_encoder: 0.6662 (0.6721)  labels_decoder: 0.3458 (0.3764)  labels_encoder_unscaled: 0.6662 (0.6721)  labels_decoder_unscaled: 0.6915 (0.7527)  time: 0.1127  data: 0.0002  max mem: 3781
Test:  [1400/1613]  eta: 0:00:27  loss: 0.7486 (1.0460)  labels_encoder: 0.4674 (0.6697)  labels_decoder: 0.2913 (0.3763)  labels_encoder_unscaled: 0.4674 (0.6697)  labels_decoder_unscaled: 0.5826 (0.7526)  time: 0.1205  data: 0.0488  max mem: 3781
Test:  [1450/1613]  eta: 0:00:20  loss: 0.4429 (1.0398)  labels_encoder: 0.2507 (0.6647)  labels_decoder: 0.2238 (0.3751)  labels_encoder_unscaled: 0.2507 (0.6647)  labels_decoder_unscaled: 0.4476 (0.7501)  time: 0.1117  data: 0.0260  max mem: 3781
Test:  [1500/1613]  eta: 0:00:14  loss: 0.4533 (1.0290)  labels_encoder: 0.2862 (0.6577)  labels_decoder: 0.1844 (0.3714)  labels_encoder_unscaled: 0.2862 (0.6577)  labels_decoder_unscaled: 0.3688 (0.7428)  time: 0.1235  data: 0.0304  max mem: 3781
Test:  [1550/1613]  eta: 0:00:07  loss: 0.8657 (1.0391)  labels_encoder: 0.5774 (0.6656)  labels_decoder: 0.2828 (0.3735)  labels_encoder_unscaled: 0.5774 (0.6656)  labels_decoder_unscaled: 0.5656 (0.7470)  time: 0.0986  data: 0.0255  max mem: 3781
Test:  [1600/1613]  eta: 0:00:01  loss: 1.2481 (1.0446)  labels_encoder: 0.7832 (0.6685)  labels_decoder: 0.4649 (0.3762)  labels_encoder_unscaled: 0.7832 (0.6685)  labels_decoder_unscaled: 0.9298 (0.7523)  time: 0.1033  data: 0.0040  max mem: 3781
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5965 (1.0439)  labels_encoder: 0.3405 (0.6683)  labels_decoder: 0.2560 (0.3755)  labels_encoder_unscaled: 0.3405 (0.6683)  labels_decoder_unscaled: 0.5120 (0.7511)  time: 0.0964  data: 0.0077  max mem: 3781
Test: Total time: 0:03:22 (0.1257 s / it)
Averaged stats: loss: 0.5965 (1.0439)  labels_encoder: 0.3405 (0.6683)  labels_decoder: 0.2560 (0.3755)  labels_encoder_unscaled: 0.3405 (0.6683)  labels_decoder_unscaled: 0.5120 (0.7511)
(21, 206375)
(21, 206375)
[Epoch-1] [IDU-kin_audio] mAP: 0.6335

dec_mAP all together: | 0.5108737501079248 |.
dec_mAP_pred | 0 : 0.5653886331726651 |.
dec_mAP_pred | 1 : 0.5546642153472371 |.
dec_mAP_pred | 2 : 0.5399888951926006 |.
dec_mAP_pred | 3 : 0.5227185163290434 |.
dec_mAP_pred | 4 : 0.5052250260284821 |.
dec_mAP_pred | 5 : 0.4877611332382618 |.
dec_mAP_pred | 6 : 0.471272638008834 |.
dec_mAP_pred | 7 : 0.45546691113973414 |.
all decoder map: | 0.5128 |.
BaseballPitch: 0.2818
BasketballDunk: 0.7816
Billiards: 0.2952
CleanAndJerk: 0.7695
CliffDiving: 0.8657
CricketBowling: 0.4542
CricketShot: 0.3241
Diving: 0.8598
FrisbeeCatch: 0.4973
GolfSwing: 0.7790
HammerThrow: 0.8577
HighJump: 0.7584
JavelinThrow: 0.7470
LongJump: 0.8147
PoleVault: 0.8753
Shotput: 0.6455
SoccerPenalty: 0.4435
TennisSwing: 0.6012
ThrowDiscus: 0.6286
VolleyballSpiking: 0.3893
Epoch: [2]  [   0/1415]  eta: 1:19:05  lr: 0.000010  loss: 0.4009 (0.4009)  labels_encoder: 0.2434 (0.2434)  labels_decoder: 0.1575 (0.1575)  labels_encoder_unscaled: 0.2434 (0.2434)  labels_decoder_unscaled: 0.3149 (0.3149)  time: 3.3536  data: 3.1189  max mem: 3781
Epoch: [2]  [  50/1415]  eta: 0:06:31  lr: 0.000010  loss: 0.2940 (0.3156)  labels_encoder: 0.1613 (0.1771)  labels_decoder: 0.1291 (0.1385)  labels_encoder_unscaled: 0.1613 (0.1771)  labels_decoder_unscaled: 0.2582 (0.2770)  time: 0.1987  data: 0.0003  max mem: 3781
Epoch: [2]  [ 100/1415]  eta: 0:05:18  lr: 0.000010  loss: 0.2671 (0.3002)  labels_encoder: 0.1271 (0.1640)  labels_decoder: 0.1330 (0.1362)  labels_encoder_unscaled: 0.1271 (0.1640)  labels_decoder_unscaled: 0.2660 (0.2724)  time: 0.1879  data: 0.0003  max mem: 3781
Epoch: [2]  [ 150/1415]  eta: 0:04:51  lr: 0.000010  loss: 0.2642 (0.2977)  labels_encoder: 0.1371 (0.1628)  labels_decoder: 0.1281 (0.1349)  labels_encoder_unscaled: 0.1371 (0.1628)  labels_decoder_unscaled: 0.2563 (0.2697)  time: 0.2032  data: 0.0003  max mem: 3781
Epoch: [2]  [ 200/1415]  eta: 0:04:32  lr: 0.000010  loss: 0.2473 (0.2916)  labels_encoder: 0.1184 (0.1581)  labels_decoder: 0.1275 (0.1336)  labels_encoder_unscaled: 0.1184 (0.1581)  labels_decoder_unscaled: 0.2550 (0.2671)  time: 0.2091  data: 0.0003  max mem: 3781
Epoch: [2]  [ 250/1415]  eta: 0:04:15  lr: 0.000010  loss: 0.2867 (0.2877)  labels_encoder: 0.1603 (0.1549)  labels_decoder: 0.1341 (0.1329)  labels_encoder_unscaled: 0.1603 (0.1549)  labels_decoder_unscaled: 0.2683 (0.2657)  time: 0.2054  data: 0.0003  max mem: 3781
Epoch: [2]  [ 300/1415]  eta: 0:04:01  lr: 0.000010  loss: 0.2532 (0.2834)  labels_encoder: 0.1379 (0.1521)  labels_decoder: 0.1182 (0.1313)  labels_encoder_unscaled: 0.1379 (0.1521)  labels_decoder_unscaled: 0.2365 (0.2626)  time: 0.2028  data: 0.0004  max mem: 3781
Epoch: [2]  [ 350/1415]  eta: 0:03:48  lr: 0.000010  loss: 0.2623 (0.2806)  labels_encoder: 0.1255 (0.1501)  labels_decoder: 0.1274 (0.1306)  labels_encoder_unscaled: 0.1255 (0.1501)  labels_decoder_unscaled: 0.2547 (0.2611)  time: 0.1984  data: 0.0003  max mem: 3781
Epoch: [2]  [ 400/1415]  eta: 0:03:35  lr: 0.000010  loss: 0.2612 (0.2787)  labels_encoder: 0.1208 (0.1487)  labels_decoder: 0.1278 (0.1300)  labels_encoder_unscaled: 0.1208 (0.1487)  labels_decoder_unscaled: 0.2556 (0.2599)  time: 0.2036  data: 0.0003  max mem: 3781
Epoch: [2]  [ 450/1415]  eta: 0:03:23  lr: 0.000010  loss: 0.2470 (0.2766)  labels_encoder: 0.1228 (0.1477)  labels_decoder: 0.1180 (0.1288)  labels_encoder_unscaled: 0.1228 (0.1477)  labels_decoder_unscaled: 0.2360 (0.2577)  time: 0.2014  data: 0.0004  max mem: 3781
Epoch: [2]  [ 500/1415]  eta: 0:03:12  lr: 0.000010  loss: 0.2773 (0.2756)  labels_encoder: 0.1463 (0.1472)  labels_decoder: 0.1234 (0.1284)  labels_encoder_unscaled: 0.1463 (0.1472)  labels_decoder_unscaled: 0.2469 (0.2568)  time: 0.1967  data: 0.0003  max mem: 3781
Epoch: [2]  [ 550/1415]  eta: 0:03:01  lr: 0.000010  loss: 0.2619 (0.2750)  labels_encoder: 0.1387 (0.1471)  labels_decoder: 0.1218 (0.1278)  labels_encoder_unscaled: 0.1387 (0.1471)  labels_decoder_unscaled: 0.2436 (0.2557)  time: 0.1987  data: 0.0003  max mem: 3781
Epoch: [2]  [ 600/1415]  eta: 0:02:50  lr: 0.000010  loss: 0.2538 (0.2735)  labels_encoder: 0.1363 (0.1462)  labels_decoder: 0.1255 (0.1273)  labels_encoder_unscaled: 0.1363 (0.1462)  labels_decoder_unscaled: 0.2510 (0.2545)  time: 0.2031  data: 0.0003  max mem: 3781
Epoch: [2]  [ 650/1415]  eta: 0:02:39  lr: 0.000010  loss: 0.2592 (0.2730)  labels_encoder: 0.1333 (0.1458)  labels_decoder: 0.1313 (0.1273)  labels_encoder_unscaled: 0.1333 (0.1458)  labels_decoder_unscaled: 0.2627 (0.2546)  time: 0.2003  data: 0.0003  max mem: 3781
Epoch: [2]  [ 700/1415]  eta: 0:02:28  lr: 0.000010  loss: 0.2419 (0.2722)  labels_encoder: 0.1305 (0.1453)  labels_decoder: 0.1158 (0.1270)  labels_encoder_unscaled: 0.1305 (0.1453)  labels_decoder_unscaled: 0.2317 (0.2540)  time: 0.2023  data: 0.0003  max mem: 3781
Epoch: [2]  [ 750/1415]  eta: 0:02:17  lr: 0.000010  loss: 0.2430 (0.2709)  labels_encoder: 0.1180 (0.1443)  labels_decoder: 0.1273 (0.1266)  labels_encoder_unscaled: 0.1180 (0.1443)  labels_decoder_unscaled: 0.2546 (0.2532)  time: 0.2088  data: 0.0004  max mem: 3781
Epoch: [2]  [ 800/1415]  eta: 0:02:07  lr: 0.000010  loss: 0.2619 (0.2697)  labels_encoder: 0.1419 (0.1435)  labels_decoder: 0.1127 (0.1262)  labels_encoder_unscaled: 0.1419 (0.1435)  labels_decoder_unscaled: 0.2254 (0.2524)  time: 0.1962  data: 0.0003  max mem: 3781
Epoch: [2]  [ 850/1415]  eta: 0:01:56  lr: 0.000010  loss: 0.2409 (0.2689)  labels_encoder: 0.1230 (0.1430)  labels_decoder: 0.1219 (0.1259)  labels_encoder_unscaled: 0.1230 (0.1430)  labels_decoder_unscaled: 0.2438 (0.2518)  time: 0.2023  data: 0.0003  max mem: 3781
Epoch: [2]  [ 900/1415]  eta: 0:01:46  lr: 0.000010  loss: 0.2430 (0.2678)  labels_encoder: 0.1267 (0.1423)  labels_decoder: 0.1170 (0.1256)  labels_encoder_unscaled: 0.1267 (0.1423)  labels_decoder_unscaled: 0.2341 (0.2511)  time: 0.1932  data: 0.0003  max mem: 3781
Epoch: [2]  [ 950/1415]  eta: 0:01:35  lr: 0.000010  loss: 0.2417 (0.2668)  labels_encoder: 0.1292 (0.1415)  labels_decoder: 0.1133 (0.1253)  labels_encoder_unscaled: 0.1292 (0.1415)  labels_decoder_unscaled: 0.2266 (0.2505)  time: 0.1918  data: 0.0003  max mem: 3781
Epoch: [2]  [1000/1415]  eta: 0:01:25  lr: 0.000010  loss: 0.2500 (0.2663)  labels_encoder: 0.1304 (0.1412)  labels_decoder: 0.1281 (0.1251)  labels_encoder_unscaled: 0.1304 (0.1412)  labels_decoder_unscaled: 0.2562 (0.2502)  time: 0.1933  data: 0.0003  max mem: 3781
Epoch: [2]  [1050/1415]  eta: 0:01:14  lr: 0.000010  loss: 0.2634 (0.2658)  labels_encoder: 0.1303 (0.1409)  labels_decoder: 0.1178 (0.1250)  labels_encoder_unscaled: 0.1303 (0.1409)  labels_decoder_unscaled: 0.2355 (0.2499)  time: 0.1960  data: 0.0003  max mem: 3781
Epoch: [2]  [1100/1415]  eta: 0:01:04  lr: 0.000010  loss: 0.2533 (0.2652)  labels_encoder: 0.1321 (0.1405)  labels_decoder: 0.1060 (0.1247)  labels_encoder_unscaled: 0.1321 (0.1405)  labels_decoder_unscaled: 0.2119 (0.2494)  time: 0.2112  data: 0.0003  max mem: 3781
Epoch: [2]  [1150/1415]  eta: 0:00:54  lr: 0.000010  loss: 0.2268 (0.2645)  labels_encoder: 0.1090 (0.1399)  labels_decoder: 0.1182 (0.1246)  labels_encoder_unscaled: 0.1090 (0.1399)  labels_decoder_unscaled: 0.2364 (0.2491)  time: 0.1995  data: 0.0004  max mem: 3781
Epoch: [2]  [1200/1415]  eta: 0:00:43  lr: 0.000010  loss: 0.2377 (0.2638)  labels_encoder: 0.1179 (0.1394)  labels_decoder: 0.1124 (0.1244)  labels_encoder_unscaled: 0.1179 (0.1394)  labels_decoder_unscaled: 0.2247 (0.2487)  time: 0.1887  data: 0.0003  max mem: 3781
Epoch: [2]  [1250/1415]  eta: 0:00:33  lr: 0.000010  loss: 0.2219 (0.2634)  labels_encoder: 0.1212 (0.1392)  labels_decoder: 0.1083 (0.1241)  labels_encoder_unscaled: 0.1212 (0.1392)  labels_decoder_unscaled: 0.2166 (0.2483)  time: 0.2091  data: 0.0004  max mem: 3781
Epoch: [2]  [1300/1415]  eta: 0:00:23  lr: 0.000010  loss: 0.2393 (0.2623)  labels_encoder: 0.1160 (0.1385)  labels_decoder: 0.1136 (0.1238)  labels_encoder_unscaled: 0.1160 (0.1385)  labels_decoder_unscaled: 0.2271 (0.2477)  time: 0.2072  data: 0.0004  max mem: 3781
Epoch: [2]  [1350/1415]  eta: 0:00:13  lr: 0.000010  loss: 0.2530 (0.2620)  labels_encoder: 0.1152 (0.1383)  labels_decoder: 0.1225 (0.1237)  labels_encoder_unscaled: 0.1152 (0.1383)  labels_decoder_unscaled: 0.2450 (0.2475)  time: 0.2037  data: 0.0003  max mem: 3781
Epoch: [2]  [1400/1415]  eta: 0:00:03  lr: 0.000010  loss: 0.2456 (0.2613)  labels_encoder: 0.1277 (0.1379)  labels_decoder: 0.1158 (0.1234)  labels_encoder_unscaled: 0.1277 (0.1379)  labels_decoder_unscaled: 0.2316 (0.2468)  time: 0.1993  data: 0.0006  max mem: 3781
Epoch: [2]  [1414/1415]  eta: 0:00:00  lr: 0.000010  loss: 0.2441 (0.2611)  labels_encoder: 0.1277 (0.1378)  labels_decoder: 0.1160 (0.1234)  labels_encoder_unscaled: 0.1277 (0.1378)  labels_decoder_unscaled: 0.2320 (0.2468)  time: 0.1617  data: 0.0003  max mem: 3781
Epoch: [2] Total time: 0:04:49 (0.2047 s / it)
Averaged stats: lr: 0.000010  loss: 0.2441 (0.2611)  labels_encoder: 0.1277 (0.1378)  labels_decoder: 0.1160 (0.1234)  labels_encoder_unscaled: 0.1277 (0.1378)  labels_decoder_unscaled: 0.2320 (0.2468)
Test:  [   0/1613]  eta: 1:46:50  loss: 1.5489 (1.5489)  labels_encoder: 0.8717 (0.8717)  labels_decoder: 0.6772 (0.6772)  labels_encoder_unscaled: 0.8717 (0.8717)  labels_decoder_unscaled: 1.3544 (1.3544)  time: 3.9740  data: 3.8123  max mem: 3781
Test:  [  50/1613]  eta: 0:05:24  loss: 0.5393 (0.8229)  labels_encoder: 0.2393 (0.4979)  labels_decoder: 0.2206 (0.3250)  labels_encoder_unscaled: 0.2393 (0.4979)  labels_decoder_unscaled: 0.4412 (0.6500)  time: 0.1221  data: 0.0101  max mem: 3781
Test:  [ 100/1613]  eta: 0:04:14  loss: 0.4289 (0.7317)  labels_encoder: 0.2726 (0.4624)  labels_decoder: 0.1913 (0.2693)  labels_encoder_unscaled: 0.2726 (0.4624)  labels_decoder_unscaled: 0.3826 (0.5386)  time: 0.1321  data: 0.0029  max mem: 3781
Test:  [ 150/1613]  eta: 0:03:49  loss: 0.8761 (0.7335)  labels_encoder: 0.6536 (0.4658)  labels_decoder: 0.2225 (0.2677)  labels_encoder_unscaled: 0.6536 (0.4658)  labels_decoder_unscaled: 0.4450 (0.5353)  time: 0.1329  data: 0.0002  max mem: 3781
Test:  [ 200/1613]  eta: 0:03:34  loss: 0.9470 (0.8497)  labels_encoder: 0.5163 (0.5410)  labels_decoder: 0.3613 (0.3087)  labels_encoder_unscaled: 0.5163 (0.5410)  labels_decoder_unscaled: 0.7226 (0.6174)  time: 0.1492  data: 0.0136  max mem: 3781
Test:  [ 250/1613]  eta: 0:03:22  loss: 0.3729 (0.8837)  labels_encoder: 0.2170 (0.5611)  labels_decoder: 0.2198 (0.3226)  labels_encoder_unscaled: 0.2170 (0.5611)  labels_decoder_unscaled: 0.4396 (0.6452)  time: 0.1274  data: 0.0196  max mem: 3781
Test:  [ 300/1613]  eta: 0:03:11  loss: 0.7674 (0.9019)  labels_encoder: 0.4645 (0.5750)  labels_decoder: 0.3391 (0.3268)  labels_encoder_unscaled: 0.4645 (0.5750)  labels_decoder_unscaled: 0.6783 (0.6537)  time: 0.1299  data: 0.0352  max mem: 3781
Test:  [ 350/1613]  eta: 0:03:02  loss: 1.0091 (0.9309)  labels_encoder: 0.5820 (0.5955)  labels_decoder: 0.4263 (0.3353)  labels_encoder_unscaled: 0.5820 (0.5955)  labels_decoder_unscaled: 0.8525 (0.6706)  time: 0.1347  data: 0.0179  max mem: 3781
Test:  [ 400/1613]  eta: 0:02:53  loss: 0.7081 (0.9957)  labels_encoder: 0.3650 (0.6412)  labels_decoder: 0.2963 (0.3545)  labels_encoder_unscaled: 0.3650 (0.6412)  labels_decoder_unscaled: 0.5925 (0.7090)  time: 0.1421  data: 0.0231  max mem: 3781
Test:  [ 450/1613]  eta: 0:02:45  loss: 1.1454 (1.0796)  labels_encoder: 0.8627 (0.7014)  labels_decoder: 0.2955 (0.3782)  labels_encoder_unscaled: 0.8627 (0.7014)  labels_decoder_unscaled: 0.5910 (0.7564)  time: 0.1405  data: 0.0367  max mem: 3781
Test:  [ 500/1613]  eta: 0:02:37  loss: 0.3419 (1.0372)  labels_encoder: 0.1795 (0.6724)  labels_decoder: 0.1625 (0.3648)  labels_encoder_unscaled: 0.1795 (0.6724)  labels_decoder_unscaled: 0.3249 (0.7297)  time: 0.1381  data: 0.0257  max mem: 3781
Test:  [ 550/1613]  eta: 0:02:30  loss: 0.6039 (1.0127)  labels_encoder: 0.3371 (0.6565)  labels_decoder: 0.2268 (0.3562)  labels_encoder_unscaled: 0.3371 (0.6565)  labels_decoder_unscaled: 0.4536 (0.7125)  time: 0.1354  data: 0.0195  max mem: 3781
Test:  [ 600/1613]  eta: 0:02:22  loss: 0.7201 (1.0603)  labels_encoder: 0.4333 (0.6955)  labels_decoder: 0.2868 (0.3648)  labels_encoder_unscaled: 0.4333 (0.6955)  labels_decoder_unscaled: 0.5737 (0.7295)  time: 0.1291  data: 0.0102  max mem: 3781
Test:  [ 650/1613]  eta: 0:02:15  loss: 1.2928 (1.0715)  labels_encoder: 0.8445 (0.6993)  labels_decoder: 0.5172 (0.3722)  labels_encoder_unscaled: 0.8445 (0.6993)  labels_decoder_unscaled: 1.0343 (0.7443)  time: 0.1461  data: 0.0294  max mem: 3781
Test:  [ 700/1613]  eta: 0:02:08  loss: 0.4810 (1.0455)  labels_encoder: 0.3269 (0.6812)  labels_decoder: 0.1809 (0.3643)  labels_encoder_unscaled: 0.3269 (0.6812)  labels_decoder_unscaled: 0.3619 (0.7285)  time: 0.1493  data: 0.0284  max mem: 3781
Test:  [ 750/1613]  eta: 0:02:01  loss: 1.1114 (1.0273)  labels_encoder: 0.5982 (0.6670)  labels_decoder: 0.3421 (0.3602)  labels_encoder_unscaled: 0.5982 (0.6670)  labels_decoder_unscaled: 0.6841 (0.7205)  time: 0.1302  data: 0.0038  max mem: 3781
Test:  [ 800/1613]  eta: 0:01:54  loss: 0.4763 (1.0245)  labels_encoder: 0.2787 (0.6662)  labels_decoder: 0.1976 (0.3583)  labels_encoder_unscaled: 0.2787 (0.6662)  labels_decoder_unscaled: 0.3951 (0.7166)  time: 0.1345  data: 0.0197  max mem: 3781
Test:  [ 850/1613]  eta: 0:01:46  loss: 0.9469 (1.0296)  labels_encoder: 0.5531 (0.6665)  labels_decoder: 0.3938 (0.3631)  labels_encoder_unscaled: 0.5531 (0.6665)  labels_decoder_unscaled: 0.7876 (0.7262)  time: 0.1285  data: 0.0461  max mem: 3781
Test:  [ 900/1613]  eta: 0:01:40  loss: 0.5336 (1.0097)  labels_encoder: 0.3038 (0.6512)  labels_decoder: 0.2518 (0.3584)  labels_encoder_unscaled: 0.3038 (0.6512)  labels_decoder_unscaled: 0.5036 (0.7169)  time: 0.1459  data: 0.0224  max mem: 3781
Test:  [ 950/1613]  eta: 0:01:32  loss: 1.0591 (1.0121)  labels_encoder: 0.7027 (0.6531)  labels_decoder: 0.3564 (0.3590)  labels_encoder_unscaled: 0.7027 (0.6531)  labels_decoder_unscaled: 0.7129 (0.7181)  time: 0.1330  data: 0.0239  max mem: 3781
Test:  [1000/1613]  eta: 0:01:25  loss: 0.7579 (1.0028)  labels_encoder: 0.4404 (0.6469)  labels_decoder: 0.2765 (0.3559)  labels_encoder_unscaled: 0.4404 (0.6469)  labels_decoder_unscaled: 0.5531 (0.7118)  time: 0.1367  data: 0.0310  max mem: 3781
Test:  [1050/1613]  eta: 0:01:18  loss: 0.9243 (1.0060)  labels_encoder: 0.6086 (0.6506)  labels_decoder: 0.3413 (0.3554)  labels_encoder_unscaled: 0.6086 (0.6506)  labels_decoder_unscaled: 0.6826 (0.7107)  time: 0.1191  data: 0.0474  max mem: 3781
Test:  [1100/1613]  eta: 0:01:11  loss: 0.4792 (1.0145)  labels_encoder: 0.2240 (0.6580)  labels_decoder: 0.2224 (0.3565)  labels_encoder_unscaled: 0.2240 (0.6580)  labels_decoder_unscaled: 0.4448 (0.7129)  time: 0.1198  data: 0.0059  max mem: 3781
Test:  [1150/1613]  eta: 0:01:03  loss: 0.4777 (1.0098)  labels_encoder: 0.3036 (0.6539)  labels_decoder: 0.2224 (0.3559)  labels_encoder_unscaled: 0.3036 (0.6539)  labels_decoder_unscaled: 0.4447 (0.7118)  time: 0.1227  data: 0.0277  max mem: 3781
Test:  [1200/1613]  eta: 0:00:56  loss: 0.5289 (1.0191)  labels_encoder: 0.2363 (0.6596)  labels_decoder: 0.2160 (0.3595)  labels_encoder_unscaled: 0.2363 (0.6596)  labels_decoder_unscaled: 0.4320 (0.7190)  time: 0.1161  data: 0.0442  max mem: 3781
Test:  [1250/1613]  eta: 0:00:49  loss: 0.5107 (1.0182)  labels_encoder: 0.2749 (0.6589)  labels_decoder: 0.2357 (0.3593)  labels_encoder_unscaled: 0.2749 (0.6589)  labels_decoder_unscaled: 0.4715 (0.7185)  time: 0.1201  data: 0.0462  max mem: 3781
Test:  [1300/1613]  eta: 0:00:42  loss: 0.5118 (1.0124)  labels_encoder: 0.3202 (0.6548)  labels_decoder: 0.2340 (0.3576)  labels_encoder_unscaled: 0.3202 (0.6548)  labels_decoder_unscaled: 0.4681 (0.7152)  time: 0.1193  data: 0.0294  max mem: 3781
Test:  [1350/1613]  eta: 0:00:35  loss: 1.1149 (1.0204)  labels_encoder: 0.7487 (0.6619)  labels_decoder: 0.3791 (0.3586)  labels_encoder_unscaled: 0.7487 (0.6619)  labels_decoder_unscaled: 0.7583 (0.7171)  time: 0.1207  data: 0.0498  max mem: 3781
Test:  [1400/1613]  eta: 0:00:28  loss: 0.7942 (1.0241)  labels_encoder: 0.4973 (0.6640)  labels_decoder: 0.3004 (0.3602)  labels_encoder_unscaled: 0.4973 (0.6640)  labels_decoder_unscaled: 0.6008 (0.7204)  time: 0.1167  data: 0.0347  max mem: 3781
Test:  [1450/1613]  eta: 0:00:21  loss: 0.5333 (1.0278)  labels_encoder: 0.3345 (0.6664)  labels_decoder: 0.2028 (0.3615)  labels_encoder_unscaled: 0.3345 (0.6664)  labels_decoder_unscaled: 0.4056 (0.7229)  time: 0.1283  data: 0.0310  max mem: 3781
Test:  [1500/1613]  eta: 0:00:15  loss: 0.5413 (1.0271)  labels_encoder: 0.3840 (0.6666)  labels_decoder: 0.1759 (0.3605)  labels_encoder_unscaled: 0.3840 (0.6666)  labels_decoder_unscaled: 0.3518 (0.7210)  time: 0.1100  data: 0.0164  max mem: 3781
Test:  [1550/1613]  eta: 0:00:08  loss: 0.8249 (1.0265)  labels_encoder: 0.5672 (0.6669)  labels_decoder: 0.2647 (0.3596)  labels_encoder_unscaled: 0.5672 (0.6669)  labels_decoder_unscaled: 0.5295 (0.7192)  time: 0.1360  data: 0.0002  max mem: 3781
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8543 (1.0251)  labels_encoder: 0.5373 (0.6653)  labels_decoder: 0.3312 (0.3598)  labels_encoder_unscaled: 0.5373 (0.6653)  labels_decoder_unscaled: 0.6624 (0.7196)  time: 0.1315  data: 0.0331  max mem: 3781
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5462 (1.0222)  labels_encoder: 0.2821 (0.6636)  labels_decoder: 0.2535 (0.3586)  labels_encoder_unscaled: 0.2821 (0.6636)  labels_decoder_unscaled: 0.5070 (0.7172)  time: 0.1237  data: 0.0035  max mem: 3781
Test: Total time: 0:03:34 (0.1332 s / it)
Averaged stats: loss: 0.5462 (1.0222)  labels_encoder: 0.2821 (0.6636)  labels_decoder: 0.2535 (0.3586)  labels_encoder_unscaled: 0.2821 (0.6636)  labels_decoder_unscaled: 0.5070 (0.7172)
(21, 206375)
(21, 206375)
[Epoch-2] [IDU-kin_audio] mAP: 0.6387

dec_mAP all together: | 0.5195523704493104 |.
dec_mAP_pred | 0 : 0.5707065584778755 |.
dec_mAP_pred | 1 : 0.5618305020952941 |.
dec_mAP_pred | 2 : 0.5477914605140456 |.
dec_mAP_pred | 3 : 0.5313865218368458 |.
dec_mAP_pred | 4 : 0.5143371462330054 |.
dec_mAP_pred | 5 : 0.4974400896363066 |.
dec_mAP_pred | 6 : 0.4813358846066394 |.
dec_mAP_pred | 7 : 0.4654648044807571 |.
all decoder map: | 0.5213 |.
BaseballPitch: 0.2979
BasketballDunk: 0.8115
Billiards: 0.3207
CleanAndJerk: 0.7576
CliffDiving: 0.8529
CricketBowling: 0.4586
CricketShot: 0.3007
Diving: 0.8727
FrisbeeCatch: 0.4731
GolfSwing: 0.7778
HammerThrow: 0.8461
HighJump: 0.7662
JavelinThrow: 0.7404
LongJump: 0.7975
PoleVault: 0.8676
Shotput: 0.7147
SoccerPenalty: 0.4351
TennisSwing: 0.6235
ThrowDiscus: 0.6255
VolleyballSpiking: 0.4335
Epoch: [3]  [   0/1415]  eta: 1:33:14  lr: 0.000001  loss: 0.2639 (0.2639)  labels_encoder: 0.1385 (0.1385)  labels_decoder: 0.1254 (0.1254)  labels_encoder_unscaled: 0.1385 (0.1385)  labels_decoder_unscaled: 0.2508 (0.2508)  time: 3.9535  data: 3.6661  max mem: 3781
Epoch: [3]  [  50/1415]  eta: 0:06:31  lr: 0.000001  loss: 0.2089 (0.2326)  labels_encoder: 0.1118 (0.1202)  labels_decoder: 0.1046 (0.1124)  labels_encoder_unscaled: 0.1118 (0.1202)  labels_decoder_unscaled: 0.2092 (0.2248)  time: 0.2099  data: 0.0004  max mem: 3781
Epoch: [3]  [ 100/1415]  eta: 0:05:20  lr: 0.000001  loss: 0.2137 (0.2285)  labels_encoder: 0.1074 (0.1150)  labels_decoder: 0.1100 (0.1134)  labels_encoder_unscaled: 0.1074 (0.1150)  labels_decoder_unscaled: 0.2199 (0.2268)  time: 0.2008  data: 0.0003  max mem: 3781
Epoch: [3]  [ 150/1415]  eta: 0:04:51  lr: 0.000001  loss: 0.2182 (0.2293)  labels_encoder: 0.1100 (0.1162)  labels_decoder: 0.1116 (0.1130)  labels_encoder_unscaled: 0.1100 (0.1162)  labels_decoder_unscaled: 0.2232 (0.2260)  time: 0.2056  data: 0.0003  max mem: 3781
Epoch: [3]  [ 200/1415]  eta: 0:04:32  lr: 0.000001  loss: 0.2171 (0.2306)  labels_encoder: 0.1080 (0.1165)  labels_decoder: 0.1099 (0.1141)  labels_encoder_unscaled: 0.1080 (0.1165)  labels_decoder_unscaled: 0.2198 (0.2282)  time: 0.2032  data: 0.0003  max mem: 3781
Epoch: [3]  [ 250/1415]  eta: 0:04:14  lr: 0.000001  loss: 0.2083 (0.2306)  labels_encoder: 0.1121 (0.1170)  labels_decoder: 0.1167 (0.1136)  labels_encoder_unscaled: 0.1121 (0.1170)  labels_decoder_unscaled: 0.2333 (0.2273)  time: 0.1951  data: 0.0003  max mem: 3781
Epoch: [3]  [ 300/1415]  eta: 0:03:59  lr: 0.000001  loss: 0.2196 (0.2289)  labels_encoder: 0.1043 (0.1156)  labels_decoder: 0.1137 (0.1133)  labels_encoder_unscaled: 0.1043 (0.1156)  labels_decoder_unscaled: 0.2274 (0.2266)  time: 0.1974  data: 0.0004  max mem: 3781
Epoch: [3]  [ 350/1415]  eta: 0:03:46  lr: 0.000001  loss: 0.2427 (0.2295)  labels_encoder: 0.1252 (0.1159)  labels_decoder: 0.1126 (0.1136)  labels_encoder_unscaled: 0.1252 (0.1159)  labels_decoder_unscaled: 0.2252 (0.2271)  time: 0.1996  data: 0.0006  max mem: 3781
Epoch: [3]  [ 400/1415]  eta: 0:03:35  lr: 0.000001  loss: 0.2443 (0.2296)  labels_encoder: 0.1163 (0.1159)  labels_decoder: 0.1177 (0.1137)  labels_encoder_unscaled: 0.1163 (0.1159)  labels_decoder_unscaled: 0.2354 (0.2274)  time: 0.2048  data: 0.0003  max mem: 3781
Epoch: [3]  [ 450/1415]  eta: 0:03:23  lr: 0.000001  loss: 0.2476 (0.2309)  labels_encoder: 0.1223 (0.1169)  labels_decoder: 0.1147 (0.1140)  labels_encoder_unscaled: 0.1223 (0.1169)  labels_decoder_unscaled: 0.2294 (0.2280)  time: 0.1976  data: 0.0003  max mem: 3781
Epoch: [3]  [ 500/1415]  eta: 0:03:12  lr: 0.000001  loss: 0.2384 (0.2312)  labels_encoder: 0.1287 (0.1174)  labels_decoder: 0.1117 (0.1138)  labels_encoder_unscaled: 0.1287 (0.1174)  labels_decoder_unscaled: 0.2234 (0.2275)  time: 0.1923  data: 0.0003  max mem: 3781
Epoch: [3]  [ 550/1415]  eta: 0:03:00  lr: 0.000001  loss: 0.2218 (0.2316)  labels_encoder: 0.1108 (0.1178)  labels_decoder: 0.1075 (0.1137)  labels_encoder_unscaled: 0.1108 (0.1178)  labels_decoder_unscaled: 0.2149 (0.2275)  time: 0.1982  data: 0.0003  max mem: 3781
Epoch: [3]  [ 600/1415]  eta: 0:02:49  lr: 0.000001  loss: 0.2242 (0.2319)  labels_encoder: 0.1074 (0.1180)  labels_decoder: 0.1131 (0.1139)  labels_encoder_unscaled: 0.1074 (0.1180)  labels_decoder_unscaled: 0.2263 (0.2279)  time: 0.1967  data: 0.0003  max mem: 3781
Epoch: [3]  [ 650/1415]  eta: 0:02:39  lr: 0.000001  loss: 0.2126 (0.2311)  labels_encoder: 0.1026 (0.1175)  labels_decoder: 0.1090 (0.1136)  labels_encoder_unscaled: 0.1026 (0.1175)  labels_decoder_unscaled: 0.2179 (0.2273)  time: 0.2045  data: 0.0003  max mem: 3781
Epoch: [3]  [ 700/1415]  eta: 0:02:28  lr: 0.000001  loss: 0.2299 (0.2309)  labels_encoder: 0.1065 (0.1172)  labels_decoder: 0.1164 (0.1137)  labels_encoder_unscaled: 0.1065 (0.1172)  labels_decoder_unscaled: 0.2328 (0.2274)  time: 0.2046  data: 0.0003  max mem: 3781
Epoch: [3]  [ 750/1415]  eta: 0:02:17  lr: 0.000001  loss: 0.2222 (0.2295)  labels_encoder: 0.1115 (0.1163)  labels_decoder: 0.1068 (0.1131)  labels_encoder_unscaled: 0.1115 (0.1163)  labels_decoder_unscaled: 0.2137 (0.2263)  time: 0.2085  data: 0.0003  max mem: 3781
Epoch: [3]  [ 800/1415]  eta: 0:02:07  lr: 0.000001  loss: 0.2249 (0.2300)  labels_encoder: 0.1094 (0.1167)  labels_decoder: 0.1126 (0.1133)  labels_encoder_unscaled: 0.1094 (0.1167)  labels_decoder_unscaled: 0.2253 (0.2266)  time: 0.1915  data: 0.0003  max mem: 3781
Epoch: [3]  [ 850/1415]  eta: 0:01:56  lr: 0.000001  loss: 0.2437 (0.2306)  labels_encoder: 0.1309 (0.1173)  labels_decoder: 0.1125 (0.1132)  labels_encoder_unscaled: 0.1309 (0.1173)  labels_decoder_unscaled: 0.2250 (0.2265)  time: 0.2073  data: 0.0003  max mem: 3781
Epoch: [3]  [ 900/1415]  eta: 0:01:45  lr: 0.000001  loss: 0.2035 (0.2304)  labels_encoder: 0.0882 (0.1171)  labels_decoder: 0.1085 (0.1133)  labels_encoder_unscaled: 0.0882 (0.1171)  labels_decoder_unscaled: 0.2170 (0.2266)  time: 0.1972  data: 0.0004  max mem: 3781
Epoch: [3]  [ 950/1415]  eta: 0:01:35  lr: 0.000001  loss: 0.1984 (0.2299)  labels_encoder: 0.0972 (0.1168)  labels_decoder: 0.1025 (0.1131)  labels_encoder_unscaled: 0.0972 (0.1168)  labels_decoder_unscaled: 0.2050 (0.2262)  time: 0.1893  data: 0.0003  max mem: 3781
Epoch: [3]  [1000/1415]  eta: 0:01:24  lr: 0.000001  loss: 0.2150 (0.2298)  labels_encoder: 0.1098 (0.1167)  labels_decoder: 0.1093 (0.1131)  labels_encoder_unscaled: 0.1098 (0.1167)  labels_decoder_unscaled: 0.2185 (0.2262)  time: 0.2134  data: 0.0003  max mem: 3781
Epoch: [3]  [1050/1415]  eta: 0:01:14  lr: 0.000001  loss: 0.2173 (0.2297)  labels_encoder: 0.1036 (0.1165)  labels_decoder: 0.1146 (0.1131)  labels_encoder_unscaled: 0.1036 (0.1165)  labels_decoder_unscaled: 0.2291 (0.2262)  time: 0.2038  data: 0.0003  max mem: 3781
Epoch: [3]  [1100/1415]  eta: 0:01:04  lr: 0.000001  loss: 0.2012 (0.2295)  labels_encoder: 0.0975 (0.1165)  labels_decoder: 0.1038 (0.1130)  labels_encoder_unscaled: 0.0975 (0.1165)  labels_decoder_unscaled: 0.2077 (0.2260)  time: 0.2086  data: 0.0004  max mem: 3781
Epoch: [3]  [1150/1415]  eta: 0:00:54  lr: 0.000001  loss: 0.2243 (0.2299)  labels_encoder: 0.1154 (0.1168)  labels_decoder: 0.1089 (0.1131)  labels_encoder_unscaled: 0.1154 (0.1168)  labels_decoder_unscaled: 0.2177 (0.2261)  time: 0.2063  data: 0.0003  max mem: 3781
Epoch: [3]  [1200/1415]  eta: 0:00:44  lr: 0.000001  loss: 0.2413 (0.2301)  labels_encoder: 0.1345 (0.1170)  labels_decoder: 0.1130 (0.1131)  labels_encoder_unscaled: 0.1345 (0.1170)  labels_decoder_unscaled: 0.2260 (0.2262)  time: 0.1997  data: 0.0003  max mem: 3781
Epoch: [3]  [1250/1415]  eta: 0:00:33  lr: 0.000001  loss: 0.2430 (0.2306)  labels_encoder: 0.1125 (0.1172)  labels_decoder: 0.1223 (0.1134)  labels_encoder_unscaled: 0.1125 (0.1172)  labels_decoder_unscaled: 0.2446 (0.2268)  time: 0.2231  data: 0.0004  max mem: 3781
Epoch: [3]  [1300/1415]  eta: 0:00:23  lr: 0.000001  loss: 0.2343 (0.2304)  labels_encoder: 0.1170 (0.1171)  labels_decoder: 0.1125 (0.1133)  labels_encoder_unscaled: 0.1170 (0.1171)  labels_decoder_unscaled: 0.2251 (0.2266)  time: 0.2074  data: 0.0003  max mem: 3781
Epoch: [3]  [1350/1415]  eta: 0:00:13  lr: 0.000001  loss: 0.2209 (0.2305)  labels_encoder: 0.1084 (0.1172)  labels_decoder: 0.1056 (0.1133)  labels_encoder_unscaled: 0.1084 (0.1172)  labels_decoder_unscaled: 0.2111 (0.2266)  time: 0.2078  data: 0.0003  max mem: 3781
Epoch: [3]  [1400/1415]  eta: 0:00:03  lr: 0.000001  loss: 0.2145 (0.2303)  labels_encoder: 0.1079 (0.1171)  labels_decoder: 0.1135 (0.1132)  labels_encoder_unscaled: 0.1079 (0.1171)  labels_decoder_unscaled: 0.2270 (0.2264)  time: 0.2092  data: 0.0007  max mem: 3781
Epoch: [3]  [1414/1415]  eta: 0:00:00  lr: 0.000001  loss: 0.2160 (0.2302)  labels_encoder: 0.1025 (0.1170)  labels_decoder: 0.1094 (0.1131)  labels_encoder_unscaled: 0.1025 (0.1170)  labels_decoder_unscaled: 0.2188 (0.2263)  time: 0.1630  data: 0.0004  max mem: 3781
Epoch: [3] Total time: 0:04:50 (0.2054 s / it)
Averaged stats: lr: 0.000001  loss: 0.2160 (0.2302)  labels_encoder: 0.1025 (0.1170)  labels_decoder: 0.1094 (0.1131)  labels_encoder_unscaled: 0.1025 (0.1170)  labels_decoder_unscaled: 0.2188 (0.2263)
Test:  [   0/1613]  eta: 1:52:57  loss: 1.2464 (1.2464)  labels_encoder: 0.7051 (0.7051)  labels_decoder: 0.5413 (0.5413)  labels_encoder_unscaled: 0.7051 (0.7051)  labels_decoder_unscaled: 1.0826 (1.0826)  time: 4.2018  data: 4.1373  max mem: 3781
Test:  [  50/1613]  eta: 0:05:21  loss: 0.4409 (0.8275)  labels_encoder: 0.2420 (0.5111)  labels_decoder: 0.2174 (0.3164)  labels_encoder_unscaled: 0.2420 (0.5111)  labels_decoder_unscaled: 0.4348 (0.6328)  time: 0.1225  data: 0.0002  max mem: 3781
Test:  [ 100/1613]  eta: 0:04:15  loss: 0.4849 (0.7564)  labels_encoder: 0.3497 (0.4882)  labels_decoder: 0.1784 (0.2682)  labels_encoder_unscaled: 0.3497 (0.4882)  labels_decoder_unscaled: 0.3568 (0.5363)  time: 0.1296  data: 0.0511  max mem: 3781
Test:  [ 150/1613]  eta: 0:03:53  loss: 0.7522 (0.7598)  labels_encoder: 0.5628 (0.4897)  labels_decoder: 0.1899 (0.2701)  labels_encoder_unscaled: 0.5628 (0.4897)  labels_decoder_unscaled: 0.3798 (0.5403)  time: 0.1333  data: 0.0175  max mem: 3781
Test:  [ 200/1613]  eta: 0:03:37  loss: 0.9418 (0.8803)  labels_encoder: 0.5712 (0.5657)  labels_decoder: 0.3659 (0.3146)  labels_encoder_unscaled: 0.5712 (0.5657)  labels_decoder_unscaled: 0.7317 (0.6293)  time: 0.1368  data: 0.0072  max mem: 3781
Test:  [ 250/1613]  eta: 0:03:26  loss: 0.5226 (0.9123)  labels_encoder: 0.2201 (0.5824)  labels_decoder: 0.2300 (0.3299)  labels_encoder_unscaled: 0.2201 (0.5824)  labels_decoder_unscaled: 0.4600 (0.6598)  time: 0.1507  data: 0.0206  max mem: 3781
Test:  [ 300/1613]  eta: 0:03:14  loss: 1.0902 (0.9614)  labels_encoder: 0.6516 (0.6154)  labels_decoder: 0.4705 (0.3460)  labels_encoder_unscaled: 0.6516 (0.6154)  labels_decoder_unscaled: 0.9409 (0.6920)  time: 0.1307  data: 0.0305  max mem: 3781
Test:  [ 350/1613]  eta: 0:03:04  loss: 1.0889 (0.9852)  labels_encoder: 0.5921 (0.6310)  labels_decoder: 0.4819 (0.3542)  labels_encoder_unscaled: 0.5921 (0.6310)  labels_decoder_unscaled: 0.9638 (0.7084)  time: 0.1283  data: 0.0337  max mem: 3781
Test:  [ 400/1613]  eta: 0:02:55  loss: 0.7073 (1.0441)  labels_encoder: 0.3753 (0.6713)  labels_decoder: 0.3271 (0.3728)  labels_encoder_unscaled: 0.3753 (0.6713)  labels_decoder_unscaled: 0.6542 (0.7457)  time: 0.1337  data: 0.0252  max mem: 3781
Test:  [ 450/1613]  eta: 0:02:47  loss: 0.9500 (1.1388)  labels_encoder: 0.7060 (0.7382)  labels_decoder: 0.2950 (0.4006)  labels_encoder_unscaled: 0.7060 (0.7382)  labels_decoder_unscaled: 0.5900 (0.8011)  time: 0.1403  data: 0.0440  max mem: 3781
Test:  [ 500/1613]  eta: 0:02:39  loss: 0.2784 (1.0877)  labels_encoder: 0.1622 (0.7030)  labels_decoder: 0.1673 (0.3846)  labels_encoder_unscaled: 0.1622 (0.7030)  labels_decoder_unscaled: 0.3345 (0.7693)  time: 0.1369  data: 0.0286  max mem: 3781
Test:  [ 550/1613]  eta: 0:02:31  loss: 0.5540 (1.0612)  labels_encoder: 0.3107 (0.6853)  labels_decoder: 0.2393 (0.3759)  labels_encoder_unscaled: 0.3107 (0.6853)  labels_decoder_unscaled: 0.4786 (0.7517)  time: 0.1419  data: 0.0159  max mem: 3781
Test:  [ 600/1613]  eta: 0:02:24  loss: 0.7578 (1.1022)  labels_encoder: 0.4501 (0.7209)  labels_decoder: 0.3077 (0.3813)  labels_encoder_unscaled: 0.4501 (0.7209)  labels_decoder_unscaled: 0.6153 (0.7626)  time: 0.1427  data: 0.0005  max mem: 3781
Test:  [ 650/1613]  eta: 0:02:17  loss: 1.0146 (1.1001)  labels_encoder: 0.5947 (0.7155)  labels_decoder: 0.4199 (0.3846)  labels_encoder_unscaled: 0.5947 (0.7155)  labels_decoder_unscaled: 0.8398 (0.7693)  time: 0.1304  data: 0.0032  max mem: 3781
Test:  [ 700/1613]  eta: 0:02:09  loss: 0.5020 (1.0717)  labels_encoder: 0.3100 (0.6957)  labels_decoder: 0.1873 (0.3760)  labels_encoder_unscaled: 0.3100 (0.6957)  labels_decoder_unscaled: 0.3746 (0.7520)  time: 0.1206  data: 0.0335  max mem: 3781
Test:  [ 750/1613]  eta: 0:02:01  loss: 0.9265 (1.0464)  labels_encoder: 0.4786 (0.6768)  labels_decoder: 0.3545 (0.3696)  labels_encoder_unscaled: 0.4786 (0.6768)  labels_decoder_unscaled: 0.7090 (0.7392)  time: 0.1229  data: 0.0037  max mem: 3781
Test:  [ 800/1613]  eta: 0:01:53  loss: 0.5810 (1.0409)  labels_encoder: 0.3474 (0.6741)  labels_decoder: 0.2336 (0.3668)  labels_encoder_unscaled: 0.3474 (0.6741)  labels_decoder_unscaled: 0.4671 (0.7335)  time: 0.1172  data: 0.0351  max mem: 3781
Test:  [ 850/1613]  eta: 0:01:45  loss: 0.8827 (1.0447)  labels_encoder: 0.5143 (0.6735)  labels_decoder: 0.3684 (0.3713)  labels_encoder_unscaled: 0.5143 (0.6735)  labels_decoder_unscaled: 0.7368 (0.7425)  time: 0.1287  data: 0.0167  max mem: 3781
Test:  [ 900/1613]  eta: 0:01:38  loss: 0.5590 (1.0230)  labels_encoder: 0.2847 (0.6570)  labels_decoder: 0.2604 (0.3660)  labels_encoder_unscaled: 0.2847 (0.6570)  labels_decoder_unscaled: 0.5208 (0.7320)  time: 0.1263  data: 0.0002  max mem: 3781
Test:  [ 950/1613]  eta: 0:01:30  loss: 1.0645 (1.0208)  labels_encoder: 0.5894 (0.6552)  labels_decoder: 0.3594 (0.3655)  labels_encoder_unscaled: 0.5894 (0.6552)  labels_decoder_unscaled: 0.7188 (0.7310)  time: 0.1162  data: 0.0233  max mem: 3781
Test:  [1000/1613]  eta: 0:01:23  loss: 0.9721 (1.0132)  labels_encoder: 0.5764 (0.6500)  labels_decoder: 0.3067 (0.3631)  labels_encoder_unscaled: 0.5764 (0.6500)  labels_decoder_unscaled: 0.6135 (0.7263)  time: 0.1313  data: 0.0572  max mem: 3781
Test:  [1050/1613]  eta: 0:01:16  loss: 0.9603 (1.0163)  labels_encoder: 0.5989 (0.6536)  labels_decoder: 0.3460 (0.3628)  labels_encoder_unscaled: 0.5989 (0.6536)  labels_decoder_unscaled: 0.6920 (0.7255)  time: 0.1356  data: 0.0293  max mem: 3781
Test:  [1100/1613]  eta: 0:01:09  loss: 0.4453 (1.0193)  labels_encoder: 0.2140 (0.6567)  labels_decoder: 0.2094 (0.3626)  labels_encoder_unscaled: 0.2140 (0.6567)  labels_decoder_unscaled: 0.4187 (0.7252)  time: 0.1209  data: 0.0432  max mem: 3781
Test:  [1150/1613]  eta: 0:01:02  loss: 0.6253 (1.0142)  labels_encoder: 0.3482 (0.6530)  labels_decoder: 0.2771 (0.3612)  labels_encoder_unscaled: 0.3482 (0.6530)  labels_decoder_unscaled: 0.5542 (0.7224)  time: 0.1258  data: 0.0032  max mem: 3781
Test:  [1200/1613]  eta: 0:00:55  loss: 0.4800 (1.0201)  labels_encoder: 0.2265 (0.6567)  labels_decoder: 0.1854 (0.3634)  labels_encoder_unscaled: 0.2265 (0.6567)  labels_decoder_unscaled: 0.3709 (0.7267)  time: 0.1326  data: 0.0306  max mem: 3781
Test:  [1250/1613]  eta: 0:00:48  loss: 0.5216 (1.0193)  labels_encoder: 0.2682 (0.6561)  labels_decoder: 0.2473 (0.3632)  labels_encoder_unscaled: 0.2682 (0.6561)  labels_decoder_unscaled: 0.4947 (0.7265)  time: 0.1255  data: 0.0511  max mem: 3781
Test:  [1300/1613]  eta: 0:00:42  loss: 0.6505 (1.0160)  labels_encoder: 0.4039 (0.6532)  labels_decoder: 0.2711 (0.3628)  labels_encoder_unscaled: 0.4039 (0.6532)  labels_decoder_unscaled: 0.5421 (0.7256)  time: 0.1320  data: 0.0444  max mem: 3781
Test:  [1350/1613]  eta: 0:00:35  loss: 1.1642 (1.0217)  labels_encoder: 0.7781 (0.6585)  labels_decoder: 0.3918 (0.3632)  labels_encoder_unscaled: 0.7781 (0.6585)  labels_decoder_unscaled: 0.7836 (0.7264)  time: 0.1337  data: 0.0304  max mem: 3781
Test:  [1400/1613]  eta: 0:00:28  loss: 0.9587 (1.0276)  labels_encoder: 0.5894 (0.6618)  labels_decoder: 0.3948 (0.3658)  labels_encoder_unscaled: 0.5894 (0.6618)  labels_decoder_unscaled: 0.7896 (0.7315)  time: 0.1328  data: 0.0308  max mem: 3781
Test:  [1450/1613]  eta: 0:00:21  loss: 0.5533 (1.0306)  labels_encoder: 0.3169 (0.6635)  labels_decoder: 0.1876 (0.3671)  labels_encoder_unscaled: 0.3169 (0.6635)  labels_decoder_unscaled: 0.3752 (0.7342)  time: 0.1377  data: 0.0492  max mem: 3781
Test:  [1500/1613]  eta: 0:00:15  loss: 0.5421 (1.0304)  labels_encoder: 0.3604 (0.6636)  labels_decoder: 0.1976 (0.3668)  labels_encoder_unscaled: 0.3604 (0.6636)  labels_decoder_unscaled: 0.3953 (0.7337)  time: 0.1392  data: 0.0391  max mem: 3781
Test:  [1550/1613]  eta: 0:00:08  loss: 0.8717 (1.0296)  labels_encoder: 0.5995 (0.6637)  labels_decoder: 0.2651 (0.3659)  labels_encoder_unscaled: 0.5995 (0.6637)  labels_decoder_unscaled: 0.5303 (0.7318)  time: 0.1260  data: 0.0211  max mem: 3781
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8177 (1.0266)  labels_encoder: 0.4861 (0.6610)  labels_decoder: 0.3155 (0.3656)  labels_encoder_unscaled: 0.4861 (0.6610)  labels_decoder_unscaled: 0.6309 (0.7312)  time: 0.1304  data: 0.0423  max mem: 3781
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5456 (1.0237)  labels_encoder: 0.2577 (0.6593)  labels_decoder: 0.2563 (0.3644)  labels_encoder_unscaled: 0.2577 (0.6593)  labels_decoder_unscaled: 0.5126 (0.7287)  time: 0.1284  data: 0.0466  max mem: 3781
Test: Total time: 0:03:36 (0.1343 s / it)
Averaged stats: loss: 0.5456 (1.0237)  labels_encoder: 0.2577 (0.6593)  labels_decoder: 0.2563 (0.3644)  labels_encoder_unscaled: 0.2577 (0.6593)  labels_decoder_unscaled: 0.5126 (0.7287)
(21, 206375)
(21, 206375)
[Epoch-3] [IDU-kin_audio] mAP: 0.6383

dec_mAP all together: | 0.5164096009787145 |.
dec_mAP_pred | 0 : 0.566685300516177 |.
dec_mAP_pred | 1 : 0.5580482075497052 |.
dec_mAP_pred | 2 : 0.5442607981393046 |.
dec_mAP_pred | 3 : 0.528128356779894 |.
dec_mAP_pred | 4 : 0.511222290356411 |.
dec_mAP_pred | 5 : 0.49460650443024984 |.
dec_mAP_pred | 6 : 0.47865488503257164 |.
dec_mAP_pred | 7 : 0.46295405640268095 |.
all decoder map: | 0.5181 |.
BaseballPitch: 0.2950
BasketballDunk: 0.8108
Billiards: 0.3210
CleanAndJerk: 0.7527
CliffDiving: 0.8523
CricketBowling: 0.4573
CricketShot: 0.3027
Diving: 0.8761
FrisbeeCatch: 0.4533
GolfSwing: 0.7755
HammerThrow: 0.8376
HighJump: 0.7817
JavelinThrow: 0.7453
LongJump: 0.7963
PoleVault: 0.8739
Shotput: 0.7178
SoccerPenalty: 0.4315
TennisSwing: 0.6232
ThrowDiscus: 0.6245
VolleyballSpiking: 0.4382
Epoch: [4]  [   0/1415]  eta: 1:38:19  lr: 0.000000  loss: 0.1541 (0.1541)  labels_encoder: 0.0777 (0.0777)  labels_decoder: 0.0764 (0.0764)  labels_encoder_unscaled: 0.0777 (0.0777)  labels_decoder_unscaled: 0.1528 (0.1528)  time: 4.1690  data: 3.8688  max mem: 3781
Epoch: [4]  [  50/1415]  eta: 0:06:47  lr: 0.000000  loss: 0.2255 (0.2297)  labels_encoder: 0.1078 (0.1123)  labels_decoder: 0.1127 (0.1175)  labels_encoder_unscaled: 0.1078 (0.1123)  labels_decoder_unscaled: 0.2253 (0.2349)  time: 0.2009  data: 0.0004  max mem: 3781
Epoch: [4]  [ 100/1415]  eta: 0:05:33  lr: 0.000000  loss: 0.2166 (0.2287)  labels_encoder: 0.0984 (0.1121)  labels_decoder: 0.1116 (0.1166)  labels_encoder_unscaled: 0.0984 (0.1121)  labels_decoder_unscaled: 0.2232 (0.2332)  time: 0.2023  data: 0.0004  max mem: 3781
Epoch: [4]  [ 150/1415]  eta: 0:05:00  lr: 0.000000  loss: 0.2187 (0.2268)  labels_encoder: 0.1015 (0.1131)  labels_decoder: 0.1036 (0.1137)  labels_encoder_unscaled: 0.1015 (0.1131)  labels_decoder_unscaled: 0.2071 (0.2274)  time: 0.2077  data: 0.0004  max mem: 3781
Epoch: [4]  [ 200/1415]  eta: 0:04:36  lr: 0.000000  loss: 0.2034 (0.2235)  labels_encoder: 0.0995 (0.1116)  labels_decoder: 0.1043 (0.1119)  labels_encoder_unscaled: 0.0995 (0.1116)  labels_decoder_unscaled: 0.2085 (0.2237)  time: 0.1857  data: 0.0004  max mem: 3781
Epoch: [4]  [ 250/1415]  eta: 0:04:19  lr: 0.000000  loss: 0.2047 (0.2239)  labels_encoder: 0.1108 (0.1127)  labels_decoder: 0.1047 (0.1112)  labels_encoder_unscaled: 0.1108 (0.1127)  labels_decoder_unscaled: 0.2095 (0.2224)  time: 0.1910  data: 0.0004  max mem: 3781
Epoch: [4]  [ 300/1415]  eta: 0:04:06  lr: 0.000000  loss: 0.2009 (0.2233)  labels_encoder: 0.0976 (0.1121)  labels_decoder: 0.1043 (0.1111)  labels_encoder_unscaled: 0.0976 (0.1121)  labels_decoder_unscaled: 0.2085 (0.2223)  time: 0.2168  data: 0.0004  max mem: 3781
Epoch: [4]  [ 350/1415]  eta: 0:03:51  lr: 0.000000  loss: 0.2129 (0.2230)  labels_encoder: 0.0985 (0.1120)  labels_decoder: 0.1122 (0.1110)  labels_encoder_unscaled: 0.0985 (0.1120)  labels_decoder_unscaled: 0.2245 (0.2221)  time: 0.2078  data: 0.0003  max mem: 3781
Epoch: [4]  [ 400/1415]  eta: 0:03:39  lr: 0.000000  loss: 0.2339 (0.2242)  labels_encoder: 0.1062 (0.1131)  labels_decoder: 0.1076 (0.1111)  labels_encoder_unscaled: 0.1062 (0.1131)  labels_decoder_unscaled: 0.2151 (0.2222)  time: 0.2015  data: 0.0005  max mem: 3781
Epoch: [4]  [ 450/1415]  eta: 0:03:27  lr: 0.000000  loss: 0.2183 (0.2243)  labels_encoder: 0.1178 (0.1132)  labels_decoder: 0.0990 (0.1111)  labels_encoder_unscaled: 0.1178 (0.1132)  labels_decoder_unscaled: 0.1981 (0.2221)  time: 0.2002  data: 0.0003  max mem: 3781
Epoch: [4]  [ 500/1415]  eta: 0:03:15  lr: 0.000000  loss: 0.2341 (0.2249)  labels_encoder: 0.1161 (0.1134)  labels_decoder: 0.1145 (0.1115)  labels_encoder_unscaled: 0.1161 (0.1134)  labels_decoder_unscaled: 0.2290 (0.2230)  time: 0.2025  data: 0.0004  max mem: 3781
Epoch: [4]  [ 550/1415]  eta: 0:03:03  lr: 0.000000  loss: 0.2180 (0.2247)  labels_encoder: 0.1111 (0.1132)  labels_decoder: 0.1092 (0.1115)  labels_encoder_unscaled: 0.1111 (0.1132)  labels_decoder_unscaled: 0.2184 (0.2230)  time: 0.1882  data: 0.0003  max mem: 3781
Epoch: [4]  [ 600/1415]  eta: 0:02:52  lr: 0.000000  loss: 0.2244 (0.2254)  labels_encoder: 0.1208 (0.1139)  labels_decoder: 0.1049 (0.1115)  labels_encoder_unscaled: 0.1208 (0.1139)  labels_decoder_unscaled: 0.2098 (0.2230)  time: 0.2037  data: 0.0003  max mem: 3781
Epoch: [4]  [ 650/1415]  eta: 0:02:41  lr: 0.000000  loss: 0.2068 (0.2255)  labels_encoder: 0.1087 (0.1139)  labels_decoder: 0.1120 (0.1116)  labels_encoder_unscaled: 0.1087 (0.1139)  labels_decoder_unscaled: 0.2241 (0.2232)  time: 0.2079  data: 0.0003  max mem: 3781
Epoch: [4]  [ 700/1415]  eta: 0:02:30  lr: 0.000000  loss: 0.2417 (0.2264)  labels_encoder: 0.1193 (0.1144)  labels_decoder: 0.1184 (0.1120)  labels_encoder_unscaled: 0.1193 (0.1144)  labels_decoder_unscaled: 0.2369 (0.2239)  time: 0.2073  data: 0.0004  max mem: 3781
Epoch: [4]  [ 750/1415]  eta: 0:02:18  lr: 0.000000  loss: 0.2258 (0.2264)  labels_encoder: 0.1069 (0.1145)  labels_decoder: 0.1141 (0.1120)  labels_encoder_unscaled: 0.1069 (0.1145)  labels_decoder_unscaled: 0.2281 (0.2239)  time: 0.1809  data: 0.0003  max mem: 3781
Epoch: [4]  [ 800/1415]  eta: 0:02:08  lr: 0.000000  loss: 0.2281 (0.2262)  labels_encoder: 0.1135 (0.1141)  labels_decoder: 0.1090 (0.1120)  labels_encoder_unscaled: 0.1135 (0.1141)  labels_decoder_unscaled: 0.2180 (0.2241)  time: 0.2102  data: 0.0004  max mem: 3781
Epoch: [4]  [ 850/1415]  eta: 0:01:58  lr: 0.000000  loss: 0.2246 (0.2257)  labels_encoder: 0.1113 (0.1138)  labels_decoder: 0.1104 (0.1119)  labels_encoder_unscaled: 0.1113 (0.1138)  labels_decoder_unscaled: 0.2208 (0.2237)  time: 0.2217  data: 0.0003  max mem: 3781
Epoch: [4]  [ 900/1415]  eta: 0:01:47  lr: 0.000000  loss: 0.2134 (0.2258)  labels_encoder: 0.0948 (0.1140)  labels_decoder: 0.1135 (0.1118)  labels_encoder_unscaled: 0.0948 (0.1140)  labels_decoder_unscaled: 0.2271 (0.2236)  time: 0.2073  data: 0.0004  max mem: 3781
Epoch: [4]  [ 950/1415]  eta: 0:01:37  lr: 0.000000  loss: 0.1994 (0.2255)  labels_encoder: 0.0985 (0.1139)  labels_decoder: 0.1012 (0.1116)  labels_encoder_unscaled: 0.0985 (0.1139)  labels_decoder_unscaled: 0.2023 (0.2233)  time: 0.2140  data: 0.0027  max mem: 3781
Epoch: [4]  [1000/1415]  eta: 0:01:26  lr: 0.000000  loss: 0.2382 (0.2261)  labels_encoder: 0.1250 (0.1143)  labels_decoder: 0.1113 (0.1118)  labels_encoder_unscaled: 0.1250 (0.1143)  labels_decoder_unscaled: 0.2227 (0.2236)  time: 0.2099  data: 0.0003  max mem: 3781
Epoch: [4]  [1050/1415]  eta: 0:01:16  lr: 0.000000  loss: 0.2101 (0.2263)  labels_encoder: 0.1088 (0.1144)  labels_decoder: 0.1020 (0.1118)  labels_encoder_unscaled: 0.1088 (0.1144)  labels_decoder_unscaled: 0.2041 (0.2237)  time: 0.2041  data: 0.0003  max mem: 3781
Epoch: [4]  [1100/1415]  eta: 0:01:05  lr: 0.000000  loss: 0.2275 (0.2265)  labels_encoder: 0.1174 (0.1147)  labels_decoder: 0.1078 (0.1118)  labels_encoder_unscaled: 0.1174 (0.1147)  labels_decoder_unscaled: 0.2155 (0.2236)  time: 0.1985  data: 0.0003  max mem: 3781
Epoch: [4]  [1150/1415]  eta: 0:00:55  lr: 0.000000  loss: 0.2194 (0.2265)  labels_encoder: 0.0994 (0.1146)  labels_decoder: 0.1156 (0.1119)  labels_encoder_unscaled: 0.0994 (0.1146)  labels_decoder_unscaled: 0.2312 (0.2238)  time: 0.2123  data: 0.0003  max mem: 3781
Epoch: [4]  [1200/1415]  eta: 0:00:44  lr: 0.000000  loss: 0.2106 (0.2264)  labels_encoder: 0.1002 (0.1144)  labels_decoder: 0.1089 (0.1119)  labels_encoder_unscaled: 0.1002 (0.1144)  labels_decoder_unscaled: 0.2178 (0.2239)  time: 0.2037  data: 0.0004  max mem: 3781
Epoch: [4]  [1250/1415]  eta: 0:00:34  lr: 0.000000  loss: 0.2273 (0.2262)  labels_encoder: 0.1184 (0.1143)  labels_decoder: 0.1061 (0.1118)  labels_encoder_unscaled: 0.1184 (0.1143)  labels_decoder_unscaled: 0.2122 (0.2236)  time: 0.2055  data: 0.0003  max mem: 3781
Epoch: [4]  [1300/1415]  eta: 0:00:23  lr: 0.000000  loss: 0.1981 (0.2261)  labels_encoder: 0.1014 (0.1142)  labels_decoder: 0.1121 (0.1118)  labels_encoder_unscaled: 0.1014 (0.1142)  labels_decoder_unscaled: 0.2242 (0.2236)  time: 0.2013  data: 0.0003  max mem: 3781
Epoch: [4]  [1350/1415]  eta: 0:00:13  lr: 0.000000  loss: 0.2154 (0.2261)  labels_encoder: 0.1121 (0.1142)  labels_decoder: 0.1144 (0.1119)  labels_encoder_unscaled: 0.1121 (0.1142)  labels_decoder_unscaled: 0.2288 (0.2238)  time: 0.2120  data: 0.0003  max mem: 3781
Epoch: [4]  [1400/1415]  eta: 0:00:03  lr: 0.000000  loss: 0.2340 (0.2264)  labels_encoder: 0.1076 (0.1145)  labels_decoder: 0.1147 (0.1119)  labels_encoder_unscaled: 0.1076 (0.1145)  labels_decoder_unscaled: 0.2294 (0.2239)  time: 0.1974  data: 0.0005  max mem: 3781
Epoch: [4]  [1414/1415]  eta: 0:00:00  lr: 0.000000  loss: 0.2306 (0.2264)  labels_encoder: 0.1097 (0.1145)  labels_decoder: 0.1175 (0.1119)  labels_encoder_unscaled: 0.1097 (0.1145)  labels_decoder_unscaled: 0.2351 (0.2239)  time: 0.1641  data: 0.0003  max mem: 3781
Epoch: [4] Total time: 0:04:53 (0.2077 s / it)
Averaged stats: lr: 0.000000  loss: 0.2306 (0.2264)  labels_encoder: 0.1097 (0.1145)  labels_decoder: 0.1175 (0.1119)  labels_encoder_unscaled: 0.1097 (0.1145)  labels_decoder_unscaled: 0.2351 (0.2239)
Test:  [   0/1613]  eta: 1:53:33  loss: 1.2691 (1.2691)  labels_encoder: 0.7061 (0.7061)  labels_decoder: 0.5630 (0.5630)  labels_encoder_unscaled: 0.7061 (0.7061)  labels_decoder_unscaled: 1.1259 (1.1259)  time: 4.2241  data: 4.1629  max mem: 3781
Test:  [  50/1613]  eta: 0:05:22  loss: 0.4648 (0.8229)  labels_encoder: 0.2340 (0.5059)  labels_decoder: 0.2140 (0.3170)  labels_encoder_unscaled: 0.2340 (0.5059)  labels_decoder_unscaled: 0.4280 (0.6340)  time: 0.1323  data: 0.0002  max mem: 3781
Test:  [ 100/1613]  eta: 0:04:08  loss: 0.4846 (0.7535)  labels_encoder: 0.3471 (0.4843)  labels_decoder: 0.1790 (0.2692)  labels_encoder_unscaled: 0.3471 (0.4843)  labels_decoder_unscaled: 0.3580 (0.5384)  time: 0.1154  data: 0.0062  max mem: 3781
Test:  [ 150/1613]  eta: 0:03:43  loss: 0.8043 (0.7580)  labels_encoder: 0.5606 (0.4875)  labels_decoder: 0.1903 (0.2705)  labels_encoder_unscaled: 0.5606 (0.4875)  labels_decoder_unscaled: 0.3806 (0.5410)  time: 0.1256  data: 0.0175  max mem: 3781
Test:  [ 200/1613]  eta: 0:03:29  loss: 0.9304 (0.8789)  labels_encoder: 0.5606 (0.5639)  labels_decoder: 0.3654 (0.3150)  labels_encoder_unscaled: 0.5606 (0.5639)  labels_decoder_unscaled: 0.7308 (0.6300)  time: 0.1362  data: 0.0154  max mem: 3781
Test:  [ 250/1613]  eta: 0:03:20  loss: 0.4738 (0.9122)  labels_encoder: 0.2164 (0.5821)  labels_decoder: 0.2275 (0.3301)  labels_encoder_unscaled: 0.2164 (0.5821)  labels_decoder_unscaled: 0.4550 (0.6602)  time: 0.1454  data: 0.0540  max mem: 3781
Test:  [ 300/1613]  eta: 0:03:09  loss: 1.0543 (0.9557)  labels_encoder: 0.6131 (0.6116)  labels_decoder: 0.4580 (0.3440)  labels_encoder_unscaled: 0.6131 (0.6116)  labels_decoder_unscaled: 0.9161 (0.6881)  time: 0.1351  data: 0.0488  max mem: 3781
Test:  [ 350/1613]  eta: 0:03:00  loss: 1.0846 (0.9798)  labels_encoder: 0.5922 (0.6272)  labels_decoder: 0.4668 (0.3526)  labels_encoder_unscaled: 0.5922 (0.6272)  labels_decoder_unscaled: 0.9335 (0.7052)  time: 0.1267  data: 0.0424  max mem: 3781
Test:  [ 400/1613]  eta: 0:02:50  loss: 0.7071 (1.0381)  labels_encoder: 0.3749 (0.6673)  labels_decoder: 0.3270 (0.3708)  labels_encoder_unscaled: 0.3749 (0.6673)  labels_decoder_unscaled: 0.6540 (0.7416)  time: 0.1281  data: 0.0313  max mem: 3781
Test:  [ 450/1613]  eta: 0:02:41  loss: 0.9792 (1.1309)  labels_encoder: 0.7199 (0.7329)  labels_decoder: 0.2994 (0.3980)  labels_encoder_unscaled: 0.7199 (0.7329)  labels_decoder_unscaled: 0.5988 (0.7960)  time: 0.1257  data: 0.0653  max mem: 3781
Test:  [ 500/1613]  eta: 0:02:33  loss: 0.2829 (1.0812)  labels_encoder: 0.1623 (0.6987)  labels_decoder: 0.1706 (0.3825)  labels_encoder_unscaled: 0.1623 (0.6987)  labels_decoder_unscaled: 0.3413 (0.7650)  time: 0.1232  data: 0.0325  max mem: 3781
Test:  [ 550/1613]  eta: 0:02:25  loss: 0.5540 (1.0557)  labels_encoder: 0.3117 (0.6817)  labels_decoder: 0.2395 (0.3740)  labels_encoder_unscaled: 0.3117 (0.6817)  labels_decoder_unscaled: 0.4790 (0.7481)  time: 0.1248  data: 0.0580  max mem: 3781
Test:  [ 600/1613]  eta: 0:02:17  loss: 0.7584 (1.0974)  labels_encoder: 0.4535 (0.7174)  labels_decoder: 0.3049 (0.3800)  labels_encoder_unscaled: 0.4535 (0.7174)  labels_decoder_unscaled: 0.6097 (0.7599)  time: 0.1265  data: 0.0413  max mem: 3781
Test:  [ 650/1613]  eta: 0:02:10  loss: 1.0042 (1.0958)  labels_encoder: 0.5912 (0.7124)  labels_decoder: 0.4122 (0.3834)  labels_encoder_unscaled: 0.5912 (0.7124)  labels_decoder_unscaled: 0.8243 (0.7667)  time: 0.1333  data: 0.0462  max mem: 3781
Test:  [ 700/1613]  eta: 0:02:03  loss: 0.4994 (1.0678)  labels_encoder: 0.3100 (0.6930)  labels_decoder: 0.1883 (0.3748)  labels_encoder_unscaled: 0.3100 (0.6930)  labels_decoder_unscaled: 0.3765 (0.7496)  time: 0.1470  data: 0.0290  max mem: 3781
Test:  [ 750/1613]  eta: 0:01:56  loss: 0.9221 (1.0432)  labels_encoder: 0.4797 (0.6747)  labels_decoder: 0.3730 (0.3685)  labels_encoder_unscaled: 0.4797 (0.6747)  labels_decoder_unscaled: 0.7461 (0.7370)  time: 0.1287  data: 0.0470  max mem: 3781
Test:  [ 800/1613]  eta: 0:01:48  loss: 0.5638 (1.0382)  labels_encoder: 0.3350 (0.6723)  labels_decoder: 0.2289 (0.3659)  labels_encoder_unscaled: 0.3350 (0.6723)  labels_decoder_unscaled: 0.4578 (0.7319)  time: 0.1139  data: 0.0215  max mem: 3781
Test:  [ 850/1613]  eta: 0:01:41  loss: 0.8768 (1.0424)  labels_encoder: 0.5136 (0.6720)  labels_decoder: 0.3631 (0.3704)  labels_encoder_unscaled: 0.5136 (0.6720)  labels_decoder_unscaled: 0.7263 (0.7409)  time: 0.1068  data: 0.0152  max mem: 3781
Test:  [ 900/1613]  eta: 0:01:33  loss: 0.5785 (1.0212)  labels_encoder: 0.2942 (0.6558)  labels_decoder: 0.2556 (0.3653)  labels_encoder_unscaled: 0.2942 (0.6558)  labels_decoder_unscaled: 0.5112 (0.7307)  time: 0.1112  data: 0.0061  max mem: 3781
Test:  [ 950/1613]  eta: 0:01:26  loss: 1.0885 (1.0205)  labels_encoder: 0.5922 (0.6551)  labels_decoder: 0.3626 (0.3654)  labels_encoder_unscaled: 0.5922 (0.6551)  labels_decoder_unscaled: 0.7252 (0.7308)  time: 0.1169  data: 0.0207  max mem: 3781
Test:  [1000/1613]  eta: 0:01:19  loss: 0.9763 (1.0128)  labels_encoder: 0.5500 (0.6498)  labels_decoder: 0.3090 (0.3629)  labels_encoder_unscaled: 0.5500 (0.6498)  labels_decoder_unscaled: 0.6180 (0.7258)  time: 0.1030  data: 0.0002  max mem: 3781
Test:  [1050/1613]  eta: 0:01:13  loss: 0.9543 (1.0163)  labels_encoder: 0.6055 (0.6538)  labels_decoder: 0.3461 (0.3626)  labels_encoder_unscaled: 0.6055 (0.6538)  labels_decoder_unscaled: 0.6923 (0.7252)  time: 0.1428  data: 0.0210  max mem: 3781
Test:  [1100/1613]  eta: 0:01:06  loss: 0.4521 (1.0200)  labels_encoder: 0.2162 (0.6575)  labels_decoder: 0.2091 (0.3625)  labels_encoder_unscaled: 0.2162 (0.6575)  labels_decoder_unscaled: 0.4181 (0.7249)  time: 0.1223  data: 0.0215  max mem: 3781
Test:  [1150/1613]  eta: 0:00:59  loss: 0.6395 (1.0153)  labels_encoder: 0.3513 (0.6540)  labels_decoder: 0.2882 (0.3613)  labels_encoder_unscaled: 0.3513 (0.6540)  labels_decoder_unscaled: 0.5764 (0.7226)  time: 0.1234  data: 0.0002  max mem: 3781
Test:  [1200/1613]  eta: 0:00:53  loss: 0.4898 (1.0214)  labels_encoder: 0.2270 (0.6578)  labels_decoder: 0.1881 (0.3635)  labels_encoder_unscaled: 0.2270 (0.6578)  labels_decoder_unscaled: 0.3762 (0.7270)  time: 0.1252  data: 0.0123  max mem: 3781
Test:  [1250/1613]  eta: 0:00:46  loss: 0.5161 (1.0205)  labels_encoder: 0.2785 (0.6571)  labels_decoder: 0.2497 (0.3633)  labels_encoder_unscaled: 0.2785 (0.6571)  labels_decoder_unscaled: 0.4993 (0.7266)  time: 0.1265  data: 0.0284  max mem: 3781
Test:  [1300/1613]  eta: 0:00:40  loss: 0.6258 (1.0166)  labels_encoder: 0.3895 (0.6540)  labels_decoder: 0.2638 (0.3626)  labels_encoder_unscaled: 0.3895 (0.6540)  labels_decoder_unscaled: 0.5275 (0.7251)  time: 0.1238  data: 0.0299  max mem: 3781
Test:  [1350/1613]  eta: 0:00:33  loss: 1.1710 (1.0227)  labels_encoder: 0.8026 (0.6597)  labels_decoder: 0.3926 (0.3630)  labels_encoder_unscaled: 0.8026 (0.6597)  labels_decoder_unscaled: 0.7853 (0.7259)  time: 0.1287  data: 0.0256  max mem: 3781
Test:  [1400/1613]  eta: 0:00:27  loss: 0.9653 (1.0286)  labels_encoder: 0.5986 (0.6631)  labels_decoder: 0.3958 (0.3655)  labels_encoder_unscaled: 0.5986 (0.6631)  labels_decoder_unscaled: 0.7916 (0.7310)  time: 0.1348  data: 0.0374  max mem: 3781
Test:  [1450/1613]  eta: 0:00:21  loss: 0.5544 (1.0317)  labels_encoder: 0.3167 (0.6649)  labels_decoder: 0.1863 (0.3668)  labels_encoder_unscaled: 0.3167 (0.6649)  labels_decoder_unscaled: 0.3725 (0.7335)  time: 0.1307  data: 0.0201  max mem: 3781
Test:  [1500/1613]  eta: 0:00:14  loss: 0.5394 (1.0312)  labels_encoder: 0.3596 (0.6648)  labels_decoder: 0.1953 (0.3664)  labels_encoder_unscaled: 0.3596 (0.6648)  labels_decoder_unscaled: 0.3906 (0.7328)  time: 0.1384  data: 0.0492  max mem: 3781
Test:  [1550/1613]  eta: 0:00:08  loss: 0.8740 (1.0308)  labels_encoder: 0.5978 (0.6652)  labels_decoder: 0.2654 (0.3656)  labels_encoder_unscaled: 0.5978 (0.6652)  labels_decoder_unscaled: 0.5308 (0.7312)  time: 0.1384  data: 0.0457  max mem: 3781
Test:  [1600/1613]  eta: 0:00:01  loss: 0.8313 (1.0279)  labels_encoder: 0.4978 (0.6626)  labels_decoder: 0.3114 (0.3653)  labels_encoder_unscaled: 0.4978 (0.6626)  labels_decoder_unscaled: 0.6229 (0.7306)  time: 0.1353  data: 0.0443  max mem: 3781
Test:  [1612/1613]  eta: 0:00:00  loss: 0.5439 (1.0250)  labels_encoder: 0.2595 (0.6609)  labels_decoder: 0.2540 (0.3641)  labels_encoder_unscaled: 0.2595 (0.6609)  labels_decoder_unscaled: 0.5080 (0.7281)  time: 0.1252  data: 0.0452  max mem: 3781
Test: Total time: 0:03:30 (0.1306 s / it)
Averaged stats: loss: 0.5439 (1.0250)  labels_encoder: 0.2595 (0.6609)  labels_decoder: 0.2540 (0.3641)  labels_encoder_unscaled: 0.2595 (0.6609)  labels_decoder_unscaled: 0.5080 (0.7281)
(21, 206375)
(21, 206375)
[Epoch-4] [IDU-kin_audio] mAP: 0.6380

dec_mAP all together: | 0.5158554963329053 |.
dec_mAP_pred | 0 : 0.5656593174449782 |.
dec_mAP_pred | 1 : 0.5571809954162965 |.
dec_mAP_pred | 2 : 0.543554921232442 |.
dec_mAP_pred | 3 : 0.5275053484240274 |.
dec_mAP_pred | 4 : 0.5107380080360319 |.
dec_mAP_pred | 5 : 0.4942464830517606 |.
dec_mAP_pred | 6 : 0.4783382629796703 |.
dec_mAP_pred | 7 : 0.4627123231425198 |.
all decoder map: | 0.5175 |.
BaseballPitch: 0.2946
BasketballDunk: 0.8110
Billiards: 0.3213
CleanAndJerk: 0.7527
CliffDiving: 0.8513
CricketBowling: 0.4567
CricketShot: 0.3021
Diving: 0.8757
FrisbeeCatch: 0.4517
GolfSwing: 0.7758
HammerThrow: 0.8378
HighJump: 0.7819
JavelinThrow: 0.7443
LongJump: 0.7965
PoleVault: 0.8732
Shotput: 0.7162
SoccerPenalty: 0.4321
TennisSwing: 0.6231
ThrowDiscus: 0.6237
VolleyballSpiking: 0.4376
Training time 0:37:04
